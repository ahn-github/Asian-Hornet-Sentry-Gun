--------------------------------------------------------------------------
[[24511,1],0]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:
Module: OpenFabrics (openib)
Host: 59a061f3469e
Another transport will be used instead, although this may result in
lower performance.
NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1130 22:37:37.155977   125 parallel.cpp:44] P2PManager::Init, global rank: [0 of 1] @ 59a061f3469e
I1130 22:37:38.220904   125 caffe.cpp:709] This is NVCaffe 0.17.0 started at Fri Nov 30 22:37:37 2018
I1130 22:37:38.221119   125 caffe.cpp:711] CuDNN version: 7401
I1130 22:37:38.221127   125 caffe.cpp:712] CuBLAS version: 10000
I1130 22:37:38.221129   125 caffe.cpp:713] CUDA version: 10000
I1130 22:37:38.221134   125 caffe.cpp:714] CUDA driver version: 10000
I1130 22:37:38.221143   125 caffe.cpp:715] Arguments:
[0]: /usr/local/bin/caffe
[1]: train
[2]: --solver=/workspace/jobs/20181130-223734-9d03/solver.prototxt
[3]: --gpu=0
[4]: --weights=/workspace/jobs/bvlc_googlenet.caffemodel
I1130 22:37:38.256207   125 upgrade_proto.cpp:1047] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /workspace/jobs/20181130-223734-9d03/solver.prototxt
I1130 22:37:38.256248   125 upgrade_proto.cpp:1054] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W1130 22:37:38.256255   125 upgrade_proto.cpp:1056] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I1130 22:37:38.256402   125 caffe.cpp:220] Using GPUs 0
I1130 22:37:38.471387   125 gpu_memory.cpp:105] GPUMemory::Manager initialized
I1130 22:37:38.471942   125 gpu_memory.cpp:107] Total memory: 16914055168, Free: 15908929536, dev_info[0]: total=16914055168 free=15908929536
I1130 22:37:38.472156   125 caffe.cpp:227] GPU 0: Tesla V100-SXM2-16GB
I1130 22:37:38.474881   125 solver.cpp:40] Solver data type: FLOAT
I1130 22:37:38.608799   125 solver.cpp:43] Initializing solver from parameters:
test_iter: 212
test_interval: 359
base_lr: 2.5e-05
display: 44
max_iter: 35900
lr_policy: "exp"
gamma: 0.999915183
momentum: 0.9
weight_decay: 2.5e-07
snapshot: 3590
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
train_state {
level: 0
stage: ""
}
type: "Adam"
I1130 22:37:38.609375   125 solver.cpp:85] Creating training net from net file: train_val.prototxt
I1130 22:37:38.612287   125 net.cpp:459] The NetState phase (0) differed from the phase (1) specified by a rule in layer val_data
I1130 22:37:38.612304   125 net.cpp:459] The NetState phase (0) differed from the phase (1) specified by a rule in layer val_label
I1130 22:37:38.612314   125 net.cpp:459] The NetState phase (0) differed from the phase (1) specified by a rule in layer val_transform
I1130 22:37:38.612402   125 net.cpp:459] The NetState phase (0) differed from the phase (1) specified by a rule in layer cluster
I1130 22:37:38.612409   125 net.cpp:459] The NetState phase (0) differed from the phase (1) specified by a rule in layer cluster_gt
I1130 22:37:38.612416   125 net.cpp:459] The NetState phase (0) differed from the phase (1) specified by a rule in layer score
I1130 22:37:38.612419   125 net.cpp:459] The NetState phase (0) differed from the phase (1) specified by a rule in layer mAP
I1130 22:37:38.613490   125 net.cpp:83] Initializing net from parameters:
state {
phase: TRAIN
level: 0
stage: ""
}
layer {
name: "train_data"
type: "Data"
top: "data"
include {
phase: TRAIN
}
data_param {
source: "/workspace/jobs/20181130-223152-9c61/train_db/features"
batch_size: 10
backend: LMDB
}
}
layer {
name: "train_label"
type: "Data"
top: "label"
include {
phase: TRAIN
}
data_param {
source: "/workspace/jobs/20181130-223152-9c61/train_db/labels"
batch_size: 10
backend: LMDB
}
}
layer {
name: "train_transform"
type: "DetectNetTransformation"
bottom: "data"
bottom: "label"
top: "transformed_data"
top: "transformed_label"
include {
phase: TRAIN
}
transform_param {
mean_value: 127
}
detectnet_groundtruth_param {
stride: 16
scale_cvg: 0.4
gridbox_type: GRIDBOX_MIN
min_cvg_len: 20
coverage_type: RECTANGULAR
image_size_x: 640
image_size_y: 640
obj_norm: true
crop_bboxes: false
object_class {
src: 1
dst: 0
}
}
detectnet_augmentation_param {
crop_prob: 1
shift_x: 32
shift_y: 32
scale_prob: 0.4
scale_min: 0.8
scale_max: 1.2
flip_prob: 0.5
rotation_prob: 0
max_rotate_degree: 5
hue_rotation_prob: 0.8
hue_rotation: 30
desaturation_prob: 0.8
desaturation_max: 0.8
}
}
layer {
name: "slice-label"
type: "Slice"
bottom: "transformed_label"
top: "foreground-label"
top: "bbox-label"
top: "size-label"
top: "obj-label"
top: "coverage-label"
slice_param {
slice_dim: 1
slice_point: 1
slice_point: 5
slice_point: 7
slice_point: 8
}
}
layer {
name: "coverage-block"
type: "Concat"
bottom: "foreground-label"
bottom: "foreground-label"
bottom: "foreground-label"
bottom: "foreground-label"
top: "coverage-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "size-block"
type: "Concat"
bottom: "size-label"
bottom: "size-label"
top: "size-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "obj-block"
type: "Concat"
bottom: "obj-label"
bottom: "obj-label"
bottom: "obj-label"
bottom: "obj-label"
top: "obj-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "bb-label-norm"
type: "Eltwise"
bottom: "bbox-label"
bottom: "size-block"
top: "bbox-label-norm"
eltwise_param {
operation: PROD
}
}
layer {
name: "bb-obj-norm"
type: "Eltwise"
bottom: "bbox-label-norm"
bottom: "obj-block"
top: "bbox-obj-label-norm"
eltwise_param {
operation: PROD
}
}
layer {
name: "conv1/7x7_s2"
type: "Convolution"
bottom: "transformed_data"
top: "conv1/7x7_s2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 3
kernel_size: 7
stride: 2
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv1/relu_7x7"
type: "ReLU"
bottom: "conv1/7x7_s2"
top: "conv1/7x7_s2"
}
layer {
name: "pool1/3x3_s2"
type: "Pooling"
bottom: "conv1/7x7_s2"
top: "pool1/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "pool1/norm1"
type: "LRN"
bottom: "pool1/3x3_s2"
top: "pool1/norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "conv2/3x3_reduce"
type: "Convolution"
bottom: "pool1/norm1"
top: "conv2/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv2/relu_3x3_reduce"
type: "ReLU"
bottom: "conv2/3x3_reduce"
top: "conv2/3x3_reduce"
}
layer {
name: "conv2/3x3"
type: "Convolution"
bottom: "conv2/3x3_reduce"
top: "conv2/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv2/relu_3x3"
type: "ReLU"
bottom: "conv2/3x3"
top: "conv2/3x3"
}
layer {
name: "conv2/norm2"
type: "LRN"
bottom: "conv2/3x3"
top: "conv2/norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2/3x3_s2"
type: "Pooling"
bottom: "conv2/norm2"
top: "pool2/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "inception_3a/1x1"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_1x1"
type: "ReLU"
bottom: "inception_3a/1x1"
top: "inception_3a/1x1"
}
layer {
name: "inception_3a/3x3_reduce"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_3a/3x3_reduce"
top: "inception_3a/3x3_reduce"
}
layer {
name: "inception_3a/3x3"
type: "Convolution"
bottom: "inception_3a/3x3_reduce"
top: "inception_3a/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_3x3"
type: "ReLU"
bottom: "inception_3a/3x3"
top: "inception_3a/3x3"
}
layer {
name: "inception_3a/5x5_reduce"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_3a/5x5_reduce"
top: "inception_3a/5x5_reduce"
}
layer {
name: "inception_3a/5x5"
type: "Convolution"
bottom: "inception_3a/5x5_reduce"
top: "inception_3a/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_5x5"
type: "ReLU"
bottom: "inception_3a/5x5"
top: "inception_3a/5x5"
}
layer {
name: "inception_3a/pool"
type: "Pooling"
bottom: "pool2/3x3_s2"
top: "inception_3a/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_3a/pool_proj"
type: "Convolution"
bottom: "inception_3a/pool"
top: "inception_3a/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_pool_proj"
type: "ReLU"
bottom: "inception_3a/pool_proj"
top: "inception_3a/pool_proj"
}
layer {
name: "inception_3a/output"
type: "Concat"
bottom: "inception_3a/1x1"
bottom: "inception_3a/3x3"
bottom: "inception_3a/5x5"
bottom: "inception_3a/pool_proj"
top: "inception_3a/output"
}
layer {
name: "inception_3b/1x1"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_1x1"
type: "ReLU"
bottom: "inception_3b/1x1"
top: "inception_3b/1x1"
}
layer {
name: "inception_3b/3x3_reduce"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_3b/3x3_reduce"
top: "inception_3b/3x3_reduce"
}
layer {
name: "inception_3b/3x3"
type: "Convolution"
bottom: "inception_3b/3x3_reduce"
top: "inception_3b/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_3x3"
type: "ReLU"
bottom: "inception_3b/3x3"
top: "inception_3b/3x3"
}
layer {
name: "inception_3b/5x5_reduce"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_3b/5x5_reduce"
top: "inception_3b/5x5_reduce"
}
layer {
name: "inception_3b/5x5"
type: "Convolution"
bottom: "inception_3b/5x5_reduce"
top: "inception_3b/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_5x5"
type: "ReLU"
bottom: "inception_3b/5x5"
top: "inception_3b/5x5"
}
layer {
name: "inception_3b/pool"
type: "Pooling"
bottom: "inception_3a/output"
top: "inception_3b/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_3b/pool_proj"
type: "Convolution"
bottom: "inception_3b/pool"
top: "inception_3b/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_pool_proj"
type: "ReLU"
bottom: "inception_3b/pool_proj"
top: "inception_3b/pool_proj"
}
layer {
name: "inception_3b/output"
type: "Concat"
bottom: "inception_3b/1x1"
bottom: "inception_3b/3x3"
bottom: "inception_3b/5x5"
bottom: "inception_3b/pool_proj"
top: "inception_3b/output"
}
layer {
name: "pool3/3x3_s2"
type: "Pooling"
bottom: "inception_3b/output"
top: "pool3/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "inception_4a/1x1"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_1x1"
type: "ReLU"
bottom: "inception_4a/1x1"
top: "inception_4a/1x1"
}
layer {
name: "inception_4a/3x3_reduce"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4a/3x3_reduce"
top: "inception_4a/3x3_reduce"
}
layer {
name: "inception_4a/3x3"
type: "Convolution"
bottom: "inception_4a/3x3_reduce"
top: "inception_4a/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 208
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_3x3"
type: "ReLU"
bottom: "inception_4a/3x3"
top: "inception_4a/3x3"
}
layer {
name: "inception_4a/5x5_reduce"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4a/5x5_reduce"
top: "inception_4a/5x5_reduce"
}
layer {
name: "inception_4a/5x5"
type: "Convolution"
bottom: "inception_4a/5x5_reduce"
top: "inception_4a/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 48
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_5x5"
type: "ReLU"
bottom: "inception_4a/5x5"
top: "inception_4a/5x5"
}
layer {
name: "inception_4a/pool"
type: "Pooling"
bottom: "pool3/3x3_s2"
top: "inception_4a/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4a/pool_proj"
type: "Convolution"
bottom: "inception_4a/pool"
top: "inception_4a/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_pool_proj"
type: "ReLU"
bottom: "inception_4a/pool_proj"
top: "inception_4a/pool_proj"
}
layer {
name: "inception_4a/output"
type: "Concat"
bottom: "inception_4a/1x1"
bottom: "inception_4a/3x3"
bottom: "inception_4a/5x5"
bottom: "inception_4a/pool_proj"
top: "inception_4a/output"
}
layer {
name: "inception_4b/1x1"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 160
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_1x1"
type: "ReLU"
bottom: "inception_4b/1x1"
top: "inception_4b/1x1"
}
layer {
name: "inception_4b/3x3_reduce"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 112
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4b/3x3_reduce"
top: "inception_4b/3x3_reduce"
}
layer {
name: "inception_4b/3x3"
type: "Convolution"
bottom: "inception_4b/3x3_reduce"
top: "inception_4b/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 224
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_3x3"
type: "ReLU"
bottom: "inception_4b/3x3"
top: "inception_4b/3x3"
}
layer {
name: "inception_4b/5x5_reduce"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 24
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4b/5x5_reduce"
top: "inception_4b/5x5_reduce"
}
layer {
name: "inception_4b/5x5"
type: "Convolution"
bottom: "inception_4b/5x5_reduce"
top: "inception_4b/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_5x5"
type: "ReLU"
bottom: "inception_4b/5x5"
top: "inception_4b/5x5"
}
layer {
name: "inception_4b/pool"
type: "Pooling"
bottom: "inception_4a/output"
top: "inception_4b/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4b/pool_proj"
type: "Convolution"
bottom: "inception_4b/pool"
top: "inception_4b/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_pool_proj"
type: "ReLU"
bottom: "inception_4b/pool_proj"
top: "inception_4b/pool_proj"
}
layer {
name: "inception_4b/output"
type: "Concat"
bottom: "inception_4b/1x1"
bottom: "inception_4b/3x3"
bottom: "inception_4b/5x5"
bottom: "inception_4b/pool_proj"
top: "inception_4b/output"
}
layer {
name: "inception_4c/1x1"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_1x1"
type: "ReLU"
bottom: "inception_4c/1x1"
top: "inception_4c/1x1"
}
layer {
name: "inception_4c/3x3_reduce"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4c/3x3_reduce"
top: "inception_4c/3x3_reduce"
}
layer {
name: "inception_4c/3x3"
type: "Convolution"
bottom: "inception_4c/3x3_reduce"
top: "inception_4c/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_3x3"
type: "ReLU"
bottom: "inception_4c/3x3"
top: "inception_4c/3x3"
}
layer {
name: "inception_4c/5x5_reduce"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 24
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4c/5x5_reduce"
top: "inception_4c/5x5_reduce"
}
layer {
name: "inception_4c/5x5"
type: "Convolution"
bottom: "inception_4c/5x5_reduce"
top: "inception_4c/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_5x5"
type: "ReLU"
bottom: "inception_4c/5x5"
top: "inception_4c/5x5"
}
layer {
name: "inception_4c/pool"
type: "Pooling"
bottom: "inception_4b/output"
top: "inception_4c/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4c/pool_proj"
type: "Convolution"
bottom: "inception_4c/pool"
top: "inception_4c/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_pool_proj"
type: "ReLU"
bottom: "inception_4c/pool_proj"
top: "inception_4c/pool_proj"
}
layer {
name: "inception_4c/output"
type: "Concat"
bottom: "inception_4c/1x1"
bottom: "inception_4c/3x3"
bottom: "inception_4c/5x5"
bottom: "inception_4c/pool_proj"
top: "inception_4c/output"
}
layer {
name: "inception_4d/1x1"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 112
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_1x1"
type: "ReLU"
bottom: "inception_4d/1x1"
top: "inception_4d/1x1"
}
layer {
name: "inception_4d/3x3_reduce"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 144
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4d/3x3_reduce"
top: "inception_4d/3x3_reduce"
}
layer {
name: "inception_4d/3x3"
type: "Convolution"
bottom: "inception_4d/3x3_reduce"
top: "inception_4d/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 288
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_3x3"
type: "ReLU"
bottom: "inception_4d/3x3"
top: "inception_4d/3x3"
}
layer {
name: "inception_4d/5x5_reduce"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4d/5x5_reduce"
top: "inception_4d/5x5_reduce"
}
layer {
name: "inception_4d/5x5"
type: "Convolution"
bottom: "inception_4d/5x5_reduce"
top: "inception_4d/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_5x5"
type: "ReLU"
bottom: "inception_4d/5x5"
top: "inception_4d/5x5"
}
layer {
name: "inception_4d/pool"
type: "Pooling"
bottom: "inception_4c/output"
top: "inception_4d/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4d/pool_proj"
type: "Convolution"
bottom: "inception_4d/pool"
top: "inception_4d/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_pool_proj"
type: "ReLU"
bottom: "inception_4d/pool_proj"
top: "inception_4d/pool_proj"
}
layer {
name: "inception_4d/output"
type: "Concat"
bottom: "inception_4d/1x1"
bottom: "inception_4d/3x3"
bottom: "inception_4d/5x5"
bottom: "inception_4d/pool_proj"
top: "inception_4d/output"
}
layer {
name: "inception_4e/1x1"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_1x1"
type: "ReLU"
bottom: "inception_4e/1x1"
top: "inception_4e/1x1"
}
layer {
name: "inception_4e/3x3_reduce"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 160
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4e/3x3_reduce"
top: "inception_4e/3x3_reduce"
}
layer {
name: "inception_4e/3x3"
type: "Convolution"
bottom: "inception_4e/3x3_reduce"
top: "inception_4e/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 320
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_3x3"
type: "ReLU"
bottom: "inception_4e/3x3"
top: "inception_4e/3x3"
}
layer {
name: "inception_4e/5x5_reduce"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4e/5x5_reduce"
top: "inception_4e/5x5_reduce"
}
layer {
name: "inception_4e/5x5"
type: "Convolution"
bottom: "inception_4e/5x5_reduce"
top: "inception_4e/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_5x5"
type: "ReLU"
bottom: "inception_4e/5x5"
top: "inception_4e/5x5"
}
layer {
name: "inception_4e/pool"
type: "Pooling"
bottom: "inception_4d/output"
top: "inception_4e/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4e/pool_proj"
type: "Convolution"
bottom: "inception_4e/pool"
top: "inception_4e/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_pool_proj"
type: "ReLU"
bottom: "inception_4e/pool_proj"
top: "inception_4e/pool_proj"
}
layer {
name: "in
I1130 22:37:38.614370   125 net.cpp:113] Using FLOAT as default forward math type
I1130 22:37:38.614387   125 net.cpp:119] Using FLOAT as default backward math type
I1130 22:37:38.614397   125 layer_factory.hpp:172] Creating layer 'train_data' of type 'Data'
I1130 22:37:38.614408   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.618600   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:38.619323   125 net.cpp:202] Created Layer train_data (0)
I1130 22:37:38.619333   125 net.cpp:544] train_data -> data
I1130 22:37:38.619419   125 data_reader.cpp:59] Sample Data Reader threads: 1, out queues: 1, depth: 10
I1130 22:37:38.620082   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:38.620093   142 blocking_queue.cpp:40] Data layer prefetch queue empty
I1130 22:37:38.621294   143 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/train_db/features
I1130 22:37:38.643405   125 data_layer.cpp:200] [n0.d0.r0] Output data size: 10, 3, 640, 640
I1130 22:37:38.643445   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:38.644124   125 net.cpp:262] Setting up train_data
I1130 22:37:38.644145   125 net.cpp:269] TRAIN Top shape for layer 0 'train_data' 10 3 640 640 (12288000)
I1130 22:37:38.644796   125 layer_factory.hpp:172] Creating layer 'train_label' of type 'Data'
I1130 22:37:38.644809   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.644842   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:38.644904   125 net.cpp:202] Created Layer train_label (1)
I1130 22:37:38.644912   125 net.cpp:544] train_label -> label
I1130 22:37:38.644927   125 data_reader.cpp:59] Sample Data Reader threads: 1, out queues: 1, depth: 10
I1130 22:37:38.644942   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:38.648638   146 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/train_db/labels
I1130 22:37:38.648836   125 data_layer.cpp:200] [n0.d0.r0] Output data size: 10, 1, 57, 16
I1130 22:37:38.649230   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:38.649893   125 net.cpp:262] Setting up train_label
I1130 22:37:38.649905   125 net.cpp:269] TRAIN Top shape for layer 1 'train_label' 10 1 57 16 (9120)
I1130 22:37:38.649912   125 layer_factory.hpp:172] Creating layer 'train_transform' of type 'DetectNetTransformation'
I1130 22:37:38.649921   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.651103   125 net.cpp:202] Created Layer train_transform (2)
I1130 22:37:38.651118   125 net.cpp:574] train_transform <- data
I1130 22:37:38.651131   125 net.cpp:574] train_transform <- label
I1130 22:37:38.651139   125 net.cpp:544] train_transform -> transformed_data
I1130 22:37:38.651149   125 net.cpp:544] train_transform -> transformed_label
I1130 22:37:38.651510   125 net.cpp:262] Setting up train_transform
I1130 22:37:38.651525   125 net.cpp:269] TRAIN Top shape for layer 2 'train_transform' 10 3 640 640 (12288000)
I1130 22:37:38.651532   125 net.cpp:269] TRAIN Top shape for layer 2 'train_transform' 10 9 40 40 (144000)
I1130 22:37:38.651540   125 layer_factory.hpp:172] Creating layer 'slice-label' of type 'Slice'
I1130 22:37:38.651546   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.651559   125 net.cpp:202] Created Layer slice-label (3)
I1130 22:37:38.651566   125 net.cpp:574] slice-label <- transformed_label
I1130 22:37:38.651572   125 net.cpp:544] slice-label -> foreground-label
I1130 22:37:38.651582   125 net.cpp:544] slice-label -> bbox-label
I1130 22:37:38.651588   125 net.cpp:544] slice-label -> size-label
I1130 22:37:38.651594   125 net.cpp:544] slice-label -> obj-label
I1130 22:37:38.651602   125 net.cpp:544] slice-label -> coverage-label
I1130 22:37:38.651671   125 net.cpp:262] Setting up slice-label
I1130 22:37:38.651696   125 net.cpp:269] TRAIN Top shape for layer 3 'slice-label' 10 1 40 40 (16000)
I1130 22:37:38.651703   125 net.cpp:269] TRAIN Top shape for layer 3 'slice-label' 10 4 40 40 (64000)
I1130 22:37:38.651710   125 net.cpp:269] TRAIN Top shape for layer 3 'slice-label' 10 2 40 40 (32000)
I1130 22:37:38.651715   125 net.cpp:269] TRAIN Top shape for layer 3 'slice-label' 10 1 40 40 (16000)
I1130 22:37:38.651721   125 net.cpp:269] TRAIN Top shape for layer 3 'slice-label' 10 1 40 40 (16000)
I1130 22:37:38.651727   125 layer_factory.hpp:172] Creating layer 'foreground-label_slice-label_0_split' of type 'Split'
I1130 22:37:38.651733   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.651744   125 net.cpp:202] Created Layer foreground-label_slice-label_0_split (4)
I1130 22:37:38.651749   125 net.cpp:574] foreground-label_slice-label_0_split <- foreground-label
I1130 22:37:38.651757   125 net.cpp:544] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_0
I1130 22:37:38.651765   125 net.cpp:544] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_1
I1130 22:37:38.651772   125 net.cpp:544] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_2
I1130 22:37:38.651778   125 net.cpp:544] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_3
I1130 22:37:38.651835   125 net.cpp:262] Setting up foreground-label_slice-label_0_split
I1130 22:37:38.651844   125 net.cpp:269] TRAIN Top shape for layer 4 'foreground-label_slice-label_0_split' 10 1 40 40 (16000)
I1130 22:37:38.651849   125 net.cpp:269] TRAIN Top shape for layer 4 'foreground-label_slice-label_0_split' 10 1 40 40 (16000)
I1130 22:37:38.651855   125 net.cpp:269] TRAIN Top shape for layer 4 'foreground-label_slice-label_0_split' 10 1 40 40 (16000)
I1130 22:37:38.651861   125 net.cpp:269] TRAIN Top shape for layer 4 'foreground-label_slice-label_0_split' 10 1 40 40 (16000)
I1130 22:37:38.651868   125 layer_factory.hpp:172] Creating layer 'size-label_slice-label_2_split' of type 'Split'
I1130 22:37:38.651873   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.651880   125 net.cpp:202] Created Layer size-label_slice-label_2_split (5)
I1130 22:37:38.651886   125 net.cpp:574] size-label_slice-label_2_split <- size-label
I1130 22:37:38.651893   125 net.cpp:544] size-label_slice-label_2_split -> size-label_slice-label_2_split_0
I1130 22:37:38.651901   125 net.cpp:544] size-label_slice-label_2_split -> size-label_slice-label_2_split_1
I1130 22:37:38.651963   125 net.cpp:262] Setting up size-label_slice-label_2_split
I1130 22:37:38.651973   125 net.cpp:269] TRAIN Top shape for layer 5 'size-label_slice-label_2_split' 10 2 40 40 (32000)
I1130 22:37:38.651980   125 net.cpp:269] TRAIN Top shape for layer 5 'size-label_slice-label_2_split' 10 2 40 40 (32000)
I1130 22:37:38.651986   125 layer_factory.hpp:172] Creating layer 'obj-label_slice-label_3_split' of type 'Split'
I1130 22:37:38.651993   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.652000   125 net.cpp:202] Created Layer obj-label_slice-label_3_split (6)
I1130 22:37:38.652006   125 net.cpp:574] obj-label_slice-label_3_split <- obj-label
I1130 22:37:38.652012   125 net.cpp:544] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_0
I1130 22:37:38.652020   125 net.cpp:544] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_1
I1130 22:37:38.652029   125 net.cpp:544] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_2
I1130 22:37:38.652037   125 net.cpp:544] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_3
I1130 22:37:38.652086   125 net.cpp:262] Setting up obj-label_slice-label_3_split
I1130 22:37:38.652093   125 net.cpp:269] TRAIN Top shape for layer 6 'obj-label_slice-label_3_split' 10 1 40 40 (16000)
I1130 22:37:38.652101   125 net.cpp:269] TRAIN Top shape for layer 6 'obj-label_slice-label_3_split' 10 1 40 40 (16000)
I1130 22:37:38.652118   125 net.cpp:269] TRAIN Top shape for layer 6 'obj-label_slice-label_3_split' 10 1 40 40 (16000)
I1130 22:37:38.652124   125 net.cpp:269] TRAIN Top shape for layer 6 'obj-label_slice-label_3_split' 10 1 40 40 (16000)
I1130 22:37:38.652129   125 layer_factory.hpp:172] Creating layer 'coverage-block' of type 'Concat'
I1130 22:37:38.652137   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.652148   125 net.cpp:202] Created Layer coverage-block (7)
I1130 22:37:38.652153   125 net.cpp:574] coverage-block <- foreground-label_slice-label_0_split_0
I1130 22:37:38.652160   125 net.cpp:574] coverage-block <- foreground-label_slice-label_0_split_1
I1130 22:37:38.652166   125 net.cpp:574] coverage-block <- foreground-label_slice-label_0_split_2
I1130 22:37:38.652173   125 net.cpp:574] coverage-block <- foreground-label_slice-label_0_split_3
I1130 22:37:38.652179   125 net.cpp:544] coverage-block -> coverage-block
I1130 22:37:38.652201   125 net.cpp:262] Setting up coverage-block
I1130 22:37:38.652209   125 net.cpp:269] TRAIN Top shape for layer 7 'coverage-block' 10 4 40 40 (64000)
I1130 22:37:38.652215   125 layer_factory.hpp:172] Creating layer 'size-block' of type 'Concat'
I1130 22:37:38.652220   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.652228   125 net.cpp:202] Created Layer size-block (8)
I1130 22:37:38.652235   125 net.cpp:574] size-block <- size-label_slice-label_2_split_0
I1130 22:37:38.652240   125 net.cpp:574] size-block <- size-label_slice-label_2_split_1
I1130 22:37:38.652246   125 net.cpp:544] size-block -> size-block
I1130 22:37:38.652264   125 net.cpp:262] Setting up size-block
I1130 22:37:38.652272   125 net.cpp:269] TRAIN Top shape for layer 8 'size-block' 10 4 40 40 (64000)
I1130 22:37:38.652278   125 layer_factory.hpp:172] Creating layer 'size-block_size-block_0_split' of type 'Split'
I1130 22:37:38.652284   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.652292   125 net.cpp:202] Created Layer size-block_size-block_0_split (9)
I1130 22:37:38.652297   125 net.cpp:574] size-block_size-block_0_split <- size-block
I1130 22:37:38.652303   125 net.cpp:544] size-block_size-block_0_split -> size-block_size-block_0_split_0
I1130 22:37:38.652310   125 net.cpp:544] size-block_size-block_0_split -> size-block_size-block_0_split_1
I1130 22:37:38.652338   125 net.cpp:262] Setting up size-block_size-block_0_split
I1130 22:37:38.652346   125 net.cpp:269] TRAIN Top shape for layer 9 'size-block_size-block_0_split' 10 4 40 40 (64000)
I1130 22:37:38.652353   125 net.cpp:269] TRAIN Top shape for layer 9 'size-block_size-block_0_split' 10 4 40 40 (64000)
I1130 22:37:38.652359   125 layer_factory.hpp:172] Creating layer 'obj-block' of type 'Concat'
I1130 22:37:38.652364   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.652372   125 net.cpp:202] Created Layer obj-block (10)
I1130 22:37:38.652377   125 net.cpp:574] obj-block <- obj-label_slice-label_3_split_0
I1130 22:37:38.652384   125 net.cpp:574] obj-block <- obj-label_slice-label_3_split_1
I1130 22:37:38.652390   125 net.cpp:574] obj-block <- obj-label_slice-label_3_split_2
I1130 22:37:38.652395   125 net.cpp:574] obj-block <- obj-label_slice-label_3_split_3
I1130 22:37:38.652401   125 net.cpp:544] obj-block -> obj-block
I1130 22:37:38.652420   125 net.cpp:262] Setting up obj-block
I1130 22:37:38.652426   125 net.cpp:269] TRAIN Top shape for layer 10 'obj-block' 10 4 40 40 (64000)
I1130 22:37:38.652432   125 layer_factory.hpp:172] Creating layer 'obj-block_obj-block_0_split' of type 'Split'
I1130 22:37:38.652438   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.652446   125 net.cpp:202] Created Layer obj-block_obj-block_0_split (11)
I1130 22:37:38.652451   125 net.cpp:574] obj-block_obj-block_0_split <- obj-block
I1130 22:37:38.652467   125 net.cpp:544] obj-block_obj-block_0_split -> obj-block_obj-block_0_split_0
I1130 22:37:38.652474   125 net.cpp:544] obj-block_obj-block_0_split -> obj-block_obj-block_0_split_1
I1130 22:37:38.652504   125 net.cpp:262] Setting up obj-block_obj-block_0_split
I1130 22:37:38.652511   125 net.cpp:269] TRAIN Top shape for layer 11 'obj-block_obj-block_0_split' 10 4 40 40 (64000)
I1130 22:37:38.652518   125 net.cpp:269] TRAIN Top shape for layer 11 'obj-block_obj-block_0_split' 10 4 40 40 (64000)
I1130 22:37:38.652524   125 layer_factory.hpp:172] Creating layer 'bb-label-norm' of type 'Eltwise'
I1130 22:37:38.652529   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.652544   125 net.cpp:202] Created Layer bb-label-norm (12)
I1130 22:37:38.652549   125 net.cpp:574] bb-label-norm <- bbox-label
I1130 22:37:38.652555   125 net.cpp:574] bb-label-norm <- size-block_size-block_0_split_0
I1130 22:37:38.652561   125 net.cpp:544] bb-label-norm -> bbox-label-norm
I1130 22:37:38.653570   125 net.cpp:262] Setting up bb-label-norm
I1130 22:37:38.653582   125 net.cpp:269] TRAIN Top shape for layer 12 'bb-label-norm' 10 4 40 40 (64000)
I1130 22:37:38.653589   125 layer_factory.hpp:172] Creating layer 'bb-obj-norm' of type 'Eltwise'
I1130 22:37:38.653595   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.653604   125 net.cpp:202] Created Layer bb-obj-norm (13)
I1130 22:37:38.653609   125 net.cpp:574] bb-obj-norm <- bbox-label-norm
I1130 22:37:38.653616   125 net.cpp:574] bb-obj-norm <- obj-block_obj-block_0_split_0
I1130 22:37:38.653622   125 net.cpp:544] bb-obj-norm -> bbox-obj-label-norm
I1130 22:37:38.653645   125 net.cpp:262] Setting up bb-obj-norm
I1130 22:37:38.653651   125 net.cpp:269] TRAIN Top shape for layer 13 'bb-obj-norm' 10 4 40 40 (64000)
I1130 22:37:38.653658   125 layer_factory.hpp:172] Creating layer 'conv1/7x7_s2' of type 'Convolution'
I1130 22:37:38.653663   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:38.653688   125 net.cpp:202] Created Layer conv1/7x7_s2 (14)
I1130 22:37:38.653694   125 net.cpp:574] conv1/7x7_s2 <- transformed_data
I1130 22:37:38.653700   125 net.cpp:544] conv1/7x7_s2 -> conv1/7x7_s2
I1130 22:37:41.927070   125 net.cpp:262] Setting up conv1/7x7_s2
I1130 22:37:41.927116   125 net.cpp:269] TRAIN Top shape for layer 14 'conv1/7x7_s2' 10 64 320 320 (65536000)
I1130 22:37:41.927160   125 layer_factory.hpp:172] Creating layer 'conv1/relu_7x7' of type 'ReLU'
I1130 22:37:41.927170   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.927191   125 net.cpp:202] Created Layer conv1/relu_7x7 (15)
I1130 22:37:41.927219   125 net.cpp:574] conv1/relu_7x7 <- conv1/7x7_s2
I1130 22:37:41.927230   125 net.cpp:529] conv1/relu_7x7 -> conv1/7x7_s2 (in-place)
I1130 22:37:41.927256   125 net.cpp:262] Setting up conv1/relu_7x7
I1130 22:37:41.927263   125 net.cpp:269] TRAIN Top shape for layer 15 'conv1/relu_7x7' 10 64 320 320 (65536000)
I1130 22:37:41.927269   125 layer_factory.hpp:172] Creating layer 'pool1/3x3_s2' of type 'Pooling'
I1130 22:37:41.927275   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.928208   125 net.cpp:202] Created Layer pool1/3x3_s2 (16)
I1130 22:37:41.928218   125 net.cpp:574] pool1/3x3_s2 <- conv1/7x7_s2
I1130 22:37:41.928225   125 net.cpp:544] pool1/3x3_s2 -> pool1/3x3_s2
I1130 22:37:41.928333   125 net.cpp:262] Setting up pool1/3x3_s2
I1130 22:37:41.928344   125 net.cpp:269] TRAIN Top shape for layer 16 'pool1/3x3_s2' 10 64 160 160 (16384000)
I1130 22:37:41.928349   125 layer_factory.hpp:172] Creating layer 'pool1/norm1' of type 'LRN'
I1130 22:37:41.928356   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.928375   125 net.cpp:202] Created Layer pool1/norm1 (17)
I1130 22:37:41.928380   125 net.cpp:574] pool1/norm1 <- pool1/3x3_s2
I1130 22:37:41.928411   125 net.cpp:544] pool1/norm1 -> pool1/norm1
I1130 22:37:41.928478   125 net.cpp:262] Setting up pool1/norm1
I1130 22:37:41.928488   125 net.cpp:269] TRAIN Top shape for layer 17 'pool1/norm1' 10 64 160 160 (16384000)
I1130 22:37:41.928494   125 layer_factory.hpp:172] Creating layer 'conv2/3x3_reduce' of type 'Convolution'
I1130 22:37:41.928500   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.928519   125 net.cpp:202] Created Layer conv2/3x3_reduce (18)
I1130 22:37:41.928525   125 net.cpp:574] conv2/3x3_reduce <- pool1/norm1
I1130 22:37:41.928532   125 net.cpp:544] conv2/3x3_reduce -> conv2/3x3_reduce
I1130 22:37:41.931407   125 net.cpp:262] Setting up conv2/3x3_reduce
I1130 22:37:41.931423   125 net.cpp:269] TRAIN Top shape for layer 18 'conv2/3x3_reduce' 10 64 160 160 (16384000)
I1130 22:37:41.931437   125 layer_factory.hpp:172] Creating layer 'conv2/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:41.931442   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.931452   125 net.cpp:202] Created Layer conv2/relu_3x3_reduce (19)
I1130 22:37:41.931458   125 net.cpp:574] conv2/relu_3x3_reduce <- conv2/3x3_reduce
I1130 22:37:41.931465   125 net.cpp:529] conv2/relu_3x3_reduce -> conv2/3x3_reduce (in-place)
I1130 22:37:41.931476   125 net.cpp:262] Setting up conv2/relu_3x3_reduce
I1130 22:37:41.931483   125 net.cpp:269] TRAIN Top shape for layer 19 'conv2/relu_3x3_reduce' 10 64 160 160 (16384000)
I1130 22:37:41.931489   125 layer_factory.hpp:172] Creating layer 'conv2/3x3' of type 'Convolution'
I1130 22:37:41.931495   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.931514   125 net.cpp:202] Created Layer conv2/3x3 (20)
I1130 22:37:41.931519   125 net.cpp:574] conv2/3x3 <- conv2/3x3_reduce
I1130 22:37:41.931524   125 net.cpp:544] conv2/3x3 -> conv2/3x3
I1130 22:37:41.934115   125 net.cpp:262] Setting up conv2/3x3
I1130 22:37:41.934131   125 net.cpp:269] TRAIN Top shape for layer 20 'conv2/3x3' 10 192 160 160 (49152000)
I1130 22:37:41.934142   125 layer_factory.hpp:172] Creating layer 'conv2/relu_3x3' of type 'ReLU'
I1130 22:37:41.934149   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.934159   125 net.cpp:202] Created Layer conv2/relu_3x3 (21)
I1130 22:37:41.934165   125 net.cpp:574] conv2/relu_3x3 <- conv2/3x3
I1130 22:37:41.934171   125 net.cpp:529] conv2/relu_3x3 -> conv2/3x3 (in-place)
I1130 22:37:41.934180   125 net.cpp:262] Setting up conv2/relu_3x3
I1130 22:37:41.934186   125 net.cpp:269] TRAIN Top shape for layer 21 'conv2/relu_3x3' 10 192 160 160 (49152000)
I1130 22:37:41.934193   125 layer_factory.hpp:172] Creating layer 'conv2/norm2' of type 'LRN'
I1130 22:37:41.934198   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.934211   125 net.cpp:202] Created Layer conv2/norm2 (22)
I1130 22:37:41.934216   125 net.cpp:574] conv2/norm2 <- conv2/3x3
I1130 22:37:41.934222   125 net.cpp:544] conv2/norm2 -> conv2/norm2
I1130 22:37:41.934275   125 net.cpp:262] Setting up conv2/norm2
I1130 22:37:41.934284   125 net.cpp:269] TRAIN Top shape for layer 22 'conv2/norm2' 10 192 160 160 (49152000)
I1130 22:37:41.934291   125 layer_factory.hpp:172] Creating layer 'pool2/3x3_s2' of type 'Pooling'
I1130 22:37:41.934298   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.934307   125 net.cpp:202] Created Layer pool2/3x3_s2 (23)
I1130 22:37:41.934312   125 net.cpp:574] pool2/3x3_s2 <- conv2/norm2
I1130 22:37:41.934319   125 net.cpp:544] pool2/3x3_s2 -> pool2/3x3_s2
I1130 22:37:41.934382   125 net.cpp:262] Setting up pool2/3x3_s2
I1130 22:37:41.934391   125 net.cpp:269] TRAIN Top shape for layer 23 'pool2/3x3_s2' 10 192 80 80 (12288000)
I1130 22:37:41.934396   125 layer_factory.hpp:172] Creating layer 'pool2/3x3_s2_pool2/3x3_s2_0_split' of type 'Split'
I1130 22:37:41.934402   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.934427   125 net.cpp:202] Created Layer pool2/3x3_s2_pool2/3x3_s2_0_split (24)
I1130 22:37:41.934432   125 net.cpp:574] pool2/3x3_s2_pool2/3x3_s2_0_split <- pool2/3x3_s2
I1130 22:37:41.934439   125 net.cpp:544] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_0
I1130 22:37:41.934448   125 net.cpp:544] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_1
I1130 22:37:41.934456   125 net.cpp:544] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_2
I1130 22:37:41.934463   125 net.cpp:544] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_3
I1130 22:37:41.934538   125 net.cpp:262] Setting up pool2/3x3_s2_pool2/3x3_s2_0_split
I1130 22:37:41.934546   125 net.cpp:269] TRAIN Top shape for layer 24 'pool2/3x3_s2_pool2/3x3_s2_0_split' 10 192 80 80 (12288000)
I1130 22:37:41.934553   125 net.cpp:269] TRAIN Top shape for layer 24 'pool2/3x3_s2_pool2/3x3_s2_0_split' 10 192 80 80 (12288000)
I1130 22:37:41.934559   125 net.cpp:269] TRAIN Top shape for layer 24 'pool2/3x3_s2_pool2/3x3_s2_0_split' 10 192 80 80 (12288000)
I1130 22:37:41.934566   125 net.cpp:269] TRAIN Top shape for layer 24 'pool2/3x3_s2_pool2/3x3_s2_0_split' 10 192 80 80 (12288000)
I1130 22:37:41.934571   125 layer_factory.hpp:172] Creating layer 'inception_3a/1x1' of type 'Convolution'
I1130 22:37:41.934577   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.934593   125 net.cpp:202] Created Layer inception_3a/1x1 (25)
I1130 22:37:41.934598   125 net.cpp:574] inception_3a/1x1 <- pool2/3x3_s2_pool2/3x3_s2_0_split_0
I1130 22:37:41.934605   125 net.cpp:544] inception_3a/1x1 -> inception_3a/1x1
I1130 22:37:41.935111   125 net.cpp:262] Setting up inception_3a/1x1
I1130 22:37:41.935122   125 net.cpp:269] TRAIN Top shape for layer 25 'inception_3a/1x1' 10 64 80 80 (4096000)
I1130 22:37:41.935132   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_1x1' of type 'ReLU'
I1130 22:37:41.935138   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.935148   125 net.cpp:202] Created Layer inception_3a/relu_1x1 (26)
I1130 22:37:41.935153   125 net.cpp:574] inception_3a/relu_1x1 <- inception_3a/1x1
I1130 22:37:41.935159   125 net.cpp:529] inception_3a/relu_1x1 -> inception_3a/1x1 (in-place)
I1130 22:37:41.935168   125 net.cpp:262] Setting up inception_3a/relu_1x1
I1130 22:37:41.935175   125 net.cpp:269] TRAIN Top shape for layer 26 'inception_3a/relu_1x1' 10 64 80 80 (4096000)
I1130 22:37:41.935181   125 layer_factory.hpp:172] Creating layer 'inception_3a/3x3_reduce' of type 'Convolution'
I1130 22:37:41.935187   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.935202   125 net.cpp:202] Created Layer inception_3a/3x3_reduce (27)
I1130 22:37:41.935209   125 net.cpp:574] inception_3a/3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_1
I1130 22:37:41.935214   125 net.cpp:544] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I1130 22:37:41.935802   125 net.cpp:262] Setting up inception_3a/3x3_reduce
I1130 22:37:41.935813   125 net.cpp:269] TRAIN Top shape for layer 27 'inception_3a/3x3_reduce' 10 96 80 80 (6144000)
I1130 22:37:41.935827   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:41.935832   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.935842   125 net.cpp:202] Created Layer inception_3a/relu_3x3_reduce (28)
I1130 22:37:41.935847   125 net.cpp:574] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce
I1130 22:37:41.935854   125 net.cpp:529] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce (in-place)
I1130 22:37:41.935863   125 net.cpp:262] Setting up inception_3a/relu_3x3_reduce
I1130 22:37:41.935869   125 net.cpp:269] TRAIN Top shape for layer 28 'inception_3a/relu_3x3_reduce' 10 96 80 80 (6144000)
I1130 22:37:41.935889   125 layer_factory.hpp:172] Creating layer 'inception_3a/3x3' of type 'Convolution'
I1130 22:37:41.935894   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.935926   125 net.cpp:202] Created Layer inception_3a/3x3 (29)
I1130 22:37:41.935933   125 net.cpp:574] inception_3a/3x3 <- inception_3a/3x3_reduce
I1130 22:37:41.935940   125 net.cpp:544] inception_3a/3x3 -> inception_3a/3x3
I1130 22:37:41.937925   125 net.cpp:262] Setting up inception_3a/3x3
I1130 22:37:41.937937   125 net.cpp:269] TRAIN Top shape for layer 29 'inception_3a/3x3' 10 128 80 80 (8192000)
I1130 22:37:41.937945   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_3x3' of type 'ReLU'
I1130 22:37:41.937952   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.937960   125 net.cpp:202] Created Layer inception_3a/relu_3x3 (30)
I1130 22:37:41.937966   125 net.cpp:574] inception_3a/relu_3x3 <- inception_3a/3x3
I1130 22:37:41.937973   125 net.cpp:529] inception_3a/relu_3x3 -> inception_3a/3x3 (in-place)
I1130 22:37:41.937980   125 net.cpp:262] Setting up inception_3a/relu_3x3
I1130 22:37:41.937988   125 net.cpp:269] TRAIN Top shape for layer 30 'inception_3a/relu_3x3' 10 128 80 80 (8192000)
I1130 22:37:41.937994   125 layer_factory.hpp:172] Creating layer 'inception_3a/5x5_reduce' of type 'Convolution'
I1130 22:37:41.937999   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.938014   125 net.cpp:202] Created Layer inception_3a/5x5_reduce (31)
I1130 22:37:41.938020   125 net.cpp:574] inception_3a/5x5_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_2
I1130 22:37:41.938026   125 net.cpp:544] inception_3a/5x5_reduce -> inception_3a/5x5_reduce
I1130 22:37:41.938379   125 net.cpp:262] Setting up inception_3a/5x5_reduce
I1130 22:37:41.938390   125 net.cpp:269] TRAIN Top shape for layer 31 'inception_3a/5x5_reduce' 10 16 80 80 (1024000)
I1130 22:37:41.938400   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:41.938405   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.938417   125 net.cpp:202] Created Layer inception_3a/relu_5x5_reduce (32)
I1130 22:37:41.938423   125 net.cpp:574] inception_3a/relu_5x5_reduce <- inception_3a/5x5_reduce
I1130 22:37:41.938431   125 net.cpp:529] inception_3a/relu_5x5_reduce -> inception_3a/5x5_reduce (in-place)
I1130 22:37:41.938439   125 net.cpp:262] Setting up inception_3a/relu_5x5_reduce
I1130 22:37:41.938444   125 net.cpp:269] TRAIN Top shape for layer 32 'inception_3a/relu_5x5_reduce' 10 16 80 80 (1024000)
I1130 22:37:41.938452   125 layer_factory.hpp:172] Creating layer 'inception_3a/5x5' of type 'Convolution'
I1130 22:37:41.938457   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.938473   125 net.cpp:202] Created Layer inception_3a/5x5 (33)
I1130 22:37:41.938478   125 net.cpp:574] inception_3a/5x5 <- inception_3a/5x5_reduce
I1130 22:37:41.938484   125 net.cpp:544] inception_3a/5x5 -> inception_3a/5x5
I1130 22:37:41.938992   125 net.cpp:262] Setting up inception_3a/5x5
I1130 22:37:41.939003   125 net.cpp:269] TRAIN Top shape for layer 33 'inception_3a/5x5' 10 32 80 80 (2048000)
I1130 22:37:41.939011   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_5x5' of type 'ReLU'
I1130 22:37:41.939018   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.939026   125 net.cpp:202] Created Layer inception_3a/relu_5x5 (34)
I1130 22:37:41.939031   125 net.cpp:574] inception_3a/relu_5x5 <- inception_3a/5x5
I1130 22:37:41.939038   125 net.cpp:529] inception_3a/relu_5x5 -> inception_3a/5x5 (in-place)
I1130 22:37:41.939046   125 net.cpp:262] Setting up inception_3a/relu_5x5
I1130 22:37:41.939054   125 net.cpp:269] TRAIN Top shape for layer 34 'inception_3a/relu_5x5' 10 32 80 80 (2048000)
I1130 22:37:41.939059   125 layer_factory.hpp:172] Creating layer 'inception_3a/pool' of type 'Pooling'
I1130 22:37:41.939077   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.939090   125 net.cpp:202] Created Layer inception_3a/pool (35)
I1130 22:37:41.939095   125 net.cpp:574] inception_3a/pool <- pool2/3x3_s2_pool2/3x3_s2_0_split_3
I1130 22:37:41.939101   125 net.cpp:544] inception_3a/pool -> inception_3a/pool
I1130 22:37:41.939169   125 net.cpp:262] Setting up inception_3a/pool
I1130 22:37:41.939178   125 net.cpp:269] TRAIN Top shape for layer 35 'inception_3a/pool' 10 192 80 80 (12288000)
I1130 22:37:41.939185   125 layer_factory.hpp:172] Creating layer 'inception_3a/pool_proj' of type 'Convolution'
I1130 22:37:41.939191   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.939206   125 net.cpp:202] Created Layer inception_3a/pool_proj (36)
I1130 22:37:41.939213   125 net.cpp:574] inception_3a/pool_proj <- inception_3a/pool
I1130 22:37:41.939218   125 net.cpp:544] inception_3a/pool_proj -> inception_3a/pool_proj
I1130 22:37:41.939617   125 net.cpp:262] Setting up inception_3a/pool_proj
I1130 22:37:41.939628   125 net.cpp:269] TRAIN Top shape for layer 36 'inception_3a/pool_proj' 10 32 80 80 (2048000)
I1130 22:37:41.939641   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_pool_proj' of type 'ReLU'
I1130 22:37:41.939648   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.939656   125 net.cpp:202] Created Layer inception_3a/relu_pool_proj (37)
I1130 22:37:41.939661   125 net.cpp:574] inception_3a/relu_pool_proj <- inception_3a/pool_proj
I1130 22:37:41.939668   125 net.cpp:529] inception_3a/relu_pool_proj -> inception_3a/pool_proj (in-place)
I1130 22:37:41.939677   125 net.cpp:262] Setting up inception_3a/relu_pool_proj
I1130 22:37:41.939683   125 net.cpp:269] TRAIN Top shape for layer 37 'inception_3a/relu_pool_proj' 10 32 80 80 (2048000)
I1130 22:37:41.939689   125 layer_factory.hpp:172] Creating layer 'inception_3a/output' of type 'Concat'
I1130 22:37:41.939695   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.939705   125 net.cpp:202] Created Layer inception_3a/output (38)
I1130 22:37:41.939710   125 net.cpp:574] inception_3a/output <- inception_3a/1x1
I1130 22:37:41.939715   125 net.cpp:574] inception_3a/output <- inception_3a/3x3
I1130 22:37:41.939721   125 net.cpp:574] inception_3a/output <- inception_3a/5x5
I1130 22:37:41.939728   125 net.cpp:574] inception_3a/output <- inception_3a/pool_proj
I1130 22:37:41.939733   125 net.cpp:544] inception_3a/output -> inception_3a/output
I1130 22:37:41.939769   125 net.cpp:262] Setting up inception_3a/output
I1130 22:37:41.939777   125 net.cpp:269] TRAIN Top shape for layer 38 'inception_3a/output' 10 256 80 80 (16384000)
I1130 22:37:41.939785   125 layer_factory.hpp:172] Creating layer 'inception_3a/output_inception_3a/output_0_split' of type 'Split'
I1130 22:37:41.939790   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.939798   125 net.cpp:202] Created Layer inception_3a/output_inception_3a/output_0_split (39)
I1130 22:37:41.939805   125 net.cpp:574] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I1130 22:37:41.939810   125 net.cpp:544] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I1130 22:37:41.939819   125 net.cpp:544] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I1130 22:37:41.939827   125 net.cpp:544] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I1130 22:37:41.939834   125 net.cpp:544] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_3
I1130 22:37:41.939908   125 net.cpp:262] Setting up inception_3a/output_inception_3a/output_0_split
I1130 22:37:41.939931   125 net.cpp:269] TRAIN Top shape for layer 39 'inception_3a/output_inception_3a/output_0_split' 10 256 80 80 (16384000)
I1130 22:37:41.939950   125 net.cpp:269] TRAIN Top shape for layer 39 'inception_3a/output_inception_3a/output_0_split' 10 256 80 80 (16384000)
I1130 22:37:41.939956   125 net.cpp:269] TRAIN Top shape for layer 39 'inception_3a/output_inception_3a/output_0_split' 10 256 80 80 (16384000)
I1130 22:37:41.939963   125 net.cpp:269] TRAIN Top shape for layer 39 'inception_3a/output_inception_3a/output_0_split' 10 256 80 80 (16384000)
I1130 22:37:41.939970   125 layer_factory.hpp:172] Creating layer 'inception_3b/1x1' of type 'Convolution'
I1130 22:37:41.939975   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.939993   125 net.cpp:202] Created Layer inception_3b/1x1 (40)
I1130 22:37:41.939999   125 net.cpp:574] inception_3b/1x1 <- inception_3a/output_inception_3a/output_0_split_0
I1130 22:37:41.940006   125 net.cpp:544] inception_3b/1x1 -> inception_3b/1x1
I1130 22:37:41.940804   125 net.cpp:262] Setting up inception_3b/1x1
I1130 22:37:41.940815   125 net.cpp:269] TRAIN Top shape for layer 40 'inception_3b/1x1' 10 128 80 80 (8192000)
I1130 22:37:41.940824   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_1x1' of type 'ReLU'
I1130 22:37:41.940830   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.940840   125 net.cpp:202] Created Layer inception_3b/relu_1x1 (41)
I1130 22:37:41.940845   125 net.cpp:574] inception_3b/relu_1x1 <- inception_3b/1x1
I1130 22:37:41.940851   125 net.cpp:529] inception_3b/relu_1x1 -> inception_3b/1x1 (in-place)
I1130 22:37:41.940860   125 net.cpp:262] Setting up inception_3b/relu_1x1
I1130 22:37:41.940867   125 net.cpp:269] TRAIN Top shape for layer 41 'inception_3b/relu_1x1' 10 128 80 80 (8192000)
I1130 22:37:41.940874   125 layer_factory.hpp:172] Creating layer 'inception_3b/3x3_reduce' of type 'Convolution'
I1130 22:37:41.940881   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.940896   125 net.cpp:202] Created Layer inception_3b/3x3_reduce (42)
I1130 22:37:41.940901   125 net.cpp:574] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I1130 22:37:41.940908   125 net.cpp:544] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I1130 22:37:41.941686   125 net.cpp:262] Setting up inception_3b/3x3_reduce
I1130 22:37:41.941696   125 net.cpp:269] TRAIN Top shape for layer 42 'inception_3b/3x3_reduce' 10 128 80 80 (8192000)
I1130 22:37:41.941705   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:41.941712   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.941720   125 net.cpp:202] Created Layer inception_3b/relu_3x3_reduce (43)
I1130 22:37:41.941725   125 net.cpp:574] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce
I1130 22:37:41.941732   125 net.cpp:529] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce (in-place)
I1130 22:37:41.941740   125 net.cpp:262] Setting up inception_3b/relu_3x3_reduce
I1130 22:37:41.941748   125 net.cpp:269] TRAIN Top shape for layer 43 'inception_3b/relu_3x3_reduce' 10 128 80 80 (8192000)
I1130 22:37:41.941754   125 layer_factory.hpp:172] Creating layer 'inception_3b/3x3' of type 'Convolution'
I1130 22:37:41.941759   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.941776   125 net.cpp:202] Created Layer inception_3b/3x3 (44)
I1130 22:37:41.941781   125 net.cpp:574] inception_3b/3x3 <- inception_3b/3x3_reduce
I1130 22:37:41.941787   125 net.cpp:544] inception_3b/3x3 -> inception_3b/3x3
I1130 22:37:41.946568   125 net.cpp:262] Setting up inception_3b/3x3
I1130 22:37:41.946584   125 net.cpp:269] TRAIN Top shape for layer 44 'inception_3b/3x3' 10 192 80 80 (12288000)
I1130 22:37:41.946595   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_3x3' of type 'ReLU'
I1130 22:37:41.946614   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.946624   125 net.cpp:202] Created Layer inception_3b/relu_3x3 (45)
I1130 22:37:41.946630   125 net.cpp:574] inception_3b/relu_3x3 <- inception_3b/3x3
I1130 22:37:41.946638   125 net.cpp:529] inception_3b/relu_3x3 -> inception_3b/3x3 (in-place)
I1130 22:37:41.946647   125 net.cpp:262] Setting up inception_3b/relu_3x3
I1130 22:37:41.946655   125 net.cpp:269] TRAIN Top shape for layer 45 'inception_3b/relu_3x3' 10 192 80 80 (12288000)
I1130 22:37:41.946661   125 layer_factory.hpp:172] Creating layer 'inception_3b/5x5_reduce' of type 'Convolution'
I1130 22:37:41.946667   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.946684   125 net.cpp:202] Created Layer inception_3b/5x5_reduce (46)
I1130 22:37:41.946689   125 net.cpp:574] inception_3b/5x5_reduce <- inception_3a/output_inception_3a/output_0_split_2
I1130 22:37:41.946696   125 net.cpp:544] inception_3b/5x5_reduce -> inception_3b/5x5_reduce
I1130 22:37:41.947146   125 net.cpp:262] Setting up inception_3b/5x5_reduce
I1130 22:37:41.947157   125 net.cpp:269] TRAIN Top shape for layer 46 'inception_3b/5x5_reduce' 10 32 80 80 (2048000)
I1130 22:37:41.947166   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:41.947173   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.947182   125 net.cpp:202] Created Layer inception_3b/relu_5x5_reduce (47)
I1130 22:37:41.947187   125 net.cpp:574] inception_3b/relu_5x5_reduce <- inception_3b/5x5_reduce
I1130 22:37:41.947193   125 net.cpp:529] inception_3b/relu_5x5_reduce -> inception_3b/5x5_reduce (in-place)
I1130 22:37:41.947203   125 net.cpp:262] Setting up inception_3b/relu_5x5_reduce
I1130 22:37:41.947211   125 net.cpp:269] TRAIN Top shape for layer 47 'inception_3b/relu_5x5_reduce' 10 32 80 80 (2048000)
I1130 22:37:41.947216   125 layer_factory.hpp:172] Creating layer 'inception_3b/5x5' of type 'Convolution'
I1130 22:37:41.947221   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.947238   125 net.cpp:202] Created Layer inception_3b/5x5 (48)
I1130 22:37:41.947244   125 net.cpp:574] inception_3b/5x5 <- inception_3b/5x5_reduce
I1130 22:37:41.947249   125 net.cpp:544] inception_3b/5x5 -> inception_3b/5x5
I1130 22:37:41.948704   125 net.cpp:262] Setting up inception_3b/5x5
I1130 22:37:41.948715   125 net.cpp:269] TRAIN Top shape for layer 48 'inception_3b/5x5' 10 96 80 80 (6144000)
I1130 22:37:41.948725   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_5x5' of type 'ReLU'
I1130 22:37:41.948731   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.948740   125 net.cpp:202] Created Layer inception_3b/relu_5x5 (49)
I1130 22:37:41.948745   125 net.cpp:574] inception_3b/relu_5x5 <- inception_3b/5x5
I1130 22:37:41.948752   125 net.cpp:529] inception_3b/relu_5x5 -> inception_3b/5x5 (in-place)
I1130 22:37:41.948760   125 net.cpp:262] Setting up inception_3b/relu_5x5
I1130 22:37:41.948767   125 net.cpp:269] TRAIN Top shape for layer 49 'inception_3b/relu_5x5' 10 96 80 80 (6144000)
I1130 22:37:41.948773   125 layer_factory.hpp:172] Creating layer 'inception_3b/pool' of type 'Pooling'
I1130 22:37:41.948779   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.948791   125 net.cpp:202] Created Layer inception_3b/pool (50)
I1130 22:37:41.948797   125 net.cpp:574] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_3
I1130 22:37:41.948803   125 net.cpp:544] inception_3b/pool -> inception_3b/pool
I1130 22:37:41.948873   125 net.cpp:262] Setting up inception_3b/pool
I1130 22:37:41.948882   125 net.cpp:269] TRAIN Top shape for layer 50 'inception_3b/pool' 10 256 80 80 (16384000)
I1130 22:37:41.948889   125 layer_factory.hpp:172] Creating layer 'inception_3b/pool_proj' of type 'Convolution'
I1130 22:37:41.948906   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.948923   125 net.cpp:202] Created Layer inception_3b/pool_proj (51)
I1130 22:37:41.948930   125 net.cpp:574] inception_3b/pool_proj <- inception_3b/pool
I1130 22:37:41.948935   125 net.cpp:544] inception_3b/pool_proj -> inception_3b/pool_proj
I1130 22:37:41.949501   125 net.cpp:262] Setting up inception_3b/pool_proj
I1130 22:37:41.949512   125 net.cpp:269] TRAIN Top shape for layer 51 'inception_3b/pool_proj' 10 64 80 80 (4096000)
I1130 22:37:41.949520   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_pool_proj' of type 'ReLU'
I1130 22:37:41.949527   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.949535   125 net.cpp:202] Created Layer inception_3b/relu_pool_proj (52)
I1130 22:37:41.949542   125 net.cpp:574] inception_3b/relu_pool_proj <- inception_3b/pool_proj
I1130 22:37:41.949548   125 net.cpp:529] inception_3b/relu_pool_proj -> inception_3b/pool_proj (in-place)
I1130 22:37:41.949556   125 net.cpp:262] Setting up inception_3b/relu_pool_proj
I1130 22:37:41.949563   125 net.cpp:269] TRAIN Top shape for layer 52 'inception_3b/relu_pool_proj' 10 64 80 80 (4096000)
I1130 22:37:41.949570   125 layer_factory.hpp:172] Creating layer 'inception_3b/output' of type 'Concat'
I1130 22:37:41.949575   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.949584   125 net.cpp:202] Created Layer inception_3b/output (53)
I1130 22:37:41.949589   125 net.cpp:574] inception_3b/output <- inception_3b/1x1
I1130 22:37:41.949595   125 net.cpp:574] inception_3b/output <- inception_3b/3x3
I1130 22:37:41.949601   125 net.cpp:574] inception_3b/output <- inception_3b/5x5
I1130 22:37:41.949607   125 net.cpp:574] inception_3b/output <- inception_3b/pool_proj
I1130 22:37:41.949612   125 net.cpp:544] inception_3b/output -> inception_3b/output
I1130 22:37:41.949647   125 net.cpp:262] Setting up inception_3b/output
I1130 22:37:41.949656   125 net.cpp:269] TRAIN Top shape for layer 53 'inception_3b/output' 10 480 80 80 (30720000)
I1130 22:37:41.949662   125 layer_factory.hpp:172] Creating layer 'pool3/3x3_s2' of type 'Pooling'
I1130 22:37:41.949668   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.949679   125 net.cpp:202] Created Layer pool3/3x3_s2 (54)
I1130 22:37:41.949685   125 net.cpp:574] pool3/3x3_s2 <- inception_3b/output
I1130 22:37:41.949692   125 net.cpp:544] pool3/3x3_s2 -> pool3/3x3_s2
I1130 22:37:41.949756   125 net.cpp:262] Setting up pool3/3x3_s2
I1130 22:37:41.949765   125 net.cpp:269] TRAIN Top shape for layer 54 'pool3/3x3_s2' 10 480 40 40 (7680000)
I1130 22:37:41.949771   125 layer_factory.hpp:172] Creating layer 'pool3/3x3_s2_pool3/3x3_s2_0_split' of type 'Split'
I1130 22:37:41.949777   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.949785   125 net.cpp:202] Created Layer pool3/3x3_s2_pool3/3x3_s2_0_split (55)
I1130 22:37:41.949791   125 net.cpp:574] pool3/3x3_s2_pool3/3x3_s2_0_split <- pool3/3x3_s2
I1130 22:37:41.949797   125 net.cpp:544] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_0
I1130 22:37:41.949807   125 net.cpp:544] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_1
I1130 22:37:41.949815   125 net.cpp:544] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_2
I1130 22:37:41.949822   125 net.cpp:544] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_3
I1130 22:37:41.949895   125 net.cpp:262] Setting up pool3/3x3_s2_pool3/3x3_s2_0_split
I1130 22:37:41.949903   125 net.cpp:269] TRAIN Top shape for layer 55 'pool3/3x3_s2_pool3/3x3_s2_0_split' 10 480 40 40 (7680000)
I1130 22:37:41.949910   125 net.cpp:269] TRAIN Top shape for layer 55 'pool3/3x3_s2_pool3/3x3_s2_0_split' 10 480 40 40 (7680000)
I1130 22:37:41.949916   125 net.cpp:269] TRAIN Top shape for layer 55 'pool3/3x3_s2_pool3/3x3_s2_0_split' 10 480 40 40 (7680000)
I1130 22:37:41.949934   125 net.cpp:269] TRAIN Top shape for layer 55 'pool3/3x3_s2_pool3/3x3_s2_0_split' 10 480 40 40 (7680000)
I1130 22:37:41.949939   125 layer_factory.hpp:172] Creating layer 'inception_4a/1x1' of type 'Convolution'
I1130 22:37:41.949945   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.949961   125 net.cpp:202] Created Layer inception_4a/1x1 (56)
I1130 22:37:41.949967   125 net.cpp:574] inception_4a/1x1 <- pool3/3x3_s2_pool3/3x3_s2_0_split_0
I1130 22:37:41.949973   125 net.cpp:544] inception_4a/1x1 -> inception_4a/1x1
I1130 22:37:41.951617   125 net.cpp:262] Setting up inception_4a/1x1
I1130 22:37:41.951630   125 net.cpp:269] TRAIN Top shape for layer 56 'inception_4a/1x1' 10 192 40 40 (3072000)
I1130 22:37:41.951639   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_1x1' of type 'ReLU'
I1130 22:37:41.951645   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.951655   125 net.cpp:202] Created Layer inception_4a/relu_1x1 (57)
I1130 22:37:41.951661   125 net.cpp:574] inception_4a/relu_1x1 <- inception_4a/1x1
I1130 22:37:41.951668   125 net.cpp:529] inception_4a/relu_1x1 -> inception_4a/1x1 (in-place)
I1130 22:37:41.951676   125 net.cpp:262] Setting up inception_4a/relu_1x1
I1130 22:37:41.951683   125 net.cpp:269] TRAIN Top shape for layer 57 'inception_4a/relu_1x1' 10 192 40 40 (3072000)
I1130 22:37:41.951689   125 layer_factory.hpp:172] Creating layer 'inception_4a/3x3_reduce' of type 'Convolution'
I1130 22:37:41.951695   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.951710   125 net.cpp:202] Created Layer inception_4a/3x3_reduce (58)
I1130 22:37:41.951716   125 net.cpp:574] inception_4a/3x3_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_1
I1130 22:37:41.951722   125 net.cpp:544] inception_4a/3x3_reduce -> inception_4a/3x3_reduce
I1130 22:37:41.952756   125 net.cpp:262] Setting up inception_4a/3x3_reduce
I1130 22:37:41.952769   125 net.cpp:269] TRAIN Top shape for layer 58 'inception_4a/3x3_reduce' 10 96 40 40 (1536000)
I1130 22:37:41.952786   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:41.952792   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.952802   125 net.cpp:202] Created Layer inception_4a/relu_3x3_reduce (59)
I1130 22:37:41.952807   125 net.cpp:574] inception_4a/relu_3x3_reduce <- inception_4a/3x3_reduce
I1130 22:37:41.952814   125 net.cpp:529] inception_4a/relu_3x3_reduce -> inception_4a/3x3_reduce (in-place)
I1130 22:37:41.952824   125 net.cpp:262] Setting up inception_4a/relu_3x3_reduce
I1130 22:37:41.952831   125 net.cpp:269] TRAIN Top shape for layer 59 'inception_4a/relu_3x3_reduce' 10 96 40 40 (1536000)
I1130 22:37:41.952837   125 layer_factory.hpp:172] Creating layer 'inception_4a/3x3' of type 'Convolution'
I1130 22:37:41.952843   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.952859   125 net.cpp:202] Created Layer inception_4a/3x3 (60)
I1130 22:37:41.952864   125 net.cpp:574] inception_4a/3x3 <- inception_4a/3x3_reduce
I1130 22:37:41.952870   125 net.cpp:544] inception_4a/3x3 -> inception_4a/3x3
I1130 22:37:41.955904   125 net.cpp:262] Setting up inception_4a/3x3
I1130 22:37:41.955935   125 net.cpp:269] TRAIN Top shape for layer 60 'inception_4a/3x3' 10 208 40 40 (3328000)
I1130 22:37:41.955946   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_3x3' of type 'ReLU'
I1130 22:37:41.955952   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.955960   125 net.cpp:202] Created Layer inception_4a/relu_3x3 (61)
I1130 22:37:41.955966   125 net.cpp:574] inception_4a/relu_3x3 <- inception_4a/3x3
I1130 22:37:41.955973   125 net.cpp:529] inception_4a/relu_3x3 -> inception_4a/3x3 (in-place)
I1130 22:37:41.955996   125 net.cpp:262] Setting up inception_4a/relu_3x3
I1130 22:37:41.956002   125 net.cpp:269] TRAIN Top shape for layer 61 'inception_4a/relu_3x3' 10 208 40 40 (3328000)
I1130 22:37:41.956009   125 layer_factory.hpp:172] Creating layer 'inception_4a/5x5_reduce' of type 'Convolution'
I1130 22:37:41.956014   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.956032   125 net.cpp:202] Created Layer inception_4a/5x5_reduce (62)
I1130 22:37:41.956037   125 net.cpp:574] inception_4a/5x5_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_2
I1130 22:37:41.956044   125 net.cpp:544] inception_4a/5x5_reduce -> inception_4a/5x5_reduce
I1130 22:37:41.956485   125 net.cpp:262] Setting up inception_4a/5x5_reduce
I1130 22:37:41.956496   125 net.cpp:269] TRAIN Top shape for layer 62 'inception_4a/5x5_reduce' 10 16 40 40 (256000)
I1130 22:37:41.956506   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:41.956511   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.956521   125 net.cpp:202] Created Layer inception_4a/relu_5x5_reduce (63)
I1130 22:37:41.956526   125 net.cpp:574] inception_4a/relu_5x5_reduce <- inception_4a/5x5_reduce
I1130 22:37:41.956532   125 net.cpp:529] inception_4a/relu_5x5_reduce -> inception_4a/5x5_reduce (in-place)
I1130 22:37:41.956542   125 net.cpp:262] Setting up inception_4a/relu_5x5_reduce
I1130 22:37:41.956548   125 net.cpp:269] TRAIN Top shape for layer 63 'inception_4a/relu_5x5_reduce' 10 16 40 40 (256000)
I1130 22:37:41.956554   125 layer_factory.hpp:172] Creating layer 'inception_4a/5x5' of type 'Convolution'
I1130 22:37:41.956559   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.956580   125 net.cpp:202] Created Layer inception_4a/5x5 (64)
I1130 22:37:41.956585   125 net.cpp:574] inception_4a/5x5 <- inception_4a/5x5_reduce
I1130 22:37:41.956591   125 net.cpp:544] inception_4a/5x5 -> inception_4a/5x5
I1130 22:37:41.957201   125 net.cpp:262] Setting up inception_4a/5x5
I1130 22:37:41.957212   125 net.cpp:269] TRAIN Top shape for layer 64 'inception_4a/5x5' 10 48 40 40 (768000)
I1130 22:37:41.957221   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_5x5' of type 'ReLU'
I1130 22:37:41.957227   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.957237   125 net.cpp:202] Created Layer inception_4a/relu_5x5 (65)
I1130 22:37:41.957242   125 net.cpp:574] inception_4a/relu_5x5 <- inception_4a/5x5
I1130 22:37:41.957248   125 net.cpp:529] inception_4a/relu_5x5 -> inception_4a/5x5 (in-place)
I1130 22:37:41.957257   125 net.cpp:262] Setting up inception_4a/relu_5x5
I1130 22:37:41.957264   125 net.cpp:269] TRAIN Top shape for layer 65 'inception_4a/relu_5x5' 10 48 40 40 (768000)
I1130 22:37:41.957270   125 layer_factory.hpp:172] Creating layer 'inception_4a/pool' of type 'Pooling'
I1130 22:37:41.957276   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.957288   125 net.cpp:202] Created Layer inception_4a/pool (66)
I1130 22:37:41.957293   125 net.cpp:574] inception_4a/pool <- pool3/3x3_s2_pool3/3x3_s2_0_split_3
I1130 22:37:41.957300   125 net.cpp:544] inception_4a/pool -> inception_4a/pool
I1130 22:37:41.957372   125 net.cpp:262] Setting up inception_4a/pool
I1130 22:37:41.957381   125 net.cpp:269] TRAIN Top shape for layer 66 'inception_4a/pool' 10 480 40 40 (7680000)
I1130 22:37:41.957387   125 layer_factory.hpp:172] Creating layer 'inception_4a/pool_proj' of type 'Convolution'
I1130 22:37:41.957394   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.957409   125 net.cpp:202] Created Layer inception_4a/pool_proj (67)
I1130 22:37:41.957414   125 net.cpp:574] inception_4a/pool_proj <- inception_4a/pool
I1130 22:37:41.957420   125 net.cpp:544] inception_4a/pool_proj -> inception_4a/pool_proj
I1130 22:37:41.958200   125 net.cpp:262] Setting up inception_4a/pool_proj
I1130 22:37:41.958232   125 net.cpp:269] TRAIN Top shape for layer 67 'inception_4a/pool_proj' 10 64 40 40 (1024000)
I1130 22:37:41.958242   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_pool_proj' of type 'ReLU'
I1130 22:37:41.958248   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.958257   125 net.cpp:202] Created Layer inception_4a/relu_pool_proj (68)
I1130 22:37:41.958263   125 net.cpp:574] inception_4a/relu_pool_proj <- inception_4a/pool_proj
I1130 22:37:41.958269   125 net.cpp:529] inception_4a/relu_pool_proj -> inception_4a/pool_proj (in-place)
I1130 22:37:41.958279   125 net.cpp:262] Setting up inception_4a/relu_pool_proj
I1130 22:37:41.958287   125 net.cpp:269] TRAIN Top shape for layer 68 'inception_4a/relu_pool_proj' 10 64 40 40 (1024000)
I1130 22:37:41.958292   125 layer_factory.hpp:172] Creating layer 'inception_4a/output' of type 'Concat'
I1130 22:37:41.958297   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.958307   125 net.cpp:202] Created Layer inception_4a/output (69)
I1130 22:37:41.958312   125 net.cpp:574] inception_4a/output <- inception_4a/1x1
I1130 22:37:41.958318   125 net.cpp:574] inception_4a/output <- inception_4a/3x3
I1130 22:37:41.958324   125 net.cpp:574] inception_4a/output <- inception_4a/5x5
I1130 22:37:41.958330   125 net.cpp:574] inception_4a/output <- inception_4a/pool_proj
I1130 22:37:41.958336   125 net.cpp:544] inception_4a/output -> inception_4a/output
I1130 22:37:41.958374   125 net.cpp:262] Setting up inception_4a/output
I1130 22:37:41.958380   125 net.cpp:269] TRAIN Top shape for layer 69 'inception_4a/output' 10 512 40 40 (8192000)
I1130 22:37:41.958387   125 layer_factory.hpp:172] Creating layer 'inception_4a/output_inception_4a/output_0_split' of type 'Split'
I1130 22:37:41.958393   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.958402   125 net.cpp:202] Created Layer inception_4a/output_inception_4a/output_0_split (70)
I1130 22:37:41.958408   125 net.cpp:574] inception_4a/output_inception_4a/output_0_split <- inception_4a/output
I1130 22:37:41.958415   125 net.cpp:544] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_0
I1130 22:37:41.958423   125 net.cpp:544] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_1
I1130 22:37:41.958432   125 net.cpp:544] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_2
I1130 22:37:41.958439   125 net.cpp:544] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_3
I1130 22:37:41.958515   125 net.cpp:262] Setting up inception_4a/output_inception_4a/output_0_split
I1130 22:37:41.958523   125 net.cpp:269] TRAIN Top shape for layer 70 'inception_4a/output_inception_4a/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.958530   125 net.cpp:269] TRAIN Top shape for layer 70 'inception_4a/output_inception_4a/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.958535   125 net.cpp:269] TRAIN Top shape for layer 70 'inception_4a/output_inception_4a/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.958541   125 net.cpp:269] TRAIN Top shape for layer 70 'inception_4a/output_inception_4a/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.958547   125 layer_factory.hpp:172] Creating layer 'inception_4b/1x1' of type 'Convolution'
I1130 22:37:41.958554   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.958570   125 net.cpp:202] Created Layer inception_4b/1x1 (71)
I1130 22:37:41.958575   125 net.cpp:574] inception_4b/1x1 <- inception_4a/output_inception_4a/output_0_split_0
I1130 22:37:41.958582   125 net.cpp:544] inception_4b/1x1 -> inception_4b/1x1
I1130 22:37:41.960163   125 net.cpp:262] Setting up inception_4b/1x1
I1130 22:37:41.960175   125 net.cpp:269] TRAIN Top shape for layer 71 'inception_4b/1x1' 10 160 40 40 (2560000)
I1130 22:37:41.960201   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_1x1' of type 'ReLU'
I1130 22:37:41.960208   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.960216   125 net.cpp:202] Created Layer inception_4b/relu_1x1 (72)
I1130 22:37:41.960222   125 net.cpp:574] inception_4b/relu_1x1 <- inception_4b/1x1
I1130 22:37:41.960229   125 net.cpp:529] inception_4b/relu_1x1 -> inception_4b/1x1 (in-place)
I1130 22:37:41.960239   125 net.cpp:262] Setting up inception_4b/relu_1x1
I1130 22:37:41.960247   125 net.cpp:269] TRAIN Top shape for layer 72 'inception_4b/relu_1x1' 10 160 40 40 (2560000)
I1130 22:37:41.960253   125 layer_factory.hpp:172] Creating layer 'inception_4b/3x3_reduce' of type 'Convolution'
I1130 22:37:41.960258   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.960274   125 net.cpp:202] Created Layer inception_4b/3x3_reduce (73)
I1130 22:37:41.960279   125 net.cpp:574] inception_4b/3x3_reduce <- inception_4a/output_inception_4a/output_0_split_1
I1130 22:37:41.960286   125 net.cpp:544] inception_4b/3x3_reduce -> inception_4b/3x3_reduce
I1130 22:37:41.961479   125 net.cpp:262] Setting up inception_4b/3x3_reduce
I1130 22:37:41.961490   125 net.cpp:269] TRAIN Top shape for layer 73 'inception_4b/3x3_reduce' 10 112 40 40 (1792000)
I1130 22:37:41.961499   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:41.961505   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.961514   125 net.cpp:202] Created Layer inception_4b/relu_3x3_reduce (74)
I1130 22:37:41.961520   125 net.cpp:574] inception_4b/relu_3x3_reduce <- inception_4b/3x3_reduce
I1130 22:37:41.961526   125 net.cpp:529] inception_4b/relu_3x3_reduce -> inception_4b/3x3_reduce (in-place)
I1130 22:37:41.961537   125 net.cpp:262] Setting up inception_4b/relu_3x3_reduce
I1130 22:37:41.961544   125 net.cpp:269] TRAIN Top shape for layer 74 'inception_4b/relu_3x3_reduce' 10 112 40 40 (1792000)
I1130 22:37:41.961550   125 layer_factory.hpp:172] Creating layer 'inception_4b/3x3' of type 'Convolution'
I1130 22:37:41.961556   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.961571   125 net.cpp:202] Created Layer inception_4b/3x3 (75)
I1130 22:37:41.961577   125 net.cpp:574] inception_4b/3x3 <- inception_4b/3x3_reduce
I1130 22:37:41.961583   125 net.cpp:544] inception_4b/3x3 -> inception_4b/3x3
I1130 22:37:41.966588   125 net.cpp:262] Setting up inception_4b/3x3
I1130 22:37:41.966605   125 net.cpp:269] TRAIN Top shape for layer 75 'inception_4b/3x3' 10 224 40 40 (3584000)
I1130 22:37:41.966615   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_3x3' of type 'ReLU'
I1130 22:37:41.966622   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.966631   125 net.cpp:202] Created Layer inception_4b/relu_3x3 (76)
I1130 22:37:41.966637   125 net.cpp:574] inception_4b/relu_3x3 <- inception_4b/3x3
I1130 22:37:41.966645   125 net.cpp:529] inception_4b/relu_3x3 -> inception_4b/3x3 (in-place)
I1130 22:37:41.966655   125 net.cpp:262] Setting up inception_4b/relu_3x3
I1130 22:37:41.966661   125 net.cpp:269] TRAIN Top shape for layer 76 'inception_4b/relu_3x3' 10 224 40 40 (3584000)
I1130 22:37:41.966667   125 layer_factory.hpp:172] Creating layer 'inception_4b/5x5_reduce' of type 'Convolution'
I1130 22:37:41.966673   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.966691   125 net.cpp:202] Created Layer inception_4b/5x5_reduce (77)
I1130 22:37:41.966697   125 net.cpp:574] inception_4b/5x5_reduce <- inception_4a/output_inception_4a/output_0_split_2
I1130 22:37:41.966703   125 net.cpp:544] inception_4b/5x5_reduce -> inception_4b/5x5_reduce
I1130 22:37:41.967222   125 net.cpp:262] Setting up inception_4b/5x5_reduce
I1130 22:37:41.967247   125 net.cpp:269] TRAIN Top shape for layer 77 'inception_4b/5x5_reduce' 10 24 40 40 (384000)
I1130 22:37:41.967257   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:41.967262   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.967272   125 net.cpp:202] Created Layer inception_4b/relu_5x5_reduce (78)
I1130 22:37:41.967278   125 net.cpp:574] inception_4b/relu_5x5_reduce <- inception_4b/5x5_reduce
I1130 22:37:41.967284   125 net.cpp:529] inception_4b/relu_5x5_reduce -> inception_4b/5x5_reduce (in-place)
I1130 22:37:41.967293   125 net.cpp:262] Setting up inception_4b/relu_5x5_reduce
I1130 22:37:41.967300   125 net.cpp:269] TRAIN Top shape for layer 78 'inception_4b/relu_5x5_reduce' 10 24 40 40 (384000)
I1130 22:37:41.967308   125 layer_factory.hpp:172] Creating layer 'inception_4b/5x5' of type 'Convolution'
I1130 22:37:41.967312   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.967329   125 net.cpp:202] Created Layer inception_4b/5x5 (79)
I1130 22:37:41.967334   125 net.cpp:574] inception_4b/5x5 <- inception_4b/5x5_reduce
I1130 22:37:41.967341   125 net.cpp:544] inception_4b/5x5 -> inception_4b/5x5
I1130 22:37:41.968267   125 net.cpp:262] Setting up inception_4b/5x5
I1130 22:37:41.968281   125 net.cpp:269] TRAIN Top shape for layer 79 'inception_4b/5x5' 10 64 40 40 (1024000)
I1130 22:37:41.968289   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_5x5' of type 'ReLU'
I1130 22:37:41.968295   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.968304   125 net.cpp:202] Created Layer inception_4b/relu_5x5 (80)
I1130 22:37:41.968310   125 net.cpp:574] inception_4b/relu_5x5 <- inception_4b/5x5
I1130 22:37:41.968317   125 net.cpp:529] inception_4b/relu_5x5 -> inception_4b/5x5 (in-place)
I1130 22:37:41.968325   125 net.cpp:262] Setting up inception_4b/relu_5x5
I1130 22:37:41.968333   125 net.cpp:269] TRAIN Top shape for layer 80 'inception_4b/relu_5x5' 10 64 40 40 (1024000)
I1130 22:37:41.968338   125 layer_factory.hpp:172] Creating layer 'inception_4b/pool' of type 'Pooling'
I1130 22:37:41.968344   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.968355   125 net.cpp:202] Created Layer inception_4b/pool (81)
I1130 22:37:41.968360   125 net.cpp:574] inception_4b/pool <- inception_4a/output_inception_4a/output_0_split_3
I1130 22:37:41.968366   125 net.cpp:544] inception_4b/pool -> inception_4b/pool
I1130 22:37:41.968441   125 net.cpp:262] Setting up inception_4b/pool
I1130 22:37:41.968449   125 net.cpp:269] TRAIN Top shape for layer 81 'inception_4b/pool' 10 512 40 40 (8192000)
I1130 22:37:41.968456   125 layer_factory.hpp:172] Creating layer 'inception_4b/pool_proj' of type 'Convolution'
I1130 22:37:41.968461   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.968477   125 net.cpp:202] Created Layer inception_4b/pool_proj (82)
I1130 22:37:41.968482   125 net.cpp:574] inception_4b/pool_proj <- inception_4b/pool
I1130 22:37:41.968488   125 net.cpp:544] inception_4b/pool_proj -> inception_4b/pool_proj
I1130 22:37:41.969305   125 net.cpp:262] Setting up inception_4b/pool_proj
I1130 22:37:41.969317   125 net.cpp:269] TRAIN Top shape for layer 82 'inception_4b/pool_proj' 10 64 40 40 (1024000)
I1130 22:37:41.969326   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_pool_proj' of type 'ReLU'
I1130 22:37:41.969332   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.969341   125 net.cpp:202] Created Layer inception_4b/relu_pool_proj (83)
I1130 22:37:41.969347   125 net.cpp:574] inception_4b/relu_pool_proj <- inception_4b/pool_proj
I1130 22:37:41.969352   125 net.cpp:529] inception_4b/relu_pool_proj -> inception_4b/pool_proj (in-place)
I1130 22:37:41.969362   125 net.cpp:262] Setting up inception_4b/relu_pool_proj
I1130 22:37:41.969380   125 net.cpp:269] TRAIN Top shape for layer 83 'inception_4b/relu_pool_proj' 10 64 40 40 (1024000)
I1130 22:37:41.969388   125 layer_factory.hpp:172] Creating layer 'inception_4b/output' of type 'Concat'
I1130 22:37:41.969393   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.969401   125 net.cpp:202] Created Layer inception_4b/output (84)
I1130 22:37:41.969406   125 net.cpp:574] inception_4b/output <- inception_4b/1x1
I1130 22:37:41.969413   125 net.cpp:574] inception_4b/output <- inception_4b/3x3
I1130 22:37:41.969419   125 net.cpp:574] inception_4b/output <- inception_4b/5x5
I1130 22:37:41.969424   125 net.cpp:574] inception_4b/output <- inception_4b/pool_proj
I1130 22:37:41.969429   125 net.cpp:544] inception_4b/output -> inception_4b/output
I1130 22:37:41.969466   125 net.cpp:262] Setting up inception_4b/output
I1130 22:37:41.969475   125 net.cpp:269] TRAIN Top shape for layer 84 'inception_4b/output' 10 512 40 40 (8192000)
I1130 22:37:41.969480   125 layer_factory.hpp:172] Creating layer 'inception_4b/output_inception_4b/output_0_split' of type 'Split'
I1130 22:37:41.969486   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.969496   125 net.cpp:202] Created Layer inception_4b/output_inception_4b/output_0_split (85)
I1130 22:37:41.969501   125 net.cpp:574] inception_4b/output_inception_4b/output_0_split <- inception_4b/output
I1130 22:37:41.969507   125 net.cpp:544] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_0
I1130 22:37:41.969516   125 net.cpp:544] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_1
I1130 22:37:41.969525   125 net.cpp:544] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_2
I1130 22:37:41.969534   125 net.cpp:544] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_3
I1130 22:37:41.969611   125 net.cpp:262] Setting up inception_4b/output_inception_4b/output_0_split
I1130 22:37:41.969619   125 net.cpp:269] TRAIN Top shape for layer 85 'inception_4b/output_inception_4b/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.969625   125 net.cpp:269] TRAIN Top shape for layer 85 'inception_4b/output_inception_4b/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.969632   125 net.cpp:269] TRAIN Top shape for layer 85 'inception_4b/output_inception_4b/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.969638   125 net.cpp:269] TRAIN Top shape for layer 85 'inception_4b/output_inception_4b/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.969643   125 layer_factory.hpp:172] Creating layer 'inception_4c/1x1' of type 'Convolution'
I1130 22:37:41.969650   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.969666   125 net.cpp:202] Created Layer inception_4c/1x1 (86)
I1130 22:37:41.969671   125 net.cpp:574] inception_4c/1x1 <- inception_4b/output_inception_4b/output_0_split_0
I1130 22:37:41.969676   125 net.cpp:544] inception_4c/1x1 -> inception_4c/1x1
I1130 22:37:41.970983   125 net.cpp:262] Setting up inception_4c/1x1
I1130 22:37:41.970993   125 net.cpp:269] TRAIN Top shape for layer 86 'inception_4c/1x1' 10 128 40 40 (2048000)
I1130 22:37:41.971002   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_1x1' of type 'ReLU'
I1130 22:37:41.971009   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.971017   125 net.cpp:202] Created Layer inception_4c/relu_1x1 (87)
I1130 22:37:41.971024   125 net.cpp:574] inception_4c/relu_1x1 <- inception_4c/1x1
I1130 22:37:41.971029   125 net.cpp:529] inception_4c/relu_1x1 -> inception_4c/1x1 (in-place)
I1130 22:37:41.971038   125 net.cpp:262] Setting up inception_4c/relu_1x1
I1130 22:37:41.971045   125 net.cpp:269] TRAIN Top shape for layer 87 'inception_4c/relu_1x1' 10 128 40 40 (2048000)
I1130 22:37:41.971061   125 layer_factory.hpp:172] Creating layer 'inception_4c/3x3_reduce' of type 'Convolution'
I1130 22:37:41.971067   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.971083   125 net.cpp:202] Created Layer inception_4c/3x3_reduce (88)
I1130 22:37:41.971089   125 net.cpp:574] inception_4c/3x3_reduce <- inception_4b/output_inception_4b/output_0_split_1
I1130 22:37:41.971096   125 net.cpp:544] inception_4c/3x3_reduce -> inception_4c/3x3_reduce
I1130 22:37:41.972429   125 net.cpp:262] Setting up inception_4c/3x3_reduce
I1130 22:37:41.972440   125 net.cpp:269] TRAIN Top shape for layer 88 'inception_4c/3x3_reduce' 10 128 40 40 (2048000)
I1130 22:37:41.972450   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:41.972457   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.972465   125 net.cpp:202] Created Layer inception_4c/relu_3x3_reduce (89)
I1130 22:37:41.972470   125 net.cpp:574] inception_4c/relu_3x3_reduce <- inception_4c/3x3_reduce
I1130 22:37:41.972477   125 net.cpp:529] inception_4c/relu_3x3_reduce -> inception_4c/3x3_reduce (in-place)
I1130 22:37:41.972487   125 net.cpp:262] Setting up inception_4c/relu_3x3_reduce
I1130 22:37:41.972493   125 net.cpp:269] TRAIN Top shape for layer 89 'inception_4c/relu_3x3_reduce' 10 128 40 40 (2048000)
I1130 22:37:41.972499   125 layer_factory.hpp:172] Creating layer 'inception_4c/3x3' of type 'Convolution'
I1130 22:37:41.972506   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.972522   125 net.cpp:202] Created Layer inception_4c/3x3 (90)
I1130 22:37:41.972527   125 net.cpp:574] inception_4c/3x3 <- inception_4c/3x3_reduce
I1130 22:37:41.972533   125 net.cpp:544] inception_4c/3x3 -> inception_4c/3x3
I1130 22:37:41.977082   125 net.cpp:262] Setting up inception_4c/3x3
I1130 22:37:41.977095   125 net.cpp:269] TRAIN Top shape for layer 90 'inception_4c/3x3' 10 256 40 40 (4096000)
I1130 22:37:41.977104   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_3x3' of type 'ReLU'
I1130 22:37:41.977110   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.977118   125 net.cpp:202] Created Layer inception_4c/relu_3x3 (91)
I1130 22:37:41.977124   125 net.cpp:574] inception_4c/relu_3x3 <- inception_4c/3x3
I1130 22:37:41.977130   125 net.cpp:529] inception_4c/relu_3x3 -> inception_4c/3x3 (in-place)
I1130 22:37:41.977139   125 net.cpp:262] Setting up inception_4c/relu_3x3
I1130 22:37:41.977146   125 net.cpp:269] TRAIN Top shape for layer 91 'inception_4c/relu_3x3' 10 256 40 40 (4096000)
I1130 22:37:41.977152   125 layer_factory.hpp:172] Creating layer 'inception_4c/5x5_reduce' of type 'Convolution'
I1130 22:37:41.977157   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.977174   125 net.cpp:202] Created Layer inception_4c/5x5_reduce (92)
I1130 22:37:41.977180   125 net.cpp:574] inception_4c/5x5_reduce <- inception_4b/output_inception_4b/output_0_split_2
I1130 22:37:41.977186   125 net.cpp:544] inception_4c/5x5_reduce -> inception_4c/5x5_reduce
I1130 22:37:41.977695   125 net.cpp:262] Setting up inception_4c/5x5_reduce
I1130 22:37:41.977705   125 net.cpp:269] TRAIN Top shape for layer 92 'inception_4c/5x5_reduce' 10 24 40 40 (384000)
I1130 22:37:41.977715   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:41.977720   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.977730   125 net.cpp:202] Created Layer inception_4c/relu_5x5_reduce (93)
I1130 22:37:41.977735   125 net.cpp:574] inception_4c/relu_5x5_reduce <- inception_4c/5x5_reduce
I1130 22:37:41.977741   125 net.cpp:529] inception_4c/relu_5x5_reduce -> inception_4c/5x5_reduce (in-place)
I1130 22:37:41.977751   125 net.cpp:262] Setting up inception_4c/relu_5x5_reduce
I1130 22:37:41.977768   125 net.cpp:269] TRAIN Top shape for layer 93 'inception_4c/relu_5x5_reduce' 10 24 40 40 (384000)
I1130 22:37:41.977774   125 layer_factory.hpp:172] Creating layer 'inception_4c/5x5' of type 'Convolution'
I1130 22:37:41.977780   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.977797   125 net.cpp:202] Created Layer inception_4c/5x5 (94)
I1130 22:37:41.977802   125 net.cpp:574] inception_4c/5x5 <- inception_4c/5x5_reduce
I1130 22:37:41.977807   125 net.cpp:544] inception_4c/5x5 -> inception_4c/5x5
I1130 22:37:41.979950   125 net.cpp:262] Setting up inception_4c/5x5
I1130 22:37:41.979966   125 net.cpp:269] TRAIN Top shape for layer 94 'inception_4c/5x5' 10 64 40 40 (1024000)
I1130 22:37:41.979976   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_5x5' of type 'ReLU'
I1130 22:37:41.979982   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.979991   125 net.cpp:202] Created Layer inception_4c/relu_5x5 (95)
I1130 22:37:41.979998   125 net.cpp:574] inception_4c/relu_5x5 <- inception_4c/5x5
I1130 22:37:41.980005   125 net.cpp:529] inception_4c/relu_5x5 -> inception_4c/5x5 (in-place)
I1130 22:37:41.980013   125 net.cpp:262] Setting up inception_4c/relu_5x5
I1130 22:37:41.980021   125 net.cpp:269] TRAIN Top shape for layer 95 'inception_4c/relu_5x5' 10 64 40 40 (1024000)
I1130 22:37:41.980027   125 layer_factory.hpp:172] Creating layer 'inception_4c/pool' of type 'Pooling'
I1130 22:37:41.980032   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.980044   125 net.cpp:202] Created Layer inception_4c/pool (96)
I1130 22:37:41.980049   125 net.cpp:574] inception_4c/pool <- inception_4b/output_inception_4b/output_0_split_3
I1130 22:37:41.980057   125 net.cpp:544] inception_4c/pool -> inception_4c/pool
I1130 22:37:41.980132   125 net.cpp:262] Setting up inception_4c/pool
I1130 22:37:41.980140   125 net.cpp:269] TRAIN Top shape for layer 96 'inception_4c/pool' 10 512 40 40 (8192000)
I1130 22:37:41.980147   125 layer_factory.hpp:172] Creating layer 'inception_4c/pool_proj' of type 'Convolution'
I1130 22:37:41.980152   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.980170   125 net.cpp:202] Created Layer inception_4c/pool_proj (97)
I1130 22:37:41.980175   125 net.cpp:574] inception_4c/pool_proj <- inception_4c/pool
I1130 22:37:41.980182   125 net.cpp:544] inception_4c/pool_proj -> inception_4c/pool_proj
I1130 22:37:41.980979   125 net.cpp:262] Setting up inception_4c/pool_proj
I1130 22:37:41.980989   125 net.cpp:269] TRAIN Top shape for layer 97 'inception_4c/pool_proj' 10 64 40 40 (1024000)
I1130 22:37:41.981011   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_pool_proj' of type 'ReLU'
I1130 22:37:41.981019   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.981027   125 net.cpp:202] Created Layer inception_4c/relu_pool_proj (98)
I1130 22:37:41.981034   125 net.cpp:574] inception_4c/relu_pool_proj <- inception_4c/pool_proj
I1130 22:37:41.981040   125 net.cpp:529] inception_4c/relu_pool_proj -> inception_4c/pool_proj (in-place)
I1130 22:37:41.981047   125 net.cpp:262] Setting up inception_4c/relu_pool_proj
I1130 22:37:41.981055   125 net.cpp:269] TRAIN Top shape for layer 98 'inception_4c/relu_pool_proj' 10 64 40 40 (1024000)
I1130 22:37:41.981060   125 layer_factory.hpp:172] Creating layer 'inception_4c/output' of type 'Concat'
I1130 22:37:41.981066   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.981075   125 net.cpp:202] Created Layer inception_4c/output (99)
I1130 22:37:41.981081   125 net.cpp:574] inception_4c/output <- inception_4c/1x1
I1130 22:37:41.981086   125 net.cpp:574] inception_4c/output <- inception_4c/3x3
I1130 22:37:41.981091   125 net.cpp:574] inception_4c/output <- inception_4c/5x5
I1130 22:37:41.981097   125 net.cpp:574] inception_4c/output <- inception_4c/pool_proj
I1130 22:37:41.981115   125 net.cpp:544] inception_4c/output -> inception_4c/output
I1130 22:37:41.981153   125 net.cpp:262] Setting up inception_4c/output
I1130 22:37:41.981160   125 net.cpp:269] TRAIN Top shape for layer 99 'inception_4c/output' 10 512 40 40 (8192000)
I1130 22:37:41.981168   125 layer_factory.hpp:172] Creating layer 'inception_4c/output_inception_4c/output_0_split' of type 'Split'
I1130 22:37:41.981173   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.981182   125 net.cpp:202] Created Layer inception_4c/output_inception_4c/output_0_split (100)
I1130 22:37:41.981187   125 net.cpp:574] inception_4c/output_inception_4c/output_0_split <- inception_4c/output
I1130 22:37:41.981194   125 net.cpp:544] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_0
I1130 22:37:41.981204   125 net.cpp:544] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_1
I1130 22:37:41.981210   125 net.cpp:544] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_2
I1130 22:37:41.981217   125 net.cpp:544] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_3
I1130 22:37:41.981294   125 net.cpp:262] Setting up inception_4c/output_inception_4c/output_0_split
I1130 22:37:41.981302   125 net.cpp:269] TRAIN Top shape for layer 100 'inception_4c/output_inception_4c/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.981308   125 net.cpp:269] TRAIN Top shape for layer 100 'inception_4c/output_inception_4c/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.981314   125 net.cpp:269] TRAIN Top shape for layer 100 'inception_4c/output_inception_4c/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.981321   125 net.cpp:269] TRAIN Top shape for layer 100 'inception_4c/output_inception_4c/output_0_split' 10 512 40 40 (8192000)
I1130 22:37:41.981328   125 layer_factory.hpp:172] Creating layer 'inception_4d/1x1' of type 'Convolution'
I1130 22:37:41.981333   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.981350   125 net.cpp:202] Created Layer inception_4d/1x1 (101)
I1130 22:37:41.981356   125 net.cpp:574] inception_4d/1x1 <- inception_4c/output_inception_4c/output_0_split_0
I1130 22:37:41.981364   125 net.cpp:544] inception_4d/1x1 -> inception_4d/1x1
I1130 22:37:41.982512   125 net.cpp:262] Setting up inception_4d/1x1
I1130 22:37:41.982523   125 net.cpp:269] TRAIN Top shape for layer 101 'inception_4d/1x1' 10 112 40 40 (1792000)
I1130 22:37:41.982533   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_1x1' of type 'ReLU'
I1130 22:37:41.982539   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.982547   125 net.cpp:202] Created Layer inception_4d/relu_1x1 (102)
I1130 22:37:41.982553   125 net.cpp:574] inception_4d/relu_1x1 <- inception_4d/1x1
I1130 22:37:41.982559   125 net.cpp:529] inception_4d/relu_1x1 -> inception_4d/1x1 (in-place)
I1130 22:37:41.982569   125 net.cpp:262] Setting up inception_4d/relu_1x1
I1130 22:37:41.982576   125 net.cpp:269] TRAIN Top shape for layer 102 'inception_4d/relu_1x1' 10 112 40 40 (1792000)
I1130 22:37:41.982583   125 layer_factory.hpp:172] Creating layer 'inception_4d/3x3_reduce' of type 'Convolution'
I1130 22:37:41.982589   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.982604   125 net.cpp:202] Created Layer inception_4d/3x3_reduce (103)
I1130 22:37:41.982609   125 net.cpp:574] inception_4d/3x3_reduce <- inception_4c/output_inception_4c/output_0_split_1
I1130 22:37:41.982615   125 net.cpp:544] inception_4d/3x3_reduce -> inception_4d/3x3_reduce
I1130 22:37:41.985221   125 net.cpp:262] Setting up inception_4d/3x3_reduce
I1130 22:37:41.985237   125 net.cpp:269] TRAIN Top shape for layer 103 'inception_4d/3x3_reduce' 10 144 40 40 (2304000)
I1130 22:37:41.985260   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:41.985266   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.985275   125 net.cpp:202] Created Layer inception_4d/relu_3x3_reduce (104)
I1130 22:37:41.985282   125 net.cpp:574] inception_4d/relu_3x3_reduce <- inception_4d/3x3_reduce
I1130 22:37:41.985288   125 net.cpp:529] inception_4d/relu_3x3_reduce -> inception_4d/3x3_reduce (in-place)
I1130 22:37:41.985298   125 net.cpp:262] Setting up inception_4d/relu_3x3_reduce
I1130 22:37:41.985306   125 net.cpp:269] TRAIN Top shape for layer 104 'inception_4d/relu_3x3_reduce' 10 144 40 40 (2304000)
I1130 22:37:41.985312   125 layer_factory.hpp:172] Creating layer 'inception_4d/3x3' of type 'Convolution'
I1130 22:37:41.985318   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.985335   125 net.cpp:202] Created Layer inception_4d/3x3 (105)
I1130 22:37:41.985340   125 net.cpp:574] inception_4d/3x3 <- inception_4d/3x3_reduce
I1130 22:37:41.985347   125 net.cpp:544] inception_4d/3x3 -> inception_4d/3x3
I1130 22:37:41.992296   125 net.cpp:262] Setting up inception_4d/3x3
I1130 22:37:41.992311   125 net.cpp:269] TRAIN Top shape for layer 105 'inception_4d/3x3' 10 288 40 40 (4608000)
I1130 22:37:41.992322   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_3x3' of type 'ReLU'
I1130 22:37:41.992331   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.992338   125 net.cpp:202] Created Layer inception_4d/relu_3x3 (106)
I1130 22:37:41.992344   125 net.cpp:574] inception_4d/relu_3x3 <- inception_4d/3x3
I1130 22:37:41.992352   125 net.cpp:529] inception_4d/relu_3x3 -> inception_4d/3x3 (in-place)
I1130 22:37:41.992362   125 net.cpp:262] Setting up inception_4d/relu_3x3
I1130 22:37:41.992368   125 net.cpp:269] TRAIN Top shape for layer 106 'inception_4d/relu_3x3' 10 288 40 40 (4608000)
I1130 22:37:41.992374   125 layer_factory.hpp:172] Creating layer 'inception_4d/5x5_reduce' of type 'Convolution'
I1130 22:37:41.992380   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.992398   125 net.cpp:202] Created Layer inception_4d/5x5_reduce (107)
I1130 22:37:41.992403   125 net.cpp:574] inception_4d/5x5_reduce <- inception_4c/output_inception_4c/output_0_split_2
I1130 22:37:41.992409   125 net.cpp:544] inception_4d/5x5_reduce -> inception_4d/5x5_reduce
I1130 22:37:41.992995   125 net.cpp:262] Setting up inception_4d/5x5_reduce
I1130 22:37:41.993005   125 net.cpp:269] TRAIN Top shape for layer 107 'inception_4d/5x5_reduce' 10 32 40 40 (512000)
I1130 22:37:41.993014   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:41.993021   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.993029   125 net.cpp:202] Created Layer inception_4d/relu_5x5_reduce (108)
I1130 22:37:41.993036   125 net.cpp:574] inception_4d/relu_5x5_reduce <- inception_4d/5x5_reduce
I1130 22:37:41.993041   125 net.cpp:529] inception_4d/relu_5x5_reduce -> inception_4d/5x5_reduce (in-place)
I1130 22:37:41.993049   125 net.cpp:262] Setting up inception_4d/relu_5x5_reduce
I1130 22:37:41.993057   125 net.cpp:269] TRAIN Top shape for layer 108 'inception_4d/relu_5x5_reduce' 10 32 40 40 (512000)
I1130 22:37:41.993063   125 layer_factory.hpp:172] Creating layer 'inception_4d/5x5' of type 'Convolution'
I1130 22:37:41.993068   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.993085   125 net.cpp:202] Created Layer inception_4d/5x5 (109)
I1130 22:37:41.993090   125 net.cpp:574] inception_4d/5x5 <- inception_4d/5x5_reduce
I1130 22:37:41.993096   125 net.cpp:544] inception_4d/5x5 -> inception_4d/5x5
I1130 22:37:41.994163   125 net.cpp:262] Setting up inception_4d/5x5
I1130 22:37:41.994172   125 net.cpp:269] TRAIN Top shape for layer 109 'inception_4d/5x5' 10 64 40 40 (1024000)
I1130 22:37:41.994194   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_5x5' of type 'ReLU'
I1130 22:37:41.994200   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.994210   125 net.cpp:202] Created Layer inception_4d/relu_5x5 (110)
I1130 22:37:41.994215   125 net.cpp:574] inception_4d/relu_5x5 <- inception_4d/5x5
I1130 22:37:41.994221   125 net.cpp:529] inception_4d/relu_5x5 -> inception_4d/5x5 (in-place)
I1130 22:37:41.994230   125 net.cpp:262] Setting up inception_4d/relu_5x5
I1130 22:37:41.994236   125 net.cpp:269] TRAIN Top shape for layer 110 'inception_4d/relu_5x5' 10 64 40 40 (1024000)
I1130 22:37:41.994242   125 layer_factory.hpp:172] Creating layer 'inception_4d/pool' of type 'Pooling'
I1130 22:37:41.994248   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.994261   125 net.cpp:202] Created Layer inception_4d/pool (111)
I1130 22:37:41.994266   125 net.cpp:574] inception_4d/pool <- inception_4c/output_inception_4c/output_0_split_3
I1130 22:37:41.994271   125 net.cpp:544] inception_4d/pool -> inception_4d/pool
I1130 22:37:41.994346   125 net.cpp:262] Setting up inception_4d/pool
I1130 22:37:41.994356   125 net.cpp:269] TRAIN Top shape for layer 111 'inception_4d/pool' 10 512 40 40 (8192000)
I1130 22:37:41.994362   125 layer_factory.hpp:172] Creating layer 'inception_4d/pool_proj' of type 'Convolution'
I1130 22:37:41.994367   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.994383   125 net.cpp:202] Created Layer inception_4d/pool_proj (112)
I1130 22:37:41.994390   125 net.cpp:574] inception_4d/pool_proj <- inception_4d/pool
I1130 22:37:41.994395   125 net.cpp:544] inception_4d/pool_proj -> inception_4d/pool_proj
I1130 22:37:41.995195   125 net.cpp:262] Setting up inception_4d/pool_proj
I1130 22:37:41.995205   125 net.cpp:269] TRAIN Top shape for layer 112 'inception_4d/pool_proj' 10 64 40 40 (1024000)
I1130 22:37:41.995215   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_pool_proj' of type 'ReLU'
I1130 22:37:41.995220   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.995229   125 net.cpp:202] Created Layer inception_4d/relu_pool_proj (113)
I1130 22:37:41.995235   125 net.cpp:574] inception_4d/relu_pool_proj <- inception_4d/pool_proj
I1130 22:37:41.995241   125 net.cpp:529] inception_4d/relu_pool_proj -> inception_4d/pool_proj (in-place)
I1130 22:37:41.995249   125 net.cpp:262] Setting up inception_4d/relu_pool_proj
I1130 22:37:41.995256   125 net.cpp:269] TRAIN Top shape for layer 113 'inception_4d/relu_pool_proj' 10 64 40 40 (1024000)
I1130 22:37:41.995262   125 layer_factory.hpp:172] Creating layer 'inception_4d/output' of type 'Concat'
I1130 22:37:41.995268   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.995277   125 net.cpp:202] Created Layer inception_4d/output (114)
I1130 22:37:41.995282   125 net.cpp:574] inception_4d/output <- inception_4d/1x1
I1130 22:37:41.995288   125 net.cpp:574] inception_4d/output <- inception_4d/3x3
I1130 22:37:41.995295   125 net.cpp:574] inception_4d/output <- inception_4d/5x5
I1130 22:37:41.995299   125 net.cpp:574] inception_4d/output <- inception_4d/pool_proj
I1130 22:37:41.995306   125 net.cpp:544] inception_4d/output -> inception_4d/output
I1130 22:37:41.995342   125 net.cpp:262] Setting up inception_4d/output
I1130 22:37:41.995349   125 net.cpp:269] TRAIN Top shape for layer 114 'inception_4d/output' 10 528 40 40 (8448000)
I1130 22:37:41.995355   125 layer_factory.hpp:172] Creating layer 'inception_4d/output_inception_4d/output_0_split' of type 'Split'
I1130 22:37:41.995360   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.995371   125 net.cpp:202] Created Layer inception_4d/output_inception_4d/output_0_split (115)
I1130 22:37:41.995378   125 net.cpp:574] inception_4d/output_inception_4d/output_0_split <- inception_4d/output
I1130 22:37:41.995395   125 net.cpp:544] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_0
I1130 22:37:41.995404   125 net.cpp:544] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_1
I1130 22:37:41.995414   125 net.cpp:544] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_2
I1130 22:37:41.995422   125 net.cpp:544] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_3
I1130 22:37:41.995501   125 net.cpp:262] Setting up inception_4d/output_inception_4d/output_0_split
I1130 22:37:41.995509   125 net.cpp:269] TRAIN Top shape for layer 115 'inception_4d/output_inception_4d/output_0_split' 10 528 40 40 (8448000)
I1130 22:37:41.995517   125 net.cpp:269] TRAIN Top shape for layer 115 'inception_4d/output_inception_4d/output_0_split' 10 528 40 40 (8448000)
I1130 22:37:41.995522   125 net.cpp:269] TRAIN Top shape for layer 115 'inception_4d/output_inception_4d/output_0_split' 10 528 40 40 (8448000)
I1130 22:37:41.995528   125 net.cpp:269] TRAIN Top shape for layer 115 'inception_4d/output_inception_4d/output_0_split' 10 528 40 40 (8448000)
I1130 22:37:41.995533   125 layer_factory.hpp:172] Creating layer 'inception_4e/1x1' of type 'Convolution'
I1130 22:37:41.995540   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.995556   125 net.cpp:202] Created Layer inception_4e/1x1 (116)
I1130 22:37:41.995563   125 net.cpp:574] inception_4e/1x1 <- inception_4d/output_inception_4d/output_0_split_0
I1130 22:37:41.995568   125 net.cpp:544] inception_4e/1x1 -> inception_4e/1x1
I1130 22:37:41.999029   125 net.cpp:262] Setting up inception_4e/1x1
I1130 22:37:41.999045   125 net.cpp:269] TRAIN Top shape for layer 116 'inception_4e/1x1' 10 256 40 40 (4096000)
I1130 22:37:41.999055   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_1x1' of type 'ReLU'
I1130 22:37:41.999061   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.999071   125 net.cpp:202] Created Layer inception_4e/relu_1x1 (117)
I1130 22:37:41.999078   125 net.cpp:574] inception_4e/relu_1x1 <- inception_4e/1x1
I1130 22:37:41.999083   125 net.cpp:529] inception_4e/relu_1x1 -> inception_4e/1x1 (in-place)
I1130 22:37:41.999094   125 net.cpp:262] Setting up inception_4e/relu_1x1
I1130 22:37:41.999100   125 net.cpp:269] TRAIN Top shape for layer 117 'inception_4e/relu_1x1' 10 256 40 40 (4096000)
I1130 22:37:41.999106   125 layer_factory.hpp:172] Creating layer 'inception_4e/3x3_reduce' of type 'Convolution'
I1130 22:37:41.999112   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:41.999127   125 net.cpp:202] Created Layer inception_4e/3x3_reduce (118)
I1130 22:37:41.999133   125 net.cpp:574] inception_4e/3x3_reduce <- inception_4d/output_inception_4d/output_0_split_1
I1130 22:37:41.999140   125 net.cpp:544] inception_4e/3x3_reduce -> inception_4e/3x3_reduce
I1130 22:37:42.000710   125 net.cpp:262] Setting up inception_4e/3x3_reduce
I1130 22:37:42.000721   125 net.cpp:269] TRAIN Top shape for layer 118 'inception_4e/3x3_reduce' 10 160 40 40 (2560000)
I1130 22:37:42.000731   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.000737   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.000746   125 net.cpp:202] Created Layer inception_4e/relu_3x3_reduce (119)
I1130 22:37:42.000751   125 net.cpp:574] inception_4e/relu_3x3_reduce <- inception_4e/3x3_reduce
I1130 22:37:42.000757   125 net.cpp:529] inception_4e/relu_3x3_reduce -> inception_4e/3x3_reduce (in-place)
I1130 22:37:42.000767   125 net.cpp:262] Setting up inception_4e/relu_3x3_reduce
I1130 22:37:42.000774   125 net.cpp:269] TRAIN Top shape for layer 119 'inception_4e/relu_3x3_reduce' 10 160 40 40 (2560000)
I1130 22:37:42.000792   125 layer_factory.hpp:172] Creating layer 'inception_4e/3x3' of type 'Convolution'
I1130 22:37:42.000798   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.000816   125 net.cpp:202] Created Layer inception_4e/3x3 (120)
I1130 22:37:42.000821   125 net.cpp:574] inception_4e/3x3 <- inception_4e/3x3_reduce
I1130 22:37:42.000826   125 net.cpp:544] inception_4e/3x3 -> inception_4e/3x3
I1130 22:37:42.008951   125 net.cpp:262] Setting up inception_4e/3x3
I1130 22:37:42.008968   125 net.cpp:269] TRAIN Top shape for layer 120 'inception_4e/3x3' 10 320 40 40 (5120000)
I1130 22:37:42.008977   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_3x3' of type 'ReLU'
I1130 22:37:42.008985   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.008993   125 net.cpp:202] Created Layer inception_4e/relu_3x3 (121)
I1130 22:37:42.008999   125 net.cpp:574] inception_4e/relu_3x3 <- inception_4e/3x3
I1130 22:37:42.009006   125 net.cpp:529] inception_4e/relu_3x3 -> inception_4e/3x3 (in-place)
I1130 22:37:42.009016   125 net.cpp:262] Setting up inception_4e/relu_3x3
I1130 22:37:42.009022   125 net.cpp:269] TRAIN Top shape for layer 121 'inception_4e/relu_3x3' 10 320 40 40 (5120000)
I1130 22:37:42.009029   125 layer_factory.hpp:172] Creating layer 'inception_4e/5x5_reduce' of type 'Convolution'
I1130 22:37:42.009034   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.009050   125 net.cpp:202] Created Layer inception_4e/5x5_reduce (122)
I1130 22:37:42.009057   125 net.cpp:574] inception_4e/5x5_reduce <- inception_4d/output_inception_4d/output_0_split_2
I1130 22:37:42.009063   125 net.cpp:544] inception_4e/5x5_reduce -> inception_4e/5x5_reduce
I1130 22:37:42.009649   125 net.cpp:262] Setting up inception_4e/5x5_reduce
I1130 22:37:42.009660   125 net.cpp:269] TRAIN Top shape for layer 122 'inception_4e/5x5_reduce' 10 32 40 40 (512000)
I1130 22:37:42.009670   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.009675   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.009685   125 net.cpp:202] Created Layer inception_4e/relu_5x5_reduce (123)
I1130 22:37:42.009690   125 net.cpp:574] inception_4e/relu_5x5_reduce <- inception_4e/5x5_reduce
I1130 22:37:42.009697   125 net.cpp:529] inception_4e/relu_5x5_reduce -> inception_4e/5x5_reduce (in-place)
I1130 22:37:42.009706   125 net.cpp:262] Setting up inception_4e/relu_5x5_reduce
I1130 22:37:42.009713   125 net.cpp:269] TRAIN Top shape for layer 123 'inception_4e/relu_5x5_reduce' 10 32 40 40 (512000)
I1130 22:37:42.009719   125 layer_factory.hpp:172] Creating layer 'inception_4e/5x5' of type 'Convolution'
I1130 22:37:42.009726   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.009742   125 net.cpp:202] Created Layer inception_4e/5x5 (124)
I1130 22:37:42.009747   125 net.cpp:574] inception_4e/5x5 <- inception_4e/5x5_reduce
I1130 22:37:42.009752   125 net.cpp:544] inception_4e/5x5 -> inception_4e/5x5
I1130 22:37:42.011545   125 net.cpp:262] Setting up inception_4e/5x5
I1130 22:37:42.011557   125 net.cpp:269] TRAIN Top shape for layer 124 'inception_4e/5x5' 10 128 40 40 (2048000)
I1130 22:37:42.011566   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_5x5' of type 'ReLU'
I1130 22:37:42.011572   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.011582   125 net.cpp:202] Created Layer inception_4e/relu_5x5 (125)
I1130 22:37:42.011588   125 net.cpp:574] inception_4e/relu_5x5 <- inception_4e/5x5
I1130 22:37:42.011595   125 net.cpp:529] inception_4e/relu_5x5 -> inception_4e/5x5 (in-place)
I1130 22:37:42.011603   125 net.cpp:262] Setting up inception_4e/relu_5x5
I1130 22:37:42.011610   125 net.cpp:269] TRAIN Top shape for layer 125 'inception_4e/relu_5x5' 10 128 40 40 (2048000)
I1130 22:37:42.011631   125 layer_factory.hpp:172] Creating layer 'inception_4e/pool' of type 'Pooling'
I1130 22:37:42.011637   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.011649   125 net.cpp:202] Created Layer inception_4e/pool (126)
I1130 22:37:42.011656   125 net.cpp:574] inception_4e/pool <- inception_4d/output_inception_4d/output_0_split_3
I1130 22:37:42.011662   125 net.cpp:544] inception_4e/pool -> inception_4e/pool
I1130 22:37:42.011739   125 net.cpp:262] Setting up inception_4e/pool
I1130 22:37:42.011749   125 net.cpp:269] TRAIN Top shape for layer 126 'inception_4e/pool' 10 528 40 40 (8448000)
I1130 22:37:42.011755   125 layer_factory.hpp:172] Creating layer 'inception_4e/pool_proj' of type 'Convolution'
I1130 22:37:42.011761   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.011776   125 net.cpp:202] Created Layer inception_4e/pool_proj (127)
I1130 22:37:42.011782   125 net.cpp:574] inception_4e/pool_proj <- inception_4e/pool
I1130 22:37:42.011790   125 net.cpp:544] inception_4e/pool_proj -> inception_4e/pool_proj
I1130 22:37:42.013129   125 net.cpp:262] Setting up inception_4e/pool_proj
I1130 22:37:42.013141   125 net.cpp:269] TRAIN Top shape for layer 127 'inception_4e/pool_proj' 10 128 40 40 (2048000)
I1130 22:37:42.013150   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.013157   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.013175   125 net.cpp:202] Created Layer inception_4e/relu_pool_proj (128)
I1130 22:37:42.013181   125 net.cpp:574] inception_4e/relu_pool_proj <- inception_4e/pool_proj
I1130 22:37:42.013188   125 net.cpp:529] inception_4e/relu_pool_proj -> inception_4e/pool_proj (in-place)
I1130 22:37:42.013197   125 net.cpp:262] Setting up inception_4e/relu_pool_proj
I1130 22:37:42.013204   125 net.cpp:269] TRAIN Top shape for layer 128 'inception_4e/relu_pool_proj' 10 128 40 40 (2048000)
I1130 22:37:42.013211   125 layer_factory.hpp:172] Creating layer 'inception_4e/output' of type 'Concat'
I1130 22:37:42.013216   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.013226   125 net.cpp:202] Created Layer inception_4e/output (129)
I1130 22:37:42.013231   125 net.cpp:574] inception_4e/output <- inception_4e/1x1
I1130 22:37:42.013236   125 net.cpp:574] inception_4e/output <- inception_4e/3x3
I1130 22:37:42.013242   125 net.cpp:574] inception_4e/output <- inception_4e/5x5
I1130 22:37:42.013248   125 net.cpp:574] inception_4e/output <- inception_4e/pool_proj
I1130 22:37:42.013254   125 net.cpp:544] inception_4e/output -> inception_4e/output
I1130 22:37:42.013288   125 net.cpp:262] Setting up inception_4e/output
I1130 22:37:42.013296   125 net.cpp:269] TRAIN Top shape for layer 129 'inception_4e/output' 10 832 40 40 (13312000)
I1130 22:37:42.013303   125 layer_factory.hpp:172] Creating layer 'inception_4e/output_inception_4e/output_0_split' of type 'Split'
I1130 22:37:42.013309   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.013316   125 net.cpp:202] Created Layer inception_4e/output_inception_4e/output_0_split (130)
I1130 22:37:42.013322   125 net.cpp:574] inception_4e/output_inception_4e/output_0_split <- inception_4e/output
I1130 22:37:42.013329   125 net.cpp:544] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_0
I1130 22:37:42.013339   125 net.cpp:544] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_1
I1130 22:37:42.013347   125 net.cpp:544] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_2
I1130 22:37:42.013355   125 net.cpp:544] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_3
I1130 22:37:42.013432   125 net.cpp:262] Setting up inception_4e/output_inception_4e/output_0_split
I1130 22:37:42.013453   125 net.cpp:269] TRAIN Top shape for layer 130 'inception_4e/output_inception_4e/output_0_split' 10 832 40 40 (13312000)
I1130 22:37:42.013460   125 net.cpp:269] TRAIN Top shape for layer 130 'inception_4e/output_inception_4e/output_0_split' 10 832 40 40 (13312000)
I1130 22:37:42.013466   125 net.cpp:269] TRAIN Top shape for layer 130 'inception_4e/output_inception_4e/output_0_split' 10 832 40 40 (13312000)
I1130 22:37:42.013473   125 net.cpp:269] TRAIN Top shape for layer 130 'inception_4e/output_inception_4e/output_0_split' 10 832 40 40 (13312000)
I1130 22:37:42.013479   125 layer_factory.hpp:172] Creating layer 'inception_5a/1x1' of type 'Convolution'
I1130 22:37:42.013484   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.013500   125 net.cpp:202] Created Layer inception_5a/1x1 (131)
I1130 22:37:42.013506   125 net.cpp:574] inception_5a/1x1 <- inception_4e/output_inception_4e/output_0_split_0
I1130 22:37:42.013514   125 net.cpp:544] inception_5a/1x1 -> inception_5a/1x1
I1130 22:37:42.018087   125 net.cpp:262] Setting up inception_5a/1x1
I1130 22:37:42.018102   125 net.cpp:269] TRAIN Top shape for layer 131 'inception_5a/1x1' 10 256 40 40 (4096000)
I1130 22:37:42.018113   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_1x1' of type 'ReLU'
I1130 22:37:42.018121   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.018129   125 net.cpp:202] Created Layer inception_5a/relu_1x1 (132)
I1130 22:37:42.018136   125 net.cpp:574] inception_5a/relu_1x1 <- inception_5a/1x1
I1130 22:37:42.018142   125 net.cpp:529] inception_5a/relu_1x1 -> inception_5a/1x1 (in-place)
I1130 22:37:42.018152   125 net.cpp:262] Setting up inception_5a/relu_1x1
I1130 22:37:42.018159   125 net.cpp:269] TRAIN Top shape for layer 132 'inception_5a/relu_1x1' 10 256 40 40 (4096000)
I1130 22:37:42.018167   125 layer_factory.hpp:172] Creating layer 'inception_5a/3x3_reduce' of type 'Convolution'
I1130 22:37:42.018172   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.018188   125 net.cpp:202] Created Layer inception_5a/3x3_reduce (133)
I1130 22:37:42.018194   125 net.cpp:574] inception_5a/3x3_reduce <- inception_4e/output_inception_4e/output_0_split_1
I1130 22:37:42.018201   125 net.cpp:544] inception_5a/3x3_reduce -> inception_5a/3x3_reduce
I1130 22:37:42.020593   125 net.cpp:262] Setting up inception_5a/3x3_reduce
I1130 22:37:42.020606   125 net.cpp:269] TRAIN Top shape for layer 133 'inception_5a/3x3_reduce' 10 160 40 40 (2560000)
I1130 22:37:42.020615   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.020622   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.020630   125 net.cpp:202] Created Layer inception_5a/relu_3x3_reduce (134)
I1130 22:37:42.020637   125 net.cpp:574] inception_5a/relu_3x3_reduce <- inception_5a/3x3_reduce
I1130 22:37:42.020642   125 net.cpp:529] inception_5a/relu_3x3_reduce -> inception_5a/3x3_reduce (in-place)
I1130 22:37:42.020651   125 net.cpp:262] Setting up inception_5a/relu_3x3_reduce
I1130 22:37:42.020659   125 net.cpp:269] TRAIN Top shape for layer 134 'inception_5a/relu_3x3_reduce' 10 160 40 40 (2560000)
I1130 22:37:42.020665   125 layer_factory.hpp:172] Creating layer 'inception_5a/3x3' of type 'Convolution'
I1130 22:37:42.020671   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.020689   125 net.cpp:202] Created Layer inception_5a/3x3 (135)
I1130 22:37:42.020694   125 net.cpp:574] inception_5a/3x3 <- inception_5a/3x3_reduce
I1130 22:37:42.020699   125 net.cpp:544] inception_5a/3x3 -> inception_5a/3x3
I1130 22:37:42.028841   125 net.cpp:262] Setting up inception_5a/3x3
I1130 22:37:42.028857   125 net.cpp:269] TRAIN Top shape for layer 135 'inception_5a/3x3' 10 320 40 40 (5120000)
I1130 22:37:42.028882   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_3x3' of type 'ReLU'
I1130 22:37:42.028888   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.028898   125 net.cpp:202] Created Layer inception_5a/relu_3x3 (136)
I1130 22:37:42.028903   125 net.cpp:574] inception_5a/relu_3x3 <- inception_5a/3x3
I1130 22:37:42.028911   125 net.cpp:529] inception_5a/relu_3x3 -> inception_5a/3x3 (in-place)
I1130 22:37:42.028920   125 net.cpp:262] Setting up inception_5a/relu_3x3
I1130 22:37:42.028928   125 net.cpp:269] TRAIN Top shape for layer 136 'inception_5a/relu_3x3' 10 320 40 40 (5120000)
I1130 22:37:42.028934   125 layer_factory.hpp:172] Creating layer 'inception_5a/5x5_reduce' of type 'Convolution'
I1130 22:37:42.028939   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.028957   125 net.cpp:202] Created Layer inception_5a/5x5_reduce (137)
I1130 22:37:42.028966   125 net.cpp:574] inception_5a/5x5_reduce <- inception_4e/output_inception_4e/output_0_split_2
I1130 22:37:42.028973   125 net.cpp:544] inception_5a/5x5_reduce -> inception_5a/5x5_reduce
I1130 22:37:42.029716   125 net.cpp:262] Setting up inception_5a/5x5_reduce
I1130 22:37:42.029726   125 net.cpp:269] TRAIN Top shape for layer 137 'inception_5a/5x5_reduce' 10 32 40 40 (512000)
I1130 22:37:42.029736   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.029742   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.029750   125 net.cpp:202] Created Layer inception_5a/relu_5x5_reduce (138)
I1130 22:37:42.029757   125 net.cpp:574] inception_5a/relu_5x5_reduce <- inception_5a/5x5_reduce
I1130 22:37:42.029763   125 net.cpp:529] inception_5a/relu_5x5_reduce -> inception_5a/5x5_reduce (in-place)
I1130 22:37:42.029772   125 net.cpp:262] Setting up inception_5a/relu_5x5_reduce
I1130 22:37:42.029779   125 net.cpp:269] TRAIN Top shape for layer 138 'inception_5a/relu_5x5_reduce' 10 32 40 40 (512000)
I1130 22:37:42.029786   125 layer_factory.hpp:172] Creating layer 'inception_5a/5x5' of type 'Convolution'
I1130 22:37:42.029791   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.029808   125 net.cpp:202] Created Layer inception_5a/5x5 (139)
I1130 22:37:42.029814   125 net.cpp:574] inception_5a/5x5 <- inception_5a/5x5_reduce
I1130 22:37:42.029819   125 net.cpp:544] inception_5a/5x5 -> inception_5a/5x5
I1130 22:37:42.031731   125 net.cpp:262] Setting up inception_5a/5x5
I1130 22:37:42.031744   125 net.cpp:269] TRAIN Top shape for layer 139 'inception_5a/5x5' 10 128 40 40 (2048000)
I1130 22:37:42.031754   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_5x5' of type 'ReLU'
I1130 22:37:42.031761   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.031769   125 net.cpp:202] Created Layer inception_5a/relu_5x5 (140)
I1130 22:37:42.031775   125 net.cpp:574] inception_5a/relu_5x5 <- inception_5a/5x5
I1130 22:37:42.031781   125 net.cpp:529] inception_5a/relu_5x5 -> inception_5a/5x5 (in-place)
I1130 22:37:42.031790   125 net.cpp:262] Setting up inception_5a/relu_5x5
I1130 22:37:42.031796   125 net.cpp:269] TRAIN Top shape for layer 140 'inception_5a/relu_5x5' 10 128 40 40 (2048000)
I1130 22:37:42.031802   125 layer_factory.hpp:172] Creating layer 'inception_5a/pool' of type 'Pooling'
I1130 22:37:42.031808   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.031821   125 net.cpp:202] Created Layer inception_5a/pool (141)
I1130 22:37:42.031826   125 net.cpp:574] inception_5a/pool <- inception_4e/output_inception_4e/output_0_split_3
I1130 22:37:42.031831   125 net.cpp:544] inception_5a/pool -> inception_5a/pool
I1130 22:37:42.031905   125 net.cpp:262] Setting up inception_5a/pool
I1130 22:37:42.031931   125 net.cpp:269] TRAIN Top shape for layer 141 'inception_5a/pool' 10 832 40 40 (13312000)
I1130 22:37:42.031950   125 layer_factory.hpp:172] Creating layer 'inception_5a/pool_proj' of type 'Convolution'
I1130 22:37:42.031956   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.031972   125 net.cpp:202] Created Layer inception_5a/pool_proj (142)
I1130 22:37:42.031978   125 net.cpp:574] inception_5a/pool_proj <- inception_5a/pool
I1130 22:37:42.031985   125 net.cpp:544] inception_5a/pool_proj -> inception_5a/pool_proj
I1130 22:37:42.033856   125 net.cpp:262] Setting up inception_5a/pool_proj
I1130 22:37:42.033869   125 net.cpp:269] TRAIN Top shape for layer 142 'inception_5a/pool_proj' 10 128 40 40 (2048000)
I1130 22:37:42.033879   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.033885   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.033893   125 net.cpp:202] Created Layer inception_5a/relu_pool_proj (143)
I1130 22:37:42.033900   125 net.cpp:574] inception_5a/relu_pool_proj <- inception_5a/pool_proj
I1130 22:37:42.033905   125 net.cpp:529] inception_5a/relu_pool_proj -> inception_5a/pool_proj (in-place)
I1130 22:37:42.033915   125 net.cpp:262] Setting up inception_5a/relu_pool_proj
I1130 22:37:42.033922   125 net.cpp:269] TRAIN Top shape for layer 143 'inception_5a/relu_pool_proj' 10 128 40 40 (2048000)
I1130 22:37:42.033929   125 layer_factory.hpp:172] Creating layer 'inception_5a/output' of type 'Concat'
I1130 22:37:42.033936   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.033944   125 net.cpp:202] Created Layer inception_5a/output (144)
I1130 22:37:42.033949   125 net.cpp:574] inception_5a/output <- inception_5a/1x1
I1130 22:37:42.033957   125 net.cpp:574] inception_5a/output <- inception_5a/3x3
I1130 22:37:42.033962   125 net.cpp:574] inception_5a/output <- inception_5a/5x5
I1130 22:37:42.033967   125 net.cpp:574] inception_5a/output <- inception_5a/pool_proj
I1130 22:37:42.033973   125 net.cpp:544] inception_5a/output -> inception_5a/output
I1130 22:37:42.034010   125 net.cpp:262] Setting up inception_5a/output
I1130 22:37:42.034018   125 net.cpp:269] TRAIN Top shape for layer 144 'inception_5a/output' 10 832 40 40 (13312000)
I1130 22:37:42.034024   125 layer_factory.hpp:172] Creating layer 'inception_5a/output_inception_5a/output_0_split' of type 'Split'
I1130 22:37:42.034030   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.034040   125 net.cpp:202] Created Layer inception_5a/output_inception_5a/output_0_split (145)
I1130 22:37:42.034046   125 net.cpp:574] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I1130 22:37:42.034052   125 net.cpp:544] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I1130 22:37:42.034060   125 net.cpp:544] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I1130 22:37:42.034070   125 net.cpp:544] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_2
I1130 22:37:42.034077   125 net.cpp:544] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_3
I1130 22:37:42.034155   125 net.cpp:262] Setting up inception_5a/output_inception_5a/output_0_split
I1130 22:37:42.034163   125 net.cpp:269] TRAIN Top shape for layer 145 'inception_5a/output_inception_5a/output_0_split' 10 832 40 40 (13312000)
I1130 22:37:42.034170   125 net.cpp:269] TRAIN Top shape for layer 145 'inception_5a/output_inception_5a/output_0_split' 10 832 40 40 (13312000)
I1130 22:37:42.034176   125 net.cpp:269] TRAIN Top shape for layer 145 'inception_5a/output_inception_5a/output_0_split' 10 832 40 40 (13312000)
I1130 22:37:42.034183   125 net.cpp:269] TRAIN Top shape for layer 145 'inception_5a/output_inception_5a/output_0_split' 10 832 40 40 (13312000)
I1130 22:37:42.034188   125 layer_factory.hpp:172] Creating layer 'inception_5b/1x1' of type 'Convolution'
I1130 22:37:42.034204   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.034221   125 net.cpp:202] Created Layer inception_5b/1x1 (146)
I1130 22:37:42.034227   125 net.cpp:574] inception_5b/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I1130 22:37:42.034234   125 net.cpp:544] inception_5b/1x1 -> inception_5b/1x1
I1130 22:37:42.040328   125 net.cpp:262] Setting up inception_5b/1x1
I1130 22:37:42.040343   125 net.cpp:269] TRAIN Top shape for layer 146 'inception_5b/1x1' 10 384 40 40 (6144000)
I1130 22:37:42.040354   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_1x1' of type 'ReLU'
I1130 22:37:42.040360   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.040370   125 net.cpp:202] Created Layer inception_5b/relu_1x1 (147)
I1130 22:37:42.040376   125 net.cpp:574] inception_5b/relu_1x1 <- inception_5b/1x1
I1130 22:37:42.040383   125 net.cpp:529] inception_5b/relu_1x1 -> inception_5b/1x1 (in-place)
I1130 22:37:42.040392   125 net.cpp:262] Setting up inception_5b/relu_1x1
I1130 22:37:42.040400   125 net.cpp:269] TRAIN Top shape for layer 147 'inception_5b/relu_1x1' 10 384 40 40 (6144000)
I1130 22:37:42.040406   125 layer_factory.hpp:172] Creating layer 'inception_5b/3x3_reduce' of type 'Convolution'
I1130 22:37:42.040412   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.040429   125 net.cpp:202] Created Layer inception_5b/3x3_reduce (148)
I1130 22:37:42.040436   125 net.cpp:574] inception_5b/3x3_reduce <- inception_5a/output_inception_5a/output_0_split_1
I1130 22:37:42.040442   125 net.cpp:544] inception_5b/3x3_reduce -> inception_5b/3x3_reduce
I1130 22:37:42.043208   125 net.cpp:262] Setting up inception_5b/3x3_reduce
I1130 22:37:42.043218   125 net.cpp:269] TRAIN Top shape for layer 148 'inception_5b/3x3_reduce' 10 192 40 40 (3072000)
I1130 22:37:42.043228   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.043236   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.043244   125 net.cpp:202] Created Layer inception_5b/relu_3x3_reduce (149)
I1130 22:37:42.043251   125 net.cpp:574] inception_5b/relu_3x3_reduce <- inception_5b/3x3_reduce
I1130 22:37:42.043256   125 net.cpp:529] inception_5b/relu_3x3_reduce -> inception_5b/3x3_reduce (in-place)
I1130 22:37:42.043267   125 net.cpp:262] Setting up inception_5b/relu_3x3_reduce
I1130 22:37:42.043272   125 net.cpp:269] TRAIN Top shape for layer 149 'inception_5b/relu_3x3_reduce' 10 192 40 40 (3072000)
I1130 22:37:42.043279   125 layer_factory.hpp:172] Creating layer 'inception_5b/3x3' of type 'Convolution'
I1130 22:37:42.043285   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.043303   125 net.cpp:202] Created Layer inception_5b/3x3 (150)
I1130 22:37:42.043308   125 net.cpp:574] inception_5b/3x3 <- inception_5b/3x3_reduce
I1130 22:37:42.043313   125 net.cpp:544] inception_5b/3x3 -> inception_5b/3x3
I1130 22:37:42.054638   125 net.cpp:262] Setting up inception_5b/3x3
I1130 22:37:42.054654   125 net.cpp:269] TRAIN Top shape for layer 150 'inception_5b/3x3' 10 384 40 40 (6144000)
I1130 22:37:42.054666   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_3x3' of type 'ReLU'
I1130 22:37:42.054672   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.054680   125 net.cpp:202] Created Layer inception_5b/relu_3x3 (151)
I1130 22:37:42.054687   125 net.cpp:574] inception_5b/relu_3x3 <- inception_5b/3x3
I1130 22:37:42.054694   125 net.cpp:529] inception_5b/relu_3x3 -> inception_5b/3x3 (in-place)
I1130 22:37:42.054703   125 net.cpp:262] Setting up inception_5b/relu_3x3
I1130 22:37:42.054711   125 net.cpp:269] TRAIN Top shape for layer 151 'inception_5b/relu_3x3' 10 384 40 40 (6144000)
I1130 22:37:42.054718   125 layer_factory.hpp:172] Creating layer 'inception_5b/5x5_reduce' of type 'Convolution'
I1130 22:37:42.054736   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.054754   125 net.cpp:202] Created Layer inception_5b/5x5_reduce (152)
I1130 22:37:42.054761   125 net.cpp:574] inception_5b/5x5_reduce <- inception_5a/output_inception_5a/output_0_split_2
I1130 22:37:42.054769   125 net.cpp:544] inception_5b/5x5_reduce -> inception_5b/5x5_reduce
I1130 22:37:42.055727   125 net.cpp:262] Setting up inception_5b/5x5_reduce
I1130 22:37:42.055739   125 net.cpp:269] TRAIN Top shape for layer 152 'inception_5b/5x5_reduce' 10 48 40 40 (768000)
I1130 22:37:42.055748   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.055755   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.055763   125 net.cpp:202] Created Layer inception_5b/relu_5x5_reduce (153)
I1130 22:37:42.055769   125 net.cpp:574] inception_5b/relu_5x5_reduce <- inception_5b/5x5_reduce
I1130 22:37:42.055775   125 net.cpp:529] inception_5b/relu_5x5_reduce -> inception_5b/5x5_reduce (in-place)
I1130 22:37:42.055784   125 net.cpp:262] Setting up inception_5b/relu_5x5_reduce
I1130 22:37:42.055791   125 net.cpp:269] TRAIN Top shape for layer 153 'inception_5b/relu_5x5_reduce' 10 48 40 40 (768000)
I1130 22:37:42.055797   125 layer_factory.hpp:172] Creating layer 'inception_5b/5x5' of type 'Convolution'
I1130 22:37:42.055804   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.055820   125 net.cpp:202] Created Layer inception_5b/5x5 (154)
I1130 22:37:42.055825   125 net.cpp:574] inception_5b/5x5 <- inception_5b/5x5_reduce
I1130 22:37:42.055831   125 net.cpp:544] inception_5b/5x5 -> inception_5b/5x5
I1130 22:37:42.059571   125 net.cpp:262] Setting up inception_5b/5x5
I1130 22:37:42.059587   125 net.cpp:269] TRAIN Top shape for layer 154 'inception_5b/5x5' 10 128 40 40 (2048000)
I1130 22:37:42.059597   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_5x5' of type 'ReLU'
I1130 22:37:42.059603   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.059613   125 net.cpp:202] Created Layer inception_5b/relu_5x5 (155)
I1130 22:37:42.059619   125 net.cpp:574] inception_5b/relu_5x5 <- inception_5b/5x5
I1130 22:37:42.059626   125 net.cpp:529] inception_5b/relu_5x5 -> inception_5b/5x5 (in-place)
I1130 22:37:42.059635   125 net.cpp:262] Setting up inception_5b/relu_5x5
I1130 22:37:42.059643   125 net.cpp:269] TRAIN Top shape for layer 155 'inception_5b/relu_5x5' 10 128 40 40 (2048000)
I1130 22:37:42.059649   125 layer_factory.hpp:172] Creating layer 'inception_5b/pool' of type 'Pooling'
I1130 22:37:42.059655   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.059666   125 net.cpp:202] Created Layer inception_5b/pool (156)
I1130 22:37:42.059672   125 net.cpp:574] inception_5b/pool <- inception_5a/output_inception_5a/output_0_split_3
I1130 22:37:42.059679   125 net.cpp:544] inception_5b/pool -> inception_5b/pool
I1130 22:37:42.059754   125 net.cpp:262] Setting up inception_5b/pool
I1130 22:37:42.059763   125 net.cpp:269] TRAIN Top shape for layer 156 'inception_5b/pool' 10 832 40 40 (13312000)
I1130 22:37:42.059769   125 layer_factory.hpp:172] Creating layer 'inception_5b/pool_proj' of type 'Convolution'
I1130 22:37:42.059775   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.059792   125 net.cpp:202] Created Layer inception_5b/pool_proj (157)
I1130 22:37:42.059798   125 net.cpp:574] inception_5b/pool_proj <- inception_5b/pool
I1130 22:37:42.059804   125 net.cpp:544] inception_5b/pool_proj -> inception_5b/pool_proj
I1130 22:37:42.061703   125 net.cpp:262] Setting up inception_5b/pool_proj
I1130 22:37:42.061715   125 net.cpp:269] TRAIN Top shape for layer 157 'inception_5b/pool_proj' 10 128 40 40 (2048000)
I1130 22:37:42.061740   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.061748   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.061755   125 net.cpp:202] Created Layer inception_5b/relu_pool_proj (158)
I1130 22:37:42.061760   125 net.cpp:574] inception_5b/relu_pool_proj <- inception_5b/pool_proj
I1130 22:37:42.061767   125 net.cpp:529] inception_5b/relu_pool_proj -> inception_5b/pool_proj (in-place)
I1130 22:37:42.061776   125 net.cpp:262] Setting up inception_5b/relu_pool_proj
I1130 22:37:42.061784   125 net.cpp:269] TRAIN Top shape for layer 158 'inception_5b/relu_pool_proj' 10 128 40 40 (2048000)
I1130 22:37:42.061789   125 layer_factory.hpp:172] Creating layer 'inception_5b/output' of type 'Concat'
I1130 22:37:42.061794   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.061805   125 net.cpp:202] Created Layer inception_5b/output (159)
I1130 22:37:42.061810   125 net.cpp:574] inception_5b/output <- inception_5b/1x1
I1130 22:37:42.061815   125 net.cpp:574] inception_5b/output <- inception_5b/3x3
I1130 22:37:42.061820   125 net.cpp:574] inception_5b/output <- inception_5b/5x5
I1130 22:37:42.061826   125 net.cpp:574] inception_5b/output <- inception_5b/pool_proj
I1130 22:37:42.061832   125 net.cpp:544] inception_5b/output -> inception_5b/output
I1130 22:37:42.061872   125 net.cpp:262] Setting up inception_5b/output
I1130 22:37:42.061880   125 net.cpp:269] TRAIN Top shape for layer 159 'inception_5b/output' 10 1024 40 40 (16384000)
I1130 22:37:42.061887   125 layer_factory.hpp:172] Creating layer 'pool5/drop_s1' of type 'Dropout'
I1130 22:37:42.061892   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.061909   125 net.cpp:202] Created Layer pool5/drop_s1 (160)
I1130 22:37:42.061914   125 net.cpp:574] pool5/drop_s1 <- inception_5b/output
I1130 22:37:42.061923   125 net.cpp:544] pool5/drop_s1 -> pool5/drop_s1
I1130 22:37:42.072262   125 net.cpp:262] Setting up pool5/drop_s1
I1130 22:37:42.072278   125 net.cpp:269] TRAIN Top shape for layer 160 'pool5/drop_s1' 10 1024 40 40 (16384000)
I1130 22:37:42.072286   125 layer_factory.hpp:172] Creating layer 'pool5/drop_s1_pool5/drop_s1_0_split' of type 'Split'
I1130 22:37:42.072293   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.072302   125 net.cpp:202] Created Layer pool5/drop_s1_pool5/drop_s1_0_split (161)
I1130 22:37:42.072309   125 net.cpp:574] pool5/drop_s1_pool5/drop_s1_0_split <- pool5/drop_s1
I1130 22:37:42.072315   125 net.cpp:544] pool5/drop_s1_pool5/drop_s1_0_split -> pool5/drop_s1_pool5/drop_s1_0_split_0
I1130 22:37:42.072324   125 net.cpp:544] pool5/drop_s1_pool5/drop_s1_0_split -> pool5/drop_s1_pool5/drop_s1_0_split_1
I1130 22:37:42.072386   125 net.cpp:262] Setting up pool5/drop_s1_pool5/drop_s1_0_split
I1130 22:37:42.072394   125 net.cpp:269] TRAIN Top shape for layer 161 'pool5/drop_s1_pool5/drop_s1_0_split' 10 1024 40 40 (16384000)
I1130 22:37:42.072401   125 net.cpp:269] TRAIN Top shape for layer 161 'pool5/drop_s1_pool5/drop_s1_0_split' 10 1024 40 40 (16384000)
I1130 22:37:42.072407   125 layer_factory.hpp:172] Creating layer 'cvg/classifier' of type 'Convolution'
I1130 22:37:42.072412   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.072435   125 net.cpp:202] Created Layer cvg/classifier (162)
I1130 22:37:42.072441   125 net.cpp:574] cvg/classifier <- pool5/drop_s1_pool5/drop_s1_0_split_0
I1130 22:37:42.072449   125 net.cpp:544] cvg/classifier -> cvg/classifier
I1130 22:37:42.072824   125 net.cpp:262] Setting up cvg/classifier
I1130 22:37:42.072834   125 net.cpp:269] TRAIN Top shape for layer 162 'cvg/classifier' 10 1 40 40 (16000)
I1130 22:37:42.072844   125 layer_factory.hpp:172] Creating layer 'coverage/sig' of type 'Sigmoid'
I1130 22:37:42.072850   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.072875   125 net.cpp:202] Created Layer coverage/sig (163)
I1130 22:37:42.072880   125 net.cpp:574] coverage/sig <- cvg/classifier
I1130 22:37:42.072887   125 net.cpp:544] coverage/sig -> coverage
I1130 22:37:42.072929   125 net.cpp:262] Setting up coverage/sig
I1130 22:37:42.072940   125 net.cpp:269] TRAIN Top shape for layer 163 'coverage/sig' 10 1 40 40 (16000)
I1130 22:37:42.072947   125 layer_factory.hpp:172] Creating layer 'bbox/regressor' of type 'Convolution'
I1130 22:37:42.072952   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.072971   125 net.cpp:202] Created Layer bbox/regressor (164)
I1130 22:37:42.072978   125 net.cpp:574] bbox/regressor <- pool5/drop_s1_pool5/drop_s1_0_split_1
I1130 22:37:42.072984   125 net.cpp:544] bbox/regressor -> bboxes
I1130 22:37:42.073382   125 net.cpp:262] Setting up bbox/regressor
I1130 22:37:42.073393   125 net.cpp:269] TRAIN Top shape for layer 164 'bbox/regressor' 10 4 40 40 (64000)
I1130 22:37:42.073402   125 layer_factory.hpp:172] Creating layer 'bbox_mask' of type 'Eltwise'
I1130 22:37:42.073408   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.073421   125 net.cpp:202] Created Layer bbox_mask (165)
I1130 22:37:42.073427   125 net.cpp:574] bbox_mask <- bboxes
I1130 22:37:42.073434   125 net.cpp:574] bbox_mask <- coverage-block
I1130 22:37:42.073441   125 net.cpp:544] bbox_mask -> bboxes-masked
I1130 22:37:42.073478   125 net.cpp:262] Setting up bbox_mask
I1130 22:37:42.073487   125 net.cpp:269] TRAIN Top shape for layer 165 'bbox_mask' 10 4 40 40 (64000)
I1130 22:37:42.073493   125 layer_factory.hpp:172] Creating layer 'bbox-norm' of type 'Eltwise'
I1130 22:37:42.073498   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.073508   125 net.cpp:202] Created Layer bbox-norm (166)
I1130 22:37:42.073513   125 net.cpp:574] bbox-norm <- bboxes-masked
I1130 22:37:42.073520   125 net.cpp:574] bbox-norm <- size-block_size-block_0_split_1
I1130 22:37:42.073527   125 net.cpp:544] bbox-norm -> bboxes-masked-norm
I1130 22:37:42.073562   125 net.cpp:262] Setting up bbox-norm
I1130 22:37:42.073572   125 net.cpp:269] TRAIN Top shape for layer 166 'bbox-norm' 10 4 40 40 (64000)
I1130 22:37:42.073580   125 layer_factory.hpp:172] Creating layer 'bbox-obj-norm' of type 'Eltwise'
I1130 22:37:42.073585   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.073592   125 net.cpp:202] Created Layer bbox-obj-norm (167)
I1130 22:37:42.073598   125 net.cpp:574] bbox-obj-norm <- bboxes-masked-norm
I1130 22:37:42.073604   125 net.cpp:574] bbox-obj-norm <- obj-block_obj-block_0_split_1
I1130 22:37:42.073611   125 net.cpp:544] bbox-obj-norm -> bboxes-obj-masked-norm
I1130 22:37:42.073647   125 net.cpp:262] Setting up bbox-obj-norm
I1130 22:37:42.073654   125 net.cpp:269] TRAIN Top shape for layer 167 'bbox-obj-norm' 10 4 40 40 (64000)
I1130 22:37:42.073660   125 layer_factory.hpp:172] Creating layer 'bbox_loss' of type 'L1Loss'
I1130 22:37:42.073666   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.073681   125 net.cpp:202] Created Layer bbox_loss (168)
I1130 22:37:42.073688   125 net.cpp:574] bbox_loss <- bboxes-obj-masked-norm
I1130 22:37:42.073693   125 net.cpp:574] bbox_loss <- bbox-obj-label-norm
I1130 22:37:42.073700   125 net.cpp:544] bbox_loss -> loss_bbox
I1130 22:37:42.074275   125 net.cpp:262] Setting up bbox_loss
I1130 22:37:42.074286   125 net.cpp:269] TRAIN Top shape for layer 168 'bbox_loss' (1)
I1130 22:37:42.074292   125 net.cpp:273]     with loss weight 2
I1130 22:37:42.074322   125 layer_factory.hpp:172] Creating layer 'coverage_loss' of type 'EuclideanLoss'
I1130 22:37:42.074328   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.074342   125 net.cpp:202] Created Layer coverage_loss (169)
I1130 22:37:42.074358   125 net.cpp:574] coverage_loss <- coverage
I1130 22:37:42.074365   125 net.cpp:574] coverage_loss <- coverage-label
I1130 22:37:42.074373   125 net.cpp:544] coverage_loss -> loss_coverage
I1130 22:37:42.074429   125 net.cpp:262] Setting up coverage_loss
I1130 22:37:42.074437   125 net.cpp:269] TRAIN Top shape for layer 169 'coverage_loss' (1)
I1130 22:37:42.074441   125 net.cpp:273]     with loss weight 1
I1130 22:37:42.074450   125 net.cpp:338] coverage_loss needs backward computation.
I1130 22:37:42.074456   125 net.cpp:338] bbox_loss needs backward computation.
I1130 22:37:42.074463   125 net.cpp:338] bbox-obj-norm needs backward computation.
I1130 22:37:42.074468   125 net.cpp:338] bbox-norm needs backward computation.
I1130 22:37:42.074474   125 net.cpp:338] bbox_mask needs backward computation.
I1130 22:37:42.074481   125 net.cpp:338] bbox/regressor needs backward computation.
I1130 22:37:42.074486   125 net.cpp:338] coverage/sig needs backward computation.
I1130 22:37:42.074491   125 net.cpp:338] cvg/classifier needs backward computation.
I1130 22:37:42.074496   125 net.cpp:338] pool5/drop_s1_pool5/drop_s1_0_split needs backward computation.
I1130 22:37:42.074502   125 net.cpp:338] pool5/drop_s1 needs backward computation.
I1130 22:37:42.074508   125 net.cpp:338] inception_5b/output needs backward computation.
I1130 22:37:42.074517   125 net.cpp:338] inception_5b/relu_pool_proj needs backward computation.
I1130 22:37:42.074522   125 net.cpp:338] inception_5b/pool_proj needs backward computation.
I1130 22:37:42.074528   125 net.cpp:338] inception_5b/pool needs backward computation.
I1130 22:37:42.074534   125 net.cpp:338] inception_5b/relu_5x5 needs backward computation.
I1130 22:37:42.074539   125 net.cpp:338] inception_5b/5x5 needs backward computation.
I1130 22:37:42.074544   125 net.cpp:338] inception_5b/relu_5x5_reduce needs backward computation.
I1130 22:37:42.074550   125 net.cpp:338] inception_5b/5x5_reduce needs backward computation.
I1130 22:37:42.074556   125 net.cpp:338] inception_5b/relu_3x3 needs backward computation.
I1130 22:37:42.074561   125 net.cpp:338] inception_5b/3x3 needs backward computation.
I1130 22:37:42.074566   125 net.cpp:338] inception_5b/relu_3x3_reduce needs backward computation.
I1130 22:37:42.074573   125 net.cpp:338] inception_5b/3x3_reduce needs backward computation.
I1130 22:37:42.074579   125 net.cpp:338] inception_5b/relu_1x1 needs backward computation.
I1130 22:37:42.074584   125 net.cpp:338] inception_5b/1x1 needs backward computation.
I1130 22:37:42.074589   125 net.cpp:338] inception_5a/output_inception_5a/output_0_split needs backward computation.
I1130 22:37:42.074594   125 net.cpp:338] inception_5a/output needs backward computation.
I1130 22:37:42.074602   125 net.cpp:338] inception_5a/relu_pool_proj needs backward computation.
I1130 22:37:42.074609   125 net.cpp:338] inception_5a/pool_proj needs backward computation.
I1130 22:37:42.074614   125 net.cpp:338] inception_5a/pool needs backward computation.
I1130 22:37:42.074620   125 net.cpp:338] inception_5a/relu_5x5 needs backward computation.
I1130 22:37:42.074625   125 net.cpp:338] inception_5a/5x5 needs backward computation.
I1130 22:37:42.074631   125 net.cpp:338] inception_5a/relu_5x5_reduce needs backward computation.
I1130 22:37:42.074636   125 net.cpp:338] inception_5a/5x5_reduce needs backward computation.
I1130 22:37:42.074642   125 net.cpp:338] inception_5a/relu_3x3 needs backward computation.
I1130 22:37:42.074647   125 net.cpp:338] inception_5a/3x3 needs backward computation.
I1130 22:37:42.074653   125 net.cpp:338] inception_5a/relu_3x3_reduce needs backward computation.
I1130 22:37:42.074659   125 net.cpp:338] inception_5a/3x3_reduce needs backward computation.
I1130 22:37:42.074664   125 net.cpp:338] inception_5a/relu_1x1 needs backward computation.
I1130 22:37:42.074671   125 net.cpp:338] inception_5a/1x1 needs backward computation.
I1130 22:37:42.074676   125 net.cpp:338] inception_4e/output_inception_4e/output_0_split needs backward computation.
I1130 22:37:42.074682   125 net.cpp:338] inception_4e/output needs backward computation.
I1130 22:37:42.074698   125 net.cpp:338] inception_4e/relu_pool_proj needs backward computation.
I1130 22:37:42.074704   125 net.cpp:338] inception_4e/pool_proj needs backward computation.
I1130 22:37:42.074710   125 net.cpp:338] inception_4e/pool needs backward computation.
I1130 22:37:42.074715   125 net.cpp:338] inception_4e/relu_5x5 needs backward computation.
I1130 22:37:42.074721   125 net.cpp:338] inception_4e/5x5 needs backward computation.
I1130 22:37:42.074728   125 net.cpp:338] inception_4e/relu_5x5_reduce needs backward computation.
I1130 22:37:42.074733   125 net.cpp:338] inception_4e/5x5_reduce needs backward computation.
I1130 22:37:42.074739   125 net.cpp:338] inception_4e/relu_3x3 needs backward computation.
I1130 22:37:42.074745   125 net.cpp:338] inception_4e/3x3 needs backward computation.
I1130 22:37:42.074750   125 net.cpp:338] inception_4e/relu_3x3_reduce needs backward computation.
I1130 22:37:42.074756   125 net.cpp:338] inception_4e/3x3_reduce needs backward computation.
I1130 22:37:42.074764   125 net.cpp:338] inception_4e/relu_1x1 needs backward computation.
I1130 22:37:42.074770   125 net.cpp:338] inception_4e/1x1 needs backward computation.
I1130 22:37:42.074776   125 net.cpp:338] inception_4d/output_inception_4d/output_0_split needs backward computation.
I1130 22:37:42.074781   125 net.cpp:338] inception_4d/output needs backward computation.
I1130 22:37:42.074790   125 net.cpp:338] inception_4d/relu_pool_proj needs backward computation.
I1130 22:37:42.074795   125 net.cpp:338] inception_4d/pool_proj needs backward computation.
I1130 22:37:42.074800   125 net.cpp:338] inception_4d/pool needs backward computation.
I1130 22:37:42.074806   125 net.cpp:338] inception_4d/relu_5x5 needs backward computation.
I1130 22:37:42.074812   125 net.cpp:338] inception_4d/5x5 needs backward computation.
I1130 22:37:42.074818   125 net.cpp:338] inception_4d/relu_5x5_reduce needs backward computation.
I1130 22:37:42.074825   125 net.cpp:338] inception_4d/5x5_reduce needs backward computation.
I1130 22:37:42.074831   125 net.cpp:338] inception_4d/relu_3x3 needs backward computation.
I1130 22:37:42.074836   125 net.cpp:338] inception_4d/3x3 needs backward computation.
I1130 22:37:42.074841   125 net.cpp:338] inception_4d/relu_3x3_reduce needs backward computation.
I1130 22:37:42.074847   125 net.cpp:338] inception_4d/3x3_reduce needs backward computation.
I1130 22:37:42.074852   125 net.cpp:338] inception_4d/relu_1x1 needs backward computation.
I1130 22:37:42.074858   125 net.cpp:338] inception_4d/1x1 needs backward computation.
I1130 22:37:42.074864   125 net.cpp:338] inception_4c/output_inception_4c/output_0_split needs backward computation.
I1130 22:37:42.074870   125 net.cpp:338] inception_4c/output needs backward computation.
I1130 22:37:42.074877   125 net.cpp:338] inception_4c/relu_pool_proj needs backward computation.
I1130 22:37:42.074882   125 net.cpp:338] inception_4c/pool_proj needs backward computation.
I1130 22:37:42.074888   125 net.cpp:338] inception_4c/pool needs backward computation.
I1130 22:37:42.074894   125 net.cpp:338] inception_4c/relu_5x5 needs backward computation.
I1130 22:37:42.074899   125 net.cpp:338] inception_4c/5x5 needs backward computation.
I1130 22:37:42.074905   125 net.cpp:338] inception_4c/relu_5x5_reduce needs backward computation.
I1130 22:37:42.074910   125 net.cpp:338] inception_4c/5x5_reduce needs backward computation.
I1130 22:37:42.074918   125 net.cpp:338] inception_4c/relu_3x3 needs backward computation.
I1130 22:37:42.074923   125 net.cpp:338] inception_4c/3x3 needs backward computation.
I1130 22:37:42.074928   125 net.cpp:338] inception_4c/relu_3x3_reduce needs backward computation.
I1130 22:37:42.074934   125 net.cpp:338] inception_4c/3x3_reduce needs backward computation.
I1130 22:37:42.074940   125 net.cpp:338] inception_4c/relu_1x1 needs backward computation.
I1130 22:37:42.074945   125 net.cpp:338] inception_4c/1x1 needs backward computation.
I1130 22:37:42.074951   125 net.cpp:338] inception_4b/output_inception_4b/output_0_split needs backward computation.
I1130 22:37:42.074965   125 net.cpp:338] inception_4b/output needs backward computation.
I1130 22:37:42.074972   125 net.cpp:338] inception_4b/relu_pool_proj needs backward computation.
I1130 22:37:42.074978   125 net.cpp:338] inception_4b/pool_proj needs backward computation.
I1130 22:37:42.074983   125 net.cpp:338] inception_4b/pool needs backward computation.
I1130 22:37:42.074990   125 net.cpp:338] inception_4b/relu_5x5 needs backward computation.
I1130 22:37:42.074995   125 net.cpp:338] inception_4b/5x5 needs backward computation.
I1130 22:37:42.075001   125 net.cpp:338] inception_4b/relu_5x5_reduce needs backward computation.
I1130 22:37:42.075006   125 net.cpp:338] inception_4b/5x5_reduce needs backward computation.
I1130 22:37:42.075017   125 net.cpp:338] inception_4b/relu_3x3 needs backward computation.
I1130 22:37:42.075024   125 net.cpp:338] inception_4b/3x3 needs backward computation.
I1130 22:37:42.075029   125 net.cpp:338] inception_4b/relu_3x3_reduce needs backward computation.
I1130 22:37:42.075036   125 net.cpp:338] inception_4b/3x3_reduce needs backward computation.
I1130 22:37:42.075042   125 net.cpp:338] inception_4b/relu_1x1 needs backward computation.
I1130 22:37:42.075047   125 net.cpp:338] inception_4b/1x1 needs backward computation.
I1130 22:37:42.075053   125 net.cpp:338] inception_4a/output_inception_4a/output_0_split needs backward computation.
I1130 22:37:42.075059   125 net.cpp:338] inception_4a/output needs backward computation.
I1130 22:37:42.075067   125 net.cpp:338] inception_4a/relu_pool_proj needs backward computation.
I1130 22:37:42.075073   125 net.cpp:338] inception_4a/pool_proj needs backward computation.
I1130 22:37:42.075078   125 net.cpp:338] inception_4a/pool needs backward computation.
I1130 22:37:42.075084   125 net.cpp:338] inception_4a/relu_5x5 needs backward computation.
I1130 22:37:42.075089   125 net.cpp:338] inception_4a/5x5 needs backward computation.
I1130 22:37:42.075095   125 net.cpp:338] inception_4a/relu_5x5_reduce needs backward computation.
I1130 22:37:42.075101   125 net.cpp:338] inception_4a/5x5_reduce needs backward computation.
I1130 22:37:42.075107   125 net.cpp:338] inception_4a/relu_3x3 needs backward computation.
I1130 22:37:42.075114   125 net.cpp:338] inception_4a/3x3 needs backward computation.
I1130 22:37:42.075119   125 net.cpp:338] inception_4a/relu_3x3_reduce needs backward computation.
I1130 22:37:42.075124   125 net.cpp:338] inception_4a/3x3_reduce needs backward computation.
I1130 22:37:42.075130   125 net.cpp:338] inception_4a/relu_1x1 needs backward computation.
I1130 22:37:42.075136   125 net.cpp:338] inception_4a/1x1 needs backward computation.
I1130 22:37:42.075142   125 net.cpp:338] pool3/3x3_s2_pool3/3x3_s2_0_split needs backward computation.
I1130 22:37:42.075148   125 net.cpp:338] pool3/3x3_s2 needs backward computation.
I1130 22:37:42.075155   125 net.cpp:338] inception_3b/output needs backward computation.
I1130 22:37:42.075162   125 net.cpp:338] inception_3b/relu_pool_proj needs backward computation.
I1130 22:37:42.075167   125 net.cpp:338] inception_3b/pool_proj needs backward computation.
I1130 22:37:42.075173   125 net.cpp:338] inception_3b/pool needs backward computation.
I1130 22:37:42.075179   125 net.cpp:338] inception_3b/relu_5x5 needs backward computation.
I1130 22:37:42.075186   125 net.cpp:338] inception_3b/5x5 needs backward computation.
I1130 22:37:42.075191   125 net.cpp:338] inception_3b/relu_5x5_reduce needs backward computation.
I1130 22:37:42.075197   125 net.cpp:338] inception_3b/5x5_reduce needs backward computation.
I1130 22:37:42.075202   125 net.cpp:338] inception_3b/relu_3x3 needs backward computation.
I1130 22:37:42.075208   125 net.cpp:338] inception_3b/3x3 needs backward computation.
I1130 22:37:42.075214   125 net.cpp:338] inception_3b/relu_3x3_reduce needs backward computation.
I1130 22:37:42.075219   125 net.cpp:338] inception_3b/3x3_reduce needs backward computation.
I1130 22:37:42.075225   125 net.cpp:338] inception_3b/relu_1x1 needs backward computation.
I1130 22:37:42.075237   125 net.cpp:338] inception_3b/1x1 needs backward computation.
I1130 22:37:42.075243   125 net.cpp:338] inception_3a/output_inception_3a/output_0_split needs backward computation.
I1130 22:37:42.075249   125 net.cpp:338] inception_3a/output needs backward computation.
I1130 22:37:42.075256   125 net.cpp:338] inception_3a/relu_pool_proj needs backward computation.
I1130 22:37:42.075263   125 net.cpp:338] inception_3a/pool_proj needs backward computation.
I1130 22:37:42.075270   125 net.cpp:338] inception_3a/pool needs backward computation.
I1130 22:37:42.075276   125 net.cpp:338] inception_3a/relu_5x5 needs backward computation.
I1130 22:37:42.075282   125 net.cpp:338] inception_3a/5x5 needs backward computation.
I1130 22:37:42.075289   125 net.cpp:338] inception_3a/relu_5x5_reduce needs backward computation.
I1130 22:37:42.075294   125 net.cpp:338] inception_3a/5x5_reduce needs backward computation.
I1130 22:37:42.075300   125 net.cpp:338] inception_3a/relu_3x3 needs backward computation.
I1130 22:37:42.075305   125 net.cpp:338] inception_3a/3x3 needs backward computation.
I1130 22:37:42.075311   125 net.cpp:338] inception_3a/relu_3x3_reduce needs backward computation.
I1130 22:37:42.075317   125 net.cpp:338] inception_3a/3x3_reduce needs backward computation.
I1130 22:37:42.075323   125 net.cpp:338] inception_3a/relu_1x1 needs backward computation.
I1130 22:37:42.075328   125 net.cpp:338] inception_3a/1x1 needs backward computation.
I1130 22:37:42.075335   125 net.cpp:338] pool2/3x3_s2_pool2/3x3_s2_0_split needs backward computation.
I1130 22:37:42.075340   125 net.cpp:338] pool2/3x3_s2 needs backward computation.
I1130 22:37:42.075346   125 net.cpp:338] conv2/norm2 needs backward computation.
I1130 22:37:42.075352   125 net.cpp:338] conv2/relu_3x3 needs backward computation.
I1130 22:37:42.075358   125 net.cpp:338] conv2/3x3 needs backward computation.
I1130 22:37:42.075364   125 net.cpp:338] conv2/relu_3x3_reduce needs backward computation.
I1130 22:37:42.075369   125 net.cpp:338] conv2/3x3_reduce needs backward computation.
I1130 22:37:42.075376   125 net.cpp:338] pool1/norm1 needs backward computation.
I1130 22:37:42.075381   125 net.cpp:338] pool1/3x3_s2 needs backward computation.
I1130 22:37:42.075387   125 net.cpp:338] conv1/relu_7x7 needs backward computation.
I1130 22:37:42.075393   125 net.cpp:338] conv1/7x7_s2 needs backward computation.
I1130 22:37:42.075399   125 net.cpp:340] bb-obj-norm does not need backward computation.
I1130 22:37:42.075407   125 net.cpp:340] bb-label-norm does not need backward computation.
I1130 22:37:42.075414   125 net.cpp:340] obj-block_obj-block_0_split does not need backward computation.
I1130 22:37:42.075422   125 net.cpp:340] obj-block does not need backward computation.
I1130 22:37:42.075430   125 net.cpp:340] size-block_size-block_0_split does not need backward computation.
I1130 22:37:42.075436   125 net.cpp:340] size-block does not need backward computation.
I1130 22:37:42.075446   125 net.cpp:340] coverage-block does not need backward computation.
I1130 22:37:42.075456   125 net.cpp:340] obj-label_slice-label_3_split does not need backward computation.
I1130 22:37:42.075464   125 net.cpp:340] size-label_slice-label_2_split does not need backward computation.
I1130 22:37:42.075471   125 net.cpp:340] foreground-label_slice-label_0_split does not need backward computation.
I1130 22:37:42.075480   125 net.cpp:340] slice-label does not need backward computation.
I1130 22:37:42.075487   125 net.cpp:340] train_transform does not need backward computation.
I1130 22:37:42.075495   125 net.cpp:340] train_label does not need backward computation.
I1130 22:37:42.075500   125 net.cpp:340] train_data does not need backward computation.
I1130 22:37:42.075505   125 net.cpp:382] This network produces output loss_bbox
I1130 22:37:42.075510   125 net.cpp:382] This network produces output loss_coverage
I1130 22:37:42.075706   125 net.cpp:405] Top memory (TRAIN) required for data: 5446948496 diff: 5446948496
I1130 22:37:42.075714   125 net.cpp:408] Bottom memory (TRAIN) required for data: 5446948480 diff: 5446948480
I1130 22:37:42.075728   125 net.cpp:411] Shared (in-place) memory (TRAIN) by data: 1163264000 diff: 1163264000
I1130 22:37:42.075733   125 net.cpp:414] Parameters memory (TRAIN) required for data: 23914712 diff: 23914712
I1130 22:37:42.075738   125 net.cpp:417] Parameters shared memory (TRAIN) by data: 0 diff: 0
I1130 22:37:42.075744   125 net.cpp:423] Network initialization done.
I1130 22:37:42.077795   125 solver.cpp:174] Creating test net (#0) specified by net file: train_val.prototxt
I1130 22:37:42.077975   125 net.cpp:459] The NetState phase (1) differed from the phase (0) specified by a rule in layer train_data
I1130 22:37:42.077983   125 net.cpp:459] The NetState phase (1) differed from the phase (0) specified by a rule in layer train_label
I1130 22:37:42.077991   125 net.cpp:459] The NetState phase (1) differed from the phase (0) specified by a rule in layer train_transform
I1130 22:37:42.078923   125 net.cpp:83] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "val_data"
type: "Data"
top: "data"
include {
phase: TEST
}
data_param {
source: "/workspace/jobs/20181130-223152-9c61/val_db/features"
batch_size: 6
backend: LMDB
}
}
layer {
name: "val_label"
type: "Data"
top: "label"
include {
phase: TEST
}
data_param {
source: "/workspace/jobs/20181130-223152-9c61/val_db/labels"
batch_size: 6
backend: LMDB
}
}
layer {
name: "val_transform"
type: "DetectNetTransformation"
bottom: "data"
bottom: "label"
top: "transformed_data"
top: "transformed_label"
include {
phase: TEST
}
transform_param {
mean_value: 127
}
detectnet_groundtruth_param {
stride: 16
scale_cvg: 0.4
gridbox_type: GRIDBOX_MIN
min_cvg_len: 20
coverage_type: RECTANGULAR
image_size_x: 640
image_size_y: 640
obj_norm: true
crop_bboxes: false
object_class {
src: 1
dst: 0
}
}
}
layer {
name: "slice-label"
type: "Slice"
bottom: "transformed_label"
top: "foreground-label"
top: "bbox-label"
top: "size-label"
top: "obj-label"
top: "coverage-label"
slice_param {
slice_dim: 1
slice_point: 1
slice_point: 5
slice_point: 7
slice_point: 8
}
}
layer {
name: "coverage-block"
type: "Concat"
bottom: "foreground-label"
bottom: "foreground-label"
bottom: "foreground-label"
bottom: "foreground-label"
top: "coverage-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "size-block"
type: "Concat"
bottom: "size-label"
bottom: "size-label"
top: "size-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "obj-block"
type: "Concat"
bottom: "obj-label"
bottom: "obj-label"
bottom: "obj-label"
bottom: "obj-label"
top: "obj-block"
concat_param {
concat_dim: 1
}
}
layer {
name: "bb-label-norm"
type: "Eltwise"
bottom: "bbox-label"
bottom: "size-block"
top: "bbox-label-norm"
eltwise_param {
operation: PROD
}
}
layer {
name: "bb-obj-norm"
type: "Eltwise"
bottom: "bbox-label-norm"
bottom: "obj-block"
top: "bbox-obj-label-norm"
eltwise_param {
operation: PROD
}
}
layer {
name: "conv1/7x7_s2"
type: "Convolution"
bottom: "transformed_data"
top: "conv1/7x7_s2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 3
kernel_size: 7
stride: 2
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv1/relu_7x7"
type: "ReLU"
bottom: "conv1/7x7_s2"
top: "conv1/7x7_s2"
}
layer {
name: "pool1/3x3_s2"
type: "Pooling"
bottom: "conv1/7x7_s2"
top: "pool1/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "pool1/norm1"
type: "LRN"
bottom: "pool1/3x3_s2"
top: "pool1/norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "conv2/3x3_reduce"
type: "Convolution"
bottom: "pool1/norm1"
top: "conv2/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv2/relu_3x3_reduce"
type: "ReLU"
bottom: "conv2/3x3_reduce"
top: "conv2/3x3_reduce"
}
layer {
name: "conv2/3x3"
type: "Convolution"
bottom: "conv2/3x3_reduce"
top: "conv2/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "conv2/relu_3x3"
type: "ReLU"
bottom: "conv2/3x3"
top: "conv2/3x3"
}
layer {
name: "conv2/norm2"
type: "LRN"
bottom: "conv2/3x3"
top: "conv2/norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2/3x3_s2"
type: "Pooling"
bottom: "conv2/norm2"
top: "pool2/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "inception_3a/1x1"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_1x1"
type: "ReLU"
bottom: "inception_3a/1x1"
top: "inception_3a/1x1"
}
layer {
name: "inception_3a/3x3_reduce"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_3a/3x3_reduce"
top: "inception_3a/3x3_reduce"
}
layer {
name: "inception_3a/3x3"
type: "Convolution"
bottom: "inception_3a/3x3_reduce"
top: "inception_3a/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_3x3"
type: "ReLU"
bottom: "inception_3a/3x3"
top: "inception_3a/3x3"
}
layer {
name: "inception_3a/5x5_reduce"
type: "Convolution"
bottom: "pool2/3x3_s2"
top: "inception_3a/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_3a/5x5_reduce"
top: "inception_3a/5x5_reduce"
}
layer {
name: "inception_3a/5x5"
type: "Convolution"
bottom: "inception_3a/5x5_reduce"
top: "inception_3a/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_5x5"
type: "ReLU"
bottom: "inception_3a/5x5"
top: "inception_3a/5x5"
}
layer {
name: "inception_3a/pool"
type: "Pooling"
bottom: "pool2/3x3_s2"
top: "inception_3a/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_3a/pool_proj"
type: "Convolution"
bottom: "inception_3a/pool"
top: "inception_3a/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3a/relu_pool_proj"
type: "ReLU"
bottom: "inception_3a/pool_proj"
top: "inception_3a/pool_proj"
}
layer {
name: "inception_3a/output"
type: "Concat"
bottom: "inception_3a/1x1"
bottom: "inception_3a/3x3"
bottom: "inception_3a/5x5"
bottom: "inception_3a/pool_proj"
top: "inception_3a/output"
}
layer {
name: "inception_3b/1x1"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_1x1"
type: "ReLU"
bottom: "inception_3b/1x1"
top: "inception_3b/1x1"
}
layer {
name: "inception_3b/3x3_reduce"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_3b/3x3_reduce"
top: "inception_3b/3x3_reduce"
}
layer {
name: "inception_3b/3x3"
type: "Convolution"
bottom: "inception_3b/3x3_reduce"
top: "inception_3b/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_3x3"
type: "ReLU"
bottom: "inception_3b/3x3"
top: "inception_3b/3x3"
}
layer {
name: "inception_3b/5x5_reduce"
type: "Convolution"
bottom: "inception_3a/output"
top: "inception_3b/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_3b/5x5_reduce"
top: "inception_3b/5x5_reduce"
}
layer {
name: "inception_3b/5x5"
type: "Convolution"
bottom: "inception_3b/5x5_reduce"
top: "inception_3b/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_5x5"
type: "ReLU"
bottom: "inception_3b/5x5"
top: "inception_3b/5x5"
}
layer {
name: "inception_3b/pool"
type: "Pooling"
bottom: "inception_3a/output"
top: "inception_3b/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_3b/pool_proj"
type: "Convolution"
bottom: "inception_3b/pool"
top: "inception_3b/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_3b/relu_pool_proj"
type: "ReLU"
bottom: "inception_3b/pool_proj"
top: "inception_3b/pool_proj"
}
layer {
name: "inception_3b/output"
type: "Concat"
bottom: "inception_3b/1x1"
bottom: "inception_3b/3x3"
bottom: "inception_3b/5x5"
bottom: "inception_3b/pool_proj"
top: "inception_3b/output"
}
layer {
name: "pool3/3x3_s2"
type: "Pooling"
bottom: "inception_3b/output"
top: "pool3/3x3_s2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "inception_4a/1x1"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 192
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_1x1"
type: "ReLU"
bottom: "inception_4a/1x1"
top: "inception_4a/1x1"
}
layer {
name: "inception_4a/3x3_reduce"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4a/3x3_reduce"
top: "inception_4a/3x3_reduce"
}
layer {
name: "inception_4a/3x3"
type: "Convolution"
bottom: "inception_4a/3x3_reduce"
top: "inception_4a/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 208
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_3x3"
type: "ReLU"
bottom: "inception_4a/3x3"
top: "inception_4a/3x3"
}
layer {
name: "inception_4a/5x5_reduce"
type: "Convolution"
bottom: "pool3/3x3_s2"
top: "inception_4a/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 16
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4a/5x5_reduce"
top: "inception_4a/5x5_reduce"
}
layer {
name: "inception_4a/5x5"
type: "Convolution"
bottom: "inception_4a/5x5_reduce"
top: "inception_4a/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 48
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_5x5"
type: "ReLU"
bottom: "inception_4a/5x5"
top: "inception_4a/5x5"
}
layer {
name: "inception_4a/pool"
type: "Pooling"
bottom: "pool3/3x3_s2"
top: "inception_4a/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4a/pool_proj"
type: "Convolution"
bottom: "inception_4a/pool"
top: "inception_4a/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4a/relu_pool_proj"
type: "ReLU"
bottom: "inception_4a/pool_proj"
top: "inception_4a/pool_proj"
}
layer {
name: "inception_4a/output"
type: "Concat"
bottom: "inception_4a/1x1"
bottom: "inception_4a/3x3"
bottom: "inception_4a/5x5"
bottom: "inception_4a/pool_proj"
top: "inception_4a/output"
}
layer {
name: "inception_4b/1x1"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 160
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_1x1"
type: "ReLU"
bottom: "inception_4b/1x1"
top: "inception_4b/1x1"
}
layer {
name: "inception_4b/3x3_reduce"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 112
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4b/3x3_reduce"
top: "inception_4b/3x3_reduce"
}
layer {
name: "inception_4b/3x3"
type: "Convolution"
bottom: "inception_4b/3x3_reduce"
top: "inception_4b/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 224
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_3x3"
type: "ReLU"
bottom: "inception_4b/3x3"
top: "inception_4b/3x3"
}
layer {
name: "inception_4b/5x5_reduce"
type: "Convolution"
bottom: "inception_4a/output"
top: "inception_4b/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 24
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4b/5x5_reduce"
top: "inception_4b/5x5_reduce"
}
layer {
name: "inception_4b/5x5"
type: "Convolution"
bottom: "inception_4b/5x5_reduce"
top: "inception_4b/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_5x5"
type: "ReLU"
bottom: "inception_4b/5x5"
top: "inception_4b/5x5"
}
layer {
name: "inception_4b/pool"
type: "Pooling"
bottom: "inception_4a/output"
top: "inception_4b/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4b/pool_proj"
type: "Convolution"
bottom: "inception_4b/pool"
top: "inception_4b/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4b/relu_pool_proj"
type: "ReLU"
bottom: "inception_4b/pool_proj"
top: "inception_4b/pool_proj"
}
layer {
name: "inception_4b/output"
type: "Concat"
bottom: "inception_4b/1x1"
bottom: "inception_4b/3x3"
bottom: "inception_4b/5x5"
bottom: "inception_4b/pool_proj"
top: "inception_4b/output"
}
layer {
name: "inception_4c/1x1"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_1x1"
type: "ReLU"
bottom: "inception_4c/1x1"
top: "inception_4c/1x1"
}
layer {
name: "inception_4c/3x3_reduce"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4c/3x3_reduce"
top: "inception_4c/3x3_reduce"
}
layer {
name: "inception_4c/3x3"
type: "Convolution"
bottom: "inception_4c/3x3_reduce"
top: "inception_4c/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_3x3"
type: "ReLU"
bottom: "inception_4c/3x3"
top: "inception_4c/3x3"
}
layer {
name: "inception_4c/5x5_reduce"
type: "Convolution"
bottom: "inception_4b/output"
top: "inception_4c/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 24
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4c/5x5_reduce"
top: "inception_4c/5x5_reduce"
}
layer {
name: "inception_4c/5x5"
type: "Convolution"
bottom: "inception_4c/5x5_reduce"
top: "inception_4c/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_5x5"
type: "ReLU"
bottom: "inception_4c/5x5"
top: "inception_4c/5x5"
}
layer {
name: "inception_4c/pool"
type: "Pooling"
bottom: "inception_4b/output"
top: "inception_4c/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4c/pool_proj"
type: "Convolution"
bottom: "inception_4c/pool"
top: "inception_4c/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4c/relu_pool_proj"
type: "ReLU"
bottom: "inception_4c/pool_proj"
top: "inception_4c/pool_proj"
}
layer {
name: "inception_4c/output"
type: "Concat"
bottom: "inception_4c/1x1"
bottom: "inception_4c/3x3"
bottom: "inception_4c/5x5"
bottom: "inception_4c/pool_proj"
top: "inception_4c/output"
}
layer {
name: "inception_4d/1x1"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 112
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_1x1"
type: "ReLU"
bottom: "inception_4d/1x1"
top: "inception_4d/1x1"
}
layer {
name: "inception_4d/3x3_reduce"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 144
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4d/3x3_reduce"
top: "inception_4d/3x3_reduce"
}
layer {
name: "inception_4d/3x3"
type: "Convolution"
bottom: "inception_4d/3x3_reduce"
top: "inception_4d/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 288
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_3x3"
type: "ReLU"
bottom: "inception_4d/3x3"
top: "inception_4d/3x3"
}
layer {
name: "inception_4d/5x5_reduce"
type: "Convolution"
bottom: "inception_4c/output"
top: "inception_4d/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4d/5x5_reduce"
top: "inception_4d/5x5_reduce"
}
layer {
name: "inception_4d/5x5"
type: "Convolution"
bottom: "inception_4d/5x5_reduce"
top: "inception_4d/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_5x5"
type: "ReLU"
bottom: "inception_4d/5x5"
top: "inception_4d/5x5"
}
layer {
name: "inception_4d/pool"
type: "Pooling"
bottom: "inception_4c/output"
top: "inception_4d/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4d/pool_proj"
type: "Convolution"
bottom: "inception_4d/pool"
top: "inception_4d/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 64
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4d/relu_pool_proj"
type: "ReLU"
bottom: "inception_4d/pool_proj"
top: "inception_4d/pool_proj"
}
layer {
name: "inception_4d/output"
type: "Concat"
bottom: "inception_4d/1x1"
bottom: "inception_4d/3x3"
bottom: "inception_4d/5x5"
bottom: "inception_4d/pool_proj"
top: "inception_4d/output"
}
layer {
name: "inception_4e/1x1"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/1x1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_1x1"
type: "ReLU"
bottom: "inception_4e/1x1"
top: "inception_4e/1x1"
}
layer {
name: "inception_4e/3x3_reduce"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/3x3_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 160
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.09
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_3x3_reduce"
type: "ReLU"
bottom: "inception_4e/3x3_reduce"
top: "inception_4e/3x3_reduce"
}
layer {
name: "inception_4e/3x3"
type: "Convolution"
bottom: "inception_4e/3x3_reduce"
top: "inception_4e/3x3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 320
pad: 1
kernel_size: 3
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_3x3"
type: "ReLU"
bottom: "inception_4e/3x3"
top: "inception_4e/3x3"
}
layer {
name: "inception_4e/5x5_reduce"
type: "Convolution"
bottom: "inception_4d/output"
top: "inception_4e/5x5_reduce"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 32
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.2
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_5x5_reduce"
type: "ReLU"
bottom: "inception_4e/5x5_reduce"
top: "inception_4e/5x5_reduce"
}
layer {
name: "inception_4e/5x5"
type: "Convolution"
bottom: "inception_4e/5x5_reduce"
top: "inception_4e/5x5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
pad: 2
kernel_size: 5
weight_filler {
type: "xavier"
std: 0.03
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_5x5"
type: "ReLU"
bottom: "inception_4e/5x5"
top: "inception_4e/5x5"
}
layer {
name: "inception_4e/pool"
type: "Pooling"
bottom: "inception_4d/output"
top: "inception_4e/pool"
pooling_param {
pool: MAX
kernel_size: 3
stride: 1
pad: 1
}
}
layer {
name: "inception_4e/pool_proj"
type: "Convolution"
bottom: "inception_4e/pool"
top: "inception_4e/pool_proj"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 128
kernel_size: 1
weight_filler {
type: "xavier"
std: 0.1
}
bias_filler {
type: "constant"
value: 0.2
}
}
}
layer {
name: "inception_4e/relu_pool_proj"
type: "ReLU"
bottom: "inception_4e/pool_proj"
top: "inception_4e/pool_proj"
}
layer {
name: "inception_4e/output"
type: "Concat"
bottom: "inception_4e/1x1"
bottom: "inception_4e/3x3"
bottom: "inception_4e/5x5"
bottom: "inception_4e/pool_proj"
top: "inception_4e/output"
}
layer {
name: "inception_5a/1x1"
type: "Convolution"
bottom: "inception_4e/output"
top: "inception_5a/1x1"
param {
lr_mult: 1
decay_mult: 1
I1130 22:37:42.079773   125 net.cpp:113] Using FLOAT as default forward math type
I1130 22:37:42.079782   125 net.cpp:119] Using FLOAT as default backward math type
I1130 22:37:42.079789   125 layer_factory.hpp:172] Creating layer 'val_data' of type 'Data'
I1130 22:37:42.079795   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.079823   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:42.080518   125 net.cpp:202] Created Layer val_data (0)
I1130 22:37:42.080528   125 net.cpp:544] val_data -> data
I1130 22:37:42.080539   125 data_reader.cpp:59] Data Reader threads: 1, out queues: 1, depth: 6
I1130 22:37:42.081245   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:42.082589   149 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/val_db/features
I1130 22:37:42.094400   125 data_layer.cpp:200] (n0.d0.r0) Output data size: 6, 3, 640, 640
I1130 22:37:42.094424   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:42.095075   125 net.cpp:262] Setting up val_data
I1130 22:37:42.095086   125 net.cpp:269] TEST Top shape for layer 0 'val_data' 6 3 640 640 (7372800)
I1130 22:37:42.095095   125 layer_factory.hpp:172] Creating layer 'val_label' of type 'Data'
I1130 22:37:42.095101   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.095724   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:42.095726   150 data_layer.cpp:105] (n0.d0.r0) Parser threads: 1
I1130 22:37:42.095741   150 data_layer.cpp:107] (n0.d0.r0) Transformer threads: 1
I1130 22:37:42.096405   125 net.cpp:202] Created Layer val_label (1)
I1130 22:37:42.096412   125 net.cpp:544] val_label -> label
I1130 22:37:42.096437   125 data_reader.cpp:59] Data Reader threads: 1, out queues: 1, depth: 6
I1130 22:37:42.096449   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:42.099689   152 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/val_db/labels
I1130 22:37:42.099901   125 data_layer.cpp:200] (n0.d0.r0) Output data size: 6, 1, 70, 16
I1130 22:37:42.099920   125 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:42.100594   125 net.cpp:262] Setting up val_label
I1130 22:37:42.100606   125 net.cpp:269] TEST Top shape for layer 1 'val_label' 6 1 70 16 (6720)
I1130 22:37:42.100612   125 layer_factory.hpp:172] Creating layer 'val_transform' of type 'DetectNetTransformation'
I1130 22:37:42.100620   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.101234   153 data_layer.cpp:105] (n0.d0.r0) Parser threads: 1
I1130 22:37:42.101244   125 net.cpp:202] Created Layer val_transform (2)
I1130 22:37:42.101249   153 data_layer.cpp:107] (n0.d0.r0) Transformer threads: 1
I1130 22:37:42.101253   125 net.cpp:574] val_transform <- data
I1130 22:37:42.101263   125 net.cpp:574] val_transform <- label
I1130 22:37:42.101269   125 net.cpp:544] val_transform -> transformed_data
I1130 22:37:42.101276   125 net.cpp:544] val_transform -> transformed_label
I1130 22:37:42.102751   125 net.cpp:262] Setting up val_transform
I1130 22:37:42.102766   125 net.cpp:269] TEST Top shape for layer 2 'val_transform' 6 3 640 640 (7372800)
I1130 22:37:42.102773   125 net.cpp:269] TEST Top shape for layer 2 'val_transform' 6 9 40 40 (86400)
I1130 22:37:42.102779   125 layer_factory.hpp:172] Creating layer 'slice-label' of type 'Slice'
I1130 22:37:42.102785   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.102795   125 net.cpp:202] Created Layer slice-label (3)
I1130 22:37:42.102802   125 net.cpp:574] slice-label <- transformed_label
I1130 22:37:42.102808   125 net.cpp:544] slice-label -> foreground-label
I1130 22:37:42.102816   125 net.cpp:544] slice-label -> bbox-label
I1130 22:37:42.102823   125 net.cpp:544] slice-label -> size-label
I1130 22:37:42.102829   125 net.cpp:544] slice-label -> obj-label
I1130 22:37:42.102835   125 net.cpp:544] slice-label -> coverage-label
I1130 22:37:42.102982   125 net.cpp:262] Setting up slice-label
I1130 22:37:42.102991   125 net.cpp:269] TEST Top shape for layer 3 'slice-label' 6 1 40 40 (9600)
I1130 22:37:42.102998   125 net.cpp:269] TEST Top shape for layer 3 'slice-label' 6 4 40 40 (38400)
I1130 22:37:42.103003   125 net.cpp:269] TEST Top shape for layer 3 'slice-label' 6 2 40 40 (19200)
I1130 22:37:42.103009   125 net.cpp:269] TEST Top shape for layer 3 'slice-label' 6 1 40 40 (9600)
I1130 22:37:42.103015   125 net.cpp:269] TEST Top shape for layer 3 'slice-label' 6 1 40 40 (9600)
I1130 22:37:42.103021   125 layer_factory.hpp:172] Creating layer 'foreground-label_slice-label_0_split' of type 'Split'
I1130 22:37:42.103027   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.103036   125 net.cpp:202] Created Layer foreground-label_slice-label_0_split (4)
I1130 22:37:42.103042   125 net.cpp:574] foreground-label_slice-label_0_split <- foreground-label
I1130 22:37:42.103049   125 net.cpp:544] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_0
I1130 22:37:42.103056   125 net.cpp:544] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_1
I1130 22:37:42.103063   125 net.cpp:544] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_2
I1130 22:37:42.103070   125 net.cpp:544] foreground-label_slice-label_0_split -> foreground-label_slice-label_0_split_3
I1130 22:37:42.103149   125 net.cpp:262] Setting up foreground-label_slice-label_0_split
I1130 22:37:42.103157   125 net.cpp:269] TEST Top shape for layer 4 'foreground-label_slice-label_0_split' 6 1 40 40 (9600)
I1130 22:37:42.103178   125 net.cpp:269] TEST Top shape for layer 4 'foreground-label_slice-label_0_split' 6 1 40 40 (9600)
I1130 22:37:42.103184   125 net.cpp:269] TEST Top shape for layer 4 'foreground-label_slice-label_0_split' 6 1 40 40 (9600)
I1130 22:37:42.103190   125 net.cpp:269] TEST Top shape for layer 4 'foreground-label_slice-label_0_split' 6 1 40 40 (9600)
I1130 22:37:42.103196   125 layer_factory.hpp:172] Creating layer 'bbox-label_slice-label_1_split' of type 'Split'
I1130 22:37:42.103202   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.103210   125 net.cpp:202] Created Layer bbox-label_slice-label_1_split (5)
I1130 22:37:42.103215   125 net.cpp:574] bbox-label_slice-label_1_split <- bbox-label
I1130 22:37:42.103222   125 net.cpp:544] bbox-label_slice-label_1_split -> bbox-label_slice-label_1_split_0
I1130 22:37:42.103229   125 net.cpp:544] bbox-label_slice-label_1_split -> bbox-label_slice-label_1_split_1
I1130 22:37:42.103278   125 net.cpp:262] Setting up bbox-label_slice-label_1_split
I1130 22:37:42.103287   125 net.cpp:269] TEST Top shape for layer 5 'bbox-label_slice-label_1_split' 6 4 40 40 (38400)
I1130 22:37:42.103293   125 net.cpp:269] TEST Top shape for layer 5 'bbox-label_slice-label_1_split' 6 4 40 40 (38400)
I1130 22:37:42.103298   125 layer_factory.hpp:172] Creating layer 'size-label_slice-label_2_split' of type 'Split'
I1130 22:37:42.103304   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.103312   125 net.cpp:202] Created Layer size-label_slice-label_2_split (6)
I1130 22:37:42.103317   125 net.cpp:574] size-label_slice-label_2_split <- size-label
I1130 22:37:42.103323   125 net.cpp:544] size-label_slice-label_2_split -> size-label_slice-label_2_split_0
I1130 22:37:42.103330   125 net.cpp:544] size-label_slice-label_2_split -> size-label_slice-label_2_split_1
I1130 22:37:42.103376   125 net.cpp:262] Setting up size-label_slice-label_2_split
I1130 22:37:42.103384   125 net.cpp:269] TEST Top shape for layer 6 'size-label_slice-label_2_split' 6 2 40 40 (19200)
I1130 22:37:42.103390   125 net.cpp:269] TEST Top shape for layer 6 'size-label_slice-label_2_split' 6 2 40 40 (19200)
I1130 22:37:42.103397   125 layer_factory.hpp:172] Creating layer 'obj-label_slice-label_3_split' of type 'Split'
I1130 22:37:42.103404   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.103410   125 net.cpp:202] Created Layer obj-label_slice-label_3_split (7)
I1130 22:37:42.103415   125 net.cpp:574] obj-label_slice-label_3_split <- obj-label
I1130 22:37:42.103422   125 net.cpp:544] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_0
I1130 22:37:42.103430   125 net.cpp:544] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_1
I1130 22:37:42.103436   125 net.cpp:544] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_2
I1130 22:37:42.103442   125 net.cpp:544] obj-label_slice-label_3_split -> obj-label_slice-label_3_split_3
I1130 22:37:42.103518   125 net.cpp:262] Setting up obj-label_slice-label_3_split
I1130 22:37:42.103525   125 net.cpp:269] TEST Top shape for layer 7 'obj-label_slice-label_3_split' 6 1 40 40 (9600)
I1130 22:37:42.103531   125 net.cpp:269] TEST Top shape for layer 7 'obj-label_slice-label_3_split' 6 1 40 40 (9600)
I1130 22:37:42.103538   125 net.cpp:269] TEST Top shape for layer 7 'obj-label_slice-label_3_split' 6 1 40 40 (9600)
I1130 22:37:42.103543   125 net.cpp:269] TEST Top shape for layer 7 'obj-label_slice-label_3_split' 6 1 40 40 (9600)
I1130 22:37:42.103549   125 layer_factory.hpp:172] Creating layer 'coverage-label_slice-label_4_split' of type 'Split'
I1130 22:37:42.103555   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.103564   125 net.cpp:202] Created Layer coverage-label_slice-label_4_split (8)
I1130 22:37:42.103569   125 net.cpp:574] coverage-label_slice-label_4_split <- coverage-label
I1130 22:37:42.103576   125 net.cpp:544] coverage-label_slice-label_4_split -> coverage-label_slice-label_4_split_0
I1130 22:37:42.103592   125 net.cpp:544] coverage-label_slice-label_4_split -> coverage-label_slice-label_4_split_1
I1130 22:37:42.103639   125 net.cpp:262] Setting up coverage-label_slice-label_4_split
I1130 22:37:42.103648   125 net.cpp:269] TEST Top shape for layer 8 'coverage-label_slice-label_4_split' 6 1 40 40 (9600)
I1130 22:37:42.103654   125 net.cpp:269] TEST Top shape for layer 8 'coverage-label_slice-label_4_split' 6 1 40 40 (9600)
I1130 22:37:42.103660   125 layer_factory.hpp:172] Creating layer 'coverage-block' of type 'Concat'
I1130 22:37:42.103667   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.103677   125 net.cpp:202] Created Layer coverage-block (9)
I1130 22:37:42.103682   125 net.cpp:574] coverage-block <- foreground-label_slice-label_0_split_0
I1130 22:37:42.116966   125 net.cpp:574] coverage-block <- foreground-label_slice-label_0_split_1
I1130 22:37:42.116977   125 net.cpp:574] coverage-block <- foreground-label_slice-label_0_split_2
I1130 22:37:42.116983   125 net.cpp:574] coverage-block <- foreground-label_slice-label_0_split_3
I1130 22:37:42.116989   125 net.cpp:544] coverage-block -> coverage-block
I1130 22:37:42.122448   125 net.cpp:262] Setting up coverage-block
I1130 22:37:42.122462   125 net.cpp:269] TEST Top shape for layer 9 'coverage-block' 6 4 40 40 (38400)
I1130 22:37:42.122468   125 layer_factory.hpp:172] Creating layer 'size-block' of type 'Concat'
I1130 22:37:42.122474   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.122483   125 net.cpp:202] Created Layer size-block (10)
I1130 22:37:42.122488   125 net.cpp:574] size-block <- size-label_slice-label_2_split_0
I1130 22:37:42.122496   125 net.cpp:574] size-block <- size-label_slice-label_2_split_1
I1130 22:37:42.122503   125 net.cpp:544] size-block -> size-block
I1130 22:37:42.122537   125 net.cpp:262] Setting up size-block
I1130 22:37:42.122545   125 net.cpp:269] TEST Top shape for layer 10 'size-block' 6 4 40 40 (38400)
I1130 22:37:42.122550   125 layer_factory.hpp:172] Creating layer 'size-block_size-block_0_split' of type 'Split'
I1130 22:37:42.122556   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.122565   125 net.cpp:202] Created Layer size-block_size-block_0_split (11)
I1130 22:37:42.122570   125 net.cpp:574] size-block_size-block_0_split <- size-block
I1130 22:37:42.122576   125 net.cpp:544] size-block_size-block_0_split -> size-block_size-block_0_split_0
I1130 22:37:42.122586   125 net.cpp:544] size-block_size-block_0_split -> size-block_size-block_0_split_1
I1130 22:37:42.122632   125 net.cpp:262] Setting up size-block_size-block_0_split
I1130 22:37:42.122639   125 net.cpp:269] TEST Top shape for layer 11 'size-block_size-block_0_split' 6 4 40 40 (38400)
I1130 22:37:42.122647   125 net.cpp:269] TEST Top shape for layer 11 'size-block_size-block_0_split' 6 4 40 40 (38400)
I1130 22:37:42.122653   125 layer_factory.hpp:172] Creating layer 'obj-block' of type 'Concat'
I1130 22:37:42.122658   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.122666   125 net.cpp:202] Created Layer obj-block (12)
I1130 22:37:42.122671   125 net.cpp:574] obj-block <- obj-label_slice-label_3_split_0
I1130 22:37:42.122678   125 net.cpp:574] obj-block <- obj-label_slice-label_3_split_1
I1130 22:37:42.122684   125 net.cpp:574] obj-block <- obj-label_slice-label_3_split_2
I1130 22:37:42.122689   125 net.cpp:574] obj-block <- obj-label_slice-label_3_split_3
I1130 22:37:42.122695   125 net.cpp:544] obj-block -> obj-block
I1130 22:37:42.122726   125 net.cpp:262] Setting up obj-block
I1130 22:37:42.122733   125 net.cpp:269] TEST Top shape for layer 12 'obj-block' 6 4 40 40 (38400)
I1130 22:37:42.122740   125 layer_factory.hpp:172] Creating layer 'obj-block_obj-block_0_split' of type 'Split'
I1130 22:37:42.122745   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.122766   125 net.cpp:202] Created Layer obj-block_obj-block_0_split (13)
I1130 22:37:42.122772   125 net.cpp:574] obj-block_obj-block_0_split <- obj-block
I1130 22:37:42.122778   125 net.cpp:544] obj-block_obj-block_0_split -> obj-block_obj-block_0_split_0
I1130 22:37:42.122786   125 net.cpp:544] obj-block_obj-block_0_split -> obj-block_obj-block_0_split_1
I1130 22:37:42.122838   125 net.cpp:262] Setting up obj-block_obj-block_0_split
I1130 22:37:42.122845   125 net.cpp:269] TEST Top shape for layer 13 'obj-block_obj-block_0_split' 6 4 40 40 (38400)
I1130 22:37:42.122851   125 net.cpp:269] TEST Top shape for layer 13 'obj-block_obj-block_0_split' 6 4 40 40 (38400)
I1130 22:37:42.122858   125 layer_factory.hpp:172] Creating layer 'bb-label-norm' of type 'Eltwise'
I1130 22:37:42.122864   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.122875   125 net.cpp:202] Created Layer bb-label-norm (14)
I1130 22:37:42.122880   125 net.cpp:574] bb-label-norm <- bbox-label_slice-label_1_split_0
I1130 22:37:42.122887   125 net.cpp:574] bb-label-norm <- size-block_size-block_0_split_0
I1130 22:37:42.122895   125 net.cpp:544] bb-label-norm -> bbox-label-norm
I1130 22:37:42.122931   125 net.cpp:262] Setting up bb-label-norm
I1130 22:37:42.122938   125 net.cpp:269] TEST Top shape for layer 14 'bb-label-norm' 6 4 40 40 (38400)
I1130 22:37:42.122944   125 layer_factory.hpp:172] Creating layer 'bb-obj-norm' of type 'Eltwise'
I1130 22:37:42.122949   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.122958   125 net.cpp:202] Created Layer bb-obj-norm (15)
I1130 22:37:42.122963   125 net.cpp:574] bb-obj-norm <- bbox-label-norm
I1130 22:37:42.122970   125 net.cpp:574] bb-obj-norm <- obj-block_obj-block_0_split_0
I1130 22:37:42.122977   125 net.cpp:544] bb-obj-norm -> bbox-obj-label-norm
I1130 22:37:42.123008   125 net.cpp:262] Setting up bb-obj-norm
I1130 22:37:42.123014   125 net.cpp:269] TEST Top shape for layer 15 'bb-obj-norm' 6 4 40 40 (38400)
I1130 22:37:42.123020   125 layer_factory.hpp:172] Creating layer 'conv1/7x7_s2' of type 'Convolution'
I1130 22:37:42.123026   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.123049   125 net.cpp:202] Created Layer conv1/7x7_s2 (16)
I1130 22:37:42.123054   125 net.cpp:574] conv1/7x7_s2 <- transformed_data
I1130 22:37:42.123060   125 net.cpp:544] conv1/7x7_s2 -> conv1/7x7_s2
I1130 22:37:42.123786   125 net.cpp:262] Setting up conv1/7x7_s2
I1130 22:37:42.123800   125 net.cpp:269] TEST Top shape for layer 16 'conv1/7x7_s2' 6 64 320 320 (39321600)
I1130 22:37:42.123814   125 layer_factory.hpp:172] Creating layer 'conv1/relu_7x7' of type 'ReLU'
I1130 22:37:42.123821   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.123831   125 net.cpp:202] Created Layer conv1/relu_7x7 (17)
I1130 22:37:42.123836   125 net.cpp:574] conv1/relu_7x7 <- conv1/7x7_s2
I1130 22:37:42.123842   125 net.cpp:529] conv1/relu_7x7 -> conv1/7x7_s2 (in-place)
I1130 22:37:42.123854   125 net.cpp:262] Setting up conv1/relu_7x7
I1130 22:37:42.123862   125 net.cpp:269] TEST Top shape for layer 17 'conv1/relu_7x7' 6 64 320 320 (39321600)
I1130 22:37:42.123867   125 layer_factory.hpp:172] Creating layer 'pool1/3x3_s2' of type 'Pooling'
I1130 22:37:42.123872   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.123883   125 net.cpp:202] Created Layer pool1/3x3_s2 (18)
I1130 22:37:42.123888   125 net.cpp:574] pool1/3x3_s2 <- conv1/7x7_s2
I1130 22:37:42.123894   125 net.cpp:544] pool1/3x3_s2 -> pool1/3x3_s2
I1130 22:37:42.124004   125 net.cpp:262] Setting up pool1/3x3_s2
I1130 22:37:42.124017   125 net.cpp:269] TEST Top shape for layer 18 'pool1/3x3_s2' 6 64 160 160 (9830400)
I1130 22:37:42.124022   125 layer_factory.hpp:172] Creating layer 'pool1/norm1' of type 'LRN'
I1130 22:37:42.124028   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.124054   125 net.cpp:202] Created Layer pool1/norm1 (19)
I1130 22:37:42.124061   125 net.cpp:574] pool1/norm1 <- pool1/3x3_s2
I1130 22:37:42.124068   125 net.cpp:544] pool1/norm1 -> pool1/norm1
I1130 22:37:42.124125   125 net.cpp:262] Setting up pool1/norm1
I1130 22:37:42.124132   125 net.cpp:269] TEST Top shape for layer 19 'pool1/norm1' 6 64 160 160 (9830400)
I1130 22:37:42.124140   125 layer_factory.hpp:172] Creating layer 'conv2/3x3_reduce' of type 'Convolution'
I1130 22:37:42.124145   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.124161   125 net.cpp:202] Created Layer conv2/3x3_reduce (20)
I1130 22:37:42.124166   125 net.cpp:574] conv2/3x3_reduce <- pool1/norm1
I1130 22:37:42.124172   125 net.cpp:544] conv2/3x3_reduce -> conv2/3x3_reduce
I1130 22:37:42.124625   125 net.cpp:262] Setting up conv2/3x3_reduce
I1130 22:37:42.124636   125 net.cpp:269] TEST Top shape for layer 20 'conv2/3x3_reduce' 6 64 160 160 (9830400)
I1130 22:37:42.124647   125 layer_factory.hpp:172] Creating layer 'conv2/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.124655   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.124663   125 net.cpp:202] Created Layer conv2/relu_3x3_reduce (21)
I1130 22:37:42.124670   125 net.cpp:574] conv2/relu_3x3_reduce <- conv2/3x3_reduce
I1130 22:37:42.124675   125 net.cpp:529] conv2/relu_3x3_reduce -> conv2/3x3_reduce (in-place)
I1130 22:37:42.124686   125 net.cpp:262] Setting up conv2/relu_3x3_reduce
I1130 22:37:42.124693   125 net.cpp:269] TEST Top shape for layer 21 'conv2/relu_3x3_reduce' 6 64 160 160 (9830400)
I1130 22:37:42.124698   125 layer_factory.hpp:172] Creating layer 'conv2/3x3' of type 'Convolution'
I1130 22:37:42.124704   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.124719   125 net.cpp:202] Created Layer conv2/3x3 (22)
I1130 22:37:42.124725   125 net.cpp:574] conv2/3x3 <- conv2/3x3_reduce
I1130 22:37:42.124730   125 net.cpp:544] conv2/3x3 -> conv2/3x3
I1130 22:37:42.126770   125 net.cpp:262] Setting up conv2/3x3
I1130 22:37:42.126781   125 net.cpp:269] TEST Top shape for layer 22 'conv2/3x3' 6 192 160 160 (29491200)
I1130 22:37:42.126793   125 layer_factory.hpp:172] Creating layer 'conv2/relu_3x3' of type 'ReLU'
I1130 22:37:42.126799   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.126808   125 net.cpp:202] Created Layer conv2/relu_3x3 (23)
I1130 22:37:42.126814   125 net.cpp:574] conv2/relu_3x3 <- conv2/3x3
I1130 22:37:42.126821   125 net.cpp:529] conv2/relu_3x3 -> conv2/3x3 (in-place)
I1130 22:37:42.126828   125 net.cpp:262] Setting up conv2/relu_3x3
I1130 22:37:42.126834   125 net.cpp:269] TEST Top shape for layer 23 'conv2/relu_3x3' 6 192 160 160 (29491200)
I1130 22:37:42.126842   125 layer_factory.hpp:172] Creating layer 'conv2/norm2' of type 'LRN'
I1130 22:37:42.126847   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.126858   125 net.cpp:202] Created Layer conv2/norm2 (24)
I1130 22:37:42.126863   125 net.cpp:574] conv2/norm2 <- conv2/3x3
I1130 22:37:42.126869   125 net.cpp:544] conv2/norm2 -> conv2/norm2
I1130 22:37:42.126926   125 net.cpp:262] Setting up conv2/norm2
I1130 22:37:42.126935   125 net.cpp:269] TEST Top shape for layer 24 'conv2/norm2' 6 192 160 160 (29491200)
I1130 22:37:42.126940   125 layer_factory.hpp:172] Creating layer 'pool2/3x3_s2' of type 'Pooling'
I1130 22:37:42.126947   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.126957   125 net.cpp:202] Created Layer pool2/3x3_s2 (25)
I1130 22:37:42.126963   125 net.cpp:574] pool2/3x3_s2 <- conv2/norm2
I1130 22:37:42.126968   125 net.cpp:544] pool2/3x3_s2 -> pool2/3x3_s2
I1130 22:37:42.127038   125 net.cpp:262] Setting up pool2/3x3_s2
I1130 22:37:42.127046   125 net.cpp:269] TEST Top shape for layer 25 'pool2/3x3_s2' 6 192 80 80 (7372800)
I1130 22:37:42.127063   125 layer_factory.hpp:172] Creating layer 'pool2/3x3_s2_pool2/3x3_s2_0_split' of type 'Split'
I1130 22:37:42.127069   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.127079   125 net.cpp:202] Created Layer pool2/3x3_s2_pool2/3x3_s2_0_split (26)
I1130 22:37:42.127084   125 net.cpp:574] pool2/3x3_s2_pool2/3x3_s2_0_split <- pool2/3x3_s2
I1130 22:37:42.127090   125 net.cpp:544] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_0
I1130 22:37:42.127099   125 net.cpp:544] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_1
I1130 22:37:42.127108   125 net.cpp:544] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_2
I1130 22:37:42.127115   125 net.cpp:544] pool2/3x3_s2_pool2/3x3_s2_0_split -> pool2/3x3_s2_pool2/3x3_s2_0_split_3
I1130 22:37:42.127195   125 net.cpp:262] Setting up pool2/3x3_s2_pool2/3x3_s2_0_split
I1130 22:37:42.127202   125 net.cpp:269] TEST Top shape for layer 26 'pool2/3x3_s2_pool2/3x3_s2_0_split' 6 192 80 80 (7372800)
I1130 22:37:42.127209   125 net.cpp:269] TEST Top shape for layer 26 'pool2/3x3_s2_pool2/3x3_s2_0_split' 6 192 80 80 (7372800)
I1130 22:37:42.127215   125 net.cpp:269] TEST Top shape for layer 26 'pool2/3x3_s2_pool2/3x3_s2_0_split' 6 192 80 80 (7372800)
I1130 22:37:42.127220   125 net.cpp:269] TEST Top shape for layer 26 'pool2/3x3_s2_pool2/3x3_s2_0_split' 6 192 80 80 (7372800)
I1130 22:37:42.127226   125 layer_factory.hpp:172] Creating layer 'inception_3a/1x1' of type 'Convolution'
I1130 22:37:42.127233   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.127248   125 net.cpp:202] Created Layer inception_3a/1x1 (27)
I1130 22:37:42.127254   125 net.cpp:574] inception_3a/1x1 <- pool2/3x3_s2_pool2/3x3_s2_0_split_0
I1130 22:37:42.127259   125 net.cpp:544] inception_3a/1x1 -> inception_3a/1x1
I1130 22:37:42.127791   125 net.cpp:262] Setting up inception_3a/1x1
I1130 22:37:42.127804   125 net.cpp:269] TEST Top shape for layer 27 'inception_3a/1x1' 6 64 80 80 (2457600)
I1130 22:37:42.127811   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_1x1' of type 'ReLU'
I1130 22:37:42.127817   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.127826   125 net.cpp:202] Created Layer inception_3a/relu_1x1 (28)
I1130 22:37:42.127831   125 net.cpp:574] inception_3a/relu_1x1 <- inception_3a/1x1
I1130 22:37:42.127837   125 net.cpp:529] inception_3a/relu_1x1 -> inception_3a/1x1 (in-place)
I1130 22:37:42.127847   125 net.cpp:262] Setting up inception_3a/relu_1x1
I1130 22:37:42.127853   125 net.cpp:269] TEST Top shape for layer 28 'inception_3a/relu_1x1' 6 64 80 80 (2457600)
I1130 22:37:42.127859   125 layer_factory.hpp:172] Creating layer 'inception_3a/3x3_reduce' of type 'Convolution'
I1130 22:37:42.127864   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.127879   125 net.cpp:202] Created Layer inception_3a/3x3_reduce (29)
I1130 22:37:42.127885   125 net.cpp:574] inception_3a/3x3_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_1
I1130 22:37:42.127892   125 net.cpp:544] inception_3a/3x3_reduce -> inception_3a/3x3_reduce
I1130 22:37:42.128581   125 net.cpp:262] Setting up inception_3a/3x3_reduce
I1130 22:37:42.128592   125 net.cpp:269] TEST Top shape for layer 29 'inception_3a/3x3_reduce' 6 96 80 80 (3686400)
I1130 22:37:42.128604   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.128610   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.128618   125 net.cpp:202] Created Layer inception_3a/relu_3x3_reduce (30)
I1130 22:37:42.128624   125 net.cpp:574] inception_3a/relu_3x3_reduce <- inception_3a/3x3_reduce
I1130 22:37:42.128630   125 net.cpp:529] inception_3a/relu_3x3_reduce -> inception_3a/3x3_reduce (in-place)
I1130 22:37:42.128651   125 net.cpp:262] Setting up inception_3a/relu_3x3_reduce
I1130 22:37:42.128659   125 net.cpp:269] TEST Top shape for layer 30 'inception_3a/relu_3x3_reduce' 6 96 80 80 (3686400)
I1130 22:37:42.128664   125 layer_factory.hpp:172] Creating layer 'inception_3a/3x3' of type 'Convolution'
I1130 22:37:42.128670   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.128685   125 net.cpp:202] Created Layer inception_3a/3x3 (31)
I1130 22:37:42.128691   125 net.cpp:574] inception_3a/3x3 <- inception_3a/3x3_reduce
I1130 22:37:42.128696   125 net.cpp:544] inception_3a/3x3 -> inception_3a/3x3
I1130 22:37:42.132000   125 net.cpp:262] Setting up inception_3a/3x3
I1130 22:37:42.132017   125 net.cpp:269] TEST Top shape for layer 31 'inception_3a/3x3' 6 128 80 80 (4915200)
I1130 22:37:42.132026   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_3x3' of type 'ReLU'
I1130 22:37:42.132032   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.132046   125 net.cpp:202] Created Layer inception_3a/relu_3x3 (32)
I1130 22:37:42.132052   125 net.cpp:574] inception_3a/relu_3x3 <- inception_3a/3x3
I1130 22:37:42.132059   125 net.cpp:529] inception_3a/relu_3x3 -> inception_3a/3x3 (in-place)
I1130 22:37:42.132067   125 net.cpp:262] Setting up inception_3a/relu_3x3
I1130 22:37:42.132074   125 net.cpp:269] TEST Top shape for layer 32 'inception_3a/relu_3x3' 6 128 80 80 (4915200)
I1130 22:37:42.132081   125 layer_factory.hpp:172] Creating layer 'inception_3a/5x5_reduce' of type 'Convolution'
I1130 22:37:42.132086   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.132102   125 net.cpp:202] Created Layer inception_3a/5x5_reduce (33)
I1130 22:37:42.132108   125 net.cpp:574] inception_3a/5x5_reduce <- pool2/3x3_s2_pool2/3x3_s2_0_split_2
I1130 22:37:42.132115   125 net.cpp:544] inception_3a/5x5_reduce -> inception_3a/5x5_reduce
I1130 22:37:42.132529   125 net.cpp:262] Setting up inception_3a/5x5_reduce
I1130 22:37:42.132539   125 net.cpp:269] TEST Top shape for layer 33 'inception_3a/5x5_reduce' 6 16 80 80 (614400)
I1130 22:37:42.132549   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.132555   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.132565   125 net.cpp:202] Created Layer inception_3a/relu_5x5_reduce (34)
I1130 22:37:42.132570   125 net.cpp:574] inception_3a/relu_5x5_reduce <- inception_3a/5x5_reduce
I1130 22:37:42.132576   125 net.cpp:529] inception_3a/relu_5x5_reduce -> inception_3a/5x5_reduce (in-place)
I1130 22:37:42.132586   125 net.cpp:262] Setting up inception_3a/relu_5x5_reduce
I1130 22:37:42.132592   125 net.cpp:269] TEST Top shape for layer 34 'inception_3a/relu_5x5_reduce' 6 16 80 80 (614400)
I1130 22:37:42.132598   125 layer_factory.hpp:172] Creating layer 'inception_3a/5x5' of type 'Convolution'
I1130 22:37:42.132604   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.132620   125 net.cpp:202] Created Layer inception_3a/5x5 (35)
I1130 22:37:42.132625   125 net.cpp:574] inception_3a/5x5 <- inception_3a/5x5_reduce
I1130 22:37:42.132630   125 net.cpp:544] inception_3a/5x5 -> inception_3a/5x5
I1130 22:37:42.133168   125 net.cpp:262] Setting up inception_3a/5x5
I1130 22:37:42.133179   125 net.cpp:269] TEST Top shape for layer 35 'inception_3a/5x5' 6 32 80 80 (1228800)
I1130 22:37:42.133188   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_5x5' of type 'ReLU'
I1130 22:37:42.133193   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.133203   125 net.cpp:202] Created Layer inception_3a/relu_5x5 (36)
I1130 22:37:42.133208   125 net.cpp:574] inception_3a/relu_5x5 <- inception_3a/5x5
I1130 22:37:42.133213   125 net.cpp:529] inception_3a/relu_5x5 -> inception_3a/5x5 (in-place)
I1130 22:37:42.133222   125 net.cpp:262] Setting up inception_3a/relu_5x5
I1130 22:37:42.133244   125 net.cpp:269] TEST Top shape for layer 36 'inception_3a/relu_5x5' 6 32 80 80 (1228800)
I1130 22:37:42.133249   125 layer_factory.hpp:172] Creating layer 'inception_3a/pool' of type 'Pooling'
I1130 22:37:42.133255   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.133265   125 net.cpp:202] Created Layer inception_3a/pool (37)
I1130 22:37:42.133271   125 net.cpp:574] inception_3a/pool <- pool2/3x3_s2_pool2/3x3_s2_0_split_3
I1130 22:37:42.133277   125 net.cpp:544] inception_3a/pool -> inception_3a/pool
I1130 22:37:42.133357   125 net.cpp:262] Setting up inception_3a/pool
I1130 22:37:42.133365   125 net.cpp:269] TEST Top shape for layer 37 'inception_3a/pool' 6 192 80 80 (7372800)
I1130 22:37:42.133373   125 layer_factory.hpp:172] Creating layer 'inception_3a/pool_proj' of type 'Convolution'
I1130 22:37:42.133378   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.133394   125 net.cpp:202] Created Layer inception_3a/pool_proj (38)
I1130 22:37:42.133399   125 net.cpp:574] inception_3a/pool_proj <- inception_3a/pool
I1130 22:37:42.133405   125 net.cpp:544] inception_3a/pool_proj -> inception_3a/pool_proj
I1130 22:37:42.133846   125 net.cpp:262] Setting up inception_3a/pool_proj
I1130 22:37:42.133855   125 net.cpp:269] TEST Top shape for layer 38 'inception_3a/pool_proj' 6 32 80 80 (1228800)
I1130 22:37:42.133869   125 layer_factory.hpp:172] Creating layer 'inception_3a/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.133877   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.133884   125 net.cpp:202] Created Layer inception_3a/relu_pool_proj (39)
I1130 22:37:42.133890   125 net.cpp:574] inception_3a/relu_pool_proj <- inception_3a/pool_proj
I1130 22:37:42.133895   125 net.cpp:529] inception_3a/relu_pool_proj -> inception_3a/pool_proj (in-place)
I1130 22:37:42.133905   125 net.cpp:262] Setting up inception_3a/relu_pool_proj
I1130 22:37:42.133911   125 net.cpp:269] TEST Top shape for layer 39 'inception_3a/relu_pool_proj' 6 32 80 80 (1228800)
I1130 22:37:42.133918   125 layer_factory.hpp:172] Creating layer 'inception_3a/output' of type 'Concat'
I1130 22:37:42.133922   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.133931   125 net.cpp:202] Created Layer inception_3a/output (40)
I1130 22:37:42.133936   125 net.cpp:574] inception_3a/output <- inception_3a/1x1
I1130 22:37:42.133942   125 net.cpp:574] inception_3a/output <- inception_3a/3x3
I1130 22:37:42.133947   125 net.cpp:574] inception_3a/output <- inception_3a/5x5
I1130 22:37:42.133954   125 net.cpp:574] inception_3a/output <- inception_3a/pool_proj
I1130 22:37:42.133960   125 net.cpp:544] inception_3a/output -> inception_3a/output
I1130 22:37:42.133996   125 net.cpp:262] Setting up inception_3a/output
I1130 22:37:42.134003   125 net.cpp:269] TEST Top shape for layer 40 'inception_3a/output' 6 256 80 80 (9830400)
I1130 22:37:42.134009   125 layer_factory.hpp:172] Creating layer 'inception_3a/output_inception_3a/output_0_split' of type 'Split'
I1130 22:37:42.134016   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.134024   125 net.cpp:202] Created Layer inception_3a/output_inception_3a/output_0_split (41)
I1130 22:37:42.134029   125 net.cpp:574] inception_3a/output_inception_3a/output_0_split <- inception_3a/output
I1130 22:37:42.134037   125 net.cpp:544] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_0
I1130 22:37:42.134045   125 net.cpp:544] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_1
I1130 22:37:42.134053   125 net.cpp:544] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_2
I1130 22:37:42.134059   125 net.cpp:544] inception_3a/output_inception_3a/output_0_split -> inception_3a/output_inception_3a/output_0_split_3
I1130 22:37:42.134157   125 net.cpp:262] Setting up inception_3a/output_inception_3a/output_0_split
I1130 22:37:42.134166   125 net.cpp:269] TEST Top shape for layer 41 'inception_3a/output_inception_3a/output_0_split' 6 256 80 80 (9830400)
I1130 22:37:42.134171   125 net.cpp:269] TEST Top shape for layer 41 'inception_3a/output_inception_3a/output_0_split' 6 256 80 80 (9830400)
I1130 22:37:42.134177   125 net.cpp:269] TEST Top shape for layer 41 'inception_3a/output_inception_3a/output_0_split' 6 256 80 80 (9830400)
I1130 22:37:42.134184   125 net.cpp:269] TEST Top shape for layer 41 'inception_3a/output_inception_3a/output_0_split' 6 256 80 80 (9830400)
I1130 22:37:42.134191   125 layer_factory.hpp:172] Creating layer 'inception_3b/1x1' of type 'Convolution'
I1130 22:37:42.134196   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.134213   125 net.cpp:202] Created Layer inception_3b/1x1 (42)
I1130 22:37:42.134219   125 net.cpp:574] inception_3b/1x1 <- inception_3a/output_inception_3a/output_0_split_0
I1130 22:37:42.134227   125 net.cpp:544] inception_3b/1x1 -> inception_3b/1x1
I1130 22:37:42.135063   125 net.cpp:262] Setting up inception_3b/1x1
I1130 22:37:42.135074   125 net.cpp:269] TEST Top shape for layer 42 'inception_3b/1x1' 6 128 80 80 (4915200)
I1130 22:37:42.135083   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_1x1' of type 'ReLU'
I1130 22:37:42.135089   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.135097   125 net.cpp:202] Created Layer inception_3b/relu_1x1 (43)
I1130 22:37:42.135103   125 net.cpp:574] inception_3b/relu_1x1 <- inception_3b/1x1
I1130 22:37:42.135110   125 net.cpp:529] inception_3b/relu_1x1 -> inception_3b/1x1 (in-place)
I1130 22:37:42.135120   125 net.cpp:262] Setting up inception_3b/relu_1x1
I1130 22:37:42.135126   125 net.cpp:269] TEST Top shape for layer 43 'inception_3b/relu_1x1' 6 128 80 80 (4915200)
I1130 22:37:42.135131   125 layer_factory.hpp:172] Creating layer 'inception_3b/3x3_reduce' of type 'Convolution'
I1130 22:37:42.135138   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.135154   125 net.cpp:202] Created Layer inception_3b/3x3_reduce (44)
I1130 22:37:42.135159   125 net.cpp:574] inception_3b/3x3_reduce <- inception_3a/output_inception_3a/output_0_split_1
I1130 22:37:42.135165   125 net.cpp:544] inception_3b/3x3_reduce -> inception_3b/3x3_reduce
I1130 22:37:42.136036   125 net.cpp:262] Setting up inception_3b/3x3_reduce
I1130 22:37:42.136049   125 net.cpp:269] TEST Top shape for layer 44 'inception_3b/3x3_reduce' 6 128 80 80 (4915200)
I1130 22:37:42.136057   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.136063   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.136073   125 net.cpp:202] Created Layer inception_3b/relu_3x3_reduce (45)
I1130 22:37:42.136080   125 net.cpp:574] inception_3b/relu_3x3_reduce <- inception_3b/3x3_reduce
I1130 22:37:42.136085   125 net.cpp:529] inception_3b/relu_3x3_reduce -> inception_3b/3x3_reduce (in-place)
I1130 22:37:42.136095   125 net.cpp:262] Setting up inception_3b/relu_3x3_reduce
I1130 22:37:42.136101   125 net.cpp:269] TEST Top shape for layer 45 'inception_3b/relu_3x3_reduce' 6 128 80 80 (4915200)
I1130 22:37:42.136108   125 layer_factory.hpp:172] Creating layer 'inception_3b/3x3' of type 'Convolution'
I1130 22:37:42.136113   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.136128   125 net.cpp:202] Created Layer inception_3b/3x3 (46)
I1130 22:37:42.136133   125 net.cpp:574] inception_3b/3x3 <- inception_3b/3x3_reduce
I1130 22:37:42.136139   125 net.cpp:544] inception_3b/3x3 -> inception_3b/3x3
I1130 22:37:42.139822   125 net.cpp:262] Setting up inception_3b/3x3
I1130 22:37:42.139833   125 net.cpp:269] TEST Top shape for layer 46 'inception_3b/3x3' 6 192 80 80 (7372800)
I1130 22:37:42.139855   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_3x3' of type 'ReLU'
I1130 22:37:42.139863   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.139871   125 net.cpp:202] Created Layer inception_3b/relu_3x3 (47)
I1130 22:37:42.139876   125 net.cpp:574] inception_3b/relu_3x3 <- inception_3b/3x3
I1130 22:37:42.139883   125 net.cpp:529] inception_3b/relu_3x3 -> inception_3b/3x3 (in-place)
I1130 22:37:42.139894   125 net.cpp:262] Setting up inception_3b/relu_3x3
I1130 22:37:42.139900   125 net.cpp:269] TEST Top shape for layer 47 'inception_3b/relu_3x3' 6 192 80 80 (7372800)
I1130 22:37:42.139905   125 layer_factory.hpp:172] Creating layer 'inception_3b/5x5_reduce' of type 'Convolution'
I1130 22:37:42.139926   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.139943   125 net.cpp:202] Created Layer inception_3b/5x5_reduce (48)
I1130 22:37:42.139950   125 net.cpp:574] inception_3b/5x5_reduce <- inception_3a/output_inception_3a/output_0_split_2
I1130 22:37:42.139955   125 net.cpp:544] inception_3b/5x5_reduce -> inception_3b/5x5_reduce
I1130 22:37:42.140434   125 net.cpp:262] Setting up inception_3b/5x5_reduce
I1130 22:37:42.140444   125 net.cpp:269] TEST Top shape for layer 48 'inception_3b/5x5_reduce' 6 32 80 80 (1228800)
I1130 22:37:42.140453   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.140460   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.140468   125 net.cpp:202] Created Layer inception_3b/relu_5x5_reduce (49)
I1130 22:37:42.140475   125 net.cpp:574] inception_3b/relu_5x5_reduce <- inception_3b/5x5_reduce
I1130 22:37:42.140480   125 net.cpp:529] inception_3b/relu_5x5_reduce -> inception_3b/5x5_reduce (in-place)
I1130 22:37:42.140488   125 net.cpp:262] Setting up inception_3b/relu_5x5_reduce
I1130 22:37:42.140496   125 net.cpp:269] TEST Top shape for layer 49 'inception_3b/relu_5x5_reduce' 6 32 80 80 (1228800)
I1130 22:37:42.140502   125 layer_factory.hpp:172] Creating layer 'inception_3b/5x5' of type 'Convolution'
I1130 22:37:42.140507   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.140522   125 net.cpp:202] Created Layer inception_3b/5x5 (50)
I1130 22:37:42.140527   125 net.cpp:574] inception_3b/5x5 <- inception_3b/5x5_reduce
I1130 22:37:42.140533   125 net.cpp:544] inception_3b/5x5 -> inception_3b/5x5
I1130 22:37:42.142032   125 net.cpp:262] Setting up inception_3b/5x5
I1130 22:37:42.142043   125 net.cpp:269] TEST Top shape for layer 50 'inception_3b/5x5' 6 96 80 80 (3686400)
I1130 22:37:42.142052   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_5x5' of type 'ReLU'
I1130 22:37:42.142058   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.142066   125 net.cpp:202] Created Layer inception_3b/relu_5x5 (51)
I1130 22:37:42.142072   125 net.cpp:574] inception_3b/relu_5x5 <- inception_3b/5x5
I1130 22:37:42.142079   125 net.cpp:529] inception_3b/relu_5x5 -> inception_3b/5x5 (in-place)
I1130 22:37:42.142088   125 net.cpp:262] Setting up inception_3b/relu_5x5
I1130 22:37:42.142094   125 net.cpp:269] TEST Top shape for layer 51 'inception_3b/relu_5x5' 6 96 80 80 (3686400)
I1130 22:37:42.142100   125 layer_factory.hpp:172] Creating layer 'inception_3b/pool' of type 'Pooling'
I1130 22:37:42.142107   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.142117   125 net.cpp:202] Created Layer inception_3b/pool (52)
I1130 22:37:42.142122   125 net.cpp:574] inception_3b/pool <- inception_3a/output_inception_3a/output_0_split_3
I1130 22:37:42.142127   125 net.cpp:544] inception_3b/pool -> inception_3b/pool
I1130 22:37:42.142202   125 net.cpp:262] Setting up inception_3b/pool
I1130 22:37:42.142211   125 net.cpp:269] TEST Top shape for layer 52 'inception_3b/pool' 6 256 80 80 (9830400)
I1130 22:37:42.142230   125 layer_factory.hpp:172] Creating layer 'inception_3b/pool_proj' of type 'Convolution'
I1130 22:37:42.142235   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.142251   125 net.cpp:202] Created Layer inception_3b/pool_proj (53)
I1130 22:37:42.142256   125 net.cpp:574] inception_3b/pool_proj <- inception_3b/pool
I1130 22:37:42.142263   125 net.cpp:544] inception_3b/pool_proj -> inception_3b/pool_proj
I1130 22:37:42.142870   125 net.cpp:262] Setting up inception_3b/pool_proj
I1130 22:37:42.142881   125 net.cpp:269] TEST Top shape for layer 53 'inception_3b/pool_proj' 6 64 80 80 (2457600)
I1130 22:37:42.142890   125 layer_factory.hpp:172] Creating layer 'inception_3b/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.142896   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.142904   125 net.cpp:202] Created Layer inception_3b/relu_pool_proj (54)
I1130 22:37:42.142910   125 net.cpp:574] inception_3b/relu_pool_proj <- inception_3b/pool_proj
I1130 22:37:42.142917   125 net.cpp:529] inception_3b/relu_pool_proj -> inception_3b/pool_proj (in-place)
I1130 22:37:42.142926   125 net.cpp:262] Setting up inception_3b/relu_pool_proj
I1130 22:37:42.142933   125 net.cpp:269] TEST Top shape for layer 54 'inception_3b/relu_pool_proj' 6 64 80 80 (2457600)
I1130 22:37:42.142940   125 layer_factory.hpp:172] Creating layer 'inception_3b/output' of type 'Concat'
I1130 22:37:42.142946   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.142956   125 net.cpp:202] Created Layer inception_3b/output (55)
I1130 22:37:42.142961   125 net.cpp:574] inception_3b/output <- inception_3b/1x1
I1130 22:37:42.142966   125 net.cpp:574] inception_3b/output <- inception_3b/3x3
I1130 22:37:42.142972   125 net.cpp:574] inception_3b/output <- inception_3b/5x5
I1130 22:37:42.142977   125 net.cpp:574] inception_3b/output <- inception_3b/pool_proj
I1130 22:37:42.142982   125 net.cpp:544] inception_3b/output -> inception_3b/output
I1130 22:37:42.143020   125 net.cpp:262] Setting up inception_3b/output
I1130 22:37:42.143028   125 net.cpp:269] TEST Top shape for layer 55 'inception_3b/output' 6 480 80 80 (18432000)
I1130 22:37:42.143034   125 layer_factory.hpp:172] Creating layer 'pool3/3x3_s2' of type 'Pooling'
I1130 22:37:42.143039   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.143049   125 net.cpp:202] Created Layer pool3/3x3_s2 (56)
I1130 22:37:42.143055   125 net.cpp:574] pool3/3x3_s2 <- inception_3b/output
I1130 22:37:42.143061   125 net.cpp:544] pool3/3x3_s2 -> pool3/3x3_s2
I1130 22:37:42.143131   125 net.cpp:262] Setting up pool3/3x3_s2
I1130 22:37:42.143141   125 net.cpp:269] TEST Top shape for layer 56 'pool3/3x3_s2' 6 480 40 40 (4608000)
I1130 22:37:42.143147   125 layer_factory.hpp:172] Creating layer 'pool3/3x3_s2_pool3/3x3_s2_0_split' of type 'Split'
I1130 22:37:42.143152   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.143160   125 net.cpp:202] Created Layer pool3/3x3_s2_pool3/3x3_s2_0_split (57)
I1130 22:37:42.143167   125 net.cpp:574] pool3/3x3_s2_pool3/3x3_s2_0_split <- pool3/3x3_s2
I1130 22:37:42.143172   125 net.cpp:544] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_0
I1130 22:37:42.143185   125 net.cpp:544] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_1
I1130 22:37:42.143193   125 net.cpp:544] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_2
I1130 22:37:42.143200   125 net.cpp:544] pool3/3x3_s2_pool3/3x3_s2_0_split -> pool3/3x3_s2_pool3/3x3_s2_0_split_3
I1130 22:37:42.143281   125 net.cpp:262] Setting up pool3/3x3_s2_pool3/3x3_s2_0_split
I1130 22:37:42.143290   125 net.cpp:269] TEST Top shape for layer 57 'pool3/3x3_s2_pool3/3x3_s2_0_split' 6 480 40 40 (4608000)
I1130 22:37:42.143296   125 net.cpp:269] TEST Top shape for layer 57 'pool3/3x3_s2_pool3/3x3_s2_0_split' 6 480 40 40 (4608000)
I1130 22:37:42.143313   125 net.cpp:269] TEST Top shape for layer 57 'pool3/3x3_s2_pool3/3x3_s2_0_split' 6 480 40 40 (4608000)
I1130 22:37:42.143321   125 net.cpp:269] TEST Top shape for layer 57 'pool3/3x3_s2_pool3/3x3_s2_0_split' 6 480 40 40 (4608000)
I1130 22:37:42.143326   125 layer_factory.hpp:172] Creating layer 'inception_4a/1x1' of type 'Convolution'
I1130 22:37:42.143332   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.143347   125 net.cpp:202] Created Layer inception_4a/1x1 (58)
I1130 22:37:42.143353   125 net.cpp:574] inception_4a/1x1 <- pool3/3x3_s2_pool3/3x3_s2_0_split_0
I1130 22:37:42.143360   125 net.cpp:544] inception_4a/1x1 -> inception_4a/1x1
I1130 22:37:42.145042   125 net.cpp:262] Setting up inception_4a/1x1
I1130 22:37:42.145056   125 net.cpp:269] TEST Top shape for layer 58 'inception_4a/1x1' 6 192 40 40 (1843200)
I1130 22:37:42.145064   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_1x1' of type 'ReLU'
I1130 22:37:42.145071   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.145079   125 net.cpp:202] Created Layer inception_4a/relu_1x1 (59)
I1130 22:37:42.145085   125 net.cpp:574] inception_4a/relu_1x1 <- inception_4a/1x1
I1130 22:37:42.145092   125 net.cpp:529] inception_4a/relu_1x1 -> inception_4a/1x1 (in-place)
I1130 22:37:42.145102   125 net.cpp:262] Setting up inception_4a/relu_1x1
I1130 22:37:42.145108   125 net.cpp:269] TEST Top shape for layer 59 'inception_4a/relu_1x1' 6 192 40 40 (1843200)
I1130 22:37:42.145114   125 layer_factory.hpp:172] Creating layer 'inception_4a/3x3_reduce' of type 'Convolution'
I1130 22:37:42.145120   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.145134   125 net.cpp:202] Created Layer inception_4a/3x3_reduce (60)
I1130 22:37:42.145139   125 net.cpp:574] inception_4a/3x3_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_1
I1130 22:37:42.145146   125 net.cpp:544] inception_4a/3x3_reduce -> inception_4a/3x3_reduce
I1130 22:37:42.146201   125 net.cpp:262] Setting up inception_4a/3x3_reduce
I1130 22:37:42.146211   125 net.cpp:269] TEST Top shape for layer 60 'inception_4a/3x3_reduce' 6 96 40 40 (921600)
I1130 22:37:42.146226   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.146234   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.146242   125 net.cpp:202] Created Layer inception_4a/relu_3x3_reduce (61)
I1130 22:37:42.146248   125 net.cpp:574] inception_4a/relu_3x3_reduce <- inception_4a/3x3_reduce
I1130 22:37:42.146255   125 net.cpp:529] inception_4a/relu_3x3_reduce -> inception_4a/3x3_reduce (in-place)
I1130 22:37:42.146262   125 net.cpp:262] Setting up inception_4a/relu_3x3_reduce
I1130 22:37:42.146270   125 net.cpp:269] TEST Top shape for layer 61 'inception_4a/relu_3x3_reduce' 6 96 40 40 (921600)
I1130 22:37:42.146275   125 layer_factory.hpp:172] Creating layer 'inception_4a/3x3' of type 'Convolution'
I1130 22:37:42.146281   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.146296   125 net.cpp:202] Created Layer inception_4a/3x3 (62)
I1130 22:37:42.146301   125 net.cpp:574] inception_4a/3x3 <- inception_4a/3x3_reduce
I1130 22:37:42.146306   125 net.cpp:544] inception_4a/3x3 -> inception_4a/3x3
I1130 22:37:42.150519   125 net.cpp:262] Setting up inception_4a/3x3
I1130 22:37:42.150535   125 net.cpp:269] TEST Top shape for layer 62 'inception_4a/3x3' 6 208 40 40 (1996800)
I1130 22:37:42.150545   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_3x3' of type 'ReLU'
I1130 22:37:42.150552   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.150562   125 net.cpp:202] Created Layer inception_4a/relu_3x3 (63)
I1130 22:37:42.150568   125 net.cpp:574] inception_4a/relu_3x3 <- inception_4a/3x3
I1130 22:37:42.150588   125 net.cpp:529] inception_4a/relu_3x3 -> inception_4a/3x3 (in-place)
I1130 22:37:42.150599   125 net.cpp:262] Setting up inception_4a/relu_3x3
I1130 22:37:42.150604   125 net.cpp:269] TEST Top shape for layer 63 'inception_4a/relu_3x3' 6 208 40 40 (1996800)
I1130 22:37:42.150611   125 layer_factory.hpp:172] Creating layer 'inception_4a/5x5_reduce' of type 'Convolution'
I1130 22:37:42.150617   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.150636   125 net.cpp:202] Created Layer inception_4a/5x5_reduce (64)
I1130 22:37:42.150642   125 net.cpp:574] inception_4a/5x5_reduce <- pool3/3x3_s2_pool3/3x3_s2_0_split_2
I1130 22:37:42.150650   125 net.cpp:544] inception_4a/5x5_reduce -> inception_4a/5x5_reduce
I1130 22:37:42.151129   125 net.cpp:262] Setting up inception_4a/5x5_reduce
I1130 22:37:42.151139   125 net.cpp:269] TEST Top shape for layer 64 'inception_4a/5x5_reduce' 6 16 40 40 (153600)
I1130 22:37:42.151147   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.151154   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.151163   125 net.cpp:202] Created Layer inception_4a/relu_5x5_reduce (65)
I1130 22:37:42.151168   125 net.cpp:574] inception_4a/relu_5x5_reduce <- inception_4a/5x5_reduce
I1130 22:37:42.151175   125 net.cpp:529] inception_4a/relu_5x5_reduce -> inception_4a/5x5_reduce (in-place)
I1130 22:37:42.151185   125 net.cpp:262] Setting up inception_4a/relu_5x5_reduce
I1130 22:37:42.151192   125 net.cpp:269] TEST Top shape for layer 65 'inception_4a/relu_5x5_reduce' 6 16 40 40 (153600)
I1130 22:37:42.151197   125 layer_factory.hpp:172] Creating layer 'inception_4a/5x5' of type 'Convolution'
I1130 22:37:42.151202   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.151218   125 net.cpp:202] Created Layer inception_4a/5x5 (66)
I1130 22:37:42.151223   125 net.cpp:574] inception_4a/5x5 <- inception_4a/5x5_reduce
I1130 22:37:42.151229   125 net.cpp:544] inception_4a/5x5 -> inception_4a/5x5
I1130 22:37:42.151870   125 net.cpp:262] Setting up inception_4a/5x5
I1130 22:37:42.151881   125 net.cpp:269] TEST Top shape for layer 66 'inception_4a/5x5' 6 48 40 40 (460800)
I1130 22:37:42.151890   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_5x5' of type 'ReLU'
I1130 22:37:42.151896   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.151904   125 net.cpp:202] Created Layer inception_4a/relu_5x5 (67)
I1130 22:37:42.151926   125 net.cpp:574] inception_4a/relu_5x5 <- inception_4a/5x5
I1130 22:37:42.151933   125 net.cpp:529] inception_4a/relu_5x5 -> inception_4a/5x5 (in-place)
I1130 22:37:42.151942   125 net.cpp:262] Setting up inception_4a/relu_5x5
I1130 22:37:42.151949   125 net.cpp:269] TEST Top shape for layer 67 'inception_4a/relu_5x5' 6 48 40 40 (460800)
I1130 22:37:42.151955   125 layer_factory.hpp:172] Creating layer 'inception_4a/pool' of type 'Pooling'
I1130 22:37:42.151962   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.151971   125 net.cpp:202] Created Layer inception_4a/pool (68)
I1130 22:37:42.151976   125 net.cpp:574] inception_4a/pool <- pool3/3x3_s2_pool3/3x3_s2_0_split_3
I1130 22:37:42.151983   125 net.cpp:544] inception_4a/pool -> inception_4a/pool
I1130 22:37:42.152062   125 net.cpp:262] Setting up inception_4a/pool
I1130 22:37:42.152070   125 net.cpp:269] TEST Top shape for layer 68 'inception_4a/pool' 6 480 40 40 (4608000)
I1130 22:37:42.152077   125 layer_factory.hpp:172] Creating layer 'inception_4a/pool_proj' of type 'Convolution'
I1130 22:37:42.152083   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.152098   125 net.cpp:202] Created Layer inception_4a/pool_proj (69)
I1130 22:37:42.152104   125 net.cpp:574] inception_4a/pool_proj <- inception_4a/pool
I1130 22:37:42.152110   125 net.cpp:544] inception_4a/pool_proj -> inception_4a/pool_proj
I1130 22:37:42.152956   125 net.cpp:262] Setting up inception_4a/pool_proj
I1130 22:37:42.152967   125 net.cpp:269] TEST Top shape for layer 69 'inception_4a/pool_proj' 6 64 40 40 (614400)
I1130 22:37:42.152976   125 layer_factory.hpp:172] Creating layer 'inception_4a/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.152982   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.152992   125 net.cpp:202] Created Layer inception_4a/relu_pool_proj (70)
I1130 22:37:42.152998   125 net.cpp:574] inception_4a/relu_pool_proj <- inception_4a/pool_proj
I1130 22:37:42.153004   125 net.cpp:529] inception_4a/relu_pool_proj -> inception_4a/pool_proj (in-place)
I1130 22:37:42.153013   125 net.cpp:262] Setting up inception_4a/relu_pool_proj
I1130 22:37:42.153021   125 net.cpp:269] TEST Top shape for layer 70 'inception_4a/relu_pool_proj' 6 64 40 40 (614400)
I1130 22:37:42.153028   125 layer_factory.hpp:172] Creating layer 'inception_4a/output' of type 'Concat'
I1130 22:37:42.153033   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.153043   125 net.cpp:202] Created Layer inception_4a/output (71)
I1130 22:37:42.153048   125 net.cpp:574] inception_4a/output <- inception_4a/1x1
I1130 22:37:42.153054   125 net.cpp:574] inception_4a/output <- inception_4a/3x3
I1130 22:37:42.153059   125 net.cpp:574] inception_4a/output <- inception_4a/5x5
I1130 22:37:42.153064   125 net.cpp:574] inception_4a/output <- inception_4a/pool_proj
I1130 22:37:42.153070   125 net.cpp:544] inception_4a/output -> inception_4a/output
I1130 22:37:42.153110   125 net.cpp:262] Setting up inception_4a/output
I1130 22:37:42.153117   125 net.cpp:269] TEST Top shape for layer 71 'inception_4a/output' 6 512 40 40 (4915200)
I1130 22:37:42.153123   125 layer_factory.hpp:172] Creating layer 'inception_4a/output_inception_4a/output_0_split' of type 'Split'
I1130 22:37:42.153129   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.153139   125 net.cpp:202] Created Layer inception_4a/output_inception_4a/output_0_split (72)
I1130 22:37:42.153144   125 net.cpp:574] inception_4a/output_inception_4a/output_0_split <- inception_4a/output
I1130 22:37:42.153151   125 net.cpp:544] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_0
I1130 22:37:42.153159   125 net.cpp:544] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_1
I1130 22:37:42.153168   125 net.cpp:544] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_2
I1130 22:37:42.153177   125 net.cpp:544] inception_4a/output_inception_4a/output_0_split -> inception_4a/output_inception_4a/output_0_split_3
I1130 22:37:42.153262   125 net.cpp:262] Setting up inception_4a/output_inception_4a/output_0_split
I1130 22:37:42.153270   125 net.cpp:269] TEST Top shape for layer 72 'inception_4a/output_inception_4a/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.153276   125 net.cpp:269] TEST Top shape for layer 72 'inception_4a/output_inception_4a/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.153282   125 net.cpp:269] TEST Top shape for layer 72 'inception_4a/output_inception_4a/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.153288   125 net.cpp:269] TEST Top shape for layer 72 'inception_4a/output_inception_4a/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.153295   125 layer_factory.hpp:172] Creating layer 'inception_4b/1x1' of type 'Convolution'
I1130 22:37:42.153301   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.153317   125 net.cpp:202] Created Layer inception_4b/1x1 (73)
I1130 22:37:42.153322   125 net.cpp:574] inception_4b/1x1 <- inception_4a/output_inception_4a/output_0_split_0
I1130 22:37:42.153329   125 net.cpp:544] inception_4b/1x1 -> inception_4b/1x1
I1130 22:37:42.154847   125 net.cpp:262] Setting up inception_4b/1x1
I1130 22:37:42.154871   125 net.cpp:269] TEST Top shape for layer 73 'inception_4b/1x1' 6 160 40 40 (1536000)
I1130 22:37:42.154881   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_1x1' of type 'ReLU'
I1130 22:37:42.154886   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.154896   125 net.cpp:202] Created Layer inception_4b/relu_1x1 (74)
I1130 22:37:42.154901   125 net.cpp:574] inception_4b/relu_1x1 <- inception_4b/1x1
I1130 22:37:42.154907   125 net.cpp:529] inception_4b/relu_1x1 -> inception_4b/1x1 (in-place)
I1130 22:37:42.154917   125 net.cpp:262] Setting up inception_4b/relu_1x1
I1130 22:37:42.154924   125 net.cpp:269] TEST Top shape for layer 74 'inception_4b/relu_1x1' 6 160 40 40 (1536000)
I1130 22:37:42.154929   125 layer_factory.hpp:172] Creating layer 'inception_4b/3x3_reduce' of type 'Convolution'
I1130 22:37:42.154935   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.154950   125 net.cpp:202] Created Layer inception_4b/3x3_reduce (75)
I1130 22:37:42.154956   125 net.cpp:574] inception_4b/3x3_reduce <- inception_4a/output_inception_4a/output_0_split_1
I1130 22:37:42.154963   125 net.cpp:544] inception_4b/3x3_reduce -> inception_4b/3x3_reduce
I1130 22:37:42.157379   125 net.cpp:262] Setting up inception_4b/3x3_reduce
I1130 22:37:42.157395   125 net.cpp:269] TEST Top shape for layer 75 'inception_4b/3x3_reduce' 6 112 40 40 (1075200)
I1130 22:37:42.157405   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.157411   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.157420   125 net.cpp:202] Created Layer inception_4b/relu_3x3_reduce (76)
I1130 22:37:42.157428   125 net.cpp:574] inception_4b/relu_3x3_reduce <- inception_4b/3x3_reduce
I1130 22:37:42.157434   125 net.cpp:529] inception_4b/relu_3x3_reduce -> inception_4b/3x3_reduce (in-place)
I1130 22:37:42.157444   125 net.cpp:262] Setting up inception_4b/relu_3x3_reduce
I1130 22:37:42.157451   125 net.cpp:269] TEST Top shape for layer 76 'inception_4b/relu_3x3_reduce' 6 112 40 40 (1075200)
I1130 22:37:42.157459   125 layer_factory.hpp:172] Creating layer 'inception_4b/3x3' of type 'Convolution'
I1130 22:37:42.157464   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.157480   125 net.cpp:202] Created Layer inception_4b/3x3 (77)
I1130 22:37:42.157485   125 net.cpp:574] inception_4b/3x3 <- inception_4b/3x3_reduce
I1130 22:37:42.157490   125 net.cpp:544] inception_4b/3x3 -> inception_4b/3x3
I1130 22:37:42.161114   125 net.cpp:262] Setting up inception_4b/3x3
I1130 22:37:42.161126   125 net.cpp:269] TEST Top shape for layer 77 'inception_4b/3x3' 6 224 40 40 (2150400)
I1130 22:37:42.161135   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_3x3' of type 'ReLU'
I1130 22:37:42.161142   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.161151   125 net.cpp:202] Created Layer inception_4b/relu_3x3 (78)
I1130 22:37:42.161156   125 net.cpp:574] inception_4b/relu_3x3 <- inception_4b/3x3
I1130 22:37:42.161164   125 net.cpp:529] inception_4b/relu_3x3 -> inception_4b/3x3 (in-place)
I1130 22:37:42.161173   125 net.cpp:262] Setting up inception_4b/relu_3x3
I1130 22:37:42.161180   125 net.cpp:269] TEST Top shape for layer 78 'inception_4b/relu_3x3' 6 224 40 40 (2150400)
I1130 22:37:42.161185   125 layer_factory.hpp:172] Creating layer 'inception_4b/5x5_reduce' of type 'Convolution'
I1130 22:37:42.161191   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.161206   125 net.cpp:202] Created Layer inception_4b/5x5_reduce (79)
I1130 22:37:42.161212   125 net.cpp:574] inception_4b/5x5_reduce <- inception_4a/output_inception_4a/output_0_split_2
I1130 22:37:42.161219   125 net.cpp:544] inception_4b/5x5_reduce -> inception_4b/5x5_reduce
I1130 22:37:42.161787   125 net.cpp:262] Setting up inception_4b/5x5_reduce
I1130 22:37:42.161798   125 net.cpp:269] TEST Top shape for layer 79 'inception_4b/5x5_reduce' 6 24 40 40 (230400)
I1130 22:37:42.161808   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.161814   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.161823   125 net.cpp:202] Created Layer inception_4b/relu_5x5_reduce (80)
I1130 22:37:42.161829   125 net.cpp:574] inception_4b/relu_5x5_reduce <- inception_4b/5x5_reduce
I1130 22:37:42.161835   125 net.cpp:529] inception_4b/relu_5x5_reduce -> inception_4b/5x5_reduce (in-place)
I1130 22:37:42.161845   125 net.cpp:262] Setting up inception_4b/relu_5x5_reduce
I1130 22:37:42.161851   125 net.cpp:269] TEST Top shape for layer 80 'inception_4b/relu_5x5_reduce' 6 24 40 40 (230400)
I1130 22:37:42.161859   125 layer_factory.hpp:172] Creating layer 'inception_4b/5x5' of type 'Convolution'
I1130 22:37:42.161864   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.161878   125 net.cpp:202] Created Layer inception_4b/5x5 (81)
I1130 22:37:42.161885   125 net.cpp:574] inception_4b/5x5 <- inception_4b/5x5_reduce
I1130 22:37:42.161890   125 net.cpp:544] inception_4b/5x5 -> inception_4b/5x5
I1130 22:37:42.162787   125 net.cpp:262] Setting up inception_4b/5x5
I1130 22:37:42.162797   125 net.cpp:269] TEST Top shape for layer 81 'inception_4b/5x5' 6 64 40 40 (614400)
I1130 22:37:42.162806   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_5x5' of type 'ReLU'
I1130 22:37:42.162812   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.162822   125 net.cpp:202] Created Layer inception_4b/relu_5x5 (82)
I1130 22:37:42.162827   125 net.cpp:574] inception_4b/relu_5x5 <- inception_4b/5x5
I1130 22:37:42.162833   125 net.cpp:529] inception_4b/relu_5x5 -> inception_4b/5x5 (in-place)
I1130 22:37:42.162842   125 net.cpp:262] Setting up inception_4b/relu_5x5
I1130 22:37:42.162849   125 net.cpp:269] TEST Top shape for layer 82 'inception_4b/relu_5x5' 6 64 40 40 (614400)
I1130 22:37:42.162855   125 layer_factory.hpp:172] Creating layer 'inception_4b/pool' of type 'Pooling'
I1130 22:37:42.162860   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.162870   125 net.cpp:202] Created Layer inception_4b/pool (83)
I1130 22:37:42.162876   125 net.cpp:574] inception_4b/pool <- inception_4a/output_inception_4a/output_0_split_3
I1130 22:37:42.162883   125 net.cpp:544] inception_4b/pool -> inception_4b/pool
I1130 22:37:42.162961   125 net.cpp:262] Setting up inception_4b/pool
I1130 22:37:42.162971   125 net.cpp:269] TEST Top shape for layer 83 'inception_4b/pool' 6 512 40 40 (4915200)
I1130 22:37:42.162977   125 layer_factory.hpp:172] Creating layer 'inception_4b/pool_proj' of type 'Convolution'
I1130 22:37:42.162982   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.162997   125 net.cpp:202] Created Layer inception_4b/pool_proj (84)
I1130 22:37:42.163003   125 net.cpp:574] inception_4b/pool_proj <- inception_4b/pool
I1130 22:37:42.163010   125 net.cpp:544] inception_4b/pool_proj -> inception_4b/pool_proj
I1130 22:37:42.163823   125 net.cpp:262] Setting up inception_4b/pool_proj
I1130 22:37:42.163833   125 net.cpp:269] TEST Top shape for layer 84 'inception_4b/pool_proj' 6 64 40 40 (614400)
I1130 22:37:42.163842   125 layer_factory.hpp:172] Creating layer 'inception_4b/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.163848   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.163856   125 net.cpp:202] Created Layer inception_4b/relu_pool_proj (85)
I1130 22:37:42.163862   125 net.cpp:574] inception_4b/relu_pool_proj <- inception_4b/pool_proj
I1130 22:37:42.163868   125 net.cpp:529] inception_4b/relu_pool_proj -> inception_4b/pool_proj (in-place)
I1130 22:37:42.163889   125 net.cpp:262] Setting up inception_4b/relu_pool_proj
I1130 22:37:42.163897   125 net.cpp:269] TEST Top shape for layer 85 'inception_4b/relu_pool_proj' 6 64 40 40 (614400)
I1130 22:37:42.198936   125 layer_factory.hpp:172] Creating layer 'inception_4b/output' of type 'Concat'
I1130 22:37:42.198958   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.198974   125 net.cpp:202] Created Layer inception_4b/output (86)
I1130 22:37:42.198984   125 net.cpp:574] inception_4b/output <- inception_4b/1x1
I1130 22:37:42.198995   125 net.cpp:574] inception_4b/output <- inception_4b/3x3
I1130 22:37:42.199003   125 net.cpp:574] inception_4b/output <- inception_4b/5x5
I1130 22:37:42.199010   125 net.cpp:574] inception_4b/output <- inception_4b/pool_proj
I1130 22:37:42.199017   125 net.cpp:544] inception_4b/output -> inception_4b/output
I1130 22:37:42.199087   125 net.cpp:262] Setting up inception_4b/output
I1130 22:37:42.199100   125 net.cpp:269] TEST Top shape for layer 86 'inception_4b/output' 6 512 40 40 (4915200)
I1130 22:37:42.199106   125 layer_factory.hpp:172] Creating layer 'inception_4b/output_inception_4b/output_0_split' of type 'Split'
I1130 22:37:42.199112   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.199123   125 net.cpp:202] Created Layer inception_4b/output_inception_4b/output_0_split (87)
I1130 22:37:42.199129   125 net.cpp:574] inception_4b/output_inception_4b/output_0_split <- inception_4b/output
I1130 22:37:42.199136   125 net.cpp:544] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_0
I1130 22:37:42.199146   125 net.cpp:544] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_1
I1130 22:37:42.199153   125 net.cpp:544] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_2
I1130 22:37:42.199162   125 net.cpp:544] inception_4b/output_inception_4b/output_0_split -> inception_4b/output_inception_4b/output_0_split_3
I1130 22:37:42.199256   125 net.cpp:262] Setting up inception_4b/output_inception_4b/output_0_split
I1130 22:37:42.199263   125 net.cpp:269] TEST Top shape for layer 87 'inception_4b/output_inception_4b/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.199270   125 net.cpp:269] TEST Top shape for layer 87 'inception_4b/output_inception_4b/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.199276   125 net.cpp:269] TEST Top shape for layer 87 'inception_4b/output_inception_4b/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.199282   125 net.cpp:269] TEST Top shape for layer 87 'inception_4b/output_inception_4b/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.199288   125 layer_factory.hpp:172] Creating layer 'inception_4c/1x1' of type 'Convolution'
I1130 22:37:42.199295   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.199316   125 net.cpp:202] Created Layer inception_4c/1x1 (88)
I1130 22:37:42.199321   125 net.cpp:574] inception_4c/1x1 <- inception_4b/output_inception_4b/output_0_split_0
I1130 22:37:42.199328   125 net.cpp:544] inception_4c/1x1 -> inception_4c/1x1
I1130 22:37:42.200803   125 net.cpp:262] Setting up inception_4c/1x1
I1130 22:37:42.200815   125 net.cpp:269] TEST Top shape for layer 88 'inception_4c/1x1' 6 128 40 40 (1228800)
I1130 22:37:42.200826   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_1x1' of type 'ReLU'
I1130 22:37:42.200832   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.200841   125 net.cpp:202] Created Layer inception_4c/relu_1x1 (89)
I1130 22:37:42.200847   125 net.cpp:574] inception_4c/relu_1x1 <- inception_4c/1x1
I1130 22:37:42.200855   125 net.cpp:529] inception_4c/relu_1x1 -> inception_4c/1x1 (in-place)
I1130 22:37:42.200865   125 net.cpp:262] Setting up inception_4c/relu_1x1
I1130 22:37:42.200871   125 net.cpp:269] TEST Top shape for layer 89 'inception_4c/relu_1x1' 6 128 40 40 (1228800)
I1130 22:37:42.200894   125 layer_factory.hpp:172] Creating layer 'inception_4c/3x3_reduce' of type 'Convolution'
I1130 22:37:42.200901   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.200917   125 net.cpp:202] Created Layer inception_4c/3x3_reduce (90)
I1130 22:37:42.200923   125 net.cpp:574] inception_4c/3x3_reduce <- inception_4b/output_inception_4b/output_0_split_1
I1130 22:37:42.200930   125 net.cpp:544] inception_4c/3x3_reduce -> inception_4c/3x3_reduce
I1130 22:37:42.202343   125 net.cpp:262] Setting up inception_4c/3x3_reduce
I1130 22:37:42.202354   125 net.cpp:269] TEST Top shape for layer 90 'inception_4c/3x3_reduce' 6 128 40 40 (1228800)
I1130 22:37:42.202363   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.202369   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.202378   125 net.cpp:202] Created Layer inception_4c/relu_3x3_reduce (91)
I1130 22:37:42.202384   125 net.cpp:574] inception_4c/relu_3x3_reduce <- inception_4c/3x3_reduce
I1130 22:37:42.202390   125 net.cpp:529] inception_4c/relu_3x3_reduce -> inception_4c/3x3_reduce (in-place)
I1130 22:37:42.202400   125 net.cpp:262] Setting up inception_4c/relu_3x3_reduce
I1130 22:37:42.202409   125 net.cpp:269] TEST Top shape for layer 91 'inception_4c/relu_3x3_reduce' 6 128 40 40 (1228800)
I1130 22:37:42.202414   125 layer_factory.hpp:172] Creating layer 'inception_4c/3x3' of type 'Convolution'
I1130 22:37:42.202419   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.202435   125 net.cpp:202] Created Layer inception_4c/3x3 (92)
I1130 22:37:42.202440   125 net.cpp:574] inception_4c/3x3 <- inception_4c/3x3_reduce
I1130 22:37:42.202446   125 net.cpp:544] inception_4c/3x3 -> inception_4c/3x3
I1130 22:37:42.208357   125 net.cpp:262] Setting up inception_4c/3x3
I1130 22:37:42.208374   125 net.cpp:269] TEST Top shape for layer 92 'inception_4c/3x3' 6 256 40 40 (2457600)
I1130 22:37:42.208384   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_3x3' of type 'ReLU'
I1130 22:37:42.208389   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.208398   125 net.cpp:202] Created Layer inception_4c/relu_3x3 (93)
I1130 22:37:42.208405   125 net.cpp:574] inception_4c/relu_3x3 <- inception_4c/3x3
I1130 22:37:42.208412   125 net.cpp:529] inception_4c/relu_3x3 -> inception_4c/3x3 (in-place)
I1130 22:37:42.208422   125 net.cpp:262] Setting up inception_4c/relu_3x3
I1130 22:37:42.208428   125 net.cpp:269] TEST Top shape for layer 93 'inception_4c/relu_3x3' 6 256 40 40 (2457600)
I1130 22:37:42.208434   125 layer_factory.hpp:172] Creating layer 'inception_4c/5x5_reduce' of type 'Convolution'
I1130 22:37:42.208443   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.208458   125 net.cpp:202] Created Layer inception_4c/5x5_reduce (94)
I1130 22:37:42.208464   125 net.cpp:574] inception_4c/5x5_reduce <- inception_4b/output_inception_4b/output_0_split_2
I1130 22:37:42.208472   125 net.cpp:544] inception_4c/5x5_reduce -> inception_4c/5x5_reduce
I1130 22:37:42.209051   125 net.cpp:262] Setting up inception_4c/5x5_reduce
I1130 22:37:42.209062   125 net.cpp:269] TEST Top shape for layer 94 'inception_4c/5x5_reduce' 6 24 40 40 (230400)
I1130 22:37:42.209071   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.209079   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.209087   125 net.cpp:202] Created Layer inception_4c/relu_5x5_reduce (95)
I1130 22:37:42.209092   125 net.cpp:574] inception_4c/relu_5x5_reduce <- inception_4c/5x5_reduce
I1130 22:37:42.209098   125 net.cpp:529] inception_4c/relu_5x5_reduce -> inception_4c/5x5_reduce (in-place)
I1130 22:37:42.209108   125 net.cpp:262] Setting up inception_4c/relu_5x5_reduce
I1130 22:37:42.209128   125 net.cpp:269] TEST Top shape for layer 95 'inception_4c/relu_5x5_reduce' 6 24 40 40 (230400)
I1130 22:37:42.209136   125 layer_factory.hpp:172] Creating layer 'inception_4c/5x5' of type 'Convolution'
I1130 22:37:42.209141   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.209156   125 net.cpp:202] Created Layer inception_4c/5x5 (96)
I1130 22:37:42.209161   125 net.cpp:574] inception_4c/5x5 <- inception_4c/5x5_reduce
I1130 22:37:42.209167   125 net.cpp:544] inception_4c/5x5 -> inception_4c/5x5
I1130 22:37:42.210110   125 net.cpp:262] Setting up inception_4c/5x5
I1130 22:37:42.210121   125 net.cpp:269] TEST Top shape for layer 96 'inception_4c/5x5' 6 64 40 40 (614400)
I1130 22:37:42.210130   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_5x5' of type 'ReLU'
I1130 22:37:42.210135   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.210144   125 net.cpp:202] Created Layer inception_4c/relu_5x5 (97)
I1130 22:37:42.210150   125 net.cpp:574] inception_4c/relu_5x5 <- inception_4c/5x5
I1130 22:37:42.210156   125 net.cpp:529] inception_4c/relu_5x5 -> inception_4c/5x5 (in-place)
I1130 22:37:42.210165   125 net.cpp:262] Setting up inception_4c/relu_5x5
I1130 22:37:42.210171   125 net.cpp:269] TEST Top shape for layer 97 'inception_4c/relu_5x5' 6 64 40 40 (614400)
I1130 22:37:42.210177   125 layer_factory.hpp:172] Creating layer 'inception_4c/pool' of type 'Pooling'
I1130 22:37:42.210182   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.210194   125 net.cpp:202] Created Layer inception_4c/pool (98)
I1130 22:37:42.210201   125 net.cpp:574] inception_4c/pool <- inception_4b/output_inception_4b/output_0_split_3
I1130 22:37:42.210206   125 net.cpp:544] inception_4c/pool -> inception_4c/pool
I1130 22:37:42.210289   125 net.cpp:262] Setting up inception_4c/pool
I1130 22:37:42.210297   125 net.cpp:269] TEST Top shape for layer 98 'inception_4c/pool' 6 512 40 40 (4915200)
I1130 22:37:42.210304   125 layer_factory.hpp:172] Creating layer 'inception_4c/pool_proj' of type 'Convolution'
I1130 22:37:42.210310   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.210325   125 net.cpp:202] Created Layer inception_4c/pool_proj (99)
I1130 22:37:42.210330   125 net.cpp:574] inception_4c/pool_proj <- inception_4c/pool
I1130 22:37:42.210336   125 net.cpp:544] inception_4c/pool_proj -> inception_4c/pool_proj
I1130 22:37:42.211227   125 net.cpp:262] Setting up inception_4c/pool_proj
I1130 22:37:42.211237   125 net.cpp:269] TEST Top shape for layer 99 'inception_4c/pool_proj' 6 64 40 40 (614400)
I1130 22:37:42.211257   125 layer_factory.hpp:172] Creating layer 'inception_4c/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.211263   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.211272   125 net.cpp:202] Created Layer inception_4c/relu_pool_proj (100)
I1130 22:37:42.211278   125 net.cpp:574] inception_4c/relu_pool_proj <- inception_4c/pool_proj
I1130 22:37:42.211284   125 net.cpp:529] inception_4c/relu_pool_proj -> inception_4c/pool_proj (in-place)
I1130 22:37:42.211293   125 net.cpp:262] Setting up inception_4c/relu_pool_proj
I1130 22:37:42.211299   125 net.cpp:269] TEST Top shape for layer 100 'inception_4c/relu_pool_proj' 6 64 40 40 (614400)
I1130 22:37:42.211305   125 layer_factory.hpp:172] Creating layer 'inception_4c/output' of type 'Concat'
I1130 22:37:42.211310   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.211319   125 net.cpp:202] Created Layer inception_4c/output (101)
I1130 22:37:42.211324   125 net.cpp:574] inception_4c/output <- inception_4c/1x1
I1130 22:37:42.211330   125 net.cpp:574] inception_4c/output <- inception_4c/3x3
I1130 22:37:42.211336   125 net.cpp:574] inception_4c/output <- inception_4c/5x5
I1130 22:37:42.211341   125 net.cpp:574] inception_4c/output <- inception_4c/pool_proj
I1130 22:37:42.211359   125 net.cpp:544] inception_4c/output -> inception_4c/output
I1130 22:37:42.211400   125 net.cpp:262] Setting up inception_4c/output
I1130 22:37:42.211407   125 net.cpp:269] TEST Top shape for layer 101 'inception_4c/output' 6 512 40 40 (4915200)
I1130 22:37:42.211413   125 layer_factory.hpp:172] Creating layer 'inception_4c/output_inception_4c/output_0_split' of type 'Split'
I1130 22:37:42.211421   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.211431   125 net.cpp:202] Created Layer inception_4c/output_inception_4c/output_0_split (102)
I1130 22:37:42.211436   125 net.cpp:574] inception_4c/output_inception_4c/output_0_split <- inception_4c/output
I1130 22:37:42.211442   125 net.cpp:544] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_0
I1130 22:37:42.211452   125 net.cpp:544] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_1
I1130 22:37:42.211460   125 net.cpp:544] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_2
I1130 22:37:42.211468   125 net.cpp:544] inception_4c/output_inception_4c/output_0_split -> inception_4c/output_inception_4c/output_0_split_3
I1130 22:37:42.211553   125 net.cpp:262] Setting up inception_4c/output_inception_4c/output_0_split
I1130 22:37:42.211561   125 net.cpp:269] TEST Top shape for layer 102 'inception_4c/output_inception_4c/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.211568   125 net.cpp:269] TEST Top shape for layer 102 'inception_4c/output_inception_4c/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.211573   125 net.cpp:269] TEST Top shape for layer 102 'inception_4c/output_inception_4c/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.211580   125 net.cpp:269] TEST Top shape for layer 102 'inception_4c/output_inception_4c/output_0_split' 6 512 40 40 (4915200)
I1130 22:37:42.211586   125 layer_factory.hpp:172] Creating layer 'inception_4d/1x1' of type 'Convolution'
I1130 22:37:42.211592   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.211608   125 net.cpp:202] Created Layer inception_4d/1x1 (103)
I1130 22:37:42.211614   125 net.cpp:574] inception_4d/1x1 <- inception_4c/output_inception_4c/output_0_split_0
I1130 22:37:42.211621   125 net.cpp:544] inception_4d/1x1 -> inception_4d/1x1
I1130 22:37:42.212877   125 net.cpp:262] Setting up inception_4d/1x1
I1130 22:37:42.212888   125 net.cpp:269] TEST Top shape for layer 103 'inception_4d/1x1' 6 112 40 40 (1075200)
I1130 22:37:42.212898   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_1x1' of type 'ReLU'
I1130 22:37:42.212903   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.212913   125 net.cpp:202] Created Layer inception_4d/relu_1x1 (104)
I1130 22:37:42.212918   125 net.cpp:574] inception_4d/relu_1x1 <- inception_4d/1x1
I1130 22:37:42.212925   125 net.cpp:529] inception_4d/relu_1x1 -> inception_4d/1x1 (in-place)
I1130 22:37:42.212935   125 net.cpp:262] Setting up inception_4d/relu_1x1
I1130 22:37:42.212941   125 net.cpp:269] TEST Top shape for layer 104 'inception_4d/relu_1x1' 6 112 40 40 (1075200)
I1130 22:37:42.212947   125 layer_factory.hpp:172] Creating layer 'inception_4d/3x3_reduce' of type 'Convolution'
I1130 22:37:42.212954   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.212968   125 net.cpp:202] Created Layer inception_4d/3x3_reduce (105)
I1130 22:37:42.212975   125 net.cpp:574] inception_4d/3x3_reduce <- inception_4c/output_inception_4c/output_0_split_1
I1130 22:37:42.212980   125 net.cpp:544] inception_4d/3x3_reduce -> inception_4d/3x3_reduce
I1130 22:37:42.214411   125 net.cpp:262] Setting up inception_4d/3x3_reduce
I1130 22:37:42.214422   125 net.cpp:269] TEST Top shape for layer 105 'inception_4d/3x3_reduce' 6 144 40 40 (1382400)
I1130 22:37:42.214442   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.214448   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.214457   125 net.cpp:202] Created Layer inception_4d/relu_3x3_reduce (106)
I1130 22:37:42.214463   125 net.cpp:574] inception_4d/relu_3x3_reduce <- inception_4d/3x3_reduce
I1130 22:37:42.214470   125 net.cpp:529] inception_4d/relu_3x3_reduce -> inception_4d/3x3_reduce (in-place)
I1130 22:37:42.214479   125 net.cpp:262] Setting up inception_4d/relu_3x3_reduce
I1130 22:37:42.214485   125 net.cpp:269] TEST Top shape for layer 106 'inception_4d/relu_3x3_reduce' 6 144 40 40 (1382400)
I1130 22:37:42.214493   125 layer_factory.hpp:172] Creating layer 'inception_4d/3x3' of type 'Convolution'
I1130 22:37:42.214498   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.214512   125 net.cpp:202] Created Layer inception_4d/3x3 (107)
I1130 22:37:42.214517   125 net.cpp:574] inception_4d/3x3 <- inception_4d/3x3_reduce
I1130 22:37:42.214524   125 net.cpp:544] inception_4d/3x3 -> inception_4d/3x3
I1130 22:37:42.221417   125 net.cpp:262] Setting up inception_4d/3x3
I1130 22:37:42.221432   125 net.cpp:269] TEST Top shape for layer 107 'inception_4d/3x3' 6 288 40 40 (2764800)
I1130 22:37:42.221442   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_3x3' of type 'ReLU'
I1130 22:37:42.221448   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.221458   125 net.cpp:202] Created Layer inception_4d/relu_3x3 (108)
I1130 22:37:42.221464   125 net.cpp:574] inception_4d/relu_3x3 <- inception_4d/3x3
I1130 22:37:42.221470   125 net.cpp:529] inception_4d/relu_3x3 -> inception_4d/3x3 (in-place)
I1130 22:37:42.221482   125 net.cpp:262] Setting up inception_4d/relu_3x3
I1130 22:37:42.221487   125 net.cpp:269] TEST Top shape for layer 108 'inception_4d/relu_3x3' 6 288 40 40 (2764800)
I1130 22:37:42.221493   125 layer_factory.hpp:172] Creating layer 'inception_4d/5x5_reduce' of type 'Convolution'
I1130 22:37:42.221498   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.221515   125 net.cpp:202] Created Layer inception_4d/5x5_reduce (109)
I1130 22:37:42.221521   125 net.cpp:574] inception_4d/5x5_reduce <- inception_4c/output_inception_4c/output_0_split_2
I1130 22:37:42.221527   125 net.cpp:544] inception_4d/5x5_reduce -> inception_4d/5x5_reduce
I1130 22:37:42.222152   125 net.cpp:262] Setting up inception_4d/5x5_reduce
I1130 22:37:42.222163   125 net.cpp:269] TEST Top shape for layer 109 'inception_4d/5x5_reduce' 6 32 40 40 (307200)
I1130 22:37:42.222172   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.222177   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.222187   125 net.cpp:202] Created Layer inception_4d/relu_5x5_reduce (110)
I1130 22:37:42.222193   125 net.cpp:574] inception_4d/relu_5x5_reduce <- inception_4d/5x5_reduce
I1130 22:37:42.222198   125 net.cpp:529] inception_4d/relu_5x5_reduce -> inception_4d/5x5_reduce (in-place)
I1130 22:37:42.222208   125 net.cpp:262] Setting up inception_4d/relu_5x5_reduce
I1130 22:37:42.222215   125 net.cpp:269] TEST Top shape for layer 110 'inception_4d/relu_5x5_reduce' 6 32 40 40 (307200)
I1130 22:37:42.222221   125 layer_factory.hpp:172] Creating layer 'inception_4d/5x5' of type 'Convolution'
I1130 22:37:42.222227   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.222241   125 net.cpp:202] Created Layer inception_4d/5x5 (111)
I1130 22:37:42.222247   125 net.cpp:574] inception_4d/5x5 <- inception_4d/5x5_reduce
I1130 22:37:42.222254   125 net.cpp:544] inception_4d/5x5 -> inception_4d/5x5
I1130 22:37:42.223384   125 net.cpp:262] Setting up inception_4d/5x5
I1130 22:37:42.223394   125 net.cpp:269] TEST Top shape for layer 111 'inception_4d/5x5' 6 64 40 40 (614400)
I1130 22:37:42.223415   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_5x5' of type 'ReLU'
I1130 22:37:42.223423   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.223430   125 net.cpp:202] Created Layer inception_4d/relu_5x5 (112)
I1130 22:37:42.223436   125 net.cpp:574] inception_4d/relu_5x5 <- inception_4d/5x5
I1130 22:37:42.223443   125 net.cpp:529] inception_4d/relu_5x5 -> inception_4d/5x5 (in-place)
I1130 22:37:42.223453   125 net.cpp:262] Setting up inception_4d/relu_5x5
I1130 22:37:42.223459   125 net.cpp:269] TEST Top shape for layer 112 'inception_4d/relu_5x5' 6 64 40 40 (614400)
I1130 22:37:42.223465   125 layer_factory.hpp:172] Creating layer 'inception_4d/pool' of type 'Pooling'
I1130 22:37:42.223470   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.223484   125 net.cpp:202] Created Layer inception_4d/pool (113)
I1130 22:37:42.223490   125 net.cpp:574] inception_4d/pool <- inception_4c/output_inception_4c/output_0_split_3
I1130 22:37:42.223496   125 net.cpp:544] inception_4d/pool -> inception_4d/pool
I1130 22:37:42.223582   125 net.cpp:262] Setting up inception_4d/pool
I1130 22:37:42.223590   125 net.cpp:269] TEST Top shape for layer 113 'inception_4d/pool' 6 512 40 40 (4915200)
I1130 22:37:42.223596   125 layer_factory.hpp:172] Creating layer 'inception_4d/pool_proj' of type 'Convolution'
I1130 22:37:42.223603   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.223618   125 net.cpp:202] Created Layer inception_4d/pool_proj (114)
I1130 22:37:42.223624   125 net.cpp:574] inception_4d/pool_proj <- inception_4d/pool
I1130 22:37:42.223630   125 net.cpp:544] inception_4d/pool_proj -> inception_4d/pool_proj
I1130 22:37:42.224503   125 net.cpp:262] Setting up inception_4d/pool_proj
I1130 22:37:42.224514   125 net.cpp:269] TEST Top shape for layer 114 'inception_4d/pool_proj' 6 64 40 40 (614400)
I1130 22:37:42.224524   125 layer_factory.hpp:172] Creating layer 'inception_4d/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.224530   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.224540   125 net.cpp:202] Created Layer inception_4d/relu_pool_proj (115)
I1130 22:37:42.224545   125 net.cpp:574] inception_4d/relu_pool_proj <- inception_4d/pool_proj
I1130 22:37:42.224552   125 net.cpp:529] inception_4d/relu_pool_proj -> inception_4d/pool_proj (in-place)
I1130 22:37:42.224561   125 net.cpp:262] Setting up inception_4d/relu_pool_proj
I1130 22:37:42.224567   125 net.cpp:269] TEST Top shape for layer 115 'inception_4d/relu_pool_proj' 6 64 40 40 (614400)
I1130 22:37:42.224572   125 layer_factory.hpp:172] Creating layer 'inception_4d/output' of type 'Concat'
I1130 22:37:42.224578   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.224588   125 net.cpp:202] Created Layer inception_4d/output (116)
I1130 22:37:42.224593   125 net.cpp:574] inception_4d/output <- inception_4d/1x1
I1130 22:37:42.224599   125 net.cpp:574] inception_4d/output <- inception_4d/3x3
I1130 22:37:42.224606   125 net.cpp:574] inception_4d/output <- inception_4d/5x5
I1130 22:37:42.224611   125 net.cpp:574] inception_4d/output <- inception_4d/pool_proj
I1130 22:37:42.224617   125 net.cpp:544] inception_4d/output -> inception_4d/output
I1130 22:37:42.224656   125 net.cpp:262] Setting up inception_4d/output
I1130 22:37:42.224664   125 net.cpp:269] TEST Top shape for layer 116 'inception_4d/output' 6 528 40 40 (5068800)
I1130 22:37:42.224670   125 layer_factory.hpp:172] Creating layer 'inception_4d/output_inception_4d/output_0_split' of type 'Split'
I1130 22:37:42.224676   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.224686   125 net.cpp:202] Created Layer inception_4d/output_inception_4d/output_0_split (117)
I1130 22:37:42.224692   125 net.cpp:574] inception_4d/output_inception_4d/output_0_split <- inception_4d/output
I1130 22:37:42.224710   125 net.cpp:544] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_0
I1130 22:37:42.224717   125 net.cpp:544] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_1
I1130 22:37:42.224727   125 net.cpp:544] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_2
I1130 22:37:42.224736   125 net.cpp:544] inception_4d/output_inception_4d/output_0_split -> inception_4d/output_inception_4d/output_0_split_3
I1130 22:37:42.224826   125 net.cpp:262] Setting up inception_4d/output_inception_4d/output_0_split
I1130 22:37:42.224834   125 net.cpp:269] TEST Top shape for layer 117 'inception_4d/output_inception_4d/output_0_split' 6 528 40 40 (5068800)
I1130 22:37:42.224840   125 net.cpp:269] TEST Top shape for layer 117 'inception_4d/output_inception_4d/output_0_split' 6 528 40 40 (5068800)
I1130 22:37:42.224848   125 net.cpp:269] TEST Top shape for layer 117 'inception_4d/output_inception_4d/output_0_split' 6 528 40 40 (5068800)
I1130 22:37:42.224853   125 net.cpp:269] TEST Top shape for layer 117 'inception_4d/output_inception_4d/output_0_split' 6 528 40 40 (5068800)
I1130 22:37:42.224859   125 layer_factory.hpp:172] Creating layer 'inception_4e/1x1' of type 'Convolution'
I1130 22:37:42.224865   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.224882   125 net.cpp:202] Created Layer inception_4e/1x1 (118)
I1130 22:37:42.224889   125 net.cpp:574] inception_4e/1x1 <- inception_4d/output_inception_4d/output_0_split_0
I1130 22:37:42.224895   125 net.cpp:544] inception_4e/1x1 -> inception_4e/1x1
I1130 22:37:42.227171   125 net.cpp:262] Setting up inception_4e/1x1
I1130 22:37:42.227183   125 net.cpp:269] TEST Top shape for layer 118 'inception_4e/1x1' 6 256 40 40 (2457600)
I1130 22:37:42.227193   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_1x1' of type 'ReLU'
I1130 22:37:42.227198   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.227210   125 net.cpp:202] Created Layer inception_4e/relu_1x1 (119)
I1130 22:37:42.227216   125 net.cpp:574] inception_4e/relu_1x1 <- inception_4e/1x1
I1130 22:37:42.227222   125 net.cpp:529] inception_4e/relu_1x1 -> inception_4e/1x1 (in-place)
I1130 22:37:42.227231   125 net.cpp:262] Setting up inception_4e/relu_1x1
I1130 22:37:42.227236   125 net.cpp:269] TEST Top shape for layer 119 'inception_4e/relu_1x1' 6 256 40 40 (2457600)
I1130 22:37:42.227242   125 layer_factory.hpp:172] Creating layer 'inception_4e/3x3_reduce' of type 'Convolution'
I1130 22:37:42.227248   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.227267   125 net.cpp:202] Created Layer inception_4e/3x3_reduce (120)
I1130 22:37:42.227272   125 net.cpp:574] inception_4e/3x3_reduce <- inception_4d/output_inception_4d/output_0_split_1
I1130 22:37:42.227279   125 net.cpp:544] inception_4e/3x3_reduce -> inception_4e/3x3_reduce
I1130 22:37:42.228886   125 net.cpp:262] Setting up inception_4e/3x3_reduce
I1130 22:37:42.228899   125 net.cpp:269] TEST Top shape for layer 120 'inception_4e/3x3_reduce' 6 160 40 40 (1536000)
I1130 22:37:42.228907   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.228914   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.228924   125 net.cpp:202] Created Layer inception_4e/relu_3x3_reduce (121)
I1130 22:37:42.228930   125 net.cpp:574] inception_4e/relu_3x3_reduce <- inception_4e/3x3_reduce
I1130 22:37:42.228936   125 net.cpp:529] inception_4e/relu_3x3_reduce -> inception_4e/3x3_reduce (in-place)
I1130 22:37:42.228945   125 net.cpp:262] Setting up inception_4e/relu_3x3_reduce
I1130 22:37:42.228957   125 net.cpp:269] TEST Top shape for layer 121 'inception_4e/relu_3x3_reduce' 6 160 40 40 (1536000)
I1130 22:37:42.228978   125 layer_factory.hpp:172] Creating layer 'inception_4e/3x3' of type 'Convolution'
I1130 22:37:42.228984   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.229003   125 net.cpp:202] Created Layer inception_4e/3x3 (122)
I1130 22:37:42.229008   125 net.cpp:574] inception_4e/3x3 <- inception_4e/3x3_reduce
I1130 22:37:42.229014   125 net.cpp:544] inception_4e/3x3 -> inception_4e/3x3
I1130 22:37:42.237231   125 net.cpp:262] Setting up inception_4e/3x3
I1130 22:37:42.237247   125 net.cpp:269] TEST Top shape for layer 122 'inception_4e/3x3' 6 320 40 40 (3072000)
I1130 22:37:42.237257   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_3x3' of type 'ReLU'
I1130 22:37:42.237263   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.237272   125 net.cpp:202] Created Layer inception_4e/relu_3x3 (123)
I1130 22:37:42.237278   125 net.cpp:574] inception_4e/relu_3x3 <- inception_4e/3x3
I1130 22:37:42.237285   125 net.cpp:529] inception_4e/relu_3x3 -> inception_4e/3x3 (in-place)
I1130 22:37:42.237298   125 net.cpp:262] Setting up inception_4e/relu_3x3
I1130 22:37:42.237303   125 net.cpp:269] TEST Top shape for layer 123 'inception_4e/relu_3x3' 6 320 40 40 (3072000)
I1130 22:37:42.237309   125 layer_factory.hpp:172] Creating layer 'inception_4e/5x5_reduce' of type 'Convolution'
I1130 22:37:42.237315   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.237334   125 net.cpp:202] Created Layer inception_4e/5x5_reduce (124)
I1130 22:37:42.237340   125 net.cpp:574] inception_4e/5x5_reduce <- inception_4d/output_inception_4d/output_0_split_2
I1130 22:37:42.237347   125 net.cpp:544] inception_4e/5x5_reduce -> inception_4e/5x5_reduce
I1130 22:37:42.237970   125 net.cpp:262] Setting up inception_4e/5x5_reduce
I1130 22:37:42.237982   125 net.cpp:269] TEST Top shape for layer 124 'inception_4e/5x5_reduce' 6 32 40 40 (307200)
I1130 22:37:42.237989   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.237995   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.238006   125 net.cpp:202] Created Layer inception_4e/relu_5x5_reduce (125)
I1130 22:37:42.238013   125 net.cpp:574] inception_4e/relu_5x5_reduce <- inception_4e/5x5_reduce
I1130 22:37:42.238018   125 net.cpp:529] inception_4e/relu_5x5_reduce -> inception_4e/5x5_reduce (in-place)
I1130 22:37:42.238026   125 net.cpp:262] Setting up inception_4e/relu_5x5_reduce
I1130 22:37:42.238034   125 net.cpp:269] TEST Top shape for layer 125 'inception_4e/relu_5x5_reduce' 6 32 40 40 (307200)
I1130 22:37:42.238039   125 layer_factory.hpp:172] Creating layer 'inception_4e/5x5' of type 'Convolution'
I1130 22:37:42.238044   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.238065   125 net.cpp:202] Created Layer inception_4e/5x5 (126)
I1130 22:37:42.238070   125 net.cpp:574] inception_4e/5x5 <- inception_4e/5x5_reduce
I1130 22:37:42.238076   125 net.cpp:544] inception_4e/5x5 -> inception_4e/5x5
I1130 22:37:42.241129   125 net.cpp:262] Setting up inception_4e/5x5
I1130 22:37:42.241144   125 net.cpp:269] TEST Top shape for layer 126 'inception_4e/5x5' 6 128 40 40 (1228800)
I1130 22:37:42.241154   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_5x5' of type 'ReLU'
I1130 22:37:42.241161   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.241169   125 net.cpp:202] Created Layer inception_4e/relu_5x5 (127)
I1130 22:37:42.241175   125 net.cpp:574] inception_4e/relu_5x5 <- inception_4e/5x5
I1130 22:37:42.241183   125 net.cpp:529] inception_4e/relu_5x5 -> inception_4e/5x5 (in-place)
I1130 22:37:42.241191   125 net.cpp:262] Setting up inception_4e/relu_5x5
I1130 22:37:42.241197   125 net.cpp:269] TEST Top shape for layer 127 'inception_4e/relu_5x5' 6 128 40 40 (1228800)
I1130 22:37:42.241204   125 layer_factory.hpp:172] Creating layer 'inception_4e/pool' of type 'Pooling'
I1130 22:37:42.241222   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.241248   125 net.cpp:202] Created Layer inception_4e/pool (128)
I1130 22:37:42.241255   125 net.cpp:574] inception_4e/pool <- inception_4d/output_inception_4d/output_0_split_3
I1130 22:37:42.241261   125 net.cpp:544] inception_4e/pool -> inception_4e/pool
I1130 22:37:42.241339   125 net.cpp:262] Setting up inception_4e/pool
I1130 22:37:42.241348   125 net.cpp:269] TEST Top shape for layer 128 'inception_4e/pool' 6 528 40 40 (5068800)
I1130 22:37:42.241353   125 layer_factory.hpp:172] Creating layer 'inception_4e/pool_proj' of type 'Convolution'
I1130 22:37:42.241360   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.241380   125 net.cpp:202] Created Layer inception_4e/pool_proj (129)
I1130 22:37:42.241386   125 net.cpp:574] inception_4e/pool_proj <- inception_4e/pool
I1130 22:37:42.241392   125 net.cpp:544] inception_4e/pool_proj -> inception_4e/pool_proj
I1130 22:37:42.242718   125 net.cpp:262] Setting up inception_4e/pool_proj
I1130 22:37:42.242730   125 net.cpp:269] TEST Top shape for layer 129 'inception_4e/pool_proj' 6 128 40 40 (1228800)
I1130 22:37:42.242738   125 layer_factory.hpp:172] Creating layer 'inception_4e/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.242744   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.242753   125 net.cpp:202] Created Layer inception_4e/relu_pool_proj (130)
I1130 22:37:42.242758   125 net.cpp:574] inception_4e/relu_pool_proj <- inception_4e/pool_proj
I1130 22:37:42.242765   125 net.cpp:529] inception_4e/relu_pool_proj -> inception_4e/pool_proj (in-place)
I1130 22:37:42.242774   125 net.cpp:262] Setting up inception_4e/relu_pool_proj
I1130 22:37:42.242781   125 net.cpp:269] TEST Top shape for layer 130 'inception_4e/relu_pool_proj' 6 128 40 40 (1228800)
I1130 22:37:42.242787   125 layer_factory.hpp:172] Creating layer 'inception_4e/output' of type 'Concat'
I1130 22:37:42.242794   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.242800   125 net.cpp:202] Created Layer inception_4e/output (131)
I1130 22:37:42.242805   125 net.cpp:574] inception_4e/output <- inception_4e/1x1
I1130 22:37:42.242812   125 net.cpp:574] inception_4e/output <- inception_4e/3x3
I1130 22:37:42.242817   125 net.cpp:574] inception_4e/output <- inception_4e/5x5
I1130 22:37:42.242823   125 net.cpp:574] inception_4e/output <- inception_4e/pool_proj
I1130 22:37:42.242828   125 net.cpp:544] inception_4e/output -> inception_4e/output
I1130 22:37:42.242872   125 net.cpp:262] Setting up inception_4e/output
I1130 22:37:42.242880   125 net.cpp:269] TEST Top shape for layer 131 'inception_4e/output' 6 832 40 40 (7987200)
I1130 22:37:42.242885   125 layer_factory.hpp:172] Creating layer 'inception_4e/output_inception_4e/output_0_split' of type 'Split'
I1130 22:37:42.242892   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.242902   125 net.cpp:202] Created Layer inception_4e/output_inception_4e/output_0_split (132)
I1130 22:37:42.242908   125 net.cpp:574] inception_4e/output_inception_4e/output_0_split <- inception_4e/output
I1130 22:37:42.242914   125 net.cpp:544] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_0
I1130 22:37:42.242921   125 net.cpp:544] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_1
I1130 22:37:42.242931   125 net.cpp:544] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_2
I1130 22:37:42.242938   125 net.cpp:544] inception_4e/output_inception_4e/output_0_split -> inception_4e/output_inception_4e/output_0_split_3
I1130 22:37:42.243026   125 net.cpp:262] Setting up inception_4e/output_inception_4e/output_0_split
I1130 22:37:42.243046   125 net.cpp:269] TEST Top shape for layer 132 'inception_4e/output_inception_4e/output_0_split' 6 832 40 40 (7987200)
I1130 22:37:42.243052   125 net.cpp:269] TEST Top shape for layer 132 'inception_4e/output_inception_4e/output_0_split' 6 832 40 40 (7987200)
I1130 22:37:42.243058   125 net.cpp:269] TEST Top shape for layer 132 'inception_4e/output_inception_4e/output_0_split' 6 832 40 40 (7987200)
I1130 22:37:42.243063   125 net.cpp:269] TEST Top shape for layer 132 'inception_4e/output_inception_4e/output_0_split' 6 832 40 40 (7987200)
I1130 22:37:42.243069   125 layer_factory.hpp:172] Creating layer 'inception_5a/1x1' of type 'Convolution'
I1130 22:37:42.243075   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.243098   125 net.cpp:202] Created Layer inception_5a/1x1 (133)
I1130 22:37:42.243103   125 net.cpp:574] inception_5a/1x1 <- inception_4e/output_inception_4e/output_0_split_0
I1130 22:37:42.243110   125 net.cpp:544] inception_5a/1x1 -> inception_5a/1x1
I1130 22:37:42.246533   125 net.cpp:262] Setting up inception_5a/1x1
I1130 22:37:42.246547   125 net.cpp:269] TEST Top shape for layer 133 'inception_5a/1x1' 6 256 40 40 (2457600)
I1130 22:37:42.246556   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_1x1' of type 'ReLU'
I1130 22:37:42.246562   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.246572   125 net.cpp:202] Created Layer inception_5a/relu_1x1 (134)
I1130 22:37:42.246578   125 net.cpp:574] inception_5a/relu_1x1 <- inception_5a/1x1
I1130 22:37:42.246584   125 net.cpp:529] inception_5a/relu_1x1 -> inception_5a/1x1 (in-place)
I1130 22:37:42.246593   125 net.cpp:262] Setting up inception_5a/relu_1x1
I1130 22:37:42.246599   125 net.cpp:269] TEST Top shape for layer 134 'inception_5a/relu_1x1' 6 256 40 40 (2457600)
I1130 22:37:42.246605   125 layer_factory.hpp:172] Creating layer 'inception_5a/3x3_reduce' of type 'Convolution'
I1130 22:37:42.246611   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.246628   125 net.cpp:202] Created Layer inception_5a/3x3_reduce (135)
I1130 22:37:42.246634   125 net.cpp:574] inception_5a/3x3_reduce <- inception_4e/output_inception_4e/output_0_split_1
I1130 22:37:42.246639   125 net.cpp:544] inception_5a/3x3_reduce -> inception_5a/3x3_reduce
I1130 22:37:42.248927   125 net.cpp:262] Setting up inception_5a/3x3_reduce
I1130 22:37:42.248942   125 net.cpp:269] TEST Top shape for layer 135 'inception_5a/3x3_reduce' 6 160 40 40 (1536000)
I1130 22:37:42.248951   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.248956   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.248965   125 net.cpp:202] Created Layer inception_5a/relu_3x3_reduce (136)
I1130 22:37:42.248970   125 net.cpp:574] inception_5a/relu_3x3_reduce <- inception_5a/3x3_reduce
I1130 22:37:42.248976   125 net.cpp:529] inception_5a/relu_3x3_reduce -> inception_5a/3x3_reduce (in-place)
I1130 22:37:42.248984   125 net.cpp:262] Setting up inception_5a/relu_3x3_reduce
I1130 22:37:42.248991   125 net.cpp:269] TEST Top shape for layer 136 'inception_5a/relu_3x3_reduce' 6 160 40 40 (1536000)
I1130 22:37:42.248996   125 layer_factory.hpp:172] Creating layer 'inception_5a/3x3' of type 'Convolution'
I1130 22:37:42.249002   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.249022   125 net.cpp:202] Created Layer inception_5a/3x3 (137)
I1130 22:37:42.249027   125 net.cpp:574] inception_5a/3x3 <- inception_5a/3x3_reduce
I1130 22:37:42.249032   125 net.cpp:544] inception_5a/3x3 -> inception_5a/3x3
I1130 22:37:42.257808   125 net.cpp:262] Setting up inception_5a/3x3
I1130 22:37:42.257829   125 net.cpp:269] TEST Top shape for layer 137 'inception_5a/3x3' 6 320 40 40 (3072000)
I1130 22:37:42.257843   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_3x3' of type 'ReLU'
I1130 22:37:42.257869   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.257879   125 net.cpp:202] Created Layer inception_5a/relu_3x3 (138)
I1130 22:37:42.257885   125 net.cpp:574] inception_5a/relu_3x3 <- inception_5a/3x3
I1130 22:37:42.257891   125 net.cpp:529] inception_5a/relu_3x3 -> inception_5a/3x3 (in-place)
I1130 22:37:42.257905   125 net.cpp:262] Setting up inception_5a/relu_3x3
I1130 22:37:42.257911   125 net.cpp:269] TEST Top shape for layer 138 'inception_5a/relu_3x3' 6 320 40 40 (3072000)
I1130 22:37:42.257917   125 layer_factory.hpp:172] Creating layer 'inception_5a/5x5_reduce' of type 'Convolution'
I1130 22:37:42.257922   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.257941   125 net.cpp:202] Created Layer inception_5a/5x5_reduce (139)
I1130 22:37:42.257947   125 net.cpp:574] inception_5a/5x5_reduce <- inception_4e/output_inception_4e/output_0_split_2
I1130 22:37:42.257953   125 net.cpp:544] inception_5a/5x5_reduce -> inception_5a/5x5_reduce
I1130 22:37:42.258771   125 net.cpp:262] Setting up inception_5a/5x5_reduce
I1130 22:37:42.258783   125 net.cpp:269] TEST Top shape for layer 139 'inception_5a/5x5_reduce' 6 32 40 40 (307200)
I1130 22:37:42.258793   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.258800   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.258810   125 net.cpp:202] Created Layer inception_5a/relu_5x5_reduce (140)
I1130 22:37:42.258816   125 net.cpp:574] inception_5a/relu_5x5_reduce <- inception_5a/5x5_reduce
I1130 22:37:42.258822   125 net.cpp:529] inception_5a/relu_5x5_reduce -> inception_5a/5x5_reduce (in-place)
I1130 22:37:42.258831   125 net.cpp:262] Setting up inception_5a/relu_5x5_reduce
I1130 22:37:42.258836   125 net.cpp:269] TEST Top shape for layer 140 'inception_5a/relu_5x5_reduce' 6 32 40 40 (307200)
I1130 22:37:42.258843   125 layer_factory.hpp:172] Creating layer 'inception_5a/5x5' of type 'Convolution'
I1130 22:37:42.258849   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.258867   125 net.cpp:202] Created Layer inception_5a/5x5 (141)
I1130 22:37:42.258872   125 net.cpp:574] inception_5a/5x5 <- inception_5a/5x5_reduce
I1130 22:37:42.258878   125 net.cpp:544] inception_5a/5x5 -> inception_5a/5x5
I1130 22:37:42.261946   125 net.cpp:262] Setting up inception_5a/5x5
I1130 22:37:42.261961   125 net.cpp:269] TEST Top shape for layer 141 'inception_5a/5x5' 6 128 40 40 (1228800)
I1130 22:37:42.261970   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_5x5' of type 'ReLU'
I1130 22:37:42.261977   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.261987   125 net.cpp:202] Created Layer inception_5a/relu_5x5 (142)
I1130 22:37:42.261994   125 net.cpp:574] inception_5a/relu_5x5 <- inception_5a/5x5
I1130 22:37:42.262001   125 net.cpp:529] inception_5a/relu_5x5 -> inception_5a/5x5 (in-place)
I1130 22:37:42.262009   125 net.cpp:262] Setting up inception_5a/relu_5x5
I1130 22:37:42.262017   125 net.cpp:269] TEST Top shape for layer 142 'inception_5a/relu_5x5' 6 128 40 40 (1228800)
I1130 22:37:42.262022   125 layer_factory.hpp:172] Creating layer 'inception_5a/pool' of type 'Pooling'
I1130 22:37:42.262027   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.262038   125 net.cpp:202] Created Layer inception_5a/pool (143)
I1130 22:37:42.262044   125 net.cpp:574] inception_5a/pool <- inception_4e/output_inception_4e/output_0_split_3
I1130 22:37:42.262050   125 net.cpp:544] inception_5a/pool -> inception_5a/pool
I1130 22:37:42.262137   125 net.cpp:262] Setting up inception_5a/pool
I1130 22:37:42.262148   125 net.cpp:269] TEST Top shape for layer 143 'inception_5a/pool' 6 832 40 40 (7987200)
I1130 22:37:42.262156   125 layer_factory.hpp:172] Creating layer 'inception_5a/pool_proj' of type 'Convolution'
I1130 22:37:42.262172   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.262192   125 net.cpp:202] Created Layer inception_5a/pool_proj (144)
I1130 22:37:42.262198   125 net.cpp:574] inception_5a/pool_proj <- inception_5a/pool
I1130 22:37:42.262205   125 net.cpp:544] inception_5a/pool_proj -> inception_5a/pool_proj
I1130 22:37:42.264107   125 net.cpp:262] Setting up inception_5a/pool_proj
I1130 22:37:42.264119   125 net.cpp:269] TEST Top shape for layer 144 'inception_5a/pool_proj' 6 128 40 40 (1228800)
I1130 22:37:42.264129   125 layer_factory.hpp:172] Creating layer 'inception_5a/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.264137   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.264144   125 net.cpp:202] Created Layer inception_5a/relu_pool_proj (145)
I1130 22:37:42.264150   125 net.cpp:574] inception_5a/relu_pool_proj <- inception_5a/pool_proj
I1130 22:37:42.264156   125 net.cpp:529] inception_5a/relu_pool_proj -> inception_5a/pool_proj (in-place)
I1130 22:37:42.264165   125 net.cpp:262] Setting up inception_5a/relu_pool_proj
I1130 22:37:42.264174   125 net.cpp:269] TEST Top shape for layer 145 'inception_5a/relu_pool_proj' 6 128 40 40 (1228800)
I1130 22:37:42.264179   125 layer_factory.hpp:172] Creating layer 'inception_5a/output' of type 'Concat'
I1130 22:37:42.264185   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.264194   125 net.cpp:202] Created Layer inception_5a/output (146)
I1130 22:37:42.264199   125 net.cpp:574] inception_5a/output <- inception_5a/1x1
I1130 22:37:42.264204   125 net.cpp:574] inception_5a/output <- inception_5a/3x3
I1130 22:37:42.264210   125 net.cpp:574] inception_5a/output <- inception_5a/5x5
I1130 22:37:42.264216   125 net.cpp:574] inception_5a/output <- inception_5a/pool_proj
I1130 22:37:42.264221   125 net.cpp:544] inception_5a/output -> inception_5a/output
I1130 22:37:42.264263   125 net.cpp:262] Setting up inception_5a/output
I1130 22:37:42.264271   125 net.cpp:269] TEST Top shape for layer 146 'inception_5a/output' 6 832 40 40 (7987200)
I1130 22:37:42.264278   125 layer_factory.hpp:172] Creating layer 'inception_5a/output_inception_5a/output_0_split' of type 'Split'
I1130 22:37:42.264284   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.264294   125 net.cpp:202] Created Layer inception_5a/output_inception_5a/output_0_split (147)
I1130 22:37:42.264302   125 net.cpp:574] inception_5a/output_inception_5a/output_0_split <- inception_5a/output
I1130 22:37:42.264308   125 net.cpp:544] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_0
I1130 22:37:42.264318   125 net.cpp:544] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_1
I1130 22:37:42.264324   125 net.cpp:544] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_2
I1130 22:37:42.264333   125 net.cpp:544] inception_5a/output_inception_5a/output_0_split -> inception_5a/output_inception_5a/output_0_split_3
I1130 22:37:42.264425   125 net.cpp:262] Setting up inception_5a/output_inception_5a/output_0_split
I1130 22:37:42.264432   125 net.cpp:269] TEST Top shape for layer 147 'inception_5a/output_inception_5a/output_0_split' 6 832 40 40 (7987200)
I1130 22:37:42.264438   125 net.cpp:269] TEST Top shape for layer 147 'inception_5a/output_inception_5a/output_0_split' 6 832 40 40 (7987200)
I1130 22:37:42.264444   125 net.cpp:269] TEST Top shape for layer 147 'inception_5a/output_inception_5a/output_0_split' 6 832 40 40 (7987200)
I1130 22:37:42.264451   125 net.cpp:269] TEST Top shape for layer 147 'inception_5a/output_inception_5a/output_0_split' 6 832 40 40 (7987200)
I1130 22:37:42.264457   125 layer_factory.hpp:172] Creating layer 'inception_5b/1x1' of type 'Convolution'
I1130 22:37:42.264463   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.264494   125 net.cpp:202] Created Layer inception_5b/1x1 (148)
I1130 22:37:42.264502   125 net.cpp:574] inception_5b/1x1 <- inception_5a/output_inception_5a/output_0_split_0
I1130 22:37:42.264508   125 net.cpp:544] inception_5b/1x1 -> inception_5b/1x1
I1130 22:37:42.270684   125 net.cpp:262] Setting up inception_5b/1x1
I1130 22:37:42.270700   125 net.cpp:269] TEST Top shape for layer 148 'inception_5b/1x1' 6 384 40 40 (3686400)
I1130 22:37:42.270710   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_1x1' of type 'ReLU'
I1130 22:37:42.270717   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.270727   125 net.cpp:202] Created Layer inception_5b/relu_1x1 (149)
I1130 22:37:42.270735   125 net.cpp:574] inception_5b/relu_1x1 <- inception_5b/1x1
I1130 22:37:42.270741   125 net.cpp:529] inception_5b/relu_1x1 -> inception_5b/1x1 (in-place)
I1130 22:37:42.270750   125 net.cpp:262] Setting up inception_5b/relu_1x1
I1130 22:37:42.270756   125 net.cpp:269] TEST Top shape for layer 149 'inception_5b/relu_1x1' 6 384 40 40 (3686400)
I1130 22:37:42.270762   125 layer_factory.hpp:172] Creating layer 'inception_5b/3x3_reduce' of type 'Convolution'
I1130 22:37:42.270768   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.270789   125 net.cpp:202] Created Layer inception_5b/3x3_reduce (150)
I1130 22:37:42.270795   125 net.cpp:574] inception_5b/3x3_reduce <- inception_5a/output_inception_5a/output_0_split_1
I1130 22:37:42.270802   125 net.cpp:544] inception_5b/3x3_reduce -> inception_5b/3x3_reduce
I1130 22:37:42.273494   125 net.cpp:262] Setting up inception_5b/3x3_reduce
I1130 22:37:42.273509   125 net.cpp:269] TEST Top shape for layer 150 'inception_5b/3x3_reduce' 6 192 40 40 (1843200)
I1130 22:37:42.273519   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_3x3_reduce' of type 'ReLU'
I1130 22:37:42.273525   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.273535   125 net.cpp:202] Created Layer inception_5b/relu_3x3_reduce (151)
I1130 22:37:42.273540   125 net.cpp:574] inception_5b/relu_3x3_reduce <- inception_5b/3x3_reduce
I1130 22:37:42.273546   125 net.cpp:529] inception_5b/relu_3x3_reduce -> inception_5b/3x3_reduce (in-place)
I1130 22:37:42.273555   125 net.cpp:262] Setting up inception_5b/relu_3x3_reduce
I1130 22:37:42.273561   125 net.cpp:269] TEST Top shape for layer 151 'inception_5b/relu_3x3_reduce' 6 192 40 40 (1843200)
I1130 22:37:42.273567   125 layer_factory.hpp:172] Creating layer 'inception_5b/3x3' of type 'Convolution'
I1130 22:37:42.273573   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.273592   125 net.cpp:202] Created Layer inception_5b/3x3 (152)
I1130 22:37:42.273598   125 net.cpp:574] inception_5b/3x3 <- inception_5b/3x3_reduce
I1130 22:37:42.273603   125 net.cpp:544] inception_5b/3x3 -> inception_5b/3x3
I1130 22:37:42.285713   125 net.cpp:262] Setting up inception_5b/3x3
I1130 22:37:42.285732   125 net.cpp:269] TEST Top shape for layer 152 'inception_5b/3x3' 6 384 40 40 (3686400)
I1130 22:37:42.285743   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_3x3' of type 'ReLU'
I1130 22:37:42.285749   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.285759   125 net.cpp:202] Created Layer inception_5b/relu_3x3 (153)
I1130 22:37:42.285766   125 net.cpp:574] inception_5b/relu_3x3 <- inception_5b/3x3
I1130 22:37:42.285775   125 net.cpp:529] inception_5b/relu_3x3 -> inception_5b/3x3 (in-place)
I1130 22:37:42.285784   125 net.cpp:262] Setting up inception_5b/relu_3x3
I1130 22:37:42.285792   125 net.cpp:269] TEST Top shape for layer 153 'inception_5b/relu_3x3' 6 384 40 40 (3686400)
I1130 22:37:42.285799   125 layer_factory.hpp:172] Creating layer 'inception_5b/5x5_reduce' of type 'Convolution'
I1130 22:37:42.285805   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.285840   125 net.cpp:202] Created Layer inception_5b/5x5_reduce (154)
I1130 22:37:42.285845   125 net.cpp:574] inception_5b/5x5_reduce <- inception_5a/output_inception_5a/output_0_split_2
I1130 22:37:42.285853   125 net.cpp:544] inception_5b/5x5_reduce -> inception_5b/5x5_reduce
I1130 22:37:42.288107   125 net.cpp:262] Setting up inception_5b/5x5_reduce
I1130 22:37:42.288122   125 net.cpp:269] TEST Top shape for layer 154 'inception_5b/5x5_reduce' 6 48 40 40 (460800)
I1130 22:37:42.288132   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_5x5_reduce' of type 'ReLU'
I1130 22:37:42.288139   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.288148   125 net.cpp:202] Created Layer inception_5b/relu_5x5_reduce (155)
I1130 22:37:42.288154   125 net.cpp:574] inception_5b/relu_5x5_reduce <- inception_5b/5x5_reduce
I1130 22:37:42.288161   125 net.cpp:529] inception_5b/relu_5x5_reduce -> inception_5b/5x5_reduce (in-place)
I1130 22:37:42.288173   125 net.cpp:262] Setting up inception_5b/relu_5x5_reduce
I1130 22:37:42.288179   125 net.cpp:269] TEST Top shape for layer 155 'inception_5b/relu_5x5_reduce' 6 48 40 40 (460800)
I1130 22:37:42.288185   125 layer_factory.hpp:172] Creating layer 'inception_5b/5x5' of type 'Convolution'
I1130 22:37:42.288192   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.288211   125 net.cpp:202] Created Layer inception_5b/5x5 (156)
I1130 22:37:42.288218   125 net.cpp:574] inception_5b/5x5 <- inception_5b/5x5_reduce
I1130 22:37:42.288223   125 net.cpp:544] inception_5b/5x5 -> inception_5b/5x5
I1130 22:37:42.290900   125 net.cpp:262] Setting up inception_5b/5x5
I1130 22:37:42.290912   125 net.cpp:269] TEST Top shape for layer 156 'inception_5b/5x5' 6 128 40 40 (1228800)
I1130 22:37:42.290922   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_5x5' of type 'ReLU'
I1130 22:37:42.290928   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.290938   125 net.cpp:202] Created Layer inception_5b/relu_5x5 (157)
I1130 22:37:42.290944   125 net.cpp:574] inception_5b/relu_5x5 <- inception_5b/5x5
I1130 22:37:42.290951   125 net.cpp:529] inception_5b/relu_5x5 -> inception_5b/5x5 (in-place)
I1130 22:37:42.290959   125 net.cpp:262] Setting up inception_5b/relu_5x5
I1130 22:37:42.290966   125 net.cpp:269] TEST Top shape for layer 157 'inception_5b/relu_5x5' 6 128 40 40 (1228800)
I1130 22:37:42.290971   125 layer_factory.hpp:172] Creating layer 'inception_5b/pool' of type 'Pooling'
I1130 22:37:42.290977   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.290989   125 net.cpp:202] Created Layer inception_5b/pool (158)
I1130 22:37:42.290995   125 net.cpp:574] inception_5b/pool <- inception_5a/output_inception_5a/output_0_split_3
I1130 22:37:42.291002   125 net.cpp:544] inception_5b/pool -> inception_5b/pool
I1130 22:37:42.291090   125 net.cpp:262] Setting up inception_5b/pool
I1130 22:37:42.291097   125 net.cpp:269] TEST Top shape for layer 158 'inception_5b/pool' 6 832 40 40 (7987200)
I1130 22:37:42.291103   125 layer_factory.hpp:172] Creating layer 'inception_5b/pool_proj' of type 'Convolution'
I1130 22:37:42.291110   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.291131   125 net.cpp:202] Created Layer inception_5b/pool_proj (159)
I1130 22:37:42.291136   125 net.cpp:574] inception_5b/pool_proj <- inception_5b/pool
I1130 22:37:42.291143   125 net.cpp:544] inception_5b/pool_proj -> inception_5b/pool_proj
I1130 22:37:42.293126   125 net.cpp:262] Setting up inception_5b/pool_proj
I1130 22:37:42.293141   125 net.cpp:269] TEST Top shape for layer 159 'inception_5b/pool_proj' 6 128 40 40 (1228800)
I1130 22:37:42.293151   125 layer_factory.hpp:172] Creating layer 'inception_5b/relu_pool_proj' of type 'ReLU'
I1130 22:37:42.293157   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.293179   125 net.cpp:202] Created Layer inception_5b/relu_pool_proj (160)
I1130 22:37:42.293185   125 net.cpp:574] inception_5b/relu_pool_proj <- inception_5b/pool_proj
I1130 22:37:42.293192   125 net.cpp:529] inception_5b/relu_pool_proj -> inception_5b/pool_proj (in-place)
I1130 22:37:42.293201   125 net.cpp:262] Setting up inception_5b/relu_pool_proj
I1130 22:37:42.293207   125 net.cpp:269] TEST Top shape for layer 160 'inception_5b/relu_pool_proj' 6 128 40 40 (1228800)
I1130 22:37:42.293213   125 layer_factory.hpp:172] Creating layer 'inception_5b/output' of type 'Concat'
I1130 22:37:42.293220   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.293231   125 net.cpp:202] Created Layer inception_5b/output (161)
I1130 22:37:42.293236   125 net.cpp:574] inception_5b/output <- inception_5b/1x1
I1130 22:37:42.293242   125 net.cpp:574] inception_5b/output <- inception_5b/3x3
I1130 22:37:42.293248   125 net.cpp:574] inception_5b/output <- inception_5b/5x5
I1130 22:37:42.293254   125 net.cpp:574] inception_5b/output <- inception_5b/pool_proj
I1130 22:37:42.293259   125 net.cpp:544] inception_5b/output -> inception_5b/output
I1130 22:37:42.293303   125 net.cpp:262] Setting up inception_5b/output
I1130 22:37:42.293310   125 net.cpp:269] TEST Top shape for layer 161 'inception_5b/output' 6 1024 40 40 (9830400)
I1130 22:37:42.293316   125 layer_factory.hpp:172] Creating layer 'pool5/drop_s1' of type 'Dropout'
I1130 22:37:42.293323   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.293336   125 net.cpp:202] Created Layer pool5/drop_s1 (162)
I1130 22:37:42.293341   125 net.cpp:574] pool5/drop_s1 <- inception_5b/output
I1130 22:37:42.293349   125 net.cpp:544] pool5/drop_s1 -> pool5/drop_s1
I1130 22:37:42.303683   125 net.cpp:262] Setting up pool5/drop_s1
I1130 22:37:42.303706   125 net.cpp:269] TEST Top shape for layer 162 'pool5/drop_s1' 6 1024 40 40 (9830400)
I1130 22:37:42.303714   125 layer_factory.hpp:172] Creating layer 'pool5/drop_s1_pool5/drop_s1_0_split' of type 'Split'
I1130 22:37:42.303721   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.303730   125 net.cpp:202] Created Layer pool5/drop_s1_pool5/drop_s1_0_split (163)
I1130 22:37:42.303737   125 net.cpp:574] pool5/drop_s1_pool5/drop_s1_0_split <- pool5/drop_s1
I1130 22:37:42.303745   125 net.cpp:544] pool5/drop_s1_pool5/drop_s1_0_split -> pool5/drop_s1_pool5/drop_s1_0_split_0
I1130 22:37:42.303753   125 net.cpp:544] pool5/drop_s1_pool5/drop_s1_0_split -> pool5/drop_s1_pool5/drop_s1_0_split_1
I1130 22:37:42.303828   125 net.cpp:262] Setting up pool5/drop_s1_pool5/drop_s1_0_split
I1130 22:37:42.303838   125 net.cpp:269] TEST Top shape for layer 163 'pool5/drop_s1_pool5/drop_s1_0_split' 6 1024 40 40 (9830400)
I1130 22:37:42.303843   125 net.cpp:269] TEST Top shape for layer 163 'pool5/drop_s1_pool5/drop_s1_0_split' 6 1024 40 40 (9830400)
I1130 22:37:42.303849   125 layer_factory.hpp:172] Creating layer 'cvg/classifier' of type 'Convolution'
I1130 22:37:42.303855   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.303874   125 net.cpp:202] Created Layer cvg/classifier (164)
I1130 22:37:42.303879   125 net.cpp:574] cvg/classifier <- pool5/drop_s1_pool5/drop_s1_0_split_0
I1130 22:37:42.303887   125 net.cpp:544] cvg/classifier -> cvg/classifier
I1130 22:37:42.304316   125 net.cpp:262] Setting up cvg/classifier
I1130 22:37:42.304328   125 net.cpp:269] TEST Top shape for layer 164 'cvg/classifier' 6 1 40 40 (9600)
I1130 22:37:42.304338   125 layer_factory.hpp:172] Creating layer 'coverage/sig' of type 'Sigmoid'
I1130 22:37:42.304344   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.304353   125 net.cpp:202] Created Layer coverage/sig (165)
I1130 22:37:42.304358   125 net.cpp:574] coverage/sig <- cvg/classifier
I1130 22:37:42.304381   125 net.cpp:544] coverage/sig -> coverage
I1130 22:37:42.304428   125 net.cpp:262] Setting up coverage/sig
I1130 22:37:42.304437   125 net.cpp:269] TEST Top shape for layer 165 'coverage/sig' 6 1 40 40 (9600)
I1130 22:37:42.304445   125 layer_factory.hpp:172] Creating layer 'coverage_coverage/sig_0_split' of type 'Split'
I1130 22:37:42.304450   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.304457   125 net.cpp:202] Created Layer coverage_coverage/sig_0_split (166)
I1130 22:37:42.304462   125 net.cpp:574] coverage_coverage/sig_0_split <- coverage
I1130 22:37:42.304469   125 net.cpp:544] coverage_coverage/sig_0_split -> coverage_coverage/sig_0_split_0
I1130 22:37:42.304478   125 net.cpp:544] coverage_coverage/sig_0_split -> coverage_coverage/sig_0_split_1
I1130 22:37:42.304534   125 net.cpp:262] Setting up coverage_coverage/sig_0_split
I1130 22:37:42.304545   125 net.cpp:269] TEST Top shape for layer 166 'coverage_coverage/sig_0_split' 6 1 40 40 (9600)
I1130 22:37:42.304551   125 net.cpp:269] TEST Top shape for layer 166 'coverage_coverage/sig_0_split' 6 1 40 40 (9600)
I1130 22:37:42.304558   125 layer_factory.hpp:172] Creating layer 'bbox/regressor' of type 'Convolution'
I1130 22:37:42.304563   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.304580   125 net.cpp:202] Created Layer bbox/regressor (167)
I1130 22:37:42.304586   125 net.cpp:574] bbox/regressor <- pool5/drop_s1_pool5/drop_s1_0_split_1
I1130 22:37:42.304594   125 net.cpp:544] bbox/regressor -> bboxes
I1130 22:37:42.305007   125 net.cpp:262] Setting up bbox/regressor
I1130 22:37:42.305018   125 net.cpp:269] TEST Top shape for layer 167 'bbox/regressor' 6 4 40 40 (38400)
I1130 22:37:42.305027   125 layer_factory.hpp:172] Creating layer 'bboxes_bbox/regressor_0_split' of type 'Split'
I1130 22:37:42.305033   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.305044   125 net.cpp:202] Created Layer bboxes_bbox/regressor_0_split (168)
I1130 22:37:42.305049   125 net.cpp:574] bboxes_bbox/regressor_0_split <- bboxes
I1130 22:37:42.305057   125 net.cpp:544] bboxes_bbox/regressor_0_split -> bboxes_bbox/regressor_0_split_0
I1130 22:37:42.305064   125 net.cpp:544] bboxes_bbox/regressor_0_split -> bboxes_bbox/regressor_0_split_1
I1130 22:37:42.305125   125 net.cpp:262] Setting up bboxes_bbox/regressor_0_split
I1130 22:37:42.305135   125 net.cpp:269] TEST Top shape for layer 168 'bboxes_bbox/regressor_0_split' 6 4 40 40 (38400)
I1130 22:37:42.305141   125 net.cpp:269] TEST Top shape for layer 168 'bboxes_bbox/regressor_0_split' 6 4 40 40 (38400)
I1130 22:37:42.305147   125 layer_factory.hpp:172] Creating layer 'bbox_mask' of type 'Eltwise'
I1130 22:37:42.305152   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.305163   125 net.cpp:202] Created Layer bbox_mask (169)
I1130 22:37:42.305169   125 net.cpp:574] bbox_mask <- bboxes_bbox/regressor_0_split_0
I1130 22:37:42.305176   125 net.cpp:574] bbox_mask <- coverage-block
I1130 22:37:42.305182   125 net.cpp:544] bbox_mask -> bboxes-masked
I1130 22:37:42.305227   125 net.cpp:262] Setting up bbox_mask
I1130 22:37:42.305238   125 net.cpp:269] TEST Top shape for layer 169 'bbox_mask' 6 4 40 40 (38400)
I1130 22:37:42.305243   125 layer_factory.hpp:172] Creating layer 'bbox-norm' of type 'Eltwise'
I1130 22:37:42.305249   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.305256   125 net.cpp:202] Created Layer bbox-norm (170)
I1130 22:37:42.305263   125 net.cpp:574] bbox-norm <- bboxes-masked
I1130 22:37:42.305269   125 net.cpp:574] bbox-norm <- size-block_size-block_0_split_1
I1130 22:37:42.305275   125 net.cpp:544] bbox-norm -> bboxes-masked-norm
I1130 22:37:42.305315   125 net.cpp:262] Setting up bbox-norm
I1130 22:37:42.305322   125 net.cpp:269] TEST Top shape for layer 170 'bbox-norm' 6 4 40 40 (38400)
I1130 22:37:42.305338   125 layer_factory.hpp:172] Creating layer 'bbox-obj-norm' of type 'Eltwise'
I1130 22:37:42.305344   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.305354   125 net.cpp:202] Created Layer bbox-obj-norm (171)
I1130 22:37:42.305361   125 net.cpp:574] bbox-obj-norm <- bboxes-masked-norm
I1130 22:37:42.305367   125 net.cpp:574] bbox-obj-norm <- obj-block_obj-block_0_split_1
I1130 22:37:42.305373   125 net.cpp:544] bbox-obj-norm -> bboxes-obj-masked-norm
I1130 22:37:42.305411   125 net.cpp:262] Setting up bbox-obj-norm
I1130 22:37:42.305419   125 net.cpp:269] TEST Top shape for layer 171 'bbox-obj-norm' 6 4 40 40 (38400)
I1130 22:37:42.305425   125 layer_factory.hpp:172] Creating layer 'bbox_loss' of type 'L1Loss'
I1130 22:37:42.305430   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.305445   125 net.cpp:202] Created Layer bbox_loss (172)
I1130 22:37:42.305450   125 net.cpp:574] bbox_loss <- bboxes-obj-masked-norm
I1130 22:37:42.305457   125 net.cpp:574] bbox_loss <- bbox-obj-label-norm
I1130 22:37:42.305464   125 net.cpp:544] bbox_loss -> loss_bbox
I1130 22:37:42.305536   125 net.cpp:262] Setting up bbox_loss
I1130 22:37:42.305543   125 net.cpp:269] TEST Top shape for layer 172 'bbox_loss' (1)
I1130 22:37:42.305548   125 net.cpp:273]     with loss weight 2
I1130 22:37:42.305565   125 layer_factory.hpp:172] Creating layer 'coverage_loss' of type 'EuclideanLoss'
I1130 22:37:42.305572   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.305580   125 net.cpp:202] Created Layer coverage_loss (173)
I1130 22:37:42.305585   125 net.cpp:574] coverage_loss <- coverage_coverage/sig_0_split_0
I1130 22:37:42.305593   125 net.cpp:574] coverage_loss <- coverage-label_slice-label_4_split_0
I1130 22:37:42.305598   125 net.cpp:544] coverage_loss -> loss_coverage
I1130 22:37:42.305654   125 net.cpp:262] Setting up coverage_loss
I1130 22:37:42.305660   125 net.cpp:269] TEST Top shape for layer 173 'coverage_loss' (1)
I1130 22:37:42.305665   125 net.cpp:273]     with loss weight 1
I1130 22:37:42.305672   125 layer_factory.hpp:172] Creating layer 'cluster' of type 'Python'
I1130 22:37:42.305678   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:42.310729   125 layer_factory.cpp:339] Importing Python module 'caffe.layers.detectnet.clustering'
I1130 22:37:43.042603   125 net.cpp:202] Created Layer cluster (174)
I1130 22:37:43.042651   125 net.cpp:574] cluster <- coverage_coverage/sig_0_split_1
I1130 22:37:43.042672   125 net.cpp:574] cluster <- bboxes_bbox/regressor_0_split_1
I1130 22:37:43.042685   125 net.cpp:544] cluster -> bbox-list
I1130 22:37:43.043197   125 net.cpp:262] Setting up cluster
I1130 22:37:43.043223   125 net.cpp:269] TEST Top shape for layer 174 'cluster' 6 50 5 (1500)
I1130 22:37:43.043234   125 layer_factory.hpp:172] Creating layer 'cluster_gt' of type 'Python'
I1130 22:37:43.043242   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:43.043292   125 layer_factory.cpp:339] Importing Python module 'caffe.layers.detectnet.clustering'
I1130 22:37:43.043328   125 net.cpp:202] Created Layer cluster_gt (175)
I1130 22:37:43.043335   125 net.cpp:574] cluster_gt <- coverage-label_slice-label_4_split_1
I1130 22:37:43.043344   125 net.cpp:574] cluster_gt <- bbox-label_slice-label_1_split_1
I1130 22:37:43.043351   125 net.cpp:544] cluster_gt -> bbox-list-label
I1130 22:37:43.043500   125 net.cpp:262] Setting up cluster_gt
I1130 22:37:43.043512   125 net.cpp:269] TEST Top shape for layer 175 'cluster_gt' 6 50 5 (1500)
I1130 22:37:43.043519   125 layer_factory.hpp:172] Creating layer 'score' of type 'Python'
I1130 22:37:43.043526   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:43.043550   125 layer_factory.cpp:339] Importing Python module 'caffe.layers.detectnet.mean_ap'
I1130 22:37:43.045498   125 net.cpp:202] Created Layer score (176)
I1130 22:37:43.045512   125 net.cpp:574] score <- bbox-list-label
I1130 22:37:43.045521   125 net.cpp:574] score <- bbox-list
I1130 22:37:43.045528   125 net.cpp:544] score -> bbox-list-scored
I1130 22:37:43.045747   125 net.cpp:262] Setting up score
I1130 22:37:43.045759   125 net.cpp:269] TEST Top shape for layer 176 'score' 6 50 5 (1500)
I1130 22:37:43.045766   125 layer_factory.hpp:172] Creating layer 'mAP' of type 'Python'
I1130 22:37:43.045773   125 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I1130 22:37:43.045797   125 layer_factory.cpp:339] Importing Python module 'caffe.layers.detectnet.mean_ap'
I1130 22:37:43.045826   125 net.cpp:202] Created Layer mAP (177)
I1130 22:37:43.045833   125 net.cpp:574] mAP <- bbox-list-scored
I1130 22:37:43.045842   125 net.cpp:544] mAP -> mAP
I1130 22:37:43.045857   125 net.cpp:544] mAP -> precision
I1130 22:37:43.045866   125 net.cpp:544] mAP -> recall
I1130 22:37:43.046008   125 net.cpp:262] Setting up mAP
I1130 22:37:43.046018   125 net.cpp:269] TEST Top shape for layer 177 'mAP' 1 (1)
I1130 22:37:43.046025   125 net.cpp:269] TEST Top shape for layer 177 'mAP' 1 (1)
I1130 22:37:43.046030   125 net.cpp:269] TEST Top shape for layer 177 'mAP' 1 (1)
I1130 22:37:43.046036   125 net.cpp:340] mAP does not need backward computation.
I1130 22:37:43.046041   125 net.cpp:340] score does not need backward computation.
I1130 22:37:43.046047   125 net.cpp:340] cluster_gt does not need backward computation.
I1130 22:37:43.046053   125 net.cpp:340] cluster does not need backward computation.
I1130 22:37:43.046059   125 net.cpp:338] coverage_loss needs backward computation.
I1130 22:37:43.046066   125 net.cpp:338] bbox_loss needs backward computation.
I1130 22:37:43.046073   125 net.cpp:338] bbox-obj-norm needs backward computation.
I1130 22:37:43.046080   125 net.cpp:338] bbox-norm needs backward computation.
I1130 22:37:43.046087   125 net.cpp:338] bbox_mask needs backward computation.
I1130 22:37:43.046094   125 net.cpp:338] bboxes_bbox/regressor_0_split needs backward computation.
I1130 22:37:43.046100   125 net.cpp:338] bbox/regressor needs backward computation.
I1130 22:37:43.046106   125 net.cpp:338] coverage_coverage/sig_0_split needs backward computation.
I1130 22:37:43.046113   125 net.cpp:338] coverage/sig needs backward computation.
I1130 22:37:43.046118   125 net.cpp:338] cvg/classifier needs backward computation.
I1130 22:37:43.046124   125 net.cpp:338] pool5/drop_s1_pool5/drop_s1_0_split needs backward computation.
I1130 22:37:43.046133   125 net.cpp:338] pool5/drop_s1 needs backward computation.
I1130 22:37:43.046138   125 net.cpp:338] inception_5b/output needs backward computation.
I1130 22:37:43.046146   125 net.cpp:338] inception_5b/relu_pool_proj needs backward computation.
I1130 22:37:43.046152   125 net.cpp:338] inception_5b/pool_proj needs backward computation.
I1130 22:37:43.046159   125 net.cpp:338] inception_5b/pool needs backward computation.
I1130 22:37:43.046165   125 net.cpp:338] inception_5b/relu_5x5 needs backward computation.
I1130 22:37:43.046171   125 net.cpp:338] inception_5b/5x5 needs backward computation.
I1130 22:37:43.046177   125 net.cpp:338] inception_5b/relu_5x5_reduce needs backward computation.
I1130 22:37:43.046183   125 net.cpp:338] inception_5b/5x5_reduce needs backward computation.
I1130 22:37:43.046190   125 net.cpp:338] inception_5b/relu_3x3 needs backward computation.
I1130 22:37:43.046195   125 net.cpp:338] inception_5b/3x3 needs backward computation.
I1130 22:37:43.046201   125 net.cpp:338] inception_5b/relu_3x3_reduce needs backward computation.
I1130 22:37:43.046207   125 net.cpp:338] inception_5b/3x3_reduce needs backward computation.
I1130 22:37:43.046213   125 net.cpp:338] inception_5b/relu_1x1 needs backward computation.
I1130 22:37:43.046219   125 net.cpp:338] inception_5b/1x1 needs backward computation.
I1130 22:37:43.046226   125 net.cpp:338] inception_5a/output_inception_5a/output_0_split needs backward computation.
I1130 22:37:43.046245   125 net.cpp:338] inception_5a/output needs backward computation.
I1130 22:37:43.046254   125 net.cpp:338] inception_5a/relu_pool_proj needs backward computation.
I1130 22:37:43.046260   125 net.cpp:338] inception_5a/pool_proj needs backward computation.
I1130 22:37:43.046267   125 net.cpp:338] inception_5a/pool needs backward computation.
I1130 22:37:43.046272   125 net.cpp:338] inception_5a/relu_5x5 needs backward computation.
I1130 22:37:43.046278   125 net.cpp:338] inception_5a/5x5 needs backward computation.
I1130 22:37:43.046284   125 net.cpp:338] inception_5a/relu_5x5_reduce needs backward computation.
I1130 22:37:43.046290   125 net.cpp:338] inception_5a/5x5_reduce needs backward computation.
I1130 22:37:43.046296   125 net.cpp:338] inception_5a/relu_3x3 needs backward computation.
I1130 22:37:43.046301   125 net.cpp:338] inception_5a/3x3 needs backward computation.
I1130 22:37:43.046308   125 net.cpp:338] inception_5a/relu_3x3_reduce needs backward computation.
I1130 22:37:43.046314   125 net.cpp:338] inception_5a/3x3_reduce needs backward computation.
I1130 22:37:43.046319   125 net.cpp:338] inception_5a/relu_1x1 needs backward computation.
I1130 22:37:43.046324   125 net.cpp:338] inception_5a/1x1 needs backward computation.
I1130 22:37:43.046330   125 net.cpp:338] inception_4e/output_inception_4e/output_0_split needs backward computation.
I1130 22:37:43.046337   125 net.cpp:338] inception_4e/output needs backward computation.
I1130 22:37:43.046344   125 net.cpp:338] inception_4e/relu_pool_proj needs backward computation.
I1130 22:37:43.046350   125 net.cpp:338] inception_4e/pool_proj needs backward computation.
I1130 22:37:43.046356   125 net.cpp:338] inception_4e/pool needs backward computation.
I1130 22:37:43.046362   125 net.cpp:338] inception_4e/relu_5x5 needs backward computation.
I1130 22:37:43.046368   125 net.cpp:338] inception_4e/5x5 needs backward computation.
I1130 22:37:43.046373   125 net.cpp:338] inception_4e/relu_5x5_reduce needs backward computation.
I1130 22:37:43.046380   125 net.cpp:338] inception_4e/5x5_reduce needs backward computation.
I1130 22:37:43.046386   125 net.cpp:338] inception_4e/relu_3x3 needs backward computation.
I1130 22:37:43.046391   125 net.cpp:338] inception_4e/3x3 needs backward computation.
I1130 22:37:43.046396   125 net.cpp:338] inception_4e/relu_3x3_reduce needs backward computation.
I1130 22:37:43.046402   125 net.cpp:338] inception_4e/3x3_reduce needs backward computation.
I1130 22:37:43.046409   125 net.cpp:338] inception_4e/relu_1x1 needs backward computation.
I1130 22:37:43.046416   125 net.cpp:338] inception_4e/1x1 needs backward computation.
I1130 22:37:43.046420   125 net.cpp:338] inception_4d/output_inception_4d/output_0_split needs backward computation.
I1130 22:37:43.046427   125 net.cpp:338] inception_4d/output needs backward computation.
I1130 22:37:43.046437   125 net.cpp:338] inception_4d/relu_pool_proj needs backward computation.
I1130 22:37:43.046442   125 net.cpp:338] inception_4d/pool_proj needs backward computation.
I1130 22:37:43.046447   125 net.cpp:338] inception_4d/pool needs backward computation.
I1130 22:37:43.046453   125 net.cpp:338] inception_4d/relu_5x5 needs backward computation.
I1130 22:37:43.046458   125 net.cpp:338] inception_4d/5x5 needs backward computation.
I1130 22:37:43.046464   125 net.cpp:338] inception_4d/relu_5x5_reduce needs backward computation.
I1130 22:37:43.046469   125 net.cpp:338] inception_4d/5x5_reduce needs backward computation.
I1130 22:37:43.046476   125 net.cpp:338] inception_4d/relu_3x3 needs backward computation.
I1130 22:37:43.046481   125 net.cpp:338] inception_4d/3x3 needs backward computation.
I1130 22:37:43.046488   125 net.cpp:338] inception_4d/relu_3x3_reduce needs backward computation.
I1130 22:37:43.046492   125 net.cpp:338] inception_4d/3x3_reduce needs backward computation.
I1130 22:37:43.046499   125 net.cpp:338] inception_4d/relu_1x1 needs backward computation.
I1130 22:37:43.046504   125 net.cpp:338] inception_4d/1x1 needs backward computation.
I1130 22:37:43.046511   125 net.cpp:338] inception_4c/output_inception_4c/output_0_split needs backward computation.
I1130 22:37:43.046524   125 net.cpp:338] inception_4c/output needs backward computation.
I1130 22:37:43.046531   125 net.cpp:338] inception_4c/relu_pool_proj needs backward computation.
I1130 22:37:43.046537   125 net.cpp:338] inception_4c/pool_proj needs backward computation.
I1130 22:37:43.046542   125 net.cpp:338] inception_4c/pool needs backward computation.
I1130 22:37:43.046548   125 net.cpp:338] inception_4c/relu_5x5 needs backward computation.
I1130 22:37:43.046555   125 net.cpp:338] inception_4c/5x5 needs backward computation.
I1130 22:37:43.046561   125 net.cpp:338] inception_4c/relu_5x5_reduce needs backward computation.
I1130 22:37:43.046566   125 net.cpp:338] inception_4c/5x5_reduce needs backward computation.
I1130 22:37:43.046572   125 net.cpp:338] inception_4c/relu_3x3 needs backward computation.
I1130 22:37:43.046578   125 net.cpp:338] inception_4c/3x3 needs backward computation.
I1130 22:37:43.046584   125 net.cpp:338] inception_4c/relu_3x3_reduce needs backward computation.
I1130 22:37:43.046591   125 net.cpp:338] inception_4c/3x3_reduce needs backward computation.
I1130 22:37:43.046597   125 net.cpp:338] inception_4c/relu_1x1 needs backward computation.
I1130 22:37:43.046602   125 net.cpp:338] inception_4c/1x1 needs backward computation.
I1130 22:37:43.046608   125 net.cpp:338] inception_4b/output_inception_4b/output_0_split needs backward computation.
I1130 22:37:43.046614   125 net.cpp:338] inception_4b/output needs backward computation.
I1130 22:37:43.046622   125 net.cpp:338] inception_4b/relu_pool_proj needs backward computation.
I1130 22:37:43.046627   125 net.cpp:338] inception_4b/pool_proj needs backward computation.
I1130 22:37:43.046633   125 net.cpp:338] inception_4b/pool needs backward computation.
I1130 22:37:43.046639   125 net.cpp:338] inception_4b/relu_5x5 needs backward computation.
I1130 22:37:43.046644   125 net.cpp:338] inception_4b/5x5 needs backward computation.
I1130 22:37:43.046650   125 net.cpp:338] inception_4b/relu_5x5_reduce needs backward computation.
I1130 22:37:43.046656   125 net.cpp:338] inception_4b/5x5_reduce needs backward computation.
I1130 22:37:43.046663   125 net.cpp:338] inception_4b/relu_3x3 needs backward computation.
I1130 22:37:43.046667   125 net.cpp:338] inception_4b/3x3 needs backward computation.
I1130 22:37:43.046674   125 net.cpp:338] inception_4b/relu_3x3_reduce needs backward computation.
I1130 22:37:43.046679   125 net.cpp:338] inception_4b/3x3_reduce needs backward computation.
I1130 22:37:43.046685   125 net.cpp:338] inception_4b/relu_1x1 needs backward computation.
I1130 22:37:43.046690   125 net.cpp:338] inception_4b/1x1 needs backward computation.
I1130 22:37:43.046696   125 net.cpp:338] inception_4a/output_inception_4a/output_0_split needs backward computation.
I1130 22:37:43.046702   125 net.cpp:338] inception_4a/output needs backward computation.
I1130 22:37:43.046710   125 net.cpp:338] inception_4a/relu_pool_proj needs backward computation.
I1130 22:37:43.046716   125 net.cpp:338] inception_4a/pool_proj needs backward computation.
I1130 22:37:43.046722   125 net.cpp:338] inception_4a/pool needs backward computation.
I1130 22:37:43.046728   125 net.cpp:338] inception_4a/relu_5x5 needs backward computation.
I1130 22:37:43.046735   125 net.cpp:338] inception_4a/5x5 needs backward computation.
I1130 22:37:43.046739   125 net.cpp:338] inception_4a/relu_5x5_reduce needs backward computation.
I1130 22:37:43.046746   125 net.cpp:338] inception_4a/5x5_reduce needs backward computation.
I1130 22:37:43.046752   125 net.cpp:338] inception_4a/relu_3x3 needs backward computation.
I1130 22:37:43.046757   125 net.cpp:338] inception_4a/3x3 needs backward computation.
I1130 22:37:43.046763   125 net.cpp:338] inception_4a/relu_3x3_reduce needs backward computation.
I1130 22:37:43.046769   125 net.cpp:338] inception_4a/3x3_reduce needs backward computation.
I1130 22:37:43.046775   125 net.cpp:338] inception_4a/relu_1x1 needs backward computation.
I1130 22:37:43.046780   125 net.cpp:338] inception_4a/1x1 needs backward computation.
I1130 22:37:43.046793   125 net.cpp:338] pool3/3x3_s2_pool3/3x3_s2_0_split needs backward computation.
I1130 22:37:43.046799   125 net.cpp:338] pool3/3x3_s2 needs backward computation.
I1130 22:37:43.046806   125 net.cpp:338] inception_3b/output needs backward computation.
I1130 22:37:43.046814   125 net.cpp:338] inception_3b/relu_pool_proj needs backward computation.
I1130 22:37:43.046819   125 net.cpp:338] inception_3b/pool_proj needs backward computation.
I1130 22:37:43.046825   125 net.cpp:338] inception_3b/pool needs backward computation.
I1130 22:37:43.046833   125 net.cpp:338] inception_3b/relu_5x5 needs backward computation.
I1130 22:37:43.046838   125 net.cpp:338] inception_3b/5x5 needs backward computation.
I1130 22:37:43.046844   125 net.cpp:338] inception_3b/relu_5x5_reduce needs backward computation.
I1130 22:37:43.046849   125 net.cpp:338] inception_3b/5x5_reduce needs backward computation.
I1130 22:37:43.046855   125 net.cpp:338] inception_3b/relu_3x3 needs backward computation.
I1130 22:37:43.046861   125 net.cpp:338] inception_3b/3x3 needs backward computation.
I1130 22:37:43.046866   125 net.cpp:338] inception_3b/relu_3x3_reduce needs backward computation.
I1130 22:37:43.046872   125 net.cpp:338] inception_3b/3x3_reduce needs backward computation.
I1130 22:37:43.046878   125 net.cpp:338] inception_3b/relu_1x1 needs backward computation.
I1130 22:37:43.046883   125 net.cpp:338] inception_3b/1x1 needs backward computation.
I1130 22:37:43.046888   125 net.cpp:338] inception_3a/output_inception_3a/output_0_split needs backward computation.
I1130 22:37:43.046895   125 net.cpp:338] inception_3a/output needs backward computation.
I1130 22:37:43.046902   125 net.cpp:338] inception_3a/relu_pool_proj needs backward computation.
I1130 22:37:43.046908   125 net.cpp:338] inception_3a/pool_proj needs backward computation.
I1130 22:37:43.046913   125 net.cpp:338] inception_3a/pool needs backward computation.
I1130 22:37:43.046919   125 net.cpp:338] inception_3a/relu_5x5 needs backward computation.
I1130 22:37:43.046926   125 net.cpp:338] inception_3a/5x5 needs backward computation.
I1130 22:37:43.046931   125 net.cpp:338] inception_3a/relu_5x5_reduce needs backward computation.
I1130 22:37:43.046936   125 net.cpp:338] inception_3a/5x5_reduce needs backward computation.
I1130 22:37:43.046942   125 net.cpp:338] inception_3a/relu_3x3 needs backward computation.
I1130 22:37:43.046948   125 net.cpp:338] inception_3a/3x3 needs backward computation.
I1130 22:37:43.046955   125 net.cpp:338] inception_3a/relu_3x3_reduce needs backward computation.
I1130 22:37:43.046959   125 net.cpp:338] inception_3a/3x3_reduce needs backward computation.
I1130 22:37:43.046967   125 net.cpp:338] inception_3a/relu_1x1 needs backward computation.
I1130 22:37:43.046972   125 net.cpp:338] inception_3a/1x1 needs backward computation.
I1130 22:37:43.046977   125 net.cpp:338] pool2/3x3_s2_pool2/3x3_s2_0_split needs backward computation.
I1130 22:37:43.046983   125 net.cpp:338] pool2/3x3_s2 needs backward computation.
I1130 22:37:43.046989   125 net.cpp:338] conv2/norm2 needs backward computation.
I1130 22:37:43.046996   125 net.cpp:338] conv2/relu_3x3 needs backward computation.
I1130 22:37:43.047001   125 net.cpp:338] conv2/3x3 needs backward computation.
I1130 22:37:43.047008   125 net.cpp:338] conv2/relu_3x3_reduce needs backward computation.
I1130 22:37:43.047014   125 net.cpp:338] conv2/3x3_reduce needs backward computation.
I1130 22:37:43.047020   125 net.cpp:338] pool1/norm1 needs backward computation.
I1130 22:37:43.047025   125 net.cpp:338] pool1/3x3_s2 needs backward computation.
I1130 22:37:43.047031   125 net.cpp:338] conv1/relu_7x7 needs backward computation.
I1130 22:37:43.047037   125 net.cpp:338] conv1/7x7_s2 needs backward computation.
I1130 22:37:43.047044   125 net.cpp:340] bb-obj-norm does not need backward computation.
I1130 22:37:43.047051   125 net.cpp:340] bb-label-norm does not need backward computation.
I1130 22:37:43.047060   125 net.cpp:340] obj-block_obj-block_0_split does not need backward computation.
I1130 22:37:43.047072   125 net.cpp:340] obj-block does not need backward computation.
I1130 22:37:43.047083   125 net.cpp:340] size-block_size-block_0_split does not need backward computation.
I1130 22:37:43.047089   125 net.cpp:340] size-block does not need backward computation.
I1130 22:37:43.047096   125 net.cpp:340] coverage-block does not need backward computation.
I1130 22:37:43.047107   125 net.cpp:340] coverage-label_slice-label_4_split does not need backward computation.
I1130 22:37:43.047116   125 net.cpp:340] obj-label_slice-label_3_split does not need backward computation.
I1130 22:37:43.047122   125 net.cpp:340] size-label_slice-label_2_split does not need backward computation.
I1130 22:37:43.047129   125 net.cpp:340] bbox-label_slice-label_1_split does not need backward computation.
I1130 22:37:43.047137   125 net.cpp:340] foreground-label_slice-label_0_split does not need backward computation.
I1130 22:37:43.047147   125 net.cpp:340] slice-label does not need backward computation.
I1130 22:37:43.047152   125 net.cpp:340] val_transform does not need backward computation.
I1130 22:37:43.047160   125 net.cpp:340] val_label does not need backward computation.
I1130 22:37:43.047165   125 net.cpp:340] val_data does not need backward computation.
I1130 22:37:43.047170   125 net.cpp:382] This network produces output loss_bbox
I1130 22:37:43.047176   125 net.cpp:382] This network produces output loss_coverage
I1130 22:37:43.047183   125 net.cpp:382] This network produces output mAP
I1130 22:37:43.047188   125 net.cpp:382] This network produces output precision
I1130 22:37:43.047194   125 net.cpp:382] This network produces output recall
I1130 22:37:43.047379   125 net.cpp:405] Top memory (TEST) required for data: 3268960120 diff: 3268960120
I1130 22:37:43.047386   125 net.cpp:408] Bottom memory (TEST) required for data: 3268960080 diff: 3268960080
I1130 22:37:43.047392   125 net.cpp:411] Shared (in-place) memory (TEST) by data: 697958400 diff: 697958400
I1130 22:37:43.047397   125 net.cpp:414] Parameters memory (TEST) required for data: 23914712 diff: 23914712
I1130 22:37:43.047402   125 net.cpp:417] Parameters shared memory (TEST) by data: 0 diff: 0
I1130 22:37:43.047407   125 net.cpp:423] Network initialization done.
I1130 22:37:43.048432   125 solver.cpp:55] Solver scaffolding done.
I1130 22:37:43.056162   125 caffe.cpp:155] Finetuning from /workspace/jobs/bvlc_googlenet.caffemodel
I1130 22:37:43.527179   125 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /workspace/jobs/bvlc_googlenet.caffemodel
I1130 22:37:43.607878   125 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I1130 22:37:43.608175   125 net.cpp:1133] Ignoring source layer data
I1130 22:37:43.608183   125 net.cpp:1133] Ignoring source layer label_data_1_split
I1130 22:37:43.608189   125 net.cpp:1141] Copying source layer conv1/7x7_s2 Type:Convolution #blobs=2
I1130 22:37:43.608332   125 net.cpp:1141] Copying source layer conv1/relu_7x7 Type:ReLU #blobs=0
I1130 22:37:43.608338   125 net.cpp:1141] Copying source layer pool1/3x3_s2 Type:Pooling #blobs=0
I1130 22:37:43.608343   125 net.cpp:1141] Copying source layer pool1/norm1 Type:LRN #blobs=0
I1130 22:37:43.608347   125 net.cpp:1141] Copying source layer conv2/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.608407   125 net.cpp:1141] Copying source layer conv2/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.608412   125 net.cpp:1141] Copying source layer conv2/3x3 Type:Convolution #blobs=2
I1130 22:37:43.609737   125 net.cpp:1141] Copying source layer conv2/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.609743   125 net.cpp:1141] Copying source layer conv2/norm2 Type:LRN #blobs=0
I1130 22:37:43.609748   125 net.cpp:1141] Copying source layer pool2/3x3_s2 Type:Pooling #blobs=0
I1130 22:37:43.609753   125 net.cpp:1141] Copying source layer pool2/3x3_s2_pool2/3x3_s2_0_split Type:Split #blobs=0
I1130 22:37:43.609758   125 net.cpp:1141] Copying source layer inception_3a/1x1 Type:Convolution #blobs=2
I1130 22:37:43.609954   125 net.cpp:1141] Copying source layer inception_3a/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.609959   125 net.cpp:1141] Copying source layer inception_3a/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.610209   125 net.cpp:1141] Copying source layer inception_3a/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.610215   125 net.cpp:1141] Copying source layer inception_3a/3x3 Type:Convolution #blobs=2
I1130 22:37:43.611543   125 net.cpp:1141] Copying source layer inception_3a/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.611549   125 net.cpp:1141] Copying source layer inception_3a/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.611596   125 net.cpp:1141] Copying source layer inception_3a/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.611601   125 net.cpp:1141] Copying source layer inception_3a/5x5 Type:Convolution #blobs=2
I1130 22:37:43.611765   125 net.cpp:1141] Copying source layer inception_3a/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.611770   125 net.cpp:1141] Copying source layer inception_3a/pool Type:Pooling #blobs=0
I1130 22:37:43.611775   125 net.cpp:1141] Copying source layer inception_3a/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.611860   125 net.cpp:1141] Copying source layer inception_3a/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.611865   125 net.cpp:1141] Copying source layer inception_3a/output Type:Concat #blobs=0
I1130 22:37:43.611868   125 net.cpp:1141] Copying source layer inception_3a/output_inception_3a/output_0_split Type:Split #blobs=0
I1130 22:37:43.611873   125 net.cpp:1141] Copying source layer inception_3b/1x1 Type:Convolution #blobs=2
I1130 22:37:43.612316   125 net.cpp:1141] Copying source layer inception_3b/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.612323   125 net.cpp:1141] Copying source layer inception_3b/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.612747   125 net.cpp:1141] Copying source layer inception_3b/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.612753   125 net.cpp:1141] Copying source layer inception_3b/3x3 Type:Convolution #blobs=2
I1130 22:37:43.615370   125 net.cpp:1141] Copying source layer inception_3b/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.615376   125 net.cpp:1141] Copying source layer inception_3b/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.615486   125 net.cpp:1141] Copying source layer inception_3b/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.615491   125 net.cpp:1141] Copying source layer inception_3b/5x5 Type:Convolution #blobs=2
I1130 22:37:43.616458   125 net.cpp:1141] Copying source layer inception_3b/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.616466   125 net.cpp:1141] Copying source layer inception_3b/pool Type:Pooling #blobs=0
I1130 22:37:43.616472   125 net.cpp:1141] Copying source layer inception_3b/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.616685   125 net.cpp:1141] Copying source layer inception_3b/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.616690   125 net.cpp:1141] Copying source layer inception_3b/output Type:Concat #blobs=0
I1130 22:37:43.616695   125 net.cpp:1141] Copying source layer pool3/3x3_s2 Type:Pooling #blobs=0
I1130 22:37:43.616700   125 net.cpp:1141] Copying source layer pool3/3x3_s2_pool3/3x3_s2_0_split Type:Split #blobs=0
I1130 22:37:43.616705   125 net.cpp:1141] Copying source layer inception_4a/1x1 Type:Convolution #blobs=2
I1130 22:37:43.617843   125 net.cpp:1141] Copying source layer inception_4a/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.617851   125 net.cpp:1141] Copying source layer inception_4a/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.618423   125 net.cpp:1141] Copying source layer inception_4a/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.618429   125 net.cpp:1141] Copying source layer inception_4a/3x3 Type:Convolution #blobs=2
I1130 22:37:43.620615   125 net.cpp:1141] Copying source layer inception_4a/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.620622   125 net.cpp:1141] Copying source layer inception_4a/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.620726   125 net.cpp:1141] Copying source layer inception_4a/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.620748   125 net.cpp:1141] Copying source layer inception_4a/5x5 Type:Convolution #blobs=2
I1130 22:37:43.621009   125 net.cpp:1141] Copying source layer inception_4a/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.621016   125 net.cpp:1141] Copying source layer inception_4a/pool Type:Pooling #blobs=0
I1130 22:37:43.621021   125 net.cpp:1141] Copying source layer inception_4a/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.621413   125 net.cpp:1141] Copying source layer inception_4a/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.621419   125 net.cpp:1141] Copying source layer inception_4a/output Type:Concat #blobs=0
I1130 22:37:43.621424   125 net.cpp:1141] Copying source layer inception_4a/output_inception_4a/output_0_split Type:Split #blobs=0
I1130 22:37:43.621429   125 net.cpp:1133] Ignoring source layer loss1/ave_pool
I1130 22:37:43.621434   125 net.cpp:1133] Ignoring source layer loss1/conv
I1130 22:37:43.621438   125 net.cpp:1133] Ignoring source layer loss1/relu_conv
I1130 22:37:43.621443   125 net.cpp:1133] Ignoring source layer loss1/fc
I1130 22:37:43.621448   125 net.cpp:1133] Ignoring source layer loss1/relu_fc
I1130 22:37:43.621453   125 net.cpp:1133] Ignoring source layer loss1/drop_fc
I1130 22:37:43.621457   125 net.cpp:1133] Ignoring source layer loss1/classifier
I1130 22:37:43.621462   125 net.cpp:1133] Ignoring source layer loss1/loss
I1130 22:37:43.621466   125 net.cpp:1141] Copying source layer inception_4b/1x1 Type:Convolution #blobs=2
I1130 22:37:43.622463   125 net.cpp:1141] Copying source layer inception_4b/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.622469   125 net.cpp:1141] Copying source layer inception_4b/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.623181   125 net.cpp:1141] Copying source layer inception_4b/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.623188   125 net.cpp:1141] Copying source layer inception_4b/3x3 Type:Convolution #blobs=2
I1130 22:37:43.625911   125 net.cpp:1141] Copying source layer inception_4b/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.625918   125 net.cpp:1141] Copying source layer inception_4b/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.626082   125 net.cpp:1141] Copying source layer inception_4b/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.626087   125 net.cpp:1141] Copying source layer inception_4b/5x5 Type:Convolution #blobs=2
I1130 22:37:43.626574   125 net.cpp:1141] Copying source layer inception_4b/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.626581   125 net.cpp:1141] Copying source layer inception_4b/pool Type:Pooling #blobs=0
I1130 22:37:43.626586   125 net.cpp:1141] Copying source layer inception_4b/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.627007   125 net.cpp:1141] Copying source layer inception_4b/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.627014   125 net.cpp:1141] Copying source layer inception_4b/output Type:Concat #blobs=0
I1130 22:37:43.627019   125 net.cpp:1141] Copying source layer inception_4b/output_inception_4b/output_0_split Type:Split #blobs=0
I1130 22:37:43.627024   125 net.cpp:1141] Copying source layer inception_4c/1x1 Type:Convolution #blobs=2
I1130 22:37:43.627828   125 net.cpp:1141] Copying source layer inception_4c/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.627835   125 net.cpp:1141] Copying source layer inception_4c/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.628659   125 net.cpp:1141] Copying source layer inception_4c/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.628665   125 net.cpp:1141] Copying source layer inception_4c/3x3 Type:Convolution #blobs=2
I1130 22:37:43.632184   125 net.cpp:1141] Copying source layer inception_4c/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.632190   125 net.cpp:1141] Copying source layer inception_4c/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.632354   125 net.cpp:1141] Copying source layer inception_4c/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.632359   125 net.cpp:1141] Copying source layer inception_4c/5x5 Type:Convolution #blobs=2
I1130 22:37:43.632838   125 net.cpp:1141] Copying source layer inception_4c/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.632860   125 net.cpp:1141] Copying source layer inception_4c/pool Type:Pooling #blobs=0
I1130 22:37:43.632865   125 net.cpp:1141] Copying source layer inception_4c/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.633285   125 net.cpp:1141] Copying source layer inception_4c/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.633291   125 net.cpp:1141] Copying source layer inception_4c/output Type:Concat #blobs=0
I1130 22:37:43.633296   125 net.cpp:1141] Copying source layer inception_4c/output_inception_4c/output_0_split Type:Split #blobs=0
I1130 22:37:43.633301   125 net.cpp:1141] Copying source layer inception_4d/1x1 Type:Convolution #blobs=2
I1130 22:37:43.634004   125 net.cpp:1141] Copying source layer inception_4d/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.634011   125 net.cpp:1141] Copying source layer inception_4d/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.634908   125 net.cpp:1141] Copying source layer inception_4d/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.634914   125 net.cpp:1141] Copying source layer inception_4d/3x3 Type:Convolution #blobs=2
I1130 22:37:43.639364   125 net.cpp:1141] Copying source layer inception_4d/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.639374   125 net.cpp:1141] Copying source layer inception_4d/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.639591   125 net.cpp:1141] Copying source layer inception_4d/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.639596   125 net.cpp:1141] Copying source layer inception_4d/5x5 Type:Convolution #blobs=2
I1130 22:37:43.640271   125 net.cpp:1141] Copying source layer inception_4d/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.640278   125 net.cpp:1141] Copying source layer inception_4d/pool Type:Pooling #blobs=0
I1130 22:37:43.640285   125 net.cpp:1141] Copying source layer inception_4d/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.640708   125 net.cpp:1141] Copying source layer inception_4d/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.640715   125 net.cpp:1141] Copying source layer inception_4d/output Type:Concat #blobs=0
I1130 22:37:43.640720   125 net.cpp:1141] Copying source layer inception_4d/output_inception_4d/output_0_split Type:Split #blobs=0
I1130 22:37:43.640727   125 net.cpp:1133] Ignoring source layer loss2/ave_pool
I1130 22:37:43.640730   125 net.cpp:1133] Ignoring source layer loss2/conv
I1130 22:37:43.640735   125 net.cpp:1133] Ignoring source layer loss2/relu_conv
I1130 22:37:43.640739   125 net.cpp:1133] Ignoring source layer loss2/fc
I1130 22:37:43.640744   125 net.cpp:1133] Ignoring source layer loss2/relu_fc
I1130 22:37:43.640750   125 net.cpp:1133] Ignoring source layer loss2/drop_fc
I1130 22:37:43.640755   125 net.cpp:1133] Ignoring source layer loss2/classifier
I1130 22:37:43.640759   125 net.cpp:1133] Ignoring source layer loss2/loss
I1130 22:37:43.640764   125 net.cpp:1141] Copying source layer inception_4e/1x1 Type:Convolution #blobs=2
I1130 22:37:43.642380   125 net.cpp:1141] Copying source layer inception_4e/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.642387   125 net.cpp:1141] Copying source layer inception_4e/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.643414   125 net.cpp:1141] Copying source layer inception_4e/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.643420   125 net.cpp:1141] Copying source layer inception_4e/3x3 Type:Convolution #blobs=2
I1130 22:37:43.648897   125 net.cpp:1141] Copying source layer inception_4e/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.648910   125 net.cpp:1141] Copying source layer inception_4e/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.649132   125 net.cpp:1141] Copying source layer inception_4e/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.649139   125 net.cpp:1141] Copying source layer inception_4e/5x5 Type:Convolution #blobs=2
I1130 22:37:43.650365   125 net.cpp:1141] Copying source layer inception_4e/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.650372   125 net.cpp:1141] Copying source layer inception_4e/pool Type:Pooling #blobs=0
I1130 22:37:43.650377   125 net.cpp:1141] Copying source layer inception_4e/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.651222   125 net.cpp:1141] Copying source layer inception_4e/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.651229   125 net.cpp:1141] Copying source layer inception_4e/output Type:Concat #blobs=0
I1130 22:37:43.651233   125 net.cpp:1133] Ignoring source layer pool4/3x3_s2
I1130 22:37:43.651238   125 net.cpp:1133] Ignoring source layer pool4/3x3_s2_pool4/3x3_s2_0_split
I1130 22:37:43.651244   125 net.cpp:1141] Copying source layer inception_5a/1x1 Type:Convolution #blobs=2
I1130 22:37:43.653803   125 net.cpp:1141] Copying source layer inception_5a/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.653811   125 net.cpp:1141] Copying source layer inception_5a/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.655402   125 net.cpp:1141] Copying source layer inception_5a/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.655409   125 net.cpp:1141] Copying source layer inception_5a/3x3 Type:Convolution #blobs=2
I1130 22:37:43.660914   125 net.cpp:1141] Copying source layer inception_5a/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.660923   125 net.cpp:1141] Copying source layer inception_5a/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.661272   125 net.cpp:1141] Copying source layer inception_5a/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.661278   125 net.cpp:1141] Copying source layer inception_5a/5x5 Type:Convolution #blobs=2
I1130 22:37:43.662514   125 net.cpp:1141] Copying source layer inception_5a/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.662521   125 net.cpp:1141] Copying source layer inception_5a/pool Type:Pooling #blobs=0
I1130 22:37:43.662526   125 net.cpp:1141] Copying source layer inception_5a/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.663806   125 net.cpp:1141] Copying source layer inception_5a/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.663813   125 net.cpp:1141] Copying source layer inception_5a/output Type:Concat #blobs=0
I1130 22:37:43.663820   125 net.cpp:1141] Copying source layer inception_5a/output_inception_5a/output_0_split Type:Split #blobs=0
I1130 22:37:43.663823   125 net.cpp:1141] Copying source layer inception_5b/1x1 Type:Convolution #blobs=2
I1130 22:37:43.667613   125 net.cpp:1141] Copying source layer inception_5b/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.667621   125 net.cpp:1141] Copying source layer inception_5b/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.669569   125 net.cpp:1141] Copying source layer inception_5b/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.669576   125 net.cpp:1141] Copying source layer inception_5b/3x3 Type:Convolution #blobs=2
I1130 22:37:43.677430   125 net.cpp:1141] Copying source layer inception_5b/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.677444   125 net.cpp:1141] Copying source layer inception_5b/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.677954   125 net.cpp:1141] Copying source layer inception_5b/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.677961   125 net.cpp:1141] Copying source layer inception_5b/5x5 Type:Convolution #blobs=2
I1130 22:37:43.679810   125 net.cpp:1141] Copying source layer inception_5b/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.679816   125 net.cpp:1141] Copying source layer inception_5b/pool Type:Pooling #blobs=0
I1130 22:37:43.679822   125 net.cpp:1141] Copying source layer inception_5b/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.681126   125 net.cpp:1141] Copying source layer inception_5b/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.681134   125 net.cpp:1141] Copying source layer inception_5b/output Type:Concat #blobs=0
I1130 22:37:43.681139   125 net.cpp:1133] Ignoring source layer pool5/7x7_s1
I1130 22:37:43.681144   125 net.cpp:1133] Ignoring source layer pool5/drop_7x7_s1
I1130 22:37:43.681149   125 net.cpp:1133] Ignoring source layer loss3/classifier
I1130 22:37:43.681154   125 net.cpp:1133] Ignoring source layer loss3/loss3
I1130 22:37:43.709040   125 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /workspace/jobs/bvlc_googlenet.caffemodel
I1130 22:37:43.788825   125 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I1130 22:37:43.789085   125 net.cpp:1133] Ignoring source layer data
I1130 22:37:43.789093   125 net.cpp:1133] Ignoring source layer label_data_1_split
I1130 22:37:43.789098   125 net.cpp:1141] Copying source layer conv1/7x7_s2 Type:Convolution #blobs=2
I1130 22:37:43.789234   125 net.cpp:1141] Copying source layer conv1/relu_7x7 Type:ReLU #blobs=0
I1130 22:37:43.789239   125 net.cpp:1141] Copying source layer pool1/3x3_s2 Type:Pooling #blobs=0
I1130 22:37:43.789244   125 net.cpp:1141] Copying source layer pool1/norm1 Type:LRN #blobs=0
I1130 22:37:43.789249   125 net.cpp:1141] Copying source layer conv2/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.789310   125 net.cpp:1141] Copying source layer conv2/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.789315   125 net.cpp:1141] Copying source layer conv2/3x3 Type:Convolution #blobs=2
I1130 22:37:43.790661   125 net.cpp:1141] Copying source layer conv2/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.790668   125 net.cpp:1141] Copying source layer conv2/norm2 Type:LRN #blobs=0
I1130 22:37:43.790673   125 net.cpp:1141] Copying source layer pool2/3x3_s2 Type:Pooling #blobs=0
I1130 22:37:43.790676   125 net.cpp:1141] Copying source layer pool2/3x3_s2_pool2/3x3_s2_0_split Type:Split #blobs=0
I1130 22:37:43.790683   125 net.cpp:1141] Copying source layer inception_3a/1x1 Type:Convolution #blobs=2
I1130 22:37:43.790845   125 net.cpp:1141] Copying source layer inception_3a/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.790850   125 net.cpp:1141] Copying source layer inception_3a/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.791101   125 net.cpp:1141] Copying source layer inception_3a/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.791107   125 net.cpp:1141] Copying source layer inception_3a/3x3 Type:Convolution #blobs=2
I1130 22:37:43.792477   125 net.cpp:1141] Copying source layer inception_3a/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.792485   125 net.cpp:1141] Copying source layer inception_3a/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.792533   125 net.cpp:1141] Copying source layer inception_3a/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.792538   125 net.cpp:1141] Copying source layer inception_3a/5x5 Type:Convolution #blobs=2
I1130 22:37:43.792711   125 net.cpp:1141] Copying source layer inception_3a/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.792717   125 net.cpp:1141] Copying source layer inception_3a/pool Type:Pooling #blobs=0
I1130 22:37:43.792721   125 net.cpp:1141] Copying source layer inception_3a/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.792812   125 net.cpp:1141] Copying source layer inception_3a/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.792817   125 net.cpp:1141] Copying source layer inception_3a/output Type:Concat #blobs=0
I1130 22:37:43.792821   125 net.cpp:1141] Copying source layer inception_3a/output_inception_3a/output_0_split Type:Split #blobs=0
I1130 22:37:43.792826   125 net.cpp:1141] Copying source layer inception_3b/1x1 Type:Convolution #blobs=2
I1130 22:37:43.793246   125 net.cpp:1141] Copying source layer inception_3b/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.793251   125 net.cpp:1141] Copying source layer inception_3b/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.793668   125 net.cpp:1141] Copying source layer inception_3b/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.793673   125 net.cpp:1141] Copying source layer inception_3b/3x3 Type:Convolution #blobs=2
I1130 22:37:43.796329   125 net.cpp:1141] Copying source layer inception_3b/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.796335   125 net.cpp:1141] Copying source layer inception_3b/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.796452   125 net.cpp:1141] Copying source layer inception_3b/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.796458   125 net.cpp:1141] Copying source layer inception_3b/5x5 Type:Convolution #blobs=2
I1130 22:37:43.797389   125 net.cpp:1141] Copying source layer inception_3b/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.797420   125 net.cpp:1141] Copying source layer inception_3b/pool Type:Pooling #blobs=0
I1130 22:37:43.797425   125 net.cpp:1141] Copying source layer inception_3b/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.797649   125 net.cpp:1141] Copying source layer inception_3b/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.797657   125 net.cpp:1141] Copying source layer inception_3b/output Type:Concat #blobs=0
I1130 22:37:43.797660   125 net.cpp:1141] Copying source layer pool3/3x3_s2 Type:Pooling #blobs=0
I1130 22:37:43.797665   125 net.cpp:1141] Copying source layer pool3/3x3_s2_pool3/3x3_s2_0_split Type:Split #blobs=0
I1130 22:37:43.797670   125 net.cpp:1141] Copying source layer inception_4a/1x1 Type:Convolution #blobs=2
I1130 22:37:43.798792   125 net.cpp:1141] Copying source layer inception_4a/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.798799   125 net.cpp:1141] Copying source layer inception_4a/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.799371   125 net.cpp:1141] Copying source layer inception_4a/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.799377   125 net.cpp:1141] Copying source layer inception_4a/3x3 Type:Convolution #blobs=2
I1130 22:37:43.801553   125 net.cpp:1141] Copying source layer inception_4a/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.801561   125 net.cpp:1141] Copying source layer inception_4a/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.801671   125 net.cpp:1141] Copying source layer inception_4a/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.801676   125 net.cpp:1141] Copying source layer inception_4a/5x5 Type:Convolution #blobs=2
I1130 22:37:43.801939   125 net.cpp:1141] Copying source layer inception_4a/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.801944   125 net.cpp:1141] Copying source layer inception_4a/pool Type:Pooling #blobs=0
I1130 22:37:43.801949   125 net.cpp:1141] Copying source layer inception_4a/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.802342   125 net.cpp:1141] Copying source layer inception_4a/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.802350   125 net.cpp:1141] Copying source layer inception_4a/output Type:Concat #blobs=0
I1130 22:37:43.802353   125 net.cpp:1141] Copying source layer inception_4a/output_inception_4a/output_0_split Type:Split #blobs=0
I1130 22:37:43.802359   125 net.cpp:1133] Ignoring source layer loss1/ave_pool
I1130 22:37:43.802363   125 net.cpp:1133] Ignoring source layer loss1/conv
I1130 22:37:43.802368   125 net.cpp:1133] Ignoring source layer loss1/relu_conv
I1130 22:37:43.802372   125 net.cpp:1133] Ignoring source layer loss1/fc
I1130 22:37:43.802376   125 net.cpp:1133] Ignoring source layer loss1/relu_fc
I1130 22:37:43.802381   125 net.cpp:1133] Ignoring source layer loss1/drop_fc
I1130 22:37:43.802388   125 net.cpp:1133] Ignoring source layer loss1/classifier
I1130 22:37:43.802392   125 net.cpp:1133] Ignoring source layer loss1/loss
I1130 22:37:43.802397   125 net.cpp:1141] Copying source layer inception_4b/1x1 Type:Convolution #blobs=2
I1130 22:37:43.803392   125 net.cpp:1141] Copying source layer inception_4b/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.803398   125 net.cpp:1141] Copying source layer inception_4b/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.804139   125 net.cpp:1141] Copying source layer inception_4b/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.804147   125 net.cpp:1141] Copying source layer inception_4b/3x3 Type:Convolution #blobs=2
I1130 22:37:43.806820   125 net.cpp:1141] Copying source layer inception_4b/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.806826   125 net.cpp:1141] Copying source layer inception_4b/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.807000   125 net.cpp:1141] Copying source layer inception_4b/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.807005   125 net.cpp:1141] Copying source layer inception_4b/5x5 Type:Convolution #blobs=2
I1130 22:37:43.807492   125 net.cpp:1141] Copying source layer inception_4b/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.807499   125 net.cpp:1141] Copying source layer inception_4b/pool Type:Pooling #blobs=0
I1130 22:37:43.807504   125 net.cpp:1141] Copying source layer inception_4b/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.807945   125 net.cpp:1141] Copying source layer inception_4b/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.807952   125 net.cpp:1141] Copying source layer inception_4b/output Type:Concat #blobs=0
I1130 22:37:43.807957   125 net.cpp:1141] Copying source layer inception_4b/output_inception_4b/output_0_split Type:Split #blobs=0
I1130 22:37:43.807962   125 net.cpp:1141] Copying source layer inception_4c/1x1 Type:Convolution #blobs=2
I1130 22:37:43.808763   125 net.cpp:1141] Copying source layer inception_4c/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.808769   125 net.cpp:1141] Copying source layer inception_4c/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.809571   125 net.cpp:1141] Copying source layer inception_4c/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.809577   125 net.cpp:1141] Copying source layer inception_4c/3x3 Type:Convolution #blobs=2
I1130 22:37:43.813195   125 net.cpp:1141] Copying source layer inception_4c/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.813206   125 net.cpp:1141] Copying source layer inception_4c/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.813375   125 net.cpp:1141] Copying source layer inception_4c/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.813381   125 net.cpp:1141] Copying source layer inception_4c/5x5 Type:Convolution #blobs=2
I1130 22:37:43.813872   125 net.cpp:1141] Copying source layer inception_4c/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.813879   125 net.cpp:1141] Copying source layer inception_4c/pool Type:Pooling #blobs=0
I1130 22:37:43.813884   125 net.cpp:1141] Copying source layer inception_4c/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.814309   125 net.cpp:1141] Copying source layer inception_4c/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.814316   125 net.cpp:1141] Copying source layer inception_4c/output Type:Concat #blobs=0
I1130 22:37:43.814319   125 net.cpp:1141] Copying source layer inception_4c/output_inception_4c/output_0_split Type:Split #blobs=0
I1130 22:37:43.814324   125 net.cpp:1141] Copying source layer inception_4d/1x1 Type:Convolution #blobs=2
I1130 22:37:43.815033   125 net.cpp:1141] Copying source layer inception_4d/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.815039   125 net.cpp:1141] Copying source layer inception_4d/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.815958   125 net.cpp:1141] Copying source layer inception_4d/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.815964   125 net.cpp:1141] Copying source layer inception_4d/3x3 Type:Convolution #blobs=2
I1130 22:37:43.820386   125 net.cpp:1141] Copying source layer inception_4d/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.820394   125 net.cpp:1141] Copying source layer inception_4d/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.820616   125 net.cpp:1141] Copying source layer inception_4d/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.820621   125 net.cpp:1141] Copying source layer inception_4d/5x5 Type:Convolution #blobs=2
I1130 22:37:43.821259   125 net.cpp:1141] Copying source layer inception_4d/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.821265   125 net.cpp:1141] Copying source layer inception_4d/pool Type:Pooling #blobs=0
I1130 22:37:43.821269   125 net.cpp:1141] Copying source layer inception_4d/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.821688   125 net.cpp:1141] Copying source layer inception_4d/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.821694   125 net.cpp:1141] Copying source layer inception_4d/output Type:Concat #blobs=0
I1130 22:37:43.821699   125 net.cpp:1141] Copying source layer inception_4d/output_inception_4d/output_0_split Type:Split #blobs=0
I1130 22:37:43.821704   125 net.cpp:1133] Ignoring source layer loss2/ave_pool
I1130 22:37:43.821709   125 net.cpp:1133] Ignoring source layer loss2/conv
I1130 22:37:43.821713   125 net.cpp:1133] Ignoring source layer loss2/relu_conv
I1130 22:37:43.821717   125 net.cpp:1133] Ignoring source layer loss2/fc
I1130 22:37:43.821722   125 net.cpp:1133] Ignoring source layer loss2/relu_fc
I1130 22:37:43.821744   125 net.cpp:1133] Ignoring source layer loss2/drop_fc
I1130 22:37:43.821750   125 net.cpp:1133] Ignoring source layer loss2/classifier
I1130 22:37:43.821754   125 net.cpp:1133] Ignoring source layer loss2/loss
I1130 22:37:43.821759   125 net.cpp:1141] Copying source layer inception_4e/1x1 Type:Convolution #blobs=2
I1130 22:37:43.823372   125 net.cpp:1141] Copying source layer inception_4e/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.823379   125 net.cpp:1141] Copying source layer inception_4e/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.824445   125 net.cpp:1141] Copying source layer inception_4e/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.824451   125 net.cpp:1141] Copying source layer inception_4e/3x3 Type:Convolution #blobs=2
I1130 22:37:43.829931   125 net.cpp:1141] Copying source layer inception_4e/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.829938   125 net.cpp:1141] Copying source layer inception_4e/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.830160   125 net.cpp:1141] Copying source layer inception_4e/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.830166   125 net.cpp:1141] Copying source layer inception_4e/5x5 Type:Convolution #blobs=2
I1130 22:37:43.831400   125 net.cpp:1141] Copying source layer inception_4e/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.831406   125 net.cpp:1141] Copying source layer inception_4e/pool Type:Pooling #blobs=0
I1130 22:37:43.831413   125 net.cpp:1141] Copying source layer inception_4e/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.832284   125 net.cpp:1141] Copying source layer inception_4e/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.832291   125 net.cpp:1141] Copying source layer inception_4e/output Type:Concat #blobs=0
I1130 22:37:43.832296   125 net.cpp:1133] Ignoring source layer pool4/3x3_s2
I1130 22:37:43.832301   125 net.cpp:1133] Ignoring source layer pool4/3x3_s2_pool4/3x3_s2_0_split
I1130 22:37:43.832306   125 net.cpp:1141] Copying source layer inception_5a/1x1 Type:Convolution #blobs=2
I1130 22:37:43.834826   125 net.cpp:1141] Copying source layer inception_5a/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.834833   125 net.cpp:1141] Copying source layer inception_5a/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.836467   125 net.cpp:1141] Copying source layer inception_5a/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.836473   125 net.cpp:1141] Copying source layer inception_5a/3x3 Type:Convolution #blobs=2
I1130 22:37:43.841912   125 net.cpp:1141] Copying source layer inception_5a/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.841920   125 net.cpp:1141] Copying source layer inception_5a/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.842276   125 net.cpp:1141] Copying source layer inception_5a/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.842283   125 net.cpp:1141] Copying source layer inception_5a/5x5 Type:Convolution #blobs=2
I1130 22:37:43.843515   125 net.cpp:1141] Copying source layer inception_5a/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.843521   125 net.cpp:1141] Copying source layer inception_5a/pool Type:Pooling #blobs=0
I1130 22:37:43.843528   125 net.cpp:1141] Copying source layer inception_5a/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.844858   125 net.cpp:1141] Copying source layer inception_5a/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.844866   125 net.cpp:1141] Copying source layer inception_5a/output Type:Concat #blobs=0
I1130 22:37:43.844871   125 net.cpp:1141] Copying source layer inception_5a/output_inception_5a/output_0_split Type:Split #blobs=0
I1130 22:37:43.844877   125 net.cpp:1141] Copying source layer inception_5b/1x1 Type:Convolution #blobs=2
I1130 22:37:43.848721   125 net.cpp:1141] Copying source layer inception_5b/relu_1x1 Type:ReLU #blobs=0
I1130 22:37:43.848728   125 net.cpp:1141] Copying source layer inception_5b/3x3_reduce Type:Convolution #blobs=2
I1130 22:37:43.850653   125 net.cpp:1141] Copying source layer inception_5b/relu_3x3_reduce Type:ReLU #blobs=0
I1130 22:37:43.850661   125 net.cpp:1141] Copying source layer inception_5b/3x3 Type:Convolution #blobs=2
I1130 22:37:43.858547   125 net.cpp:1141] Copying source layer inception_5b/relu_3x3 Type:ReLU #blobs=0
I1130 22:37:43.858556   125 net.cpp:1141] Copying source layer inception_5b/5x5_reduce Type:Convolution #blobs=2
I1130 22:37:43.859058   125 net.cpp:1141] Copying source layer inception_5b/relu_5x5_reduce Type:ReLU #blobs=0
I1130 22:37:43.859066   125 net.cpp:1141] Copying source layer inception_5b/5x5 Type:Convolution #blobs=2
I1130 22:37:43.860973   125 net.cpp:1141] Copying source layer inception_5b/relu_5x5 Type:ReLU #blobs=0
I1130 22:37:43.860983   125 net.cpp:1141] Copying source layer inception_5b/pool Type:Pooling #blobs=0
I1130 22:37:43.860990   125 net.cpp:1141] Copying source layer inception_5b/pool_proj Type:Convolution #blobs=2
I1130 22:37:43.862277   125 net.cpp:1141] Copying source layer inception_5b/relu_pool_proj Type:ReLU #blobs=0
I1130 22:37:43.862282   125 net.cpp:1141] Copying source layer inception_5b/output Type:Concat #blobs=0
I1130 22:37:43.862287   125 net.cpp:1133] Ignoring source layer pool5/7x7_s1
I1130 22:37:43.862291   125 net.cpp:1133] Ignoring source layer pool5/drop_7x7_s1
I1130 22:37:43.862296   125 net.cpp:1133] Ignoring source layer loss3/classifier
I1130 22:37:43.862301   125 net.cpp:1133] Ignoring source layer loss3/loss3
I1130 22:37:43.864970   125 caffe.cpp:257] Starting Optimization
I1130 22:37:43.865006   125 solver.cpp:418] [0.0] Solving  Learning Rate Policy: exp
I1130 22:37:43.865090   125 net.cpp:1422] [0.0] Reserving 23918336 bytes of shared learnable space for type FLOAT
I1130 22:37:43.875861   125 solver.cpp:257] Initial Test started...
I1130 22:37:43.875913   125 solver.cpp:501] Iteration 0, Testing net (#0)
I1130 22:37:43.875923   125 net.cpp:1068] Ignoring source layer train_data
I1130 22:37:43.875928   125 net.cpp:1068] Ignoring source layer train_label
I1130 22:37:43.875932   125 net.cpp:1068] Ignoring source layer train_transform
I1130 22:37:43.877346   156 common.cpp:533] NVML initialized, thread 156
I1130 22:37:43.906462   156 common.cpp:555] {0.0} NVML succeeded to set CPU affinity
I1130 22:37:43.959141   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 5.01033 (* 2 = 10.0207 loss)
I1130 22:37:43.959177   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 131.104 (* 1 = 131.104 loss)
I1130 22:37:43.959187   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:37:43.959194   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:37:43.959201   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:37:43.959236   125 solver.cpp:262] Initial Test completed in 0.0833106s
I1130 22:37:43.959830   144 internal_thread.cpp:42] Restarting 4 internal thread(s) on device 0
I1130 22:37:43.960302   147 internal_thread.cpp:42] Restarting 4 internal thread(s) on device 0
I1130 22:37:43.968055   147 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:43.968065   144 internal_thread.cpp:18] {0} Starting 1 internal thread(s) on device 0
I1130 22:37:43.969445   147 data_reader.cpp:59] Data Reader threads: 3, out queues: 12, depth: 10
I1130 22:37:43.969453   165 common.cpp:555] {0.0} NVML succeeded to set CPU affinity
I1130 22:37:43.969462   144 data_reader.cpp:59] Data Reader threads: 3, out queues: 12, depth: 10
I1130 22:37:43.970091   147 internal_thread.cpp:18] {0} Starting 3 internal thread(s) on device 0
I1130 22:37:43.970100   166 common.cpp:555] {0.0} NVML succeeded to set CPU affinity
I1130 22:37:43.970122   144 internal_thread.cpp:18] {0} Starting 3 internal thread(s) on device 0
I1130 22:37:43.972370   167 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/train_db/labels
I1130 22:37:43.973448   147 data_layer.cpp:200] [n0.d0.r0] Output data size: 10, 1, 57, 16
I1130 22:37:43.973515   147 data_layer.cpp:105] [n0.d0.r0] Parser threads: 3 (auto)
I1130 22:37:43.973528   147 data_layer.cpp:107] [n0.d0.r0] Transformer threads: 4 (auto)
I1130 22:37:43.974319   168 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/train_db/labels
I1130 22:37:43.975244   169 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/train_db/features
I1130 22:37:43.975929   170 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/train_db/labels
I1130 22:37:43.976785   171 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/train_db/features
I1130 22:37:43.977411   172 db_lmdb.cpp:36] Opened lmdb /workspace/jobs/20181130-223152-9c61/train_db/features
I1130 22:37:43.985366   144 data_layer.cpp:200] [n0.d0.r0] Output data size: 10, 3, 640, 640
I1130 22:37:43.985414   144 data_layer.cpp:105] [n0.d0.r0] Parser threads: 3 (auto)
I1130 22:37:43.985421   144 data_layer.cpp:107] [n0.d0.r0] Transformer threads: 4 (auto)
I1130 22:37:44.769003   125 solver.cpp:341]     [0.0] Iteration 0 (0.809669 s), loss = 156.34
I1130 22:37:44.769106   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 2.54556 (* 2 = 5.09111 loss)
I1130 22:37:44.769136   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 151.248 (* 1 = 151.248 loss)
I1130 22:37:44.769167   125 sgd_solver.cpp:180] [0.0] Iteration 0, lr = 2.5e-05, m = 0.9, lrm = 0.00025, wd = 2.5e-07, gs = 1
I1130 22:37:44.954440   125 solver.cpp:341]     [0.0] Iteration 1 (0.185441 s), loss = 99.3885
I1130 22:37:44.954497   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 2.51329 (* 2 = 5.02658 loss)
I1130 22:37:44.954509   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 94.3619 (* 1 = 94.3619 loss)
I1130 22:37:45.067066   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'conv1/7x7_s2' with space 0.61M 3/1 1 1 0 	(avail 6.24G, req 0.61M)	t: 0 0 2.57
I1130 22:37:45.338394   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'conv2/3x3_reduce' with space 0.61M 64/1 1 1 0 	(avail 6.24G, req 0.61M)	t: 0 0.24 0.78
I1130 22:37:45.856832   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'conv2/3x3' with space 0.59G 64/1 6 4 5 	(avail 5.65G, req 0.59G)	t: 0 2.21 4.15
I1130 22:37:46.124840   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3a/1x1' with space 0.59G 192/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.19 0.42
I1130 22:37:46.412860   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3a/3x3_reduce' with space 0.59G 192/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.23 0.39
I1130 22:37:46.704861   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3a/3x3' with space 0.59G 96/1 6 4 5 	(avail 5.65G, req 0.59G)	t: 0 0.58 0.68
I1130 22:37:46.932852   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3a/5x5_reduce' with space 0.59G 192/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.13 0.23
I1130 22:37:47.148856   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3a/5x5' with space 0.59G 16/1 1 5 0 	(avail 5.65G, req 0.59G)	t: 0 0.35 0.24
I1130 22:37:47.396839   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3a/pool_proj' with space 0.59G 192/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.15 0.24
I1130 22:37:47.752832   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3b/1x1' with space 0.59G 256/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.35 0.5
I1130 22:37:48.108896   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3b/3x3_reduce' with space 0.59G 256/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.36 0.53
I1130 22:37:48.492833   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3b/3x3' with space 0.59G 128/1 6 4 5 	(avail 5.65G, req 0.59G)	t: 0 1.09 1.1
I1130 22:37:48.744873   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3b/5x5_reduce' with space 0.59G 256/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.16 0.31
I1130 22:37:48.992841   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3b/5x5' with space 0.59G 32/1 5 5 5 	(avail 5.65G, req 0.59G)	t: 0 1.02 0.76
I1130 22:37:49.276834   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_3b/pool_proj' with space 0.59G 256/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.24 0.65
I1130 22:37:49.556840   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4a/1x1' with space 0.59G 480/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.27 0.47
I1130 22:37:49.796842   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4a/3x3_reduce' with space 0.59G 480/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.17 0.26
I1130 22:37:50.033429   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4a/3x3' with space 0.59G 96/1 6 4 5 	(avail 5.65G, req 0.59G)	t: 0 0.29 0.29
I1130 22:37:50.240850   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4a/5x5_reduce' with space 0.59G 480/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.1 0.19
I1130 22:37:50.445065   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4a/5x5' with space 0.59G 16/1 1 5 0 	(avail 5.65G, req 0.59G)	t: 0 0.15 0.15
I1130 22:37:50.672835   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4a/pool_proj' with space 0.59G 480/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.14 0.27
I1130 22:37:50.988852   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4b/1x1' with space 0.59G 512/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.25 0.47
I1130 22:37:51.240844   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4b/3x3_reduce' with space 0.59G 512/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.18 0.26
I1130 22:37:51.492832   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4b/3x3' with space 0.59G 112/1 6 4 5 	(avail 5.65G, req 0.59G)	t: 0 0.39 0.3
I1130 22:37:51.704836   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4b/5x5_reduce' with space 0.59G 512/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.11 0.19
I1130 22:37:51.912834   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4b/5x5' with space 0.59G 24/1 1 5 0 	(avail 5.65G, req 0.59G)	t: 0 0.19 0.19
I1130 22:37:52.141410   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4b/pool_proj' with space 0.59G 512/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.14 0.27
I1130 22:37:52.396869   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4c/1x1' with space 0.59G 512/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.2 0.27
I1130 22:37:52.656827   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4c/3x3_reduce' with space 0.59G 512/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.23 0.29
I1130 22:37:52.908820   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4c/3x3' with space 0.59G 128/1 6 4 5 	(avail 5.65G, req 0.59G)	t: 0 0.47 0.35
I1130 22:37:53.120817   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4c/5x5_reduce' with space 0.59G 512/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.14 0.23
I1130 22:37:53.328830   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4c/5x5' with space 0.59G 24/1 1 5 0 	(avail 5.65G, req 0.59G)	t: 0 0.22 0.22
I1130 22:37:53.560833   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4c/pool_proj' with space 0.59G 512/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.17 0.31
I1130 22:37:53.812846   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4d/1x1' with space 0.59G 512/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.22 0.3
I1130 22:37:54.096825   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4d/3x3_reduce' with space 0.59G 512/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.25 0.5
I1130 22:37:54.368863   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4d/3x3' with space 0.59G 144/1 6 4 5 	(avail 5.65G, req 0.59G)	t: 0 0.63 0.62
I1130 22:37:54.588830   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4d/5x5_reduce' with space 0.59G 512/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.11 0.19
I1130 22:37:54.796847   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4d/5x5' with space 0.59G 32/1 7 5 5 	(avail 5.65G, req 0.59G)	t: 0 0.19 0.2
I1130 22:37:55.028828   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4d/pool_proj' with space 0.59G 512/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.14 0.27
I1130 22:37:55.344833   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4e/1x1' with space 0.59G 528/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.42 0.54
I1130 22:37:55.620822   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4e/3x3_reduce' with space 0.59G 528/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.3 0.51
I1130 22:37:55.904819   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4e/3x3' with space 0.59G 160/1 7 4 5 	(avail 5.65G, req 0.59G)	t: 0 0.71 0.64
I1130 22:37:56.124821   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4e/5x5_reduce' with space 0.59G 528/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.15 0.21
I1130 22:37:56.341521   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4e/5x5' with space 0.59G 32/1 7 5 5 	(avail 5.65G, req 0.59G)	t: 0 0.37 0.28
I1130 22:37:56.600864   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_4e/pool_proj' with space 0.59G 528/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.25 0.39
I1130 22:37:56.820854   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5a/1x1' with space 0.59G 832/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.55 0.75
I1130 22:37:57.136819   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5a/3x3_reduce' with space 0.59G 832/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.36 0.68
I1130 22:37:57.416842   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5a/3x3' with space 0.59G 160/1 7 4 5 	(avail 5.65G, req 0.59G)	t: 0 0.66 0.61
I1130 22:37:57.676895   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5a/5x5_reduce' with space 0.59G 832/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.15 0.26
I1130 22:37:57.892839   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5a/5x5' with space 0.59G 32/1 7 5 5 	(avail 5.65G, req 0.59G)	t: 0 0.34 0.24
I1130 22:37:58.184836   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5a/pool_proj' with space 0.59G 832/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.32 0.42
I1130 22:37:58.413594   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5b/1x1' with space 0.59G 832/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.75 1.06
I1130 22:37:58.748849   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5b/3x3_reduce' with space 0.59G 832/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.43 0.71
I1130 22:37:59.060830   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5b/3x3' with space 0.59G 192/1 7 5 5 	(avail 5.65G, req 0.59G)	t: 0 0.91 0.72
I1130 22:37:59.348850   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5b/5x5_reduce' with space 0.59G 832/1 1 1 3 	(avail 5.65G, req 0.59G)	t: 0 0.19 0.51
I1130 22:37:59.564832   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5b/5x5' with space 0.59G 48/1 7 5 5 	(avail 5.65G, req 0.59G)	t: 0 0.36 0.27
I1130 22:37:59.856869   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'inception_5b/pool_proj' with space 0.59G 832/1 1 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.31 0.42
I1130 22:38:00.072818   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'cvg/classifier' with space 0.59G 1024/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.16 0.3
I1130 22:38:00.288872   125 cudnn_conv_layer.cpp:849] [n0.d0.r0] Conv Algos (F,BD,BF): 'bbox/regressor' with space 0.59G 1024/1 0 1 0 	(avail 5.65G, req 0.59G)	t: 0 0.13 0.28
I1130 22:38:00.369807   125 solver.cpp:341]     [0.0] Iteration 2 (15.4154 s), loss = 82.4189
I1130 22:38:00.369851   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 4.08554 (* 2 = 8.17107 loss)
I1130 22:38:00.369863   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 74.2478 (* 1 = 74.2478 loss)
I1130 22:38:05.514951   125 solver.cpp:333]     [0.0] Iteration 44 (8.16301 iter/s, 5.14516s/42 iter), loss = 47.9196
I1130 22:38:05.515005   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 7.30947 (* 2 = 14.6189 loss)
I1130 22:38:05.515015   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 33.3007 (* 1 = 33.3007 loss)
I1130 22:38:05.515027   125 sgd_solver.cpp:180] [0.0] Iteration 44, lr = 2.49069e-05, m = 0.9, lrm = 0.000249069, wd = 2.5e-07, gs = 1
I1130 22:38:10.865226   125 solver.cpp:333]     [0.0] Iteration 88 (8.22384 iter/s, 5.3503s/44 iter), loss = 29.1423
I1130 22:38:10.865715   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 3.17227 (* 2 = 6.34454 loss)
I1130 22:38:10.865728   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 22.7977 (* 1 = 22.7977 loss)
I1130 22:38:10.865741   125 sgd_solver.cpp:180] [0.0] Iteration 88, lr = 2.48141e-05, m = 0.9, lrm = 0.000248141, wd = 2.5e-07, gs = 1
I1130 22:38:16.220324   125 solver.cpp:333]     [0.0] Iteration 132 (8.21642 iter/s, 5.35513s/44 iter), loss = 28.0713
I1130 22:38:16.220379   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 4.02298 (* 2 = 8.04596 loss)
I1130 22:38:16.220391   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 20.0254 (* 1 = 20.0254 loss)
I1130 22:38:16.220402   125 sgd_solver.cpp:180] [0.0] Iteration 132, lr = 2.47217e-05, m = 0.9, lrm = 0.000247216, wd = 2.5e-07, gs = 1
I1130 22:38:21.576839   125 solver.cpp:333]     [0.0] Iteration 176 (8.21429 iter/s, 5.35652s/44 iter), loss = 18.318
I1130 22:38:21.576894   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.8502 (* 2 = 1.7004 loss)
I1130 22:38:21.576905   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 16.6176 (* 1 = 16.6176 loss)
I1130 22:38:21.576916   125 sgd_solver.cpp:180] [0.0] Iteration 176, lr = 2.46296e-05, m = 0.9, lrm = 0.000246296, wd = 2.5e-07, gs = 1
I1130 22:38:26.926807   125 solver.cpp:333]     [0.0] Iteration 220 (8.22433 iter/s, 5.34998s/44 iter), loss = 34.2216
I1130 22:38:26.926863   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 3.55391 (* 2 = 7.10782 loss)
I1130 22:38:26.926873   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 27.1138 (* 1 = 27.1138 loss)
I1130 22:38:26.926885   125 sgd_solver.cpp:180] [0.0] Iteration 220, lr = 2.45378e-05, m = 0.9, lrm = 0.000245378, wd = 2.5e-07, gs = 1
I1130 22:38:32.287339   125 solver.cpp:333]     [0.0] Iteration 264 (8.20812 iter/s, 5.36055s/44 iter), loss = 20.2136
I1130 22:38:32.287394   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.930148 (* 2 = 1.8603 loss)
I1130 22:38:32.287405   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 18.3534 (* 1 = 18.3534 loss)
I1130 22:38:32.287417   125 sgd_solver.cpp:180] [0.0] Iteration 264, lr = 2.44464e-05, m = 0.9, lrm = 0.000244464, wd = 2.5e-07, gs = 1
I1130 22:38:37.744449   125 solver.cpp:333]     [0.0] Iteration 308 (8.06285 iter/s, 5.45713s/44 iter), loss = 30.3898
I1130 22:38:37.744508   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.41845 (* 2 = 2.83689 loss)
I1130 22:38:37.744518   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 27.5529 (* 1 = 27.5529 loss)
I1130 22:38:37.744530   125 sgd_solver.cpp:180] [0.0] Iteration 308, lr = 2.43553e-05, m = 0.9, lrm = 0.000243553, wd = 2.5e-07, gs = 1
I1130 22:38:40.445415   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:38:40.564667   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:38:43.127022   125 solver.cpp:333]     [0.0] Iteration 352 (8.17452 iter/s, 5.38258s/44 iter), 1/100ep, loss = 53.2293
I1130 22:38:43.127260   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 4.03849 (* 2 = 8.07698 loss)
I1130 22:38:43.127274   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 45.1523 (* 1 = 45.1523 loss)
I1130 22:38:43.127288   125 sgd_solver.cpp:180] [0.0] Iteration 352, lr = 2.42646e-05, m = 0.9, lrm = 0.000242646, wd = 2.5e-07, gs = 1
I1130 22:38:43.859823   125 solver.cpp:501] Iteration 359, Testing net (#0)
I1130 22:39:00.844539   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:39:00.958896   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:39:01.196369   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 1.14998 (* 2 = 2.29997 loss)
I1130 22:39:01.196409   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.4904 (* 1 = 21.4904 loss)
I1130 22:39:01.196419   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:39:01.196425   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:39:01.196431   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:39:01.196465   125 solver.cpp:271] Tests completed in 18.0696s
I1130 22:39:05.933686   125 solver.cpp:333]     [0.0] Iteration 396 (2.43503 iter/s, 18.0696s/44 iter), 1.1/100ep, loss = 18.7379
I1130 22:39:05.933743   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 3.1178 (* 2 = 6.23559 loss)
I1130 22:39:05.933760   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.5023 (* 1 = 12.5023 loss)
I1130 22:39:05.933776   125 sgd_solver.cpp:180] [0.0] Iteration 396, lr = 2.41742e-05, m = 0.9, lrm = 0.000241742, wd = 2.5e-07, gs = 1
I1130 22:39:11.362051   125 solver.cpp:333]     [0.0] Iteration 440 (8.10556 iter/s, 5.42837s/44 iter), 1.2/100ep, loss = 35.1532
I1130 22:39:11.362093   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.39956 (* 2 = 2.79912 loss)
I1130 22:39:11.362104   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 32.3541 (* 1 = 32.3541 loss)
I1130 22:39:11.362115   125 sgd_solver.cpp:180] [0.0] Iteration 440, lr = 2.40842e-05, m = 0.9, lrm = 0.000240842, wd = 2.5e-07, gs = 1
I1130 22:39:16.730376   125 solver.cpp:333]     [0.0] Iteration 484 (8.19619 iter/s, 5.36835s/44 iter), 1.3/100ep, loss = 34.849
I1130 22:39:16.730526   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.07333 (* 2 = 2.14665 loss)
I1130 22:39:16.730540   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 32.7023 (* 1 = 32.7023 loss)
I1130 22:39:16.730552   125 sgd_solver.cpp:180] [0.0] Iteration 484, lr = 2.39944e-05, m = 0.9, lrm = 0.000239944, wd = 2.5e-07, gs = 1
I1130 22:39:22.101527   125 solver.cpp:333]     [0.0] Iteration 528 (8.19189 iter/s, 5.37116s/44 iter), 1.5/100ep, loss = 28.112
I1130 22:39:22.101568   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.67979 (* 2 = 3.35958 loss)
I1130 22:39:22.101579   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 24.7524 (* 1 = 24.7524 loss)
I1130 22:39:22.101591   125 sgd_solver.cpp:180] [0.0] Iteration 528, lr = 2.39051e-05, m = 0.9, lrm = 0.000239051, wd = 2.5e-07, gs = 1
I1130 22:39:27.473925   125 solver.cpp:333]     [0.0] Iteration 572 (8.19 iter/s, 5.3724s/44 iter), 1.6/100ep, loss = 8.57397
I1130 22:39:27.473968   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.31094 (* 2 = 0.621881 loss)
I1130 22:39:27.473979   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.95209 (* 1 = 7.95209 loss)
I1130 22:39:27.473990   125 sgd_solver.cpp:180] [0.0] Iteration 572, lr = 2.3816e-05, m = 0.9, lrm = 0.00023816, wd = 2.5e-07, gs = 1
I1130 22:39:32.841920   125 solver.cpp:333]     [0.0] Iteration 616 (8.1967 iter/s, 5.36801s/44 iter), 1.7/100ep, loss = 26.0619
I1130 22:39:32.841962   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.754011 (* 2 = 1.50802 loss)
I1130 22:39:32.841974   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 24.5538 (* 1 = 24.5538 loss)
I1130 22:39:32.841986   125 sgd_solver.cpp:180] [0.0] Iteration 616, lr = 2.37273e-05, m = 0.9, lrm = 0.000237273, wd = 2.5e-07, gs = 1
I1130 22:39:38.213163   125 solver.cpp:333]     [0.0] Iteration 660 (8.19175 iter/s, 5.37126s/44 iter), 1.8/100ep, loss = 20.3802
I1130 22:39:38.213204   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.48949 (* 2 = 2.97898 loss)
I1130 22:39:38.213215   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.4012 (* 1 = 17.4012 loss)
I1130 22:39:38.213227   125 sgd_solver.cpp:180] [0.0] Iteration 660, lr = 2.36389e-05, m = 0.9, lrm = 0.000236389, wd = 2.5e-07, gs = 1
I1130 22:39:41.876963   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:39:42.002756   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:39:43.586930   125 solver.cpp:333]     [0.0] Iteration 704 (8.18794 iter/s, 5.37376s/44 iter), 2/100ep, loss = 23.1415
I1130 22:39:43.586972   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.52026 (* 2 = 3.04051 loss)
I1130 22:39:43.586983   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 20.101 (* 1 = 20.101 loss)
I1130 22:39:43.586994   125 sgd_solver.cpp:180] [0.0] Iteration 704, lr = 2.35508e-05, m = 0.9, lrm = 0.000235508, wd = 2.5e-07, gs = 1
I1130 22:39:45.175745   125 solver.cpp:501] Iteration 718, Testing net (#0)
I1130 22:40:02.395733   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:40:02.549456   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:40:02.832120   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.985657 (* 2 = 1.97131 loss)
I1130 22:40:02.832164   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.4202 (* 1 = 21.4202 loss)
I1130 22:40:02.832172   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:40:02.832180   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:40:02.832185   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:40:02.832218   125 solver.cpp:271] Tests completed in 19.2454s
I1130 22:40:06.642771   125 solver.cpp:333]     [0.0] Iteration 748 (2.28626 iter/s, 19.2454s/44 iter), 2.1/100ep, loss = 46.5947
I1130 22:40:06.642812   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.99452 (* 2 = 3.98905 loss)
I1130 22:40:06.642822   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 42.6056 (* 1 = 42.6056 loss)
I1130 22:40:06.642835   125 sgd_solver.cpp:180] [0.0] Iteration 748, lr = 2.34631e-05, m = 0.9, lrm = 0.000234631, wd = 2.5e-07, gs = 1
I1130 22:40:12.022882   125 solver.cpp:333]     [0.0] Iteration 792 (8.17826 iter/s, 5.38012s/44 iter), 2.2/100ep, loss = 23.7263
I1130 22:40:12.022927   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.66226 (* 2 = 3.32451 loss)
I1130 22:40:12.022938   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 20.4018 (* 1 = 20.4018 loss)
I1130 22:40:12.022948   125 sgd_solver.cpp:180] [0.0] Iteration 792, lr = 2.33757e-05, m = 0.9, lrm = 0.000233757, wd = 2.5e-07, gs = 1
I1130 22:40:17.398984   125 solver.cpp:333]     [0.0] Iteration 836 (8.18438 iter/s, 5.3761s/44 iter), 2.3/100ep, loss = 18.2169
I1130 22:40:17.399027   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.657195 (* 2 = 1.31439 loss)
I1130 22:40:17.399039   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 16.9025 (* 1 = 16.9025 loss)
I1130 22:40:17.399050   125 sgd_solver.cpp:180] [0.0] Iteration 836, lr = 2.32886e-05, m = 0.9, lrm = 0.000232886, wd = 2.5e-07, gs = 1
I1130 22:40:22.776626   125 solver.cpp:333]     [0.0] Iteration 880 (8.18201 iter/s, 5.37765s/44 iter), 2.5/100ep, loss = 20.728
I1130 22:40:22.776670   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.43584 (* 2 = 2.87168 loss)
I1130 22:40:22.776680   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.8563 (* 1 = 17.8563 loss)
I1130 22:40:22.776693   125 sgd_solver.cpp:180] [0.0] Iteration 880, lr = 2.32019e-05, m = 0.9, lrm = 0.000232019, wd = 2.5e-07, gs = 1
I1130 22:40:28.144872   125 solver.cpp:333]     [0.0] Iteration 924 (8.19632 iter/s, 5.36826s/44 iter), 2.6/100ep, loss = 37.0772
I1130 22:40:28.144917   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.41329 (* 2 = 2.82657 loss)
I1130 22:40:28.144927   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 34.2506 (* 1 = 34.2506 loss)
I1130 22:40:28.144938   125 sgd_solver.cpp:180] [0.0] Iteration 924, lr = 2.31154e-05, m = 0.9, lrm = 0.000231154, wd = 2.5e-07, gs = 1
I1130 22:40:33.517163   125 solver.cpp:333]     [0.0] Iteration 968 (8.19019 iter/s, 5.37228s/44 iter), 2.7/100ep, loss = 31.1506
I1130 22:40:33.517361   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.999607 (* 2 = 1.99921 loss)
I1130 22:40:33.517376   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 29.1514 (* 1 = 29.1514 loss)
I1130 22:40:33.517390   125 sgd_solver.cpp:180] [0.0] Iteration 968, lr = 2.30293e-05, m = 0.9, lrm = 0.000230293, wd = 2.5e-07, gs = 1
I1130 22:40:38.914996   125 solver.cpp:333]     [0.0] Iteration 1012 (8.1514 iter/s, 5.39784s/44 iter), 2.8/100ep, loss = 25.7822
I1130 22:40:38.915037   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.564853 (* 2 = 1.12971 loss)
I1130 22:40:38.915050   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 24.6525 (* 1 = 24.6525 loss)
I1130 22:40:38.915061   125 sgd_solver.cpp:180] [0.0] Iteration 1012, lr = 2.29436e-05, m = 0.9, lrm = 0.000229435, wd = 2.5e-07, gs = 1
I1130 22:40:43.255707   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:40:43.374799   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:40:44.363199   125 solver.cpp:333]     [0.0] Iteration 1056 (8.07608 iter/s, 5.44819s/44 iter), 2.9/100ep, loss = 30.2108
I1130 22:40:44.363255   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.05496 (* 2 = 2.10993 loss)
I1130 22:40:44.363270   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 28.1009 (* 1 = 28.1009 loss)
I1130 22:40:44.363287   125 sgd_solver.cpp:180] [0.0] Iteration 1056, lr = 2.28581e-05, m = 0.9, lrm = 0.000228581, wd = 2.5e-07, gs = 1
I1130 22:40:46.830415   125 solver.cpp:501] Iteration 1077, Testing net (#0)
I1130 22:41:05.736528   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:41:05.869474   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:41:06.214603   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.771235 (* 2 = 1.54247 loss)
I1130 22:41:06.214658   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.3883 (* 1 = 21.3883 loss)
I1130 22:41:06.214671   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:41:06.214682   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:41:06.214692   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:41:06.214735   125 solver.cpp:271] Tests completed in 21.8517s
I1130 22:41:09.150424   125 solver.cpp:333]     [0.0] Iteration 1100 (2.01358 iter/s, 21.8517s/44 iter), 3.1/100ep, loss = 27.4545
I1130 22:41:09.150467   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.576096 (* 2 = 1.15219 loss)
I1130 22:41:09.150480   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 26.3023 (* 1 = 26.3023 loss)
I1130 22:41:09.150491   125 sgd_solver.cpp:180] [0.0] Iteration 1100, lr = 2.27729e-05, m = 0.9, lrm = 0.000227729, wd = 2.5e-07, gs = 1
I1130 22:41:14.511449   125 solver.cpp:333]     [0.0] Iteration 1144 (8.2074 iter/s, 5.36102s/44 iter), 3.2/100ep, loss = 18.5262
I1130 22:41:14.511490   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.362181 (* 2 = 0.724363 loss)
I1130 22:41:14.511502   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.8019 (* 1 = 17.8019 loss)
I1130 22:41:14.511512   125 sgd_solver.cpp:180] [0.0] Iteration 1144, lr = 2.26881e-05, m = 0.9, lrm = 0.000226881, wd = 2.5e-07, gs = 1
I1130 22:41:19.866142   125 solver.cpp:333]     [0.0] Iteration 1188 (8.21708 iter/s, 5.3547s/44 iter), 3.3/100ep, loss = 24.9039
I1130 22:41:19.866181   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.951512 (* 2 = 1.90302 loss)
I1130 22:41:19.866194   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 23.0009 (* 1 = 23.0009 loss)
I1130 22:41:19.866204   125 sgd_solver.cpp:180] [0.0] Iteration 1188, lr = 2.26036e-05, m = 0.9, lrm = 0.000226036, wd = 2.5e-07, gs = 1
I1130 22:41:25.221227   125 solver.cpp:333]     [0.0] Iteration 1232 (8.21649 iter/s, 5.35509s/44 iter), 3.4/100ep, loss = 36.3305
I1130 22:41:25.221268   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.8149 (* 2 = 1.6298 loss)
I1130 22:41:25.221280   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 34.7007 (* 1 = 34.7007 loss)
I1130 22:41:25.221292   125 sgd_solver.cpp:180] [0.0] Iteration 1232, lr = 2.25194e-05, m = 0.9, lrm = 0.000225194, wd = 2.5e-07, gs = 1
I1130 22:41:30.593726   125 solver.cpp:333]     [0.0] Iteration 1276 (8.18989 iter/s, 5.37248s/44 iter), 3.6/100ep, loss = 28.2738
I1130 22:41:30.593770   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 2.13673 (* 2 = 4.27347 loss)
I1130 22:41:30.593780   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 24.0004 (* 1 = 24.0004 loss)
I1130 22:41:30.593793   125 sgd_solver.cpp:180] [0.0] Iteration 1276, lr = 2.24355e-05, m = 0.9, lrm = 0.000224355, wd = 2.5e-07, gs = 1
I1130 22:41:35.972193   125 solver.cpp:333]     [0.0] Iteration 1320 (8.18075 iter/s, 5.37848s/44 iter), 3.7/100ep, loss = 10.9006
I1130 22:41:35.972391   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.325103 (* 2 = 0.650206 loss)
I1130 22:41:35.972405   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.2504 (* 1 = 10.2504 loss)
I1130 22:41:35.972417   125 sgd_solver.cpp:180] [0.0] Iteration 1320, lr = 2.23519e-05, m = 0.9, lrm = 0.000223519, wd = 2.5e-07, gs = 1
I1130 22:41:41.348836   125 solver.cpp:333]     [0.0] Iteration 1364 (8.18358 iter/s, 5.37662s/44 iter), 3.8/100ep, loss = 48.6133
I1130 22:41:41.348877   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 3.18131 (* 2 = 6.36262 loss)
I1130 22:41:41.348888   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 42.2507 (* 1 = 42.2507 loss)
I1130 22:41:41.348901   125 sgd_solver.cpp:180] [0.0] Iteration 1364, lr = 2.22687e-05, m = 0.9, lrm = 0.000222686, wd = 2.5e-07, gs = 1
I1130 22:41:46.591655   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:41:46.706060   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:41:46.708963   125 solver.cpp:333]     [0.0] Iteration 1408 (8.20873 iter/s, 5.36015s/44 iter), 3.9/100ep, loss = 22.5301
I1130 22:41:46.708990   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.01489 (* 2 = 2.02977 loss)
I1130 22:41:46.709000   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 20.5003 (* 1 = 20.5003 loss)
I1130 22:41:46.709012   125 sgd_solver.cpp:180] [0.0] Iteration 1408, lr = 2.21857e-05, m = 0.9, lrm = 0.000221857, wd = 2.5e-07, gs = 1
I1130 22:41:50.001026   125 solver.cpp:501] Iteration 1436, Testing net (#0)
I1130 22:42:08.767722   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:42:08.940238   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:42:09.342730   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.67437 (* 2 = 1.34874 loss)
I1130 22:42:09.342782   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.6455 (* 1 = 21.6455 loss)
I1130 22:42:09.342797   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:42:09.342808   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:42:09.342818   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:42:09.342859   125 solver.cpp:271] Tests completed in 22.634s
I1130 22:42:11.426862   125 solver.cpp:333]     [0.0] Iteration 1452 (1.94398 iter/s, 22.634s/44 iter), 4/100ep, loss = 9.44682
I1130 22:42:11.426903   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.223128 (* 2 = 0.446257 loss)
I1130 22:42:11.426914   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.00056 (* 1 = 9.00056 loss)
I1130 22:42:11.426926   125 sgd_solver.cpp:180] [0.0] Iteration 1452, lr = 2.21031e-05, m = 0.9, lrm = 0.00022103, wd = 2.5e-07, gs = 1
I1130 22:42:16.777889   125 solver.cpp:333]     [0.0] Iteration 1496 (8.22271 iter/s, 5.35103s/44 iter), 4.2/100ep, loss = 23.1126
I1130 22:42:16.777932   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.831135 (* 2 = 1.66227 loss)
I1130 22:42:16.777943   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 21.4503 (* 1 = 21.4503 loss)
I1130 22:42:16.777956   125 sgd_solver.cpp:180] [0.0] Iteration 1496, lr = 2.20207e-05, m = 0.9, lrm = 0.000220207, wd = 2.5e-07, gs = 1
I1130 22:42:22.131260   125 solver.cpp:333]     [0.0] Iteration 1540 (8.21912 iter/s, 5.35337s/44 iter), 4.3/100ep, loss = 19.0463
I1130 22:42:22.131299   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.597846 (* 2 = 1.19569 loss)
I1130 22:42:22.131310   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.8506 (* 1 = 17.8506 loss)
I1130 22:42:22.131322   125 sgd_solver.cpp:180] [0.0] Iteration 1540, lr = 2.19387e-05, m = 0.9, lrm = 0.000219387, wd = 2.5e-07, gs = 1
I1130 22:42:27.483098   125 solver.cpp:333]     [0.0] Iteration 1584 (8.2215 iter/s, 5.35182s/44 iter), 4.4/100ep, loss = 40.0112
I1130 22:42:27.483139   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.855533 (* 2 = 1.71107 loss)
I1130 22:42:27.483150   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 38.3001 (* 1 = 38.3001 loss)
I1130 22:42:27.483162   125 sgd_solver.cpp:180] [0.0] Iteration 1584, lr = 2.1857e-05, m = 0.9, lrm = 0.00021857, wd = 2.5e-07, gs = 1
I1130 22:42:32.831631   125 solver.cpp:333]     [0.0] Iteration 1628 (8.22655 iter/s, 5.34854s/44 iter), 4.5/100ep, loss = 20.8549
I1130 22:42:32.831674   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.427316 (* 2 = 0.854632 loss)
I1130 22:42:32.831686   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 20.0002 (* 1 = 20.0002 loss)
I1130 22:42:32.831698   125 sgd_solver.cpp:180] [0.0] Iteration 1628, lr = 2.17755e-05, m = 0.9, lrm = 0.000217755, wd = 2.5e-07, gs = 1
I1130 22:42:38.177323   125 solver.cpp:333]     [0.0] Iteration 1672 (8.23093 iter/s, 5.34569s/44 iter), 4.7/100ep, loss = 25.8046
I1130 22:42:38.177366   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.826882 (* 2 = 1.65376 loss)
I1130 22:42:38.177377   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 24.1509 (* 1 = 24.1509 loss)
I1130 22:42:38.177389   125 sgd_solver.cpp:180] [0.0] Iteration 1672, lr = 2.16944e-05, m = 0.9, lrm = 0.000216944, wd = 2.5e-07, gs = 1
I1130 22:42:43.547801   125 solver.cpp:333]     [0.0] Iteration 1716 (8.19295 iter/s, 5.37047s/44 iter), 4.8/100ep, loss = 33.8576
I1130 22:42:43.547996   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.978731 (* 2 = 1.95746 loss)
I1130 22:42:43.548012   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 31.9001 (* 1 = 31.9001 loss)
I1130 22:42:43.548024   125 sgd_solver.cpp:180] [0.0] Iteration 1716, lr = 2.16136e-05, m = 0.9, lrm = 0.000216136, wd = 2.5e-07, gs = 1
I1130 22:42:48.926973   125 solver.cpp:333]     [0.0] Iteration 1760 (8.1797 iter/s, 5.37917s/44 iter), 4.9/100ep, loss = 16.9278
I1130 22:42:48.927016   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 2.18882 (* 2 = 4.37764 loss)
I1130 22:42:48.927026   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.5502 (* 1 = 12.5502 loss)
I1130 22:42:48.927038   125 sgd_solver.cpp:180] [0.0] Iteration 1760, lr = 2.15331e-05, m = 0.9, lrm = 0.000215331, wd = 2.5e-07, gs = 1
I1130 22:42:49.781742   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:42:49.902940   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:42:53.075901   125 solver.cpp:501] Iteration 1795, Testing net (#0)
I1130 22:43:09.823701   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:43:09.939033   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:43:10.329942   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.6284 (* 2 = 1.2568 loss)
I1130 22:43:10.329984   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.4276 (* 1 = 21.4276 loss)
I1130 22:43:10.329994   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:43:10.330001   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:43:10.330008   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:43:10.330046   125 solver.cpp:271] Tests completed in 21.4031s
I1130 22:43:11.553010   125 solver.cpp:333]     [0.0] Iteration 1804 (2.05577 iter/s, 21.4031s/44 iter), 5/100ep, loss = 30.3551
I1130 22:43:11.553055   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.701429 (* 2 = 1.40286 loss)
I1130 22:43:11.553066   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 28.9522 (* 1 = 28.9522 loss)
I1130 22:43:11.553077   125 sgd_solver.cpp:180] [0.0] Iteration 1804, lr = 2.14529e-05, m = 0.9, lrm = 0.000214529, wd = 2.5e-07, gs = 1
I1130 22:43:16.920683   125 solver.cpp:333]     [0.0] Iteration 1848 (8.19723 iter/s, 5.36767s/44 iter), 5.1/100ep, loss = 5.71694
I1130 22:43:16.920878   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.233076 (* 2 = 0.466151 loss)
I1130 22:43:16.920892   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.25079 (* 1 = 5.25079 loss)
I1130 22:43:16.920904   125 sgd_solver.cpp:180] [0.0] Iteration 1848, lr = 2.1373e-05, m = 0.9, lrm = 0.00021373, wd = 2.5e-07, gs = 1
I1130 22:43:22.292672   125 solver.cpp:333]     [0.0] Iteration 1892 (8.19063 iter/s, 5.37199s/44 iter), 5.3/100ep, loss = 13.9712
I1130 22:43:22.292716   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.385355 (* 2 = 0.77071 loss)
I1130 22:43:22.292728   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.2004 (* 1 = 13.2004 loss)
I1130 22:43:22.292740   125 sgd_solver.cpp:180] [0.0] Iteration 1892, lr = 2.12933e-05, m = 0.9, lrm = 0.000212933, wd = 2.5e-07, gs = 1
I1130 22:43:27.655424   125 solver.cpp:333]     [0.0] Iteration 1936 (8.20476 iter/s, 5.36274s/44 iter), 5.4/100ep, loss = 13.4503
I1130 22:43:27.655467   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.399872 (* 2 = 0.799743 loss)
I1130 22:43:27.655478   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.6506 (* 1 = 12.6506 loss)
I1130 22:43:27.655491   125 sgd_solver.cpp:180] [0.0] Iteration 1936, lr = 2.1214e-05, m = 0.9, lrm = 0.00021214, wd = 2.5e-07, gs = 1
I1130 22:43:33.031957   125 solver.cpp:333]     [0.0] Iteration 1980 (8.18371 iter/s, 5.37653s/44 iter), 5.5/100ep, loss = 30.7664
I1130 22:43:33.032001   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.783116 (* 2 = 1.56623 loss)
I1130 22:43:33.032014   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 29.2002 (* 1 = 29.2002 loss)
I1130 22:43:33.032027   125 sgd_solver.cpp:180] [0.0] Iteration 1980, lr = 2.1135e-05, m = 0.9, lrm = 0.00021135, wd = 2.5e-07, gs = 1
I1130 22:43:38.413976   125 solver.cpp:333]     [0.0] Iteration 2024 (8.1754 iter/s, 5.382s/44 iter), 5.6/100ep, loss = 23.9518
I1130 22:43:38.414019   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.575748 (* 2 = 1.1515 loss)
I1130 22:43:38.414031   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 22.8003 (* 1 = 22.8003 loss)
I1130 22:43:38.414043   125 sgd_solver.cpp:180] [0.0] Iteration 2024, lr = 2.10563e-05, m = 0.9, lrm = 0.000210563, wd = 2.5e-07, gs = 1
I1130 22:43:43.795805   125 solver.cpp:333]     [0.0] Iteration 2068 (8.17566 iter/s, 5.38183s/44 iter), 5.8/100ep, loss = 15.36
I1130 22:43:43.795845   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.254776 (* 2 = 0.509552 loss)
I1130 22:43:43.795857   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.8505 (* 1 = 14.8505 loss)
I1130 22:43:43.795869   125 sgd_solver.cpp:180] [0.0] Iteration 2068, lr = 2.09778e-05, m = 0.9, lrm = 0.000209778, wd = 2.5e-07, gs = 1
I1130 22:43:49.169603   125 solver.cpp:333]     [0.0] Iteration 2112 (8.18786 iter/s, 5.37381s/44 iter), 5.9/100ep, loss = 18.0922
I1130 22:43:49.169807   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.346047 (* 2 = 0.692094 loss)
I1130 22:43:49.169821   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.4001 (* 1 = 17.4001 loss)
I1130 22:43:49.169833   125 sgd_solver.cpp:180] [0.0] Iteration 2112, lr = 2.08997e-05, m = 0.9, lrm = 0.000208997, wd = 2.5e-07, gs = 1
I1130 22:43:50.636418   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:43:50.758395   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:43:54.175066   125 solver.cpp:501] Iteration 2154, Testing net (#0)
I1130 22:44:11.018304   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:44:11.194145   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:44:11.685274   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.607489 (* 2 = 1.21498 loss)
I1130 22:44:11.685326   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.4244 (* 1 = 21.4244 loss)
I1130 22:44:11.685340   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:44:11.685351   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:44:11.685361   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:44:11.685405   125 solver.cpp:271] Tests completed in 22.5159s
I1130 22:44:12.065811   125 solver.cpp:333]     [0.0] Iteration 2156 (1.95418 iter/s, 22.5159s/44 iter), 6/100ep, loss = 15.7572
I1130 22:44:12.065853   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.05343 (* 2 = 2.10685 loss)
I1130 22:44:12.065865   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.6504 (* 1 = 13.6504 loss)
I1130 22:44:12.065876   125 sgd_solver.cpp:180] [0.0] Iteration 2156, lr = 2.08218e-05, m = 0.9, lrm = 0.000208218, wd = 2.5e-07, gs = 1
I1130 22:44:17.430382   125 solver.cpp:333]     [0.0] Iteration 2200 (8.202 iter/s, 5.36455s/44 iter), 6.1/100ep, loss = 25.5698
I1130 22:44:17.430425   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 2.00976 (* 2 = 4.01953 loss)
I1130 22:44:17.430435   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 21.5503 (* 1 = 21.5503 loss)
I1130 22:44:17.430449   125 sgd_solver.cpp:180] [0.0] Iteration 2200, lr = 2.07443e-05, m = 0.9, lrm = 0.000207443, wd = 2.5e-07, gs = 1
I1130 22:44:22.804386   125 solver.cpp:333]     [0.0] Iteration 2244 (8.18756 iter/s, 5.37401s/44 iter), 6.3/100ep, loss = 24.1081
I1130 22:44:22.804533   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.35386 (* 2 = 0.707719 loss)
I1130 22:44:22.804546   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 23.4004 (* 1 = 23.4004 loss)
I1130 22:44:22.804559   125 sgd_solver.cpp:180] [0.0] Iteration 2244, lr = 2.0667e-05, m = 0.9, lrm = 0.00020667, wd = 2.5e-07, gs = 1
I1130 22:44:28.174365   125 solver.cpp:333]     [0.0] Iteration 2288 (8.19371 iter/s, 5.36997s/44 iter), 6.4/100ep, loss = 54.3291
I1130 22:44:28.174407   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.764432 (* 2 = 1.52886 loss)
I1130 22:44:28.174419   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 52.8002 (* 1 = 52.8002 loss)
I1130 22:44:28.174433   125 sgd_solver.cpp:180] [0.0] Iteration 2288, lr = 2.059e-05, m = 0.9, lrm = 0.0002059, wd = 2.5e-07, gs = 1
I1130 22:44:33.548986   125 solver.cpp:333]     [0.0] Iteration 2332 (8.18664 iter/s, 5.37461s/44 iter), 6.5/100ep, loss = 20.5928
I1130 22:44:33.549029   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.69638 (* 2 = 1.39276 loss)
I1130 22:44:33.549041   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 19.2001 (* 1 = 19.2001 loss)
I1130 22:44:33.549053   125 sgd_solver.cpp:180] [0.0] Iteration 2332, lr = 2.05133e-05, m = 0.9, lrm = 0.000205133, wd = 2.5e-07, gs = 1
I1130 22:44:38.923540   125 solver.cpp:333]     [0.0] Iteration 2376 (8.18673 iter/s, 5.37455s/44 iter), 6.6/100ep, loss = 34.0692
I1130 22:44:38.923581   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.534579 (* 2 = 1.06916 loss)
I1130 22:44:38.923593   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 33.0001 (* 1 = 33.0001 loss)
I1130 22:44:38.923605   125 sgd_solver.cpp:180] [0.0] Iteration 2376, lr = 2.04369e-05, m = 0.9, lrm = 0.000204369, wd = 2.5e-07, gs = 1
I1130 22:44:44.304062   125 solver.cpp:333]     [0.0] Iteration 2420 (8.17763 iter/s, 5.38053s/44 iter), 6.7/100ep, loss = 26.2384
I1130 22:44:44.304108   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.644115 (* 2 = 1.28823 loss)
I1130 22:44:44.304119   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 24.9502 (* 1 = 24.9502 loss)
I1130 22:44:44.304132   125 sgd_solver.cpp:180] [0.0] Iteration 2420, lr = 2.03607e-05, m = 0.9, lrm = 0.000203607, wd = 2.5e-07, gs = 1
I1130 22:44:49.750555   125 solver.cpp:333]     [0.0] Iteration 2464 (8.07862 iter/s, 5.44647s/44 iter), 6.9/100ep, loss = 15.9344
I1130 22:44:49.750599   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.89211 (* 2 = 1.78422 loss)
I1130 22:44:49.750610   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.1502 (* 1 = 14.1502 loss)
I1130 22:44:49.750623   125 sgd_solver.cpp:180] [0.0] Iteration 2464, lr = 2.02849e-05, m = 0.9, lrm = 0.000202849, wd = 2.5e-07, gs = 1
I1130 22:44:52.228236   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:44:52.345984   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:44:55.189287   125 solver.cpp:333]     [0.0] Iteration 2508 (8.09012 iter/s, 5.43873s/44 iter), 7/100ep, loss = 27.3051
I1130 22:44:55.189486   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.727486 (* 2 = 1.45497 loss)
I1130 22:44:55.189505   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 25.8502 (* 1 = 25.8502 loss)
I1130 22:44:55.189523   125 sgd_solver.cpp:180] [0.0] Iteration 2508, lr = 2.02093e-05, m = 0.9, lrm = 0.000202093, wd = 2.5e-07, gs = 1
I1130 22:44:55.681665   125 solver.cpp:501] Iteration 2513, Testing net (#0)
I1130 22:45:12.341048   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:45:12.454386   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:45:12.913480   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.670435 (* 2 = 1.34087 loss)
I1130 22:45:12.913518   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.4687 (* 1 = 21.4687 loss)
I1130 22:45:12.913527   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:45:12.913533   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:45:12.913540   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:45:12.913573   125 solver.cpp:271] Tests completed in 17.7243s
I1130 22:45:17.842327   125 solver.cpp:333]     [0.0] Iteration 2552 (2.48246 iter/s, 17.7243s/44 iter), 7.1/100ep, loss = 28.7241
I1130 22:45:17.842367   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.06198 (* 2 = 2.12396 loss)
I1130 22:45:17.842378   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 26.6001 (* 1 = 26.6001 loss)
I1130 22:45:17.842391   125 sgd_solver.cpp:180] [0.0] Iteration 2552, lr = 2.01341e-05, m = 0.9, lrm = 0.00020134, wd = 2.5e-07, gs = 1
I1130 22:45:23.273416   125 solver.cpp:333]     [0.0] Iteration 2596 (8.1015 iter/s, 5.43109s/44 iter), 7.2/100ep, loss = 24.6267
I1130 22:45:23.273456   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.838268 (* 2 = 1.67654 loss)
I1130 22:45:23.273468   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 22.9501 (* 1 = 22.9501 loss)
I1130 22:45:23.273479   125 sgd_solver.cpp:180] [0.0] Iteration 2596, lr = 2.00591e-05, m = 0.9, lrm = 0.00020059, wd = 2.5e-07, gs = 1
I1130 22:45:28.708747   125 solver.cpp:333]     [0.0] Iteration 2640 (8.09522 iter/s, 5.4353s/44 iter), 7.4/100ep, loss = 25.6526
I1130 22:45:28.708971   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.776219 (* 2 = 1.55244 loss)
I1130 22:45:28.708992   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 24.1002 (* 1 = 24.1002 loss)
I1130 22:45:28.709010   125 sgd_solver.cpp:180] [0.0] Iteration 2640, lr = 1.99843e-05, m = 0.9, lrm = 0.000199843, wd = 2.5e-07, gs = 1
I1130 22:45:34.121256   125 solver.cpp:333]     [0.0] Iteration 2684 (8.12932 iter/s, 5.4125s/44 iter), 7.5/100ep, loss = 21.6144
I1130 22:45:34.121297   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.507122 (* 2 = 1.01424 loss)
I1130 22:45:34.121310   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 20.6002 (* 1 = 20.6002 loss)
I1130 22:45:34.121321   125 sgd_solver.cpp:180] [0.0] Iteration 2684, lr = 1.99099e-05, m = 0.9, lrm = 0.000199099, wd = 2.5e-07, gs = 1
I1130 22:45:39.472585   125 solver.cpp:333]     [0.0] Iteration 2728 (8.22228 iter/s, 5.35132s/44 iter), 7.6/100ep, loss = 25.1818
I1130 22:45:39.472627   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.765834 (* 2 = 1.53167 loss)
I1130 22:45:39.472640   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 23.6502 (* 1 = 23.6502 loss)
I1130 22:45:39.472649   125 sgd_solver.cpp:180] [0.0] Iteration 2728, lr = 1.98357e-05, m = 0.9, lrm = 0.000198357, wd = 2.5e-07, gs = 1
I1130 22:45:44.824614   125 solver.cpp:333]     [0.0] Iteration 2772 (8.22118 iter/s, 5.35203s/44 iter), 7.7/100ep, loss = 27.7998
I1130 22:45:44.824653   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.724671 (* 2 = 1.44934 loss)
I1130 22:45:44.824666   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 26.3504 (* 1 = 26.3504 loss)
I1130 22:45:44.824676   125 sgd_solver.cpp:180] [0.0] Iteration 2772, lr = 1.97618e-05, m = 0.9, lrm = 0.000197618, wd = 2.5e-07, gs = 1
I1130 22:45:50.168512   125 solver.cpp:333]     [0.0] Iteration 2816 (8.23369 iter/s, 5.3439s/44 iter), 7.8/100ep, loss = 17.4834
I1130 22:45:50.168552   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.491688 (* 2 = 0.983377 loss)
I1130 22:45:50.168565   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 16.5 (* 1 = 16.5 loss)
I1130 22:45:50.168576   125 sgd_solver.cpp:180] [0.0] Iteration 2816, lr = 1.96882e-05, m = 0.9, lrm = 0.000196882, wd = 2.5e-07, gs = 1
I1130 22:45:53.577479   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:45:53.700795   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:45:55.521843   125 solver.cpp:333]     [0.0] Iteration 2860 (8.21922 iter/s, 5.35331s/44 iter), 8/100ep, loss = 22.9052
I1130 22:45:55.521884   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.776972 (* 2 = 1.55394 loss)
I1130 22:45:55.521896   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 21.3512 (* 1 = 21.3512 loss)
I1130 22:45:55.521908   125 sgd_solver.cpp:180] [0.0] Iteration 2860, lr = 1.96149e-05, m = 0.9, lrm = 0.000196149, wd = 2.5e-07, gs = 1
I1130 22:45:56.860393   125 solver.cpp:501] Iteration 2872, Testing net (#0)
I1130 22:46:13.420817   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:46:13.573702   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:46:14.077952   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.573583 (* 2 = 1.14717 loss)
I1130 22:46:14.077991   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.4537 (* 1 = 21.4537 loss)
I1130 22:46:14.077998   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:46:14.078006   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:46:14.078012   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:46:14.078044   125 solver.cpp:271] Tests completed in 18.5563s
I1130 22:46:18.096976   125 solver.cpp:333]     [0.0] Iteration 2904 (2.37117 iter/s, 18.5563s/44 iter), 8.1/100ep, loss = 15.929
I1130 22:46:18.097014   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.489418 (* 2 = 0.978837 loss)
I1130 22:46:18.097025   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.9501 (* 1 = 14.9501 loss)
I1130 22:46:18.097036   125 sgd_solver.cpp:180] [0.0] Iteration 2904, lr = 1.95418e-05, m = 0.9, lrm = 0.000195418, wd = 2.5e-07, gs = 1
I1130 22:46:23.456315   125 solver.cpp:333]     [0.0] Iteration 2948 (8.21001 iter/s, 5.35931s/44 iter), 8.2/100ep, loss = 30.2802
I1130 22:46:23.456354   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.715012 (* 2 = 1.43002 loss)
I1130 22:46:23.456365   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 28.8502 (* 1 = 28.8502 loss)
I1130 22:46:23.456378   125 sgd_solver.cpp:180] [0.0] Iteration 2948, lr = 1.9469e-05, m = 0.9, lrm = 0.00019469, wd = 2.5e-07, gs = 1
I1130 22:46:28.808017   125 solver.cpp:333]     [0.0] Iteration 2992 (8.22168 iter/s, 5.35171s/44 iter), 8.3/100ep, loss = 21.1679
I1130 22:46:28.808058   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.858872 (* 2 = 1.71774 loss)
I1130 22:46:28.808070   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 19.4501 (* 1 = 19.4501 loss)
I1130 22:46:28.808082   125 sgd_solver.cpp:180] [0.0] Iteration 2992, lr = 1.93965e-05, m = 0.9, lrm = 0.000193965, wd = 2.5e-07, gs = 1
I1130 22:46:34.155792   125 solver.cpp:333]     [0.0] Iteration 3036 (8.22772 iter/s, 5.34777s/44 iter), 8.5/100ep, loss = 18.1987
I1130 22:46:34.155834   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.52428 (* 2 = 3.04856 loss)
I1130 22:46:34.155845   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.1502 (* 1 = 15.1502 loss)
I1130 22:46:34.155858   125 sgd_solver.cpp:180] [0.0] Iteration 3036, lr = 1.93242e-05, m = 0.9, lrm = 0.000193242, wd = 2.5e-07, gs = 1
I1130 22:46:39.501569   125 solver.cpp:333]     [0.0] Iteration 3080 (8.23083 iter/s, 5.34575s/44 iter), 8.6/100ep, loss = 31.9218
I1130 22:46:39.501610   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.785848 (* 2 = 1.5717 loss)
I1130 22:46:39.501621   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 30.3501 (* 1 = 30.3501 loss)
I1130 22:46:39.501632   125 sgd_solver.cpp:180] [0.0] Iteration 3080, lr = 1.92522e-05, m = 0.9, lrm = 0.000192522, wd = 2.5e-07, gs = 1
I1130 22:46:44.848131   125 solver.cpp:333]     [0.0] Iteration 3124 (8.22959 iter/s, 5.34656s/44 iter), 8.7/100ep, loss = 18.649
I1130 22:46:44.848322   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.399468 (* 2 = 0.798936 loss)
I1130 22:46:44.848335   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.8501 (* 1 = 17.8501 loss)
I1130 22:46:44.848347   125 sgd_solver.cpp:180] [0.0] Iteration 3124, lr = 1.91805e-05, m = 0.9, lrm = 0.000191805, wd = 2.5e-07, gs = 1
I1130 22:46:50.199098   125 solver.cpp:333]     [0.0] Iteration 3168 (8.22282 iter/s, 5.35096s/44 iter), 8.8/100ep, loss = 24.1798
I1130 22:46:50.199141   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.689826 (* 2 = 1.37965 loss)
I1130 22:46:50.199152   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 22.8001 (* 1 = 22.8001 loss)
I1130 22:46:50.199165   125 sgd_solver.cpp:180] [0.0] Iteration 3168, lr = 1.91091e-05, m = 0.9, lrm = 0.000191091, wd = 2.5e-07, gs = 1
I1130 22:46:54.288484   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:46:54.408769   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:46:55.652474   125 solver.cpp:333]     [0.0] Iteration 3212 (8.06841 iter/s, 5.45336s/44 iter), 8.9/100ep, loss = 28.5515
I1130 22:46:55.652518   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.500669 (* 2 = 1.00134 loss)
I1130 22:46:55.652529   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 27.5502 (* 1 = 27.5502 loss)
I1130 22:46:55.652540   125 sgd_solver.cpp:180] [0.0] Iteration 3212, lr = 1.90379e-05, m = 0.9, lrm = 0.000190379, wd = 2.5e-07, gs = 1
I1130 22:46:57.885455   125 solver.cpp:501] Iteration 3231, Testing net (#0)
I1130 22:47:14.511924   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:47:14.626047   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:47:15.167480   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.583041 (* 2 = 1.16608 loss)
I1130 22:47:15.167608   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.3877 (* 1 = 21.3877 loss)
I1130 22:47:15.167619   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:47:15.167625   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:47:15.167632   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:47:15.167667   125 solver.cpp:271] Tests completed in 19.5153s
I1130 22:47:18.398337   125 solver.cpp:333]     [0.0] Iteration 3256 (2.25465 iter/s, 19.5153s/44 iter), 9.1/100ep, loss = 14.7495
I1130 22:47:18.398392   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.19972 (* 2 = 2.39943 loss)
I1130 22:47:18.398409   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.3501 (* 1 = 12.3501 loss)
I1130 22:47:18.398427   125 sgd_solver.cpp:180] [0.0] Iteration 3256, lr = 1.8967e-05, m = 0.9, lrm = 0.00018967, wd = 2.5e-07, gs = 1
I1130 22:47:23.765148   125 solver.cpp:333]     [0.0] Iteration 3300 (8.19851 iter/s, 5.36683s/44 iter), 9.2/100ep, loss = 14.9629
I1130 22:47:23.765190   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.606312 (* 2 = 1.21262 loss)
I1130 22:47:23.765202   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.7503 (* 1 = 13.7503 loss)
I1130 22:47:23.765213   125 sgd_solver.cpp:180] [0.0] Iteration 3300, lr = 1.88963e-05, m = 0.9, lrm = 0.000188963, wd = 2.5e-07, gs = 1
I1130 22:47:29.130640   125 solver.cpp:333]     [0.0] Iteration 3344 (8.20056 iter/s, 5.36549s/44 iter), 9.3/100ep, loss = 30.2214
I1130 22:47:29.130682   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.560681 (* 2 = 1.12136 loss)
I1130 22:47:29.130694   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 29.1001 (* 1 = 29.1001 loss)
I1130 22:47:29.130707   125 sgd_solver.cpp:180] [0.0] Iteration 3344, lr = 1.88259e-05, m = 0.9, lrm = 0.000188259, wd = 2.5e-07, gs = 1
I1130 22:47:34.493571   125 solver.cpp:333]     [0.0] Iteration 3388 (8.2045 iter/s, 5.36291s/44 iter), 9.4/100ep, loss = 28.2895
I1130 22:47:34.493611   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.944693 (* 2 = 1.88939 loss)
I1130 22:47:34.493623   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 26.4001 (* 1 = 26.4001 loss)
I1130 22:47:34.493635   125 sgd_solver.cpp:180] [0.0] Iteration 3388, lr = 1.87558e-05, m = 0.9, lrm = 0.000187558, wd = 2.5e-07, gs = 1
I1130 22:47:39.861368   125 solver.cpp:333]     [0.0] Iteration 3432 (8.19703 iter/s, 5.3678s/44 iter), 9.6/100ep, loss = 29.8313
I1130 22:47:39.861412   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.838764 (* 2 = 1.67753 loss)
I1130 22:47:39.861423   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 28.1537 (* 1 = 28.1537 loss)
I1130 22:47:39.861435   125 sgd_solver.cpp:180] [0.0] Iteration 3432, lr = 1.86859e-05, m = 0.9, lrm = 0.000186859, wd = 2.5e-07, gs = 1
I1130 22:47:45.231778   125 solver.cpp:333]     [0.0] Iteration 3476 (8.19306 iter/s, 5.3704s/44 iter), 9.7/100ep, loss = 13.4469
I1130 22:47:45.231948   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.1734 (* 2 = 2.34681 loss)
I1130 22:47:45.231963   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.1 (* 1 = 11.1 loss)
I1130 22:47:45.231976   125 sgd_solver.cpp:180] [0.0] Iteration 3476, lr = 1.86163e-05, m = 0.9, lrm = 0.000186163, wd = 2.5e-07, gs = 1
I1130 22:47:50.598489   125 solver.cpp:333]     [0.0] Iteration 3520 (8.19871 iter/s, 5.3667s/44 iter), 9.8/100ep, loss = 22.2422
I1130 22:47:50.598528   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.896067 (* 2 = 1.79213 loss)
I1130 22:47:50.598541   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 20.4501 (* 1 = 20.4501 loss)
I1130 22:47:50.598552   125 sgd_solver.cpp:180] [0.0] Iteration 3520, lr = 1.8547e-05, m = 0.9, lrm = 0.00018547, wd = 2.5e-07, gs = 1
I1130 22:47:55.608655   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:47:55.720531   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:47:55.969269   125 solver.cpp:333]     [0.0] Iteration 3564 (8.19249 iter/s, 5.37077s/44 iter), 9.9/100ep, loss = 28.3141
I1130 22:47:55.969311   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.906971 (* 2 = 1.81394 loss)
I1130 22:47:55.969322   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 26.5001 (* 1 = 26.5001 loss)
I1130 22:47:55.969334   125 sgd_solver.cpp:180] [0.0] Iteration 3564, lr = 1.84779e-05, m = 0.9, lrm = 0.000184779, wd = 2.5e-07, gs = 1
I1130 22:47:59.018888   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_3590.caffemodel
I1130 22:47:59.110339   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_3590.solverstate
I1130 22:47:59.153167   125 solver.cpp:501] Iteration 3590, Testing net (#0)
I1130 22:48:15.523191   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:48:15.673568   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:48:16.254262   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.639338 (* 2 = 1.27868 loss)
I1130 22:48:16.254302   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.6412 (* 1 = 21.6412 loss)
I1130 22:48:16.254309   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:48:16.254317   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:48:16.254323   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:48:16.254357   125 solver.cpp:271] Tests completed in 20.2852s
I1130 22:48:18.571785   125 solver.cpp:333]     [0.0] Iteration 3608 (2.16907 iter/s, 20.2852s/44 iter), 10.1/100ep, loss = 25.2748
I1130 22:48:18.571825   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.762324 (* 2 = 1.52465 loss)
I1130 22:48:18.571837   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 23.7501 (* 1 = 23.7501 loss)
I1130 22:48:18.571851   125 sgd_solver.cpp:180] [0.0] Iteration 3608, lr = 1.8409e-05, m = 0.9, lrm = 0.00018409, wd = 2.5e-07, gs = 1
I1130 22:48:23.936358   125 solver.cpp:333]     [0.0] Iteration 3652 (8.20189 iter/s, 5.36462s/44 iter), 10.2/100ep, loss = 25.497
I1130 22:48:23.936398   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.14844 (* 2 = 2.29687 loss)
I1130 22:48:23.936408   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 23.2001 (* 1 = 23.2001 loss)
I1130 22:48:23.936421   125 sgd_solver.cpp:180] [0.0] Iteration 3652, lr = 1.83405e-05, m = 0.9, lrm = 0.000183405, wd = 2.5e-07, gs = 1
I1130 22:48:29.303789   125 solver.cpp:333]     [0.0] Iteration 3696 (8.19749 iter/s, 5.3675s/44 iter), 10.3/100ep, loss = 17.6518
I1130 22:48:29.303831   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.225838 (* 2 = 0.451676 loss)
I1130 22:48:29.303843   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.2001 (* 1 = 17.2001 loss)
I1130 22:48:29.303854   125 sgd_solver.cpp:180] [0.0] Iteration 3696, lr = 1.82721e-05, m = 0.9, lrm = 0.000182721, wd = 2.5e-07, gs = 1
I1130 22:48:34.683818   125 solver.cpp:333]     [0.0] Iteration 3740 (8.17835 iter/s, 5.38006s/44 iter), 10.4/100ep, loss = 16.7861
I1130 22:48:34.683862   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.367952 (* 2 = 0.735905 loss)
I1130 22:48:34.683874   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 16.0502 (* 1 = 16.0502 loss)
I1130 22:48:34.683887   125 sgd_solver.cpp:180] [0.0] Iteration 3740, lr = 1.82041e-05, m = 0.9, lrm = 0.000182041, wd = 2.5e-07, gs = 1
I1130 22:48:40.046597   125 solver.cpp:333]     [0.0] Iteration 3784 (8.20461 iter/s, 5.36284s/44 iter), 10.5/100ep, loss = 36.3595
I1130 22:48:40.046641   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.80468 (* 2 = 1.60936 loss)
I1130 22:48:40.046653   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 34.7501 (* 1 = 34.7501 loss)
I1130 22:48:40.046665   125 sgd_solver.cpp:180] [0.0] Iteration 3784, lr = 1.81363e-05, m = 0.9, lrm = 0.000181363, wd = 2.5e-07, gs = 1
I1130 22:48:45.415477   125 solver.cpp:333]     [0.0] Iteration 3828 (8.19534 iter/s, 5.3689s/44 iter), 10.7/100ep, loss = 41.4246
I1130 22:48:45.415520   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.987218 (* 2 = 1.97444 loss)
I1130 22:48:45.415532   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 39.4501 (* 1 = 39.4501 loss)
I1130 22:48:45.415545   125 sgd_solver.cpp:180] [0.0] Iteration 3828, lr = 1.80687e-05, m = 0.9, lrm = 0.000180687, wd = 2.5e-07, gs = 1
I1130 22:48:50.788286   125 solver.cpp:333]     [0.0] Iteration 3872 (8.18929 iter/s, 5.37287s/44 iter), 10.8/100ep, loss = 35.5584
I1130 22:48:50.788482   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.57911 (* 2 = 3.15822 loss)
I1130 22:48:50.788496   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 32.4001 (* 1 = 32.4001 loss)
I1130 22:48:50.788508   125 sgd_solver.cpp:180] [0.0] Iteration 3872, lr = 1.80014e-05, m = 0.9, lrm = 0.000180014, wd = 2.5e-07, gs = 1
I1130 22:48:56.171835   125 solver.cpp:333]     [0.0] Iteration 3916 (8.17297 iter/s, 5.3836s/44 iter), 10.9/100ep, loss = 31.8699
I1130 22:48:56.171878   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.659853 (* 2 = 1.31971 loss)
I1130 22:48:56.171890   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 30.5502 (* 1 = 30.5502 loss)
I1130 22:48:56.171902   125 sgd_solver.cpp:180] [0.0] Iteration 3916, lr = 1.79343e-05, m = 0.9, lrm = 0.000179343, wd = 2.5e-07, gs = 1
I1130 22:48:56.783068   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:48:56.907744   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:49:00.110097   125 solver.cpp:501] Iteration 3949, Testing net (#0)
I1130 22:49:16.601534   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:49:16.715736   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:49:17.333726   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.545705 (* 2 = 1.09141 loss)
I1130 22:49:17.333763   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 21.423 (* 1 = 21.423 loss)
I1130 22:49:17.333772   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 0
I1130 22:49:17.333779   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 0
I1130 22:49:17.333786   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 0
I1130 22:49:17.333819   125 solver.cpp:271] Tests completed in 21.1622s
I1130 22:49:18.798089   125 solver.cpp:333]     [0.0] Iteration 3960 (2.07917 iter/s, 21.1622s/44 iter), 11/100ep, loss = 26.577
I1130 22:49:18.798130   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.613457 (* 2 = 1.22691 loss)
I1130 22:49:18.798143   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 25.3501 (* 1 = 25.3501 loss)
I1130 22:49:18.798154   125 sgd_solver.cpp:180] [0.0] Iteration 3960, lr = 1.78675e-05, m = 0.9, lrm = 0.000178675, wd = 2.5e-07, gs = 1
I1130 22:49:24.147624   125 solver.cpp:333]     [0.0] Iteration 4004 (8.22494 iter/s, 5.34958s/44 iter), 11.2/100ep, loss = 12.8062
I1130 22:49:24.147773   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.278061 (* 2 = 0.556123 loss)
I1130 22:49:24.147786   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.2501 (* 1 = 12.2501 loss)
I1130 22:49:24.147799   125 sgd_solver.cpp:180] [0.0] Iteration 4004, lr = 1.7801e-05, m = 0.9, lrm = 0.00017801, wd = 2.5e-07, gs = 1
I1130 22:49:29.490072   125 solver.cpp:333]     [0.0] Iteration 4048 (8.23588 iter/s, 5.34248s/44 iter), 11.3/100ep, loss = 25.3417
I1130 22:49:29.490113   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.620772 (* 2 = 1.24154 loss)
I1130 22:49:29.490125   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 24.1001 (* 1 = 24.1001 loss)
I1130 22:49:29.490137   125 sgd_solver.cpp:180] [0.0] Iteration 4048, lr = 1.77347e-05, m = 0.9, lrm = 0.000177346, wd = 2.5e-07, gs = 1
I1130 22:49:34.844153   125 solver.cpp:333]     [0.0] Iteration 4092 (8.21795 iter/s, 5.35413s/44 iter), 11.4/100ep, loss = 20.1763
I1130 22:49:34.844193   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.363083 (* 2 = 0.726166 loss)
I1130 22:49:34.844204   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 19.4501 (* 1 = 19.4501 loss)
I1130 22:49:34.844215   125 sgd_solver.cpp:180] [0.0] Iteration 4092, lr = 1.76686e-05, m = 0.9, lrm = 0.000176686, wd = 2.5e-07, gs = 1
I1130 22:49:40.182842   125 solver.cpp:333]     [0.0] Iteration 4136 (8.24166 iter/s, 5.33873s/44 iter), 11.5/100ep, loss = 36.9004
I1130 22:49:40.182883   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.650146 (* 2 = 1.30029 loss)
I1130 22:49:40.182894   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 35.6001 (* 1 = 35.6001 loss)
I1130 22:49:40.182906   125 sgd_solver.cpp:180] [0.0] Iteration 4136, lr = 1.76028e-05, m = 0.9, lrm = 0.000176028, wd = 2.5e-07, gs = 1
I1130 22:49:45.521194   125 solver.cpp:333]     [0.0] Iteration 4180 (8.2422 iter/s, 5.33838s/44 iter), 11.6/100ep, loss = 10.0279
I1130 22:49:45.521236   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.188955 (* 2 = 0.37791 loss)
I1130 22:49:45.521247   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.64993 (* 1 = 9.64993 loss)
I1130 22:49:45.521258   125 sgd_solver.cpp:180] [0.0] Iteration 4180, lr = 1.75372e-05, m = 0.9, lrm = 0.000175372, wd = 2.5e-07, gs = 1
I1130 22:49:50.869982   125 solver.cpp:333]     [0.0] Iteration 4224 (8.22609 iter/s, 5.34884s/44 iter), 11.8/100ep, loss = 14.3314
I1130 22:49:50.870025   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.365549 (* 2 = 0.731099 loss)
I1130 22:49:50.870036   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.6003 (* 1 = 13.6003 loss)
I1130 22:49:50.870048   125 sgd_solver.cpp:180] [0.0] Iteration 4224, lr = 1.74719e-05, m = 0.9, lrm = 0.000174719, wd = 2.5e-07, gs = 1
I1130 22:49:56.221297   125 solver.cpp:333]     [0.0] Iteration 4268 (8.22222 iter/s, 5.35135s/44 iter), 11.9/100ep, loss = 16.4303
I1130 22:49:56.221475   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.48303 (* 2 = 0.96606 loss)
I1130 22:49:56.221490   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.4643 (* 1 = 15.4643 loss)
I1130 22:49:56.221503   125 sgd_solver.cpp:180] [0.0] Iteration 4268, lr = 1.74068e-05, m = 0.9, lrm = 0.000174068, wd = 2.5e-07, gs = 1
I1130 22:49:57.441426   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:49:57.560245   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:50:00.964146   125 solver.cpp:501] Iteration 4308, Testing net (#0)
I1130 22:50:17.414451   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:50:17.568136   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:50:18.235810   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.662534 (* 2 = 1.32507 loss)
I1130 22:50:18.235853   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 15.9643 (* 1 = 15.9643 loss)
I1130 22:50:18.235862   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 4.61843
I1130 22:50:18.235870   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 10.7083
I1130 22:50:18.235877   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 14.7381
I1130 22:50:18.235930   125 solver.cpp:271] Tests completed in 22.0149s
I1130 22:50:18.848068   125 solver.cpp:333]     [0.0] Iteration 4312 (1.99865 iter/s, 22.0149s/44 iter), 12/100ep, loss = 6.60111
I1130 22:50:18.848111   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.189435 (* 2 = 0.37887 loss)
I1130 22:50:18.848121   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.22222 (* 1 = 6.22222 loss)
I1130 22:50:18.848134   125 sgd_solver.cpp:180] [0.0] Iteration 4312, lr = 1.73419e-05, m = 0.9, lrm = 0.000173419, wd = 2.5e-07, gs = 1
I1130 22:50:24.321249   125 solver.cpp:333]     [0.0] Iteration 4356 (8.03915 iter/s, 5.47322s/44 iter), 12.1/100ep, loss = 40.0687
I1130 22:50:24.321293   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.4948 (* 2 = 2.98959 loss)
I1130 22:50:24.321305   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 37.079 (* 1 = 37.079 loss)
I1130 22:50:24.321316   125 sgd_solver.cpp:180] [0.0] Iteration 4356, lr = 1.72773e-05, m = 0.9, lrm = 0.000172773, wd = 2.5e-07, gs = 1
I1130 22:50:29.788570   125 solver.cpp:333]     [0.0] Iteration 4400 (8.04778 iter/s, 5.46735s/44 iter), 12.3/100ep, loss = 9.79549
I1130 22:50:29.788753   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.00347 (* 2 = 2.00695 loss)
I1130 22:50:29.788765   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.78852 (* 1 = 7.78852 loss)
I1130 22:50:29.788777   125 sgd_solver.cpp:180] [0.0] Iteration 4400, lr = 1.7213e-05, m = 0.9, lrm = 0.00017213, wd = 2.5e-07, gs = 1
I1130 22:50:35.220475   125 solver.cpp:333]     [0.0] Iteration 4444 (8.10021 iter/s, 5.43196s/44 iter), 12.4/100ep, loss = 32.3299
I1130 22:50:35.220520   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.854566 (* 2 = 1.70913 loss)
I1130 22:50:35.220530   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 30.6207 (* 1 = 30.6207 loss)
I1130 22:50:35.220543   125 sgd_solver.cpp:180] [0.0] Iteration 4444, lr = 1.71489e-05, m = 0.9, lrm = 0.000171488, wd = 2.5e-07, gs = 1
I1130 22:50:40.684643   125 solver.cpp:333]     [0.0] Iteration 4488 (8.05242 iter/s, 5.46419s/44 iter), 12.5/100ep, loss = 14.8342
I1130 22:50:40.684685   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.397685 (* 2 = 0.79537 loss)
I1130 22:50:40.684696   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.0388 (* 1 = 14.0388 loss)
I1130 22:50:40.684710   125 sgd_solver.cpp:180] [0.0] Iteration 4488, lr = 1.7085e-05, m = 0.9, lrm = 0.00017085, wd = 2.5e-07, gs = 1
I1130 22:50:46.099457   125 solver.cpp:333]     [0.0] Iteration 4532 (8.12579 iter/s, 5.41486s/44 iter), 12.6/100ep, loss = 25.7154
I1130 22:50:46.099498   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.684932 (* 2 = 1.36986 loss)
I1130 22:50:46.099509   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 24.3455 (* 1 = 24.3455 loss)
I1130 22:50:46.099521   125 sgd_solver.cpp:180] [0.0] Iteration 4532, lr = 1.70213e-05, m = 0.9, lrm = 0.000170213, wd = 2.5e-07, gs = 1
I1130 22:50:51.478651   125 solver.cpp:333]     [0.0] Iteration 4576 (8.17964 iter/s, 5.37921s/44 iter), 12.7/100ep, loss = 20.5542
I1130 22:50:51.478696   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.730899 (* 2 = 1.4618 loss)
I1130 22:50:51.478708   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 19.0924 (* 1 = 19.0924 loss)
I1130 22:50:51.478720   125 sgd_solver.cpp:180] [0.0] Iteration 4576, lr = 1.69579e-05, m = 0.9, lrm = 0.000169579, wd = 2.5e-07, gs = 1
I1130 22:50:56.849947   125 solver.cpp:333]     [0.0] Iteration 4620 (8.19163 iter/s, 5.37134s/44 iter), 12.9/100ep, loss = 27.0404
I1130 22:50:56.849990   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.707466 (* 2 = 1.41493 loss)
I1130 22:50:56.850003   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 25.6254 (* 1 = 25.6254 loss)
I1130 22:50:56.850013   125 sgd_solver.cpp:180] [0.0] Iteration 4620, lr = 1.68947e-05, m = 0.9, lrm = 0.000168947, wd = 2.5e-07, gs = 1
I1130 22:50:59.052014   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:50:59.164355   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:51:02.235230   125 solver.cpp:333]     [0.0] Iteration 4664 (8.17034 iter/s, 5.38533s/44 iter), 13/100ep, loss = 20.4942
I1130 22:51:02.235440   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.580593 (* 2 = 1.16119 loss)
I1130 22:51:02.235455   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 19.333 (* 1 = 19.333 loss)
I1130 22:51:02.235467   125 sgd_solver.cpp:180] [0.0] Iteration 4664, lr = 1.68318e-05, m = 0.9, lrm = 0.000168318, wd = 2.5e-07, gs = 1
I1130 22:51:02.479359   125 solver.cpp:501] Iteration 4667, Testing net (#0)
I1130 22:51:19.297029   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:51:19.412847   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:51:20.114116   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.615023 (* 2 = 1.23005 loss)
I1130 22:51:20.114159   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 13.6789 (* 1 = 13.6789 loss)
I1130 22:51:20.114168   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 9.06228
I1130 22:51:20.114176   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 16.1169
I1130 22:51:20.114182   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 30.2157
I1130 22:51:20.114215   125 solver.cpp:271] Tests completed in 17.8792s
I1130 22:51:25.226747   125 solver.cpp:333]     [0.0] Iteration 4708 (2.46096 iter/s, 17.8792s/44 iter), 13.1/100ep, loss = 2.86378
I1130 22:51:25.226788   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.17622 (* 2 = 0.35244 loss)
I1130 22:51:25.226799   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.51132 (* 1 = 2.51132 loss)
I1130 22:51:25.226809   125 sgd_solver.cpp:180] [0.0] Iteration 4708, lr = 1.67691e-05, m = 0.9, lrm = 0.000167691, wd = 2.5e-07, gs = 1
I1130 22:51:30.598069   125 solver.cpp:333]     [0.0] Iteration 4752 (8.19163 iter/s, 5.37134s/44 iter), 13.2/100ep, loss = 15.9563
I1130 22:51:30.598111   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.741357 (* 2 = 1.48271 loss)
I1130 22:51:30.598122   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.4735 (* 1 = 14.4735 loss)
I1130 22:51:30.598134   125 sgd_solver.cpp:180] [0.0] Iteration 4752, lr = 1.67066e-05, m = 0.9, lrm = 0.000167066, wd = 2.5e-07, gs = 1
I1130 22:51:35.955281   125 solver.cpp:333]     [0.0] Iteration 4796 (8.21317 iter/s, 5.35725s/44 iter), 13.4/100ep, loss = 22.7463
I1130 22:51:35.955441   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.16396 (* 2 = 2.32791 loss)
I1130 22:51:35.955454   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 20.4184 (* 1 = 20.4184 loss)
I1130 22:51:35.955466   125 sgd_solver.cpp:180] [0.0] Iteration 4796, lr = 1.66444e-05, m = 0.9, lrm = 0.000166444, wd = 2.5e-07, gs = 1
I1130 22:51:41.319036   125 solver.cpp:333]     [0.0] Iteration 4840 (8.20315 iter/s, 5.36379s/44 iter), 13.5/100ep, loss = 24.7973
I1130 22:51:41.319077   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.721729 (* 2 = 1.44346 loss)
I1130 22:51:41.319089   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 23.3539 (* 1 = 23.3539 loss)
I1130 22:51:41.319102   125 sgd_solver.cpp:180] [0.0] Iteration 4840, lr = 1.65824e-05, m = 0.9, lrm = 0.000165824, wd = 2.5e-07, gs = 1
I1130 22:51:46.673391   125 solver.cpp:333]     [0.0] Iteration 4884 (8.21758 iter/s, 5.35438s/44 iter), 13.6/100ep, loss = 16.6494
I1130 22:51:46.673434   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.641289 (* 2 = 1.28258 loss)
I1130 22:51:46.673446   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.3668 (* 1 = 15.3668 loss)
I1130 22:51:46.673457   125 sgd_solver.cpp:180] [0.0] Iteration 4884, lr = 1.65206e-05, m = 0.9, lrm = 0.000165206, wd = 2.5e-07, gs = 1
I1130 22:51:52.025853   125 solver.cpp:333]     [0.0] Iteration 4928 (8.22046 iter/s, 5.3525s/44 iter), 13.7/100ep, loss = 7.84335
I1130 22:51:52.025902   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.489283 (* 2 = 0.978565 loss)
I1130 22:51:52.025913   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.86475 (* 1 = 6.86475 loss)
I1130 22:51:52.025923   125 sgd_solver.cpp:180] [0.0] Iteration 4928, lr = 1.64591e-05, m = 0.9, lrm = 0.000164591, wd = 2.5e-07, gs = 1
I1130 22:51:57.470058   125 solver.cpp:333]     [0.0] Iteration 4972 (8.08199 iter/s, 5.44421s/44 iter), 13.8/100ep, loss = 7.71868
I1130 22:51:57.470113   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.276162 (* 2 = 0.552324 loss)
I1130 22:51:57.470130   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.16632 (* 1 = 7.16632 loss)
I1130 22:51:57.470146   125 sgd_solver.cpp:180] [0.0] Iteration 4972, lr = 1.63978e-05, m = 0.9, lrm = 0.000163978, wd = 2.5e-07, gs = 1
I1130 22:52:00.705902   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:52:00.824226   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:52:02.925415   125 solver.cpp:333]     [0.0] Iteration 5016 (8.0654 iter/s, 5.45541s/44 iter), 14/100ep, loss = 27.6732
I1130 22:52:02.925456   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.17037 (* 2 = 2.34074 loss)
I1130 22:52:02.925467   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 25.3324 (* 1 = 25.3324 loss)
I1130 22:52:02.925477   125 sgd_solver.cpp:180] [0.0] Iteration 5016, lr = 1.63367e-05, m = 0.9, lrm = 0.000163367, wd = 2.5e-07, gs = 1
I1130 22:52:04.048370   125 solver.cpp:501] Iteration 5026, Testing net (#0)
I1130 22:52:20.340881   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:52:20.492429   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:52:21.238927   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.605562 (* 2 = 1.21112 loss)
I1130 22:52:21.238971   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 13.2288 (* 1 = 13.2288 loss)
I1130 22:52:21.238979   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 9.38905
I1130 22:52:21.238987   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 17.0877
I1130 22:52:21.238994   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 32.496
I1130 22:52:21.239027   125 solver.cpp:271] Tests completed in 18.3138s
I1130 22:52:25.519913   125 solver.cpp:333]     [0.0] Iteration 5060 (2.40256 iter/s, 18.3138s/44 iter), 14.1/100ep, loss = 8.98729
I1130 22:52:25.519960   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.504919 (* 2 = 1.00984 loss)
I1130 22:52:25.519971   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.97742 (* 1 = 7.97742 loss)
I1130 22:52:25.519984   125 sgd_solver.cpp:180] [0.0] Iteration 5060, lr = 1.62758e-05, m = 0.9, lrm = 0.000162758, wd = 2.5e-07, gs = 1
I1130 22:52:30.886941   125 solver.cpp:333]     [0.0] Iteration 5104 (8.19815 iter/s, 5.36706s/44 iter), 14.2/100ep, loss = 23.4656
I1130 22:52:30.886986   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.322129 (* 2 = 0.644257 loss)
I1130 22:52:30.886998   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 22.8214 (* 1 = 22.8214 loss)
I1130 22:52:30.887010   125 sgd_solver.cpp:180] [0.0] Iteration 5104, lr = 1.62152e-05, m = 0.9, lrm = 0.000162152, wd = 2.5e-07, gs = 1
I1130 22:52:36.246048   125 solver.cpp:333]     [0.0] Iteration 5148 (8.21027 iter/s, 5.35914s/44 iter), 14.3/100ep, loss = 21.9534
I1130 22:52:36.246093   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.9591 (* 2 = 1.9182 loss)
I1130 22:52:36.246104   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 20.0352 (* 1 = 20.0352 loss)
I1130 22:52:36.246117   125 sgd_solver.cpp:180] [0.0] Iteration 5148, lr = 1.61548e-05, m = 0.9, lrm = 0.000161548, wd = 2.5e-07, gs = 1
I1130 22:52:41.607614   125 solver.cpp:333]     [0.0] Iteration 5192 (8.20655 iter/s, 5.36157s/44 iter), 14.5/100ep, loss = 16.1579
I1130 22:52:41.607656   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.710043 (* 2 = 1.42009 loss)
I1130 22:52:41.607667   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.7378 (* 1 = 14.7378 loss)
I1130 22:52:41.607679   125 sgd_solver.cpp:180] [0.0] Iteration 5192, lr = 1.60946e-05, m = 0.9, lrm = 0.000160946, wd = 2.5e-07, gs = 1
I1130 22:52:46.972424   125 solver.cpp:333]     [0.0] Iteration 5236 (8.20153 iter/s, 5.36485s/44 iter), 14.6/100ep, loss = 18.8987
I1130 22:52:46.972466   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.525354 (* 2 = 1.05071 loss)
I1130 22:52:46.972477   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.8479 (* 1 = 17.8479 loss)
I1130 22:52:46.972491   125 sgd_solver.cpp:180] [0.0] Iteration 5236, lr = 1.60347e-05, m = 0.9, lrm = 0.000160347, wd = 2.5e-07, gs = 1
I1130 22:52:52.335444   125 solver.cpp:333]     [0.0] Iteration 5280 (8.20428 iter/s, 5.36305s/44 iter), 14.7/100ep, loss = 11.3338
I1130 22:52:52.335623   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.359054 (* 2 = 0.718107 loss)
I1130 22:52:52.335636   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.6156 (* 1 = 10.6156 loss)
I1130 22:52:52.335650   125 sgd_solver.cpp:180] [0.0] Iteration 5280, lr = 1.59749e-05, m = 0.9, lrm = 0.000159749, wd = 2.5e-07, gs = 1
I1130 22:52:57.710422   125 solver.cpp:333]     [0.0] Iteration 5324 (8.18606 iter/s, 5.37499s/44 iter), 14.8/100ep, loss = 11.3459
I1130 22:52:57.710464   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.51498 (* 2 = 1.02996 loss)
I1130 22:52:57.710475   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.3159 (* 1 = 10.3159 loss)
I1130 22:52:57.710487   125 sgd_solver.cpp:180] [0.0] Iteration 5324, lr = 1.59154e-05, m = 0.9, lrm = 0.000159154, wd = 2.5e-07, gs = 1
I1130 22:53:01.524950   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:53:01.647349   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:53:03.130919   125 solver.cpp:333]     [0.0] Iteration 5368 (8.11729 iter/s, 5.42053s/44 iter), 15/100ep, loss = 15.1665
I1130 22:53:03.130973   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.715675 (* 2 = 1.43135 loss)
I1130 22:53:03.130991   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.7351 (* 1 = 13.7351 loss)
I1130 22:53:03.131009   125 sgd_solver.cpp:180] [0.0] Iteration 5368, lr = 1.58561e-05, m = 0.9, lrm = 0.000158561, wd = 2.5e-07, gs = 1
I1130 22:53:05.098744   125 solver.cpp:501] Iteration 5385, Testing net (#0)
I1130 22:53:21.472146   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:53:21.583746   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:53:22.356089   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.610949 (* 2 = 1.2219 loss)
I1130 22:53:22.356221   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 12.5975 (* 1 = 12.5975 loss)
I1130 22:53:22.356232   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 11.0521
I1130 22:53:22.356240   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 19.9667
I1130 22:53:22.356247   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 31.5761
I1130 22:53:22.356281   125 solver.cpp:271] Tests completed in 19.2255s
I1130 22:53:25.815024   125 solver.cpp:333]     [0.0] Iteration 5412 (2.28862 iter/s, 19.2255s/44 iter), 15.1/100ep, loss = 14.2154
I1130 22:53:25.815066   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.607591 (* 2 = 1.21518 loss)
I1130 22:53:25.815078   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.0002 (* 1 = 13.0002 loss)
I1130 22:53:25.815091   125 sgd_solver.cpp:180] [0.0] Iteration 5412, lr = 1.57971e-05, m = 0.9, lrm = 0.000157971, wd = 2.5e-07, gs = 1
I1130 22:53:31.199904   125 solver.cpp:333]     [0.0] Iteration 5456 (8.17099 iter/s, 5.38491s/44 iter), 15.2/100ep, loss = 16.7341
I1130 22:53:31.199945   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.841832 (* 2 = 1.68366 loss)
I1130 22:53:31.199959   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.0504 (* 1 = 15.0504 loss)
I1130 22:53:31.199970   125 sgd_solver.cpp:180] [0.0] Iteration 5456, lr = 1.57382e-05, m = 0.9, lrm = 0.000157382, wd = 2.5e-07, gs = 1
I1130 22:53:36.559012   125 solver.cpp:333]     [0.0] Iteration 5500 (8.2103 iter/s, 5.35912s/44 iter), 15.3/100ep, loss = 10.4385
I1130 22:53:36.559053   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.627722 (* 2 = 1.25544 loss)
I1130 22:53:36.559064   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.18305 (* 1 = 9.18305 loss)
I1130 22:53:36.559077   125 sgd_solver.cpp:180] [0.0] Iteration 5500, lr = 1.56796e-05, m = 0.9, lrm = 0.000156796, wd = 2.5e-07, gs = 1
I1130 22:53:41.919785   125 solver.cpp:333]     [0.0] Iteration 5544 (8.20772 iter/s, 5.3608s/44 iter), 15.4/100ep, loss = 13.2005
I1130 22:53:41.919826   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.544556 (* 2 = 1.08911 loss)
I1130 22:53:41.919838   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.1113 (* 1 = 12.1113 loss)
I1130 22:53:41.919849   125 sgd_solver.cpp:180] [0.0] Iteration 5544, lr = 1.56212e-05, m = 0.9, lrm = 0.000156212, wd = 2.5e-07, gs = 1
I1130 22:53:47.284986   125 solver.cpp:333]     [0.0] Iteration 5588 (8.20096 iter/s, 5.36523s/44 iter), 15.6/100ep, loss = 15.0774
I1130 22:53:47.285029   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.17677 (* 2 = 2.35353 loss)
I1130 22:53:47.285040   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.7238 (* 1 = 12.7238 loss)
I1130 22:53:47.285053   125 sgd_solver.cpp:180] [0.0] Iteration 5588, lr = 1.5563e-05, m = 0.9, lrm = 0.00015563, wd = 2.5e-07, gs = 1
I1130 22:53:52.653398   125 solver.cpp:333]     [0.0] Iteration 5632 (8.19609 iter/s, 5.36841s/44 iter), 15.7/100ep, loss = 16.8385
I1130 22:53:52.653570   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.664343 (* 2 = 1.32869 loss)
I1130 22:53:52.653585   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.5098 (* 1 = 15.5098 loss)
I1130 22:53:52.653597   125 sgd_solver.cpp:180] [0.0] Iteration 5632, lr = 1.5505e-05, m = 0.9, lrm = 0.00015505, wd = 2.5e-07, gs = 1
I1130 22:53:58.018168   125 solver.cpp:333]     [0.0] Iteration 5676 (8.2016 iter/s, 5.36481s/44 iter), 15.8/100ep, loss = 6.35468
I1130 22:53:58.018211   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.327385 (* 2 = 0.654771 loss)
I1130 22:53:58.018223   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.69988 (* 1 = 5.69988 loss)
I1130 22:53:58.018234   125 sgd_solver.cpp:180] [0.0] Iteration 5676, lr = 1.54473e-05, m = 0.9, lrm = 0.000154473, wd = 2.5e-07, gs = 1
I1130 22:54:02.785835   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:54:02.904701   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:54:03.396428   125 solver.cpp:333]     [0.0] Iteration 5720 (8.18107 iter/s, 5.37827s/44 iter), 15.9/100ep, loss = 19.0171
I1130 22:54:03.396473   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.88988 (* 2 = 1.77976 loss)
I1130 22:54:03.396486   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.2373 (* 1 = 17.2373 loss)
I1130 22:54:03.396497   125 sgd_solver.cpp:180] [0.0] Iteration 5720, lr = 1.53897e-05, m = 0.9, lrm = 0.000153897, wd = 2.5e-07, gs = 1
I1130 22:54:06.201440   125 solver.cpp:501] Iteration 5744, Testing net (#0)
I1130 22:54:22.343297   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:54:22.495301   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:54:23.320003   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.587781 (* 2 = 1.17556 loss)
I1130 22:54:23.320206   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 12.0232 (* 1 = 12.0232 loss)
I1130 22:54:23.320219   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 10.0101
I1130 22:54:23.320226   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 18.9755
I1130 22:54:23.320232   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 35.0508
I1130 22:54:23.320267   125 solver.cpp:271] Tests completed in 19.924s
I1130 22:54:25.880170   125 solver.cpp:333]     [0.0] Iteration 5764 (2.20839 iter/s, 19.924s/44 iter), 16.1/100ep, loss = 8.81557
I1130 22:54:25.880210   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.4781 (* 2 = 0.9562 loss)
I1130 22:54:25.880220   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.85934 (* 1 = 7.85934 loss)
I1130 22:54:25.880234   125 sgd_solver.cpp:180] [0.0] Iteration 5764, lr = 1.53324e-05, m = 0.9, lrm = 0.000153324, wd = 2.5e-07, gs = 1
I1130 22:54:31.249270   125 solver.cpp:333]     [0.0] Iteration 5808 (8.195 iter/s, 5.36913s/44 iter), 16.2/100ep, loss = 4.22933
I1130 22:54:31.249313   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.183258 (* 2 = 0.366517 loss)
I1130 22:54:31.249325   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.86278 (* 1 = 3.86278 loss)
I1130 22:54:31.249336   125 sgd_solver.cpp:180] [0.0] Iteration 5808, lr = 1.52753e-05, m = 0.9, lrm = 0.000152753, wd = 2.5e-07, gs = 1
I1130 22:54:36.623011   125 solver.cpp:333]     [0.0] Iteration 5852 (8.18796 iter/s, 5.37374s/44 iter), 16.3/100ep, loss = 12.8042
I1130 22:54:36.623054   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.685375 (* 2 = 1.37075 loss)
I1130 22:54:36.623065   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.4334 (* 1 = 11.4334 loss)
I1130 22:54:36.623078   125 sgd_solver.cpp:180] [0.0] Iteration 5852, lr = 1.52184e-05, m = 0.9, lrm = 0.000152184, wd = 2.5e-07, gs = 1
I1130 22:54:41.996690   125 solver.cpp:333]     [0.0] Iteration 5896 (8.18801 iter/s, 5.37371s/44 iter), 16.4/100ep, loss = 10.3003
I1130 22:54:41.996729   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.45513 (* 2 = 2.91025 loss)
I1130 22:54:41.996739   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.39006 (* 1 = 7.39006 loss)
I1130 22:54:41.996752   125 sgd_solver.cpp:180] [0.0] Iteration 5896, lr = 1.51617e-05, m = 0.9, lrm = 0.000151617, wd = 2.5e-07, gs = 1
I1130 22:54:47.362895   125 solver.cpp:333]     [0.0] Iteration 5940 (8.19942 iter/s, 5.36623s/44 iter), 16.5/100ep, loss = 8.62446
I1130 22:54:47.362936   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.934165 (* 2 = 1.86833 loss)
I1130 22:54:47.362948   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.7561 (* 1 = 6.7561 loss)
I1130 22:54:47.362960   125 sgd_solver.cpp:180] [0.0] Iteration 5940, lr = 1.51052e-05, m = 0.9, lrm = 0.000151052, wd = 2.5e-07, gs = 1
I1130 22:54:52.728790   125 solver.cpp:333]     [0.0] Iteration 5984 (8.19996 iter/s, 5.36588s/44 iter), 16.7/100ep, loss = 12.8403
I1130 22:54:52.728832   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.692536 (* 2 = 1.38507 loss)
I1130 22:54:52.728842   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.4552 (* 1 = 11.4552 loss)
I1130 22:54:52.728854   125 sgd_solver.cpp:180] [0.0] Iteration 5984, lr = 1.50489e-05, m = 0.9, lrm = 0.000150489, wd = 2.5e-07, gs = 1
I1130 22:54:58.091655   125 solver.cpp:333]     [0.0] Iteration 6028 (8.20454 iter/s, 5.36288s/44 iter), 16.8/100ep, loss = 12.3163
I1130 22:54:58.091820   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.809299 (* 2 = 1.6186 loss)
I1130 22:54:58.091835   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.6977 (* 1 = 10.6977 loss)
I1130 22:54:58.091848   125 sgd_solver.cpp:180] [0.0] Iteration 6028, lr = 1.49929e-05, m = 0.9, lrm = 0.000149929, wd = 2.5e-07, gs = 1
I1130 22:55:03.461689   125 solver.cpp:333]     [0.0] Iteration 6072 (8.19359 iter/s, 5.37005s/44 iter), 16.9/100ep, loss = 11.5127
I1130 22:55:03.461730   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.755477 (* 2 = 1.51095 loss)
I1130 22:55:03.461742   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.0017 (* 1 = 10.0017 loss)
I1130 22:55:03.461755   125 sgd_solver.cpp:180] [0.0] Iteration 6072, lr = 1.4937e-05, m = 0.9, lrm = 0.00014937, wd = 2.5e-07, gs = 1
I1130 22:55:03.832695   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:55:03.950752   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:55:07.120822   125 solver.cpp:501] Iteration 6103, Testing net (#0)
I1130 22:55:23.410629   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:55:23.523783   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:55:24.374748   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.589009 (* 2 = 1.17802 loss)
I1130 22:55:24.374788   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 11.6276 (* 1 = 11.6276 loss)
I1130 22:55:24.374796   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 12.8652
I1130 22:55:24.374804   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 23.4909
I1130 22:55:24.374810   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 36.7391
I1130 22:55:24.374843   125 solver.cpp:271] Tests completed in 20.9133s
I1130 22:55:26.080672   125 solver.cpp:333]     [0.0] Iteration 6116 (2.10392 iter/s, 20.9133s/44 iter), 17/100ep, loss = 7.56699
I1130 22:55:26.080714   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.414987 (* 2 = 0.829974 loss)
I1130 22:55:26.080725   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.73699 (* 1 = 6.73699 loss)
I1130 22:55:26.080736   125 sgd_solver.cpp:180] [0.0] Iteration 6116, lr = 1.48814e-05, m = 0.9, lrm = 0.000148814, wd = 2.5e-07, gs = 1
I1130 22:55:31.449026   125 solver.cpp:333]     [0.0] Iteration 6160 (8.19619 iter/s, 5.36835s/44 iter), 17.2/100ep, loss = 6.30674
I1130 22:55:31.449211   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.680709 (* 2 = 1.36142 loss)
I1130 22:55:31.449225   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.94529 (* 1 = 4.94529 loss)
I1130 22:55:31.449237   125 sgd_solver.cpp:180] [0.0] Iteration 6160, lr = 1.48259e-05, m = 0.9, lrm = 0.000148259, wd = 2.5e-07, gs = 1
I1130 22:55:36.815508   125 solver.cpp:333]     [0.0] Iteration 6204 (8.19899 iter/s, 5.36652s/44 iter), 17.3/100ep, loss = 18.0121
I1130 22:55:36.815548   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.5056 (* 2 = 3.01119 loss)
I1130 22:55:36.815559   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.0008 (* 1 = 15.0008 loss)
I1130 22:55:36.815570   125 sgd_solver.cpp:180] [0.0] Iteration 6204, lr = 1.47707e-05, m = 0.9, lrm = 0.000147707, wd = 2.5e-07, gs = 1
I1130 22:55:42.176795   125 solver.cpp:333]     [0.0] Iteration 6248 (8.20695 iter/s, 5.36131s/44 iter), 17.4/100ep, loss = 15.7982
I1130 22:55:42.176836   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.745647 (* 2 = 1.49129 loss)
I1130 22:55:42.176848   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.3068 (* 1 = 14.3068 loss)
I1130 22:55:42.176861   125 sgd_solver.cpp:180] [0.0] Iteration 6248, lr = 1.47157e-05, m = 0.9, lrm = 0.000147157, wd = 2.5e-07, gs = 1
I1130 22:55:47.539182   125 solver.cpp:333]     [0.0] Iteration 6292 (8.20529 iter/s, 5.36239s/44 iter), 17.5/100ep, loss = 17.0564
I1130 22:55:47.539227   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.993877 (* 2 = 1.98775 loss)
I1130 22:55:47.539238   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.0686 (* 1 = 15.0686 loss)
I1130 22:55:47.539249   125 sgd_solver.cpp:180] [0.0] Iteration 6292, lr = 1.46609e-05, m = 0.9, lrm = 0.000146609, wd = 2.5e-07, gs = 1
I1130 22:55:52.897483   125 solver.cpp:333]     [0.0] Iteration 6336 (8.21152 iter/s, 5.35832s/44 iter), 17.6/100ep, loss = 13.9569
I1130 22:55:52.897526   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.744338 (* 2 = 1.48868 loss)
I1130 22:55:52.897537   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.4682 (* 1 = 12.4682 loss)
I1130 22:55:52.897549   125 sgd_solver.cpp:180] [0.0] Iteration 6336, lr = 1.46063e-05, m = 0.9, lrm = 0.000146063, wd = 2.5e-07, gs = 1
I1130 22:55:58.258632   125 solver.cpp:333]     [0.0] Iteration 6380 (8.20716 iter/s, 5.36117s/44 iter), 17.8/100ep, loss = 14.5314
I1130 22:55:58.258675   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.13585 (* 2 = 2.27171 loss)
I1130 22:55:58.258687   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.2596 (* 1 = 12.2596 loss)
I1130 22:55:58.258698   125 sgd_solver.cpp:180] [0.0] Iteration 6380, lr = 1.45518e-05, m = 0.9, lrm = 0.000145518, wd = 2.5e-07, gs = 1
I1130 22:56:03.629855   125 solver.cpp:333]     [0.0] Iteration 6424 (8.1918 iter/s, 5.37123s/44 iter), 17.9/100ep, loss = 8.94931
I1130 22:56:03.630050   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.952307 (* 2 = 1.90461 loss)
I1130 22:56:03.630064   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.04467 (* 1 = 7.04467 loss)
I1130 22:56:03.630077   125 sgd_solver.cpp:180] [0.0] Iteration 6424, lr = 1.44976e-05, m = 0.9, lrm = 0.000144976, wd = 2.5e-07, gs = 1
I1130 22:56:04.605741   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:56:04.730723   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:56:08.139416   125 solver.cpp:501] Iteration 6462, Testing net (#0)
I1130 22:56:24.211220   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:56:24.363586   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:56:25.282703   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.637678 (* 2 = 1.27536 loss)
I1130 22:56:25.282747   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 10.8203 (* 1 = 10.8203 loss)
I1130 22:56:25.282757   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 16.5086
I1130 22:56:25.282764   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 34.4258
I1130 22:56:25.282770   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 30.3815
I1130 22:56:25.282805   125 solver.cpp:271] Tests completed in 21.6531s
I1130 22:56:26.139746   125 solver.cpp:333]     [0.0] Iteration 6468 (2.03204 iter/s, 21.6531s/44 iter), 18/100ep, loss = 15.9606
I1130 22:56:26.139788   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.32107 (* 2 = 2.64214 loss)
I1130 22:56:26.139799   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.3185 (* 1 = 13.3185 loss)
I1130 22:56:26.139811   125 sgd_solver.cpp:180] [0.0] Iteration 6468, lr = 1.44436e-05, m = 0.9, lrm = 0.000144436, wd = 2.5e-07, gs = 1
I1130 22:56:31.504443   125 solver.cpp:333]     [0.0] Iteration 6512 (8.20177 iter/s, 5.3647s/44 iter), 18.1/100ep, loss = 14.7833
I1130 22:56:31.504487   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.565366 (* 2 = 1.13073 loss)
I1130 22:56:31.504498   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.6525 (* 1 = 13.6525 loss)
I1130 22:56:31.504511   125 sgd_solver.cpp:180] [0.0] Iteration 6512, lr = 1.43898e-05, m = 0.9, lrm = 0.000143898, wd = 2.5e-07, gs = 1
I1130 22:56:36.873306   125 solver.cpp:333]     [0.0] Iteration 6556 (8.19536 iter/s, 5.36889s/44 iter), 18.3/100ep, loss = 7.64933
I1130 22:56:36.873481   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.311569 (* 2 = 0.623139 loss)
I1130 22:56:36.873494   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.02616 (* 1 = 7.02616 loss)
I1130 22:56:36.873507   125 sgd_solver.cpp:180] [0.0] Iteration 6556, lr = 1.43362e-05, m = 0.9, lrm = 0.000143362, wd = 2.5e-07, gs = 1
I1130 22:56:42.243377   125 solver.cpp:333]     [0.0] Iteration 6600 (8.19353 iter/s, 5.37009s/44 iter), 18.4/100ep, loss = 4.24543
I1130 22:56:42.243422   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.30767 (* 2 = 0.61534 loss)
I1130 22:56:42.243432   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.63007 (* 1 = 3.63007 loss)
I1130 22:56:42.243443   125 sgd_solver.cpp:180] [0.0] Iteration 6600, lr = 1.42828e-05, m = 0.9, lrm = 0.000142828, wd = 2.5e-07, gs = 1
I1130 22:56:47.609592   125 solver.cpp:333]     [0.0] Iteration 6644 (8.19943 iter/s, 5.36623s/44 iter), 18.5/100ep, loss = 19.1018
I1130 22:56:47.609637   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.885597 (* 2 = 1.77119 loss)
I1130 22:56:47.609648   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.3306 (* 1 = 17.3306 loss)
I1130 22:56:47.609660   125 sgd_solver.cpp:180] [0.0] Iteration 6644, lr = 1.42296e-05, m = 0.9, lrm = 0.000142296, wd = 2.5e-07, gs = 1
I1130 22:56:52.998354   125 solver.cpp:333]     [0.0] Iteration 6688 (8.16511 iter/s, 5.38878s/44 iter), 18.6/100ep, loss = 19.8395
I1130 22:56:52.998396   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.07239 (* 2 = 2.14478 loss)
I1130 22:56:52.998407   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 17.6947 (* 1 = 17.6947 loss)
I1130 22:56:52.998420   125 sgd_solver.cpp:180] [0.0] Iteration 6688, lr = 1.41766e-05, m = 0.9, lrm = 0.000141766, wd = 2.5e-07, gs = 1
I1130 22:56:58.365345   125 solver.cpp:333]     [0.0] Iteration 6732 (8.19823 iter/s, 5.36701s/44 iter), 18.8/100ep, loss = 6.10109
I1130 22:56:58.365388   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.941617 (* 2 = 1.88323 loss)
I1130 22:56:58.365399   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.21783 (* 1 = 4.21783 loss)
I1130 22:56:58.365411   125 sgd_solver.cpp:180] [0.0] Iteration 6732, lr = 1.41238e-05, m = 0.9, lrm = 0.000141238, wd = 2.5e-07, gs = 1
I1130 22:57:03.735024   125 solver.cpp:333]     [0.0] Iteration 6776 (8.19415 iter/s, 5.36968s/44 iter), 18.9/100ep, loss = 8.94764
I1130 22:57:03.735064   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.512749 (* 2 = 1.0255 loss)
I1130 22:57:03.735075   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.92212 (* 1 = 7.92212 loss)
I1130 22:57:03.735086   125 sgd_solver.cpp:180] [0.0] Iteration 6776, lr = 1.40712e-05, m = 0.9, lrm = 0.000140712, wd = 2.5e-07, gs = 1
I1130 22:57:05.688608   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:57:05.803710   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:57:09.096462   125 solver.cpp:333]     [0.0] Iteration 6820 (8.20671 iter/s, 5.36147s/44 iter), 19/100ep, loss = 16.8157
I1130 22:57:09.096635   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.721224 (* 2 = 1.44245 loss)
I1130 22:57:09.096649   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.3732 (* 1 = 15.3732 loss)
I1130 22:57:09.096660   125 sgd_solver.cpp:180] [0.0] Iteration 6820, lr = 1.40188e-05, m = 0.9, lrm = 0.000140188, wd = 2.5e-07, gs = 1
I1130 22:57:09.096673   125 solver.cpp:501] Iteration 6821, Testing net (#0)
I1130 22:57:25.101928   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:57:25.216135   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:57:26.151489   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.658377 (* 2 = 1.31675 loss)
I1130 22:57:26.151526   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 9.98635 (* 1 = 9.98635 loss)
I1130 22:57:26.151535   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 15.2386
I1130 22:57:26.151543   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 32.1332
I1130 22:57:26.151551   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 27.3941
I1130 22:57:26.151583   125 solver.cpp:271] Tests completed in 17.0552s
I1130 22:57:31.521359   125 solver.cpp:333]     [0.0] Iteration 6864 (2.57985 iter/s, 17.0552s/44 iter), 19.1/100ep, loss = 9.66231
I1130 22:57:31.521401   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.646674 (* 2 = 1.29335 loss)
I1130 22:57:31.521414   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.36894 (* 1 = 8.36894 loss)
I1130 22:57:31.521425   125 sgd_solver.cpp:180] [0.0] Iteration 6864, lr = 1.39665e-05, m = 0.9, lrm = 0.000139665, wd = 2.5e-07, gs = 1
I1130 22:57:36.959457   125 solver.cpp:333]     [0.0] Iteration 6908 (8.09102 iter/s, 5.43813s/44 iter), 19.2/100ep, loss = 2.25922
I1130 22:57:36.959501   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.301721 (* 2 = 0.603442 loss)
I1130 22:57:36.959511   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.65576 (* 1 = 1.65576 loss)
I1130 22:57:36.959522   125 sgd_solver.cpp:180] [0.0] Iteration 6908, lr = 1.39145e-05, m = 0.9, lrm = 0.000139145, wd = 2.5e-07, gs = 1
I1130 22:57:42.413071   125 solver.cpp:333]     [0.0] Iteration 6952 (8.06804 iter/s, 5.45362s/44 iter), 19.4/100ep, loss = 8.86802
I1130 22:57:42.413238   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.457286 (* 2 = 0.914572 loss)
I1130 22:57:42.413251   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.95342 (* 1 = 7.95342 loss)
I1130 22:57:42.413264   125 sgd_solver.cpp:180] [0.0] Iteration 6952, lr = 1.38627e-05, m = 0.9, lrm = 0.000138627, wd = 2.5e-07, gs = 1
I1130 22:57:47.867946   125 solver.cpp:333]     [0.0] Iteration 6996 (8.06617 iter/s, 5.45488s/44 iter), 19.5/100ep, loss = 10.7028
I1130 22:57:47.868026   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.663722 (* 2 = 1.32744 loss)
I1130 22:57:47.868046   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.37531 (* 1 = 9.37531 loss)
I1130 22:57:47.868063   125 sgd_solver.cpp:180] [0.0] Iteration 6996, lr = 1.3811e-05, m = 0.9, lrm = 0.00013811, wd = 2.5e-07, gs = 1
I1130 22:57:53.324173   125 solver.cpp:333]     [0.0] Iteration 7040 (8.06415 iter/s, 5.45625s/44 iter), 19.6/100ep, loss = 5.69035
I1130 22:57:53.324234   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.394051 (* 2 = 0.788103 loss)
I1130 22:57:53.324250   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.90222 (* 1 = 4.90222 loss)
I1130 22:57:53.324267   125 sgd_solver.cpp:180] [0.0] Iteration 7040, lr = 1.37596e-05, m = 0.9, lrm = 0.000137596, wd = 2.5e-07, gs = 1
I1130 22:57:58.712903   125 solver.cpp:333]     [0.0] Iteration 7084 (8.16516 iter/s, 5.38875s/44 iter), 19.7/100ep, loss = 6.51125
I1130 22:57:58.712947   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.453569 (* 2 = 0.907138 loss)
I1130 22:57:58.712957   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.60409 (* 1 = 5.60409 loss)
I1130 22:57:58.712968   125 sgd_solver.cpp:180] [0.0] Iteration 7084, lr = 1.37083e-05, m = 0.9, lrm = 0.000137083, wd = 2.5e-07, gs = 1
I1130 22:58:04.071619   125 solver.cpp:333]     [0.0] Iteration 7128 (8.21089 iter/s, 5.35874s/44 iter), 19.9/100ep, loss = 5.24859
I1130 22:58:04.071661   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.484049 (* 2 = 0.968097 loss)
I1130 22:58:04.071672   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.28047 (* 1 = 4.28047 loss)
I1130 22:58:04.071686   125 sgd_solver.cpp:180] [0.0] Iteration 7128, lr = 1.36573e-05, m = 0.9, lrm = 0.000136573, wd = 2.5e-07, gs = 1
I1130 22:58:06.995441   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:58:07.117389   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:58:09.432884   125 solver.cpp:333]     [0.0] Iteration 7172 (8.20701 iter/s, 5.36127s/44 iter), 20/100ep, loss = 13.4248
I1130 22:58:09.432926   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.36831 (* 2 = 2.73663 loss)
I1130 22:58:09.432937   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.6882 (* 1 = 10.6882 loss)
I1130 22:58:09.432948   125 sgd_solver.cpp:180] [0.0] Iteration 7172, lr = 1.36064e-05, m = 0.9, lrm = 0.000136064, wd = 2.5e-07, gs = 1
I1130 22:58:10.285976   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_7180.caffemodel
I1130 22:58:10.338718   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_7180.solverstate
I1130 22:58:10.381461   125 solver.cpp:501] Iteration 7180, Testing net (#0)
I1130 22:58:26.365303   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:58:26.516609   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:58:27.513645   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.649406 (* 2 = 1.29881 loss)
I1130 22:58:27.513686   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 9.76888 (* 1 = 9.76888 loss)
I1130 22:58:27.513695   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 15.6754
I1130 22:58:27.513703   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 35.2263
I1130 22:58:27.513710   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 27.5414
I1130 22:58:27.513743   125 solver.cpp:271] Tests completed in 18.081s
I1130 22:58:32.034368   125 solver.cpp:333]     [0.0] Iteration 7216 (2.4335 iter/s, 18.081s/44 iter), 20.1/100ep, loss = 19.1479
I1130 22:58:32.034407   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.44787 (* 2 = 2.89573 loss)
I1130 22:58:32.034417   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 16.2521 (* 1 = 16.2521 loss)
I1130 22:58:32.034430   125 sgd_solver.cpp:180] [0.0] Iteration 7216, lr = 1.35557e-05, m = 0.9, lrm = 0.000135557, wd = 2.5e-07, gs = 1
I1130 22:58:37.397456   125 solver.cpp:333]     [0.0] Iteration 7260 (8.20423 iter/s, 5.36309s/44 iter), 20.2/100ep, loss = 8.82731
I1130 22:58:37.397497   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.66351 (* 2 = 3.32702 loss)
I1130 22:58:37.397507   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.50026 (* 1 = 5.50026 loss)
I1130 22:58:37.397519   125 sgd_solver.cpp:180] [0.0] Iteration 7260, lr = 1.35052e-05, m = 0.9, lrm = 0.000135052, wd = 2.5e-07, gs = 1
I1130 22:58:42.768084   125 solver.cpp:333]     [0.0] Iteration 7304 (8.19268 iter/s, 5.37065s/44 iter), 20.3/100ep, loss = 14.2454
I1130 22:58:42.768123   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.774469 (* 2 = 1.54894 loss)
I1130 22:58:42.768134   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.6965 (* 1 = 12.6965 loss)
I1130 22:58:42.768147   125 sgd_solver.cpp:180] [0.0] Iteration 7304, lr = 1.34549e-05, m = 0.9, lrm = 0.000134549, wd = 2.5e-07, gs = 1
I1130 22:58:48.128296   125 solver.cpp:333]     [0.0] Iteration 7348 (8.2086 iter/s, 5.36023s/44 iter), 20.5/100ep, loss = 9.59527
I1130 22:58:48.128337   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.512088 (* 2 = 1.02418 loss)
I1130 22:58:48.128348   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.57107 (* 1 = 8.57107 loss)
I1130 22:58:48.128360   125 sgd_solver.cpp:180] [0.0] Iteration 7348, lr = 1.34048e-05, m = 0.9, lrm = 0.000134048, wd = 2.5e-07, gs = 1
I1130 22:58:53.487304   125 solver.cpp:333]     [0.0] Iteration 7392 (8.21047 iter/s, 5.35901s/44 iter), 20.6/100ep, loss = 12.8308
I1130 22:58:53.487345   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.20632 (* 2 = 2.41265 loss)
I1130 22:58:53.487355   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.4182 (* 1 = 10.4182 loss)
I1130 22:58:53.487367   125 sgd_solver.cpp:180] [0.0] Iteration 7392, lr = 1.33548e-05, m = 0.9, lrm = 0.000133548, wd = 2.5e-07, gs = 1
I1130 22:58:58.841851   125 solver.cpp:333]     [0.0] Iteration 7436 (8.2173 iter/s, 5.35456s/44 iter), 20.7/100ep, loss = 8.62389
I1130 22:58:58.841991   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.476174 (* 2 = 0.952348 loss)
I1130 22:58:58.842005   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.67152 (* 1 = 7.67152 loss)
I1130 22:58:58.842016   125 sgd_solver.cpp:180] [0.0] Iteration 7436, lr = 1.33051e-05, m = 0.9, lrm = 0.000133051, wd = 2.5e-07, gs = 1
I1130 22:59:04.196848   125 solver.cpp:333]     [0.0] Iteration 7480 (8.21659 iter/s, 5.35502s/44 iter), 20.8/100ep, loss = 16.6597
I1130 22:59:04.196890   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.798558 (* 2 = 1.59712 loss)
I1130 22:59:04.196902   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.0626 (* 1 = 15.0626 loss)
I1130 22:59:04.196914   125 sgd_solver.cpp:180] [0.0] Iteration 7480, lr = 1.32555e-05, m = 0.9, lrm = 0.000132555, wd = 2.5e-07, gs = 1
I1130 22:59:07.734818   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:59:07.854266   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:59:09.559744   125 solver.cpp:333]     [0.0] Iteration 7524 (8.20452 iter/s, 5.3629s/44 iter), 21/100ep, loss = 9.78931
I1130 22:59:09.559784   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.512044 (* 2 = 1.02409 loss)
I1130 22:59:09.559795   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.7652 (* 1 = 8.7652 loss)
I1130 22:59:09.559808   125 sgd_solver.cpp:180] [0.0] Iteration 7524, lr = 1.32061e-05, m = 0.9, lrm = 0.000132061, wd = 2.5e-07, gs = 1
I1130 22:59:11.265693   125 solver.cpp:501] Iteration 7539, Testing net (#0)
I1130 22:59:27.248067   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:59:27.362329   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 22:59:28.372484   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.63954 (* 2 = 1.27908 loss)
I1130 22:59:28.372521   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 9.47847 (* 1 = 9.47847 loss)
I1130 22:59:28.372530   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 15.5833
I1130 22:59:28.372539   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 33.3227
I1130 22:59:28.372545   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 26.3137
I1130 22:59:28.372578   125 solver.cpp:271] Tests completed in 18.813s
I1130 22:59:32.032155   125 solver.cpp:333]     [0.0] Iteration 7568 (2.33881 iter/s, 18.813s/44 iter), 21.1/100ep, loss = 5.246
I1130 22:59:32.032335   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.527931 (* 2 = 1.05586 loss)
I1130 22:59:32.032348   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.19011 (* 1 = 4.19011 loss)
I1130 22:59:32.032361   125 sgd_solver.cpp:180] [0.0] Iteration 7568, lr = 1.3157e-05, m = 0.9, lrm = 0.00013157, wd = 2.5e-07, gs = 1
I1130 22:59:37.403594   125 solver.cpp:333]     [0.0] Iteration 7612 (8.19147 iter/s, 5.37144s/44 iter), 21.2/100ep, loss = 10.5202
I1130 22:59:37.403635   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.710948 (* 2 = 1.4219 loss)
I1130 22:59:37.403646   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.09826 (* 1 = 9.09826 loss)
I1130 22:59:37.403657   125 sgd_solver.cpp:180] [0.0] Iteration 7612, lr = 1.31079e-05, m = 0.9, lrm = 0.000131079, wd = 2.5e-07, gs = 1
I1130 22:59:42.769558   125 solver.cpp:333]     [0.0] Iteration 7656 (8.19981 iter/s, 5.36597s/44 iter), 21.3/100ep, loss = 7.76198
I1130 22:59:42.769598   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.830009 (* 2 = 1.66002 loss)
I1130 22:59:42.769610   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.10193 (* 1 = 6.10193 loss)
I1130 22:59:42.769621   125 sgd_solver.cpp:180] [0.0] Iteration 7656, lr = 1.30591e-05, m = 0.9, lrm = 0.000130591, wd = 2.5e-07, gs = 1
I1130 22:59:48.135097   125 solver.cpp:333]     [0.0] Iteration 7700 (8.20046 iter/s, 5.36555s/44 iter), 21.4/100ep, loss = 8.72989
I1130 22:59:48.135138   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.10094 (* 2 = 2.20188 loss)
I1130 22:59:48.135149   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.52799 (* 1 = 6.52799 loss)
I1130 22:59:48.135159   125 sgd_solver.cpp:180] [0.0] Iteration 7700, lr = 1.30105e-05, m = 0.9, lrm = 0.000130105, wd = 2.5e-07, gs = 1
I1130 22:59:53.499044   125 solver.cpp:333]     [0.0] Iteration 7744 (8.2029 iter/s, 5.36395s/44 iter), 21.6/100ep, loss = 10.3264
I1130 22:59:53.499083   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.750392 (* 2 = 1.50078 loss)
I1130 22:59:53.499095   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.82562 (* 1 = 8.82562 loss)
I1130 22:59:53.499106   125 sgd_solver.cpp:180] [0.0] Iteration 7744, lr = 1.2962e-05, m = 0.9, lrm = 0.00012962, wd = 2.5e-07, gs = 1
I1130 22:59:58.863312   125 solver.cpp:333]     [0.0] Iteration 7788 (8.20241 iter/s, 5.36428s/44 iter), 21.7/100ep, loss = 7.26737
I1130 22:59:58.863354   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.440634 (* 2 = 0.881269 loss)
I1130 22:59:58.863365   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.38607 (* 1 = 6.38607 loss)
I1130 22:59:58.863376   125 sgd_solver.cpp:180] [0.0] Iteration 7788, lr = 1.29137e-05, m = 0.9, lrm = 0.000129137, wd = 2.5e-07, gs = 1
I1130 23:00:04.230401   125 solver.cpp:333]     [0.0] Iteration 7832 (8.19811 iter/s, 5.36709s/44 iter), 21.8/100ep, loss = 12.255
I1130 23:00:04.230592   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.923742 (* 2 = 1.84748 loss)
I1130 23:00:04.230608   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.4075 (* 1 = 10.4075 loss)
I1130 23:00:04.230620   125 sgd_solver.cpp:180] [0.0] Iteration 7832, lr = 1.28656e-05, m = 0.9, lrm = 0.000128656, wd = 2.5e-07, gs = 1
I1130 23:00:08.739612   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:00:08.855217   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:00:09.590832   125 solver.cpp:333]     [0.0] Iteration 7876 (8.20828 iter/s, 5.36044s/44 iter), 21.9/100ep, loss = 18.3998
I1130 23:00:09.590873   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.42111 (* 2 = 2.84223 loss)
I1130 23:00:09.590884   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.5575 (* 1 = 15.5575 loss)
I1130 23:00:09.590895   125 sgd_solver.cpp:180] [0.0] Iteration 7876, lr = 1.28177e-05, m = 0.9, lrm = 0.000128177, wd = 2.5e-07, gs = 1
I1130 23:00:12.152985   125 solver.cpp:501] Iteration 7898, Testing net (#0)
I1130 23:00:28.137115   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:00:28.289155   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:00:29.371285   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.627743 (* 2 = 1.25549 loss)
I1130 23:00:29.371325   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 9.40856 (* 1 = 9.40856 loss)
I1130 23:00:29.371332   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.0449
I1130 23:00:29.371340   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 36.7951
I1130 23:00:29.371347   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 30.0758
I1130 23:00:29.371381   125 solver.cpp:271] Tests completed in 19.7807s
I1130 23:00:32.176990   125 solver.cpp:333]     [0.0] Iteration 7920 (2.22439 iter/s, 19.7807s/44 iter), 22.1/100ep, loss = 4.50931
I1130 23:00:32.177032   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.765426 (* 2 = 1.53085 loss)
I1130 23:00:32.177043   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.97843 (* 1 = 2.97843 loss)
I1130 23:00:32.177057   125 sgd_solver.cpp:180] [0.0] Iteration 7920, lr = 1.27699e-05, m = 0.9, lrm = 0.000127699, wd = 2.5e-07, gs = 1
I1130 23:00:37.541942   125 solver.cpp:333]     [0.0] Iteration 7964 (8.20138 iter/s, 5.36495s/44 iter), 22.2/100ep, loss = 12.4034
I1130 23:00:37.542104   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.970064 (* 2 = 1.94013 loss)
I1130 23:00:37.542117   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.4632 (* 1 = 10.4632 loss)
I1130 23:00:37.542130   125 sgd_solver.cpp:180] [0.0] Iteration 7964, lr = 1.27224e-05, m = 0.9, lrm = 0.000127224, wd = 2.5e-07, gs = 1
I1130 23:00:42.909816   125 solver.cpp:333]     [0.0] Iteration 8008 (8.19689 iter/s, 5.36789s/44 iter), 22.3/100ep, loss = 14.2433
I1130 23:00:42.909858   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.04938 (* 2 = 2.09876 loss)
I1130 23:00:42.909868   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.1445 (* 1 = 12.1445 loss)
I1130 23:00:42.909881   125 sgd_solver.cpp:180] [0.0] Iteration 8008, lr = 1.2675e-05, m = 0.9, lrm = 0.00012675, wd = 2.5e-07, gs = 1
I1130 23:00:48.271443   125 solver.cpp:333]     [0.0] Iteration 8052 (8.20644 iter/s, 5.36165s/44 iter), 22.4/100ep, loss = 9.55893
I1130 23:00:48.271484   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.39568 (* 2 = 2.79136 loss)
I1130 23:00:48.271497   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.76753 (* 1 = 6.76753 loss)
I1130 23:00:48.271508   125 sgd_solver.cpp:180] [0.0] Iteration 8052, lr = 1.26278e-05, m = 0.9, lrm = 0.000126278, wd = 2.5e-07, gs = 1
I1130 23:00:53.628304   125 solver.cpp:333]     [0.0] Iteration 8096 (8.21378 iter/s, 5.35685s/44 iter), 22.6/100ep, loss = 8.27404
I1130 23:00:53.628347   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.740701 (* 2 = 1.4814 loss)
I1130 23:00:53.628358   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.7926 (* 1 = 6.7926 loss)
I1130 23:00:53.628371   125 sgd_solver.cpp:180] [0.0] Iteration 8096, lr = 1.25807e-05, m = 0.9, lrm = 0.000125807, wd = 2.5e-07, gs = 1
I1130 23:00:58.985160   125 solver.cpp:333]     [0.0] Iteration 8140 (8.21374 iter/s, 5.35688s/44 iter), 22.7/100ep, loss = 8.95094
I1130 23:00:58.985201   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.483117 (* 2 = 0.966233 loss)
I1130 23:00:58.985213   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.98468 (* 1 = 7.98468 loss)
I1130 23:00:58.985224   125 sgd_solver.cpp:180] [0.0] Iteration 8140, lr = 1.25338e-05, m = 0.9, lrm = 0.000125338, wd = 2.5e-07, gs = 1
I1130 23:01:04.353266   125 solver.cpp:333]     [0.0] Iteration 8184 (8.19656 iter/s, 5.36811s/44 iter), 22.8/100ep, loss = 17.2932
I1130 23:01:04.353307   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.86425 (* 2 = 1.7285 loss)
I1130 23:01:04.353318   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.5647 (* 1 = 15.5647 loss)
I1130 23:01:04.353332   125 sgd_solver.cpp:180] [0.0] Iteration 8184, lr = 1.24872e-05, m = 0.9, lrm = 0.000124872, wd = 2.5e-07, gs = 1
I1130 23:01:09.715896   125 solver.cpp:333]     [0.0] Iteration 8228 (8.20492 iter/s, 5.36264s/44 iter), 22.9/100ep, loss = 10.8139
I1130 23:01:09.716084   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.662919 (* 2 = 1.32584 loss)
I1130 23:01:09.716097   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.48807 (* 1 = 9.48807 loss)
I1130 23:01:09.716109   125 sgd_solver.cpp:180] [0.0] Iteration 8228, lr = 1.24406e-05, m = 0.9, lrm = 0.000124406, wd = 2.5e-07, gs = 1
I1130 23:01:09.838055   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:01:09.959904   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:01:13.133522   125 solver.cpp:501] Iteration 8257, Testing net (#0)
I1130 23:01:29.179891   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:01:29.295305   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:01:30.408643   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.608186 (* 2 = 1.21637 loss)
I1130 23:01:30.408679   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 9.13632 (* 1 = 9.13632 loss)
I1130 23:01:30.408689   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.185
I1130 23:01:30.408695   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 35.9503
I1130 23:01:30.408702   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 32.8481
I1130 23:01:30.408736   125 solver.cpp:271] Tests completed in 20.693s
I1130 23:01:32.364236   125 solver.cpp:333]     [0.0] Iteration 8272 (2.12633 iter/s, 20.693s/44 iter), 23/100ep, loss = 10.3438
I1130 23:01:32.364279   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.737521 (* 2 = 1.47504 loss)
I1130 23:01:32.364291   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.86876 (* 1 = 8.86876 loss)
I1130 23:01:32.364302   125 sgd_solver.cpp:180] [0.0] Iteration 8272, lr = 1.23943e-05, m = 0.9, lrm = 0.000123943, wd = 2.5e-07, gs = 1
I1130 23:01:37.736034   125 solver.cpp:333]     [0.0] Iteration 8316 (8.19094 iter/s, 5.37179s/44 iter), 23.2/100ep, loss = 9.36889
I1130 23:01:37.736078   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.927879 (* 2 = 1.85576 loss)
I1130 23:01:37.736089   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.5131 (* 1 = 7.5131 loss)
I1130 23:01:37.736101   125 sgd_solver.cpp:180] [0.0] Iteration 8316, lr = 1.23481e-05, m = 0.9, lrm = 0.000123481, wd = 2.5e-07, gs = 1
I1130 23:01:43.104432   125 solver.cpp:333]     [0.0] Iteration 8360 (8.1961 iter/s, 5.36841s/44 iter), 23.3/100ep, loss = 10.2842
I1130 23:01:43.104611   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.496661 (* 2 = 0.993322 loss)
I1130 23:01:43.104625   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.29089 (* 1 = 9.29089 loss)
I1130 23:01:43.104636   125 sgd_solver.cpp:180] [0.0] Iteration 8360, lr = 1.23021e-05, m = 0.9, lrm = 0.000123021, wd = 2.5e-07, gs = 1
I1130 23:01:48.466661   125 solver.cpp:333]     [0.0] Iteration 8404 (8.20555 iter/s, 5.36223s/44 iter), 23.4/100ep, loss = 9.55793
I1130 23:01:48.466702   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.725218 (* 2 = 1.45044 loss)
I1130 23:01:48.466714   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.10747 (* 1 = 8.10747 loss)
I1130 23:01:48.466727   125 sgd_solver.cpp:180] [0.0] Iteration 8404, lr = 1.22563e-05, m = 0.9, lrm = 0.000122563, wd = 2.5e-07, gs = 1
I1130 23:01:53.834172   125 solver.cpp:333]     [0.0] Iteration 8448 (8.19745 iter/s, 5.36752s/44 iter), 23.5/100ep, loss = 9.63413
I1130 23:01:53.834213   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.774312 (* 2 = 1.54862 loss)
I1130 23:01:53.834225   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.08547 (* 1 = 8.08547 loss)
I1130 23:01:53.834237   125 sgd_solver.cpp:180] [0.0] Iteration 8448, lr = 1.22106e-05, m = 0.9, lrm = 0.000122106, wd = 2.5e-07, gs = 1
I1130 23:01:59.199178   125 solver.cpp:333]     [0.0] Iteration 8492 (8.20128 iter/s, 5.36502s/44 iter), 23.7/100ep, loss = 11.8164
I1130 23:01:59.199224   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.15986 (* 2 = 2.31972 loss)
I1130 23:01:59.199234   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.49662 (* 1 = 9.49662 loss)
I1130 23:01:59.199246   125 sgd_solver.cpp:180] [0.0] Iteration 8492, lr = 1.21652e-05, m = 0.9, lrm = 0.000121652, wd = 2.5e-07, gs = 1
I1130 23:02:04.568591   125 solver.cpp:333]     [0.0] Iteration 8536 (8.19457 iter/s, 5.36941s/44 iter), 23.8/100ep, loss = 5.4223
I1130 23:02:04.568635   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.305362 (* 2 = 0.610724 loss)
I1130 23:02:04.568646   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.81155 (* 1 = 4.81155 loss)
I1130 23:02:04.568658   125 sgd_solver.cpp:180] [0.0] Iteration 8536, lr = 1.21198e-05, m = 0.9, lrm = 0.000121198, wd = 2.5e-07, gs = 1
I1130 23:02:09.932711   125 solver.cpp:333]     [0.0] Iteration 8580 (8.20262 iter/s, 5.36414s/44 iter), 23.9/100ep, loss = 16.8384
I1130 23:02:09.932755   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.49438 (* 2 = 2.98876 loss)
I1130 23:02:09.932766   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.8496 (* 1 = 13.8496 loss)
I1130 23:02:09.932777   125 sgd_solver.cpp:180] [0.0] Iteration 8580, lr = 1.20747e-05, m = 0.9, lrm = 0.000120747, wd = 2.5e-07, gs = 1
I1130 23:02:10.670269   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:02:10.792163   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:02:14.202549   125 solver.cpp:501] Iteration 8616, Testing net (#0)
I1130 23:02:23.868824   151 blocking_queue.cpp:40] Data layer prefetch queue empty
I1130 23:02:30.124481   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:02:30.278889   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:02:31.437252   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.59487 (* 2 = 1.18974 loss)
I1130 23:02:31.437292   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.99949 (* 1 = 8.99949 loss)
I1130 23:02:31.437301   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.1335
I1130 23:02:31.437309   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 37.5043
I1130 23:02:31.437316   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 32.7203
I1130 23:02:31.437350   125 solver.cpp:271] Tests completed in 21.5047s
I1130 23:02:32.535001   125 solver.cpp:333]     [0.0] Iteration 8624 (2.04606 iter/s, 21.5047s/44 iter), 24/100ep, loss = 10.1571
I1130 23:02:32.535045   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.3106 (* 2 = 2.62121 loss)
I1130 23:02:32.535056   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.53588 (* 1 = 7.53588 loss)
I1130 23:02:32.535068   125 sgd_solver.cpp:180] [0.0] Iteration 8624, lr = 1.20297e-05, m = 0.9, lrm = 0.000120297, wd = 2.5e-07, gs = 1
I1130 23:02:37.899978   125 solver.cpp:333]     [0.0] Iteration 8668 (8.20132 iter/s, 5.36499s/44 iter), 24.1/100ep, loss = 3.72674
I1130 23:02:37.900022   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.192613 (* 2 = 0.385225 loss)
I1130 23:02:37.900032   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.34149 (* 1 = 3.34149 loss)
I1130 23:02:37.900043   125 sgd_solver.cpp:180] [0.0] Iteration 8668, lr = 1.19849e-05, m = 0.9, lrm = 0.000119849, wd = 2.5e-07, gs = 1
I1130 23:02:43.273710   125 solver.cpp:333]     [0.0] Iteration 8712 (8.18796 iter/s, 5.37374s/44 iter), 24.3/100ep, loss = 16.2166
I1130 23:02:43.273749   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.53469 (* 2 = 3.06937 loss)
I1130 23:02:43.273761   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.1472 (* 1 = 13.1472 loss)
I1130 23:02:43.273773   125 sgd_solver.cpp:180] [0.0] Iteration 8712, lr = 1.19403e-05, m = 0.9, lrm = 0.000119402, wd = 2.5e-07, gs = 1
I1130 23:02:48.638252   125 solver.cpp:333]     [0.0] Iteration 8756 (8.20202 iter/s, 5.36453s/44 iter), 24.4/100ep, loss = 17.3112
I1130 23:02:48.638433   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.840654 (* 2 = 1.68131 loss)
I1130 23:02:48.638448   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.6299 (* 1 = 15.6299 loss)
I1130 23:02:48.638460   125 sgd_solver.cpp:180] [0.0] Iteration 8756, lr = 1.18958e-05, m = 0.9, lrm = 0.000118958, wd = 2.5e-07, gs = 1
I1130 23:02:54.006928   125 solver.cpp:333]     [0.0] Iteration 8800 (8.19566 iter/s, 5.36869s/44 iter), 24.5/100ep, loss = 7.4133
I1130 23:02:54.006969   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.901695 (* 2 = 1.80339 loss)
I1130 23:02:54.006980   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.60989 (* 1 = 5.60989 loss)
I1130 23:02:54.006991   125 sgd_solver.cpp:180] [0.0] Iteration 8800, lr = 1.18515e-05, m = 0.9, lrm = 0.000118515, wd = 2.5e-07, gs = 1
I1130 23:02:59.367775   125 solver.cpp:333]     [0.0] Iteration 8844 (8.20763 iter/s, 5.36087s/44 iter), 24.6/100ep, loss = 12.8551
I1130 23:02:59.367815   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.647829 (* 2 = 1.29566 loss)
I1130 23:02:59.367827   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.5594 (* 1 = 11.5594 loss)
I1130 23:02:59.367838   125 sgd_solver.cpp:180] [0.0] Iteration 8844, lr = 1.18073e-05, m = 0.9, lrm = 0.000118073, wd = 2.5e-07, gs = 1
I1130 23:03:04.728536   125 solver.cpp:333]     [0.0] Iteration 8888 (8.20781 iter/s, 5.36075s/44 iter), 24.8/100ep, loss = 13.354
I1130 23:03:04.728579   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.993296 (* 2 = 1.98659 loss)
I1130 23:03:04.728590   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.3674 (* 1 = 11.3674 loss)
I1130 23:03:04.728603   125 sgd_solver.cpp:180] [0.0] Iteration 8888, lr = 1.17633e-05, m = 0.9, lrm = 0.000117633, wd = 2.5e-07, gs = 1
I1130 23:03:10.093411   125 solver.cpp:333]     [0.0] Iteration 8932 (8.20147 iter/s, 5.36489s/44 iter), 24.9/100ep, loss = 9.73547
I1130 23:03:10.093456   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.700434 (* 2 = 1.40087 loss)
I1130 23:03:10.093467   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.33458 (* 1 = 8.33458 loss)
I1130 23:03:10.093479   125 sgd_solver.cpp:180] [0.0] Iteration 8932, lr = 1.17195e-05, m = 0.9, lrm = 0.000117195, wd = 2.5e-07, gs = 1
I1130 23:03:11.804409   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:03:11.918447   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:03:15.210127   125 solver.cpp:501] Iteration 8975, Testing net (#0)
I1130 23:03:31.047839   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:03:31.164135   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:03:32.359313   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.586396 (* 2 = 1.17279 loss)
I1130 23:03:32.359355   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 9.18939 (* 1 = 9.18939 loss)
I1130 23:03:32.359364   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.3415
I1130 23:03:32.359372   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 33.5345
I1130 23:03:32.359378   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 36.6315
I1130 23:03:32.359413   125 solver.cpp:271] Tests completed in 22.2661s
I1130 23:03:32.604648   125 solver.cpp:333]     [0.0] Iteration 8976 (1.9761 iter/s, 22.2661s/44 iter), 25/100ep, loss = 10.5887
I1130 23:03:32.604691   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.661416 (* 2 = 1.32283 loss)
I1130 23:03:32.604702   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.26587 (* 1 = 9.26587 loss)
I1130 23:03:32.604714   125 sgd_solver.cpp:180] [0.0] Iteration 8976, lr = 1.16758e-05, m = 0.9, lrm = 0.000116758, wd = 2.5e-07, gs = 1
I1130 23:03:37.973172   125 solver.cpp:333]     [0.0] Iteration 9020 (8.19591 iter/s, 5.36853s/44 iter), 25.1/100ep, loss = 15.2865
I1130 23:03:37.973217   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.652732 (* 2 = 1.30546 loss)
I1130 23:03:37.973227   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.981 (* 1 = 13.981 loss)
I1130 23:03:37.973239   125 sgd_solver.cpp:180] [0.0] Iteration 9020, lr = 1.16324e-05, m = 0.9, lrm = 0.000116324, wd = 2.5e-07, gs = 1
I1130 23:03:43.341293   125 solver.cpp:333]     [0.0] Iteration 9064 (8.19653 iter/s, 5.36813s/44 iter), 25.2/100ep, loss = 13.7633
I1130 23:03:43.341336   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.40284 (* 2 = 2.80569 loss)
I1130 23:03:43.341346   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.9576 (* 1 = 10.9576 loss)
I1130 23:03:43.341358   125 sgd_solver.cpp:180] [0.0] Iteration 9064, lr = 1.1589e-05, m = 0.9, lrm = 0.00011589, wd = 2.5e-07, gs = 1
I1130 23:03:48.702261   125 solver.cpp:333]     [0.0] Iteration 9108 (8.20747 iter/s, 5.36097s/44 iter), 25.4/100ep, loss = 9.05704
I1130 23:03:48.702302   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.743001 (* 2 = 1.486 loss)
I1130 23:03:48.702313   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.57102 (* 1 = 7.57102 loss)
I1130 23:03:48.702324   125 sgd_solver.cpp:180] [0.0] Iteration 9108, lr = 1.15458e-05, m = 0.9, lrm = 0.000115458, wd = 2.5e-07, gs = 1
I1130 23:03:54.064774   125 solver.cpp:333]     [0.0] Iteration 9152 (8.20509 iter/s, 5.36252s/44 iter), 25.5/100ep, loss = 4.63113
I1130 23:03:54.064816   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.598721 (* 2 = 1.19744 loss)
I1130 23:03:54.064827   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.43368 (* 1 = 3.43368 loss)
I1130 23:03:54.064839   125 sgd_solver.cpp:180] [0.0] Iteration 9152, lr = 1.15028e-05, m = 0.9, lrm = 0.000115028, wd = 2.5e-07, gs = 1
I1130 23:03:59.433037   125 solver.cpp:333]     [0.0] Iteration 9196 (8.19634 iter/s, 5.36825s/44 iter), 25.6/100ep, loss = 12.1294
I1130 23:03:59.433080   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.865721 (* 2 = 1.73144 loss)
I1130 23:03:59.433092   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.3979 (* 1 = 10.3979 loss)
I1130 23:03:59.433104   125 sgd_solver.cpp:180] [0.0] Iteration 9196, lr = 1.146e-05, m = 0.9, lrm = 0.0001146, wd = 2.5e-07, gs = 1
I1130 23:04:04.803691   125 solver.cpp:333]     [0.0] Iteration 9240 (8.19265 iter/s, 5.37067s/44 iter), 25.7/100ep, loss = 9.32766
I1130 23:04:04.803885   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.01272 (* 2 = 2.02544 loss)
I1130 23:04:04.803898   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.3022 (* 1 = 7.3022 loss)
I1130 23:04:04.803910   125 sgd_solver.cpp:180] [0.0] Iteration 9240, lr = 1.14173e-05, m = 0.9, lrm = 0.000114173, wd = 2.5e-07, gs = 1
I1130 23:04:10.171072   125 solver.cpp:333]     [0.0] Iteration 9284 (8.19765 iter/s, 5.36739s/44 iter), 25.9/100ep, loss = 8.14093
I1130 23:04:10.171115   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.84746 (* 2 = 1.69492 loss)
I1130 23:04:10.171126   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.446 (* 1 = 6.446 loss)
I1130 23:04:10.171139   125 sgd_solver.cpp:180] [0.0] Iteration 9284, lr = 1.13748e-05, m = 0.9, lrm = 0.000113748, wd = 2.5e-07, gs = 1
I1130 23:04:12.863260   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:04:12.980090   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:04:15.542958   125 solver.cpp:333]     [0.0] Iteration 9328 (8.19079 iter/s, 5.37188s/44 iter), 26/100ep, loss = 11.4798
I1130 23:04:15.543004   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.44859 (* 2 = 2.89718 loss)
I1130 23:04:15.543015   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.58265 (* 1 = 8.58265 loss)
I1130 23:04:15.543026   125 sgd_solver.cpp:180] [0.0] Iteration 9328, lr = 1.13324e-05, m = 0.9, lrm = 0.000113324, wd = 2.5e-07, gs = 1
I1130 23:04:16.152846   125 solver.cpp:501] Iteration 9334, Testing net (#0)
I1130 23:04:31.969950   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:04:32.128654   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:04:33.530232   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.574477 (* 2 = 1.14895 loss)
I1130 23:04:33.530283   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.98193 (* 1 = 8.98193 loss)
I1130 23:04:33.530298   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.6991
I1130 23:04:33.530310   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 35.7466
I1130 23:04:33.530321   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 36.655
I1130 23:04:33.530364   125 solver.cpp:271] Tests completed in 17.9875s
I1130 23:04:38.273393   125 solver.cpp:333]     [0.0] Iteration 9372 (2.44614 iter/s, 17.9875s/44 iter), 26.1/100ep, loss = 12.1548
I1130 23:04:38.273516   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.982226 (* 2 = 1.96445 loss)
I1130 23:04:38.273530   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.1903 (* 1 = 10.1903 loss)
I1130 23:04:38.273542   125 sgd_solver.cpp:180] [0.0] Iteration 9372, lr = 1.12902e-05, m = 0.9, lrm = 0.000112902, wd = 2.5e-07, gs = 1
I1130 23:04:43.610517   125 solver.cpp:333]     [0.0] Iteration 9416 (8.24416 iter/s, 5.33711s/44 iter), 26.2/100ep, loss = 6.71644
I1130 23:04:43.610558   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.824308 (* 2 = 1.64862 loss)
I1130 23:04:43.610569   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.06781 (* 1 = 5.06781 loss)
I1130 23:04:43.610580   125 sgd_solver.cpp:180] [0.0] Iteration 9416, lr = 1.12481e-05, m = 0.9, lrm = 0.000112481, wd = 2.5e-07, gs = 1
I1130 23:04:48.953985   125 solver.cpp:333]     [0.0] Iteration 9460 (8.23433 iter/s, 5.34348s/44 iter), 26.4/100ep, loss = 4.39199
I1130 23:04:48.954021   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.242697 (* 2 = 0.485394 loss)
I1130 23:04:48.954032   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.90658 (* 1 = 3.90658 loss)
I1130 23:04:48.954043   125 sgd_solver.cpp:180] [0.0] Iteration 9460, lr = 1.12062e-05, m = 0.9, lrm = 0.000112062, wd = 2.5e-07, gs = 1
I1130 23:04:54.293520   125 solver.cpp:333]     [0.0] Iteration 9504 (8.24041 iter/s, 5.33954s/44 iter), 26.5/100ep, loss = 7.06637
I1130 23:04:54.293561   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.576585 (* 2 = 1.15317 loss)
I1130 23:04:54.293572   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.91319 (* 1 = 5.91319 loss)
I1130 23:04:54.293584   125 sgd_solver.cpp:180] [0.0] Iteration 9504, lr = 1.11645e-05, m = 0.9, lrm = 0.000111645, wd = 2.5e-07, gs = 1
I1130 23:04:59.640218   125 solver.cpp:333]     [0.0] Iteration 9548 (8.2294 iter/s, 5.34668s/44 iter), 26.6/100ep, loss = 13.2274
I1130 23:04:59.640259   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.28675 (* 2 = 2.57351 loss)
I1130 23:04:59.640270   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.6539 (* 1 = 10.6539 loss)
I1130 23:04:59.640281   125 sgd_solver.cpp:180] [0.0] Iteration 9548, lr = 1.11229e-05, m = 0.9, lrm = 0.000111229, wd = 2.5e-07, gs = 1
I1130 23:05:04.987876   125 solver.cpp:333]     [0.0] Iteration 9592 (8.22789 iter/s, 5.34766s/44 iter), 26.7/100ep, loss = 5.04546
I1130 23:05:04.987917   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.995164 (* 2 = 1.99033 loss)
I1130 23:05:04.987929   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.05512 (* 1 = 3.05512 loss)
I1130 23:05:04.987939   125 sgd_solver.cpp:180] [0.0] Iteration 9592, lr = 1.10815e-05, m = 0.9, lrm = 0.000110814, wd = 2.5e-07, gs = 1
I1130 23:05:10.334755   125 solver.cpp:333]     [0.0] Iteration 9636 (8.22907 iter/s, 5.3469s/44 iter), 26.8/100ep, loss = 15.3209
I1130 23:05:10.334957   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.831212 (* 2 = 1.66242 loss)
I1130 23:05:10.334972   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.6585 (* 1 = 13.6585 loss)
I1130 23:05:10.334985   125 sgd_solver.cpp:180] [0.0] Iteration 9636, lr = 1.10402e-05, m = 0.9, lrm = 0.000110402, wd = 2.5e-07, gs = 1
I1130 23:05:13.627816   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:05:13.747243   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:05:15.690037   125 solver.cpp:333]     [0.0] Iteration 9680 (8.2162 iter/s, 5.35527s/44 iter), 27/100ep, loss = 7.90204
I1130 23:05:15.690080   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.501135 (* 2 = 1.00227 loss)
I1130 23:05:15.690091   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.89975 (* 1 = 6.89975 loss)
I1130 23:05:15.690104   125 sgd_solver.cpp:180] [0.0] Iteration 9680, lr = 1.0999e-05, m = 0.9, lrm = 0.00010999, wd = 2.5e-07, gs = 1
I1130 23:05:17.146749   125 solver.cpp:501] Iteration 9693, Testing net (#0)
I1130 23:05:33.030496   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:05:33.144593   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:05:34.438649   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.572396 (* 2 = 1.14479 loss)
I1130 23:05:34.438690   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 9.04268 (* 1 = 9.04268 loss)
I1130 23:05:34.438699   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 20.4187
I1130 23:05:34.438707   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 35.4994
I1130 23:05:34.438714   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 39.944
I1130 23:05:34.438750   125 solver.cpp:271] Tests completed in 18.7488s
I1130 23:05:38.345660   125 solver.cpp:333]     [0.0] Iteration 9724 (2.34682 iter/s, 18.7488s/44 iter), 27.1/100ep, loss = 8.73545
I1130 23:05:38.345702   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.4615 (* 2 = 0.923 loss)
I1130 23:05:38.345712   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.81243 (* 1 = 7.81243 loss)
I1130 23:05:38.345724   125 sgd_solver.cpp:180] [0.0] Iteration 9724, lr = 1.09581e-05, m = 0.9, lrm = 0.000109581, wd = 2.5e-07, gs = 1
I1130 23:05:43.696364   125 solver.cpp:333]     [0.0] Iteration 9768 (8.22324 iter/s, 5.35069s/44 iter), 27.2/100ep, loss = 11.6391
I1130 23:05:43.696522   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.682247 (* 2 = 1.36449 loss)
I1130 23:05:43.696537   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.2746 (* 1 = 10.2746 loss)
I1130 23:05:43.696548   125 sgd_solver.cpp:180] [0.0] Iteration 9768, lr = 1.09173e-05, m = 0.9, lrm = 0.000109172, wd = 2.5e-07, gs = 1
I1130 23:05:49.045771   125 solver.cpp:333]     [0.0] Iteration 9812 (8.22519 iter/s, 5.34942s/44 iter), 27.3/100ep, loss = 9.54331
I1130 23:05:49.045814   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.917888 (* 2 = 1.83578 loss)
I1130 23:05:49.045825   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.70751 (* 1 = 7.70751 loss)
I1130 23:05:49.045836   125 sgd_solver.cpp:180] [0.0] Iteration 9812, lr = 1.08766e-05, m = 0.9, lrm = 0.000108766, wd = 2.5e-07, gs = 1
I1130 23:05:54.392495   125 solver.cpp:333]     [0.0] Iteration 9856 (8.22932 iter/s, 5.34674s/44 iter), 27.5/100ep, loss = 7.8682
I1130 23:05:54.392534   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.544738 (* 2 = 1.08948 loss)
I1130 23:05:54.392547   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.77871 (* 1 = 6.77871 loss)
I1130 23:05:54.392560   125 sgd_solver.cpp:180] [0.0] Iteration 9856, lr = 1.08361e-05, m = 0.9, lrm = 0.000108361, wd = 2.5e-07, gs = 1
I1130 23:05:59.742205   125 solver.cpp:333]     [0.0] Iteration 9900 (8.22476 iter/s, 5.3497s/44 iter), 27.6/100ep, loss = 8.76702
I1130 23:05:59.742247   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.27023 (* 2 = 2.54046 loss)
I1130 23:05:59.742257   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.22655 (* 1 = 6.22655 loss)
I1130 23:05:59.742269   125 sgd_solver.cpp:180] [0.0] Iteration 9900, lr = 1.07957e-05, m = 0.9, lrm = 0.000107957, wd = 2.5e-07, gs = 1
I1130 23:06:05.103971   125 solver.cpp:333]     [0.0] Iteration 9944 (8.20625 iter/s, 5.36177s/44 iter), 27.7/100ep, loss = 16.1655
I1130 23:06:05.104012   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.48619 (* 2 = 2.97237 loss)
I1130 23:06:05.104022   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.1931 (* 1 = 13.1931 loss)
I1130 23:06:05.104035   125 sgd_solver.cpp:180] [0.0] Iteration 9944, lr = 1.07555e-05, m = 0.9, lrm = 0.000107555, wd = 2.5e-07, gs = 1
I1130 23:06:10.451469   125 solver.cpp:333]     [0.0] Iteration 9988 (8.22815 iter/s, 5.34749s/44 iter), 27.8/100ep, loss = 4.97031
I1130 23:06:10.451514   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.460396 (* 2 = 0.920791 loss)
I1130 23:06:10.451524   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.0495 (* 1 = 4.0495 loss)
I1130 23:06:10.451536   125 sgd_solver.cpp:180] [0.0] Iteration 9988, lr = 1.07154e-05, m = 0.9, lrm = 0.000107154, wd = 2.5e-07, gs = 1
I1130 23:06:14.709345   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:06:14.825986   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:06:15.802284   125 solver.cpp:333]     [0.0] Iteration 10032 (8.22303 iter/s, 5.35083s/44 iter), 27.9/100ep, loss = 7.97935
I1130 23:06:15.802326   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.54919 (* 2 = 1.09838 loss)
I1130 23:06:15.802338   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.88095 (* 1 = 6.88095 loss)
I1130 23:06:15.802350   125 sgd_solver.cpp:180] [0.0] Iteration 10032, lr = 1.06755e-05, m = 0.9, lrm = 0.000106755, wd = 2.5e-07, gs = 1
I1130 23:06:18.113610   125 solver.cpp:501] Iteration 10052, Testing net (#0)
I1130 23:06:33.838997   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:06:33.991333   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:06:35.315255   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.56478 (* 2 = 1.12956 loss)
I1130 23:06:35.315297   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.91291 (* 1 = 8.91291 loss)
I1130 23:06:35.315305   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.3183
I1130 23:06:35.315313   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 34.093
I1130 23:06:35.315320   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 39.0506
I1130 23:06:35.315354   125 solver.cpp:271] Tests completed in 19.5132s
I1130 23:06:38.353363   125 solver.cpp:333]     [0.0] Iteration 10076 (2.25489 iter/s, 19.5132s/44 iter), 28.1/100ep, loss = 14.5188
I1130 23:06:38.353404   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.03188 (* 2 = 2.06375 loss)
I1130 23:06:38.353415   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.455 (* 1 = 12.455 loss)
I1130 23:06:38.353427   125 sgd_solver.cpp:180] [0.0] Iteration 10076, lr = 1.06357e-05, m = 0.9, lrm = 0.000106357, wd = 2.5e-07, gs = 1
I1130 23:06:43.697010   125 solver.cpp:333]     [0.0] Iteration 10120 (8.23408 iter/s, 5.34364s/44 iter), 28.2/100ep, loss = 9.10383
I1130 23:06:43.697051   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.65431 (* 2 = 3.30863 loss)
I1130 23:06:43.697060   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.79519 (* 1 = 5.79519 loss)
I1130 23:06:43.697072   125 sgd_solver.cpp:180] [0.0] Iteration 10120, lr = 1.05961e-05, m = 0.9, lrm = 0.000105961, wd = 2.5e-07, gs = 1
I1130 23:06:49.049252   125 solver.cpp:333]     [0.0] Iteration 10164 (8.22084 iter/s, 5.35225s/44 iter), 28.3/100ep, loss = 13.0612
I1130 23:06:49.049394   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.56688 (* 2 = 3.13377 loss)
I1130 23:06:49.049407   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.92738 (* 1 = 9.92738 loss)
I1130 23:06:49.049418   125 sgd_solver.cpp:180] [0.0] Iteration 10164, lr = 1.05566e-05, m = 0.9, lrm = 0.000105566, wd = 2.5e-07, gs = 1
I1130 23:06:54.412354   125 solver.cpp:333]     [0.0] Iteration 10208 (8.20419 iter/s, 5.36311s/44 iter), 28.4/100ep, loss = 9.70099
I1130 23:06:54.412395   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.674178 (* 2 = 1.34836 loss)
I1130 23:06:54.412407   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.35262 (* 1 = 8.35262 loss)
I1130 23:06:54.412418   125 sgd_solver.cpp:180] [0.0] Iteration 10208, lr = 1.05173e-05, m = 0.9, lrm = 0.000105173, wd = 2.5e-07, gs = 1
I1130 23:06:59.761338   125 solver.cpp:333]     [0.0] Iteration 10252 (8.22588 iter/s, 5.34897s/44 iter), 28.6/100ep, loss = 11.1405
I1130 23:06:59.761380   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.27428 (* 2 = 2.54857 loss)
I1130 23:06:59.761390   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.59194 (* 1 = 8.59194 loss)
I1130 23:06:59.761401   125 sgd_solver.cpp:180] [0.0] Iteration 10252, lr = 1.04781e-05, m = 0.9, lrm = 0.000104781, wd = 2.5e-07, gs = 1
I1130 23:07:05.117611   125 solver.cpp:333]     [0.0] Iteration 10296 (8.21466 iter/s, 5.35628s/44 iter), 28.7/100ep, loss = 8.91283
I1130 23:07:05.117652   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.69561 (* 2 = 1.39122 loss)
I1130 23:07:05.117663   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.52159 (* 1 = 7.52159 loss)
I1130 23:07:05.117674   125 sgd_solver.cpp:180] [0.0] Iteration 10296, lr = 1.04391e-05, m = 0.9, lrm = 0.000104391, wd = 2.5e-07, gs = 1
I1130 23:07:10.469204   125 solver.cpp:333]     [0.0] Iteration 10340 (8.22187 iter/s, 5.35158s/44 iter), 28.8/100ep, loss = 3.61453
I1130 23:07:10.469249   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.290511 (* 2 = 0.581022 loss)
I1130 23:07:10.469259   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.03349 (* 1 = 3.03349 loss)
I1130 23:07:10.469270   125 sgd_solver.cpp:180] [0.0] Iteration 10340, lr = 1.04002e-05, m = 0.9, lrm = 0.000104002, wd = 2.5e-07, gs = 1
I1130 23:07:15.700378   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:07:15.816081   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:07:15.816978   125 solver.cpp:333]     [0.0] Iteration 10384 (8.22769 iter/s, 5.34779s/44 iter), 28.9/100ep, loss = 9.47935
I1130 23:07:15.817000   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.433105 (* 2 = 0.866209 loss)
I1130 23:07:15.817013   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.61312 (* 1 = 8.61312 loss)
I1130 23:07:15.817023   125 sgd_solver.cpp:180] [0.0] Iteration 10384, lr = 1.03615e-05, m = 0.9, lrm = 0.000103615, wd = 2.5e-07, gs = 1
I1130 23:07:18.977829   125 solver.cpp:501] Iteration 10411, Testing net (#0)
I1130 23:07:34.674892   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:07:34.788787   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:07:36.154821   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.562135 (* 2 = 1.12427 loss)
I1130 23:07:36.154861   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.93978 (* 1 = 8.93978 loss)
I1130 23:07:36.154870   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.947
I1130 23:07:36.154878   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 32.8012
I1130 23:07:36.154886   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 40.8788
I1130 23:07:36.154918   125 solver.cpp:271] Tests completed in 20.338s
I1130 23:07:38.338297   125 solver.cpp:333]     [0.0] Iteration 10428 (2.16343 iter/s, 20.338s/44 iter), 29/100ep, loss = 11.4312
I1130 23:07:38.338340   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.504774 (* 2 = 1.00955 loss)
I1130 23:07:38.338352   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.4217 (* 1 = 10.4217 loss)
I1130 23:07:38.338364   125 sgd_solver.cpp:180] [0.0] Iteration 10428, lr = 1.03229e-05, m = 0.9, lrm = 0.000103229, wd = 2.5e-07, gs = 1
I1130 23:07:43.677153   125 solver.cpp:333]     [0.0] Iteration 10472 (8.24147 iter/s, 5.33885s/44 iter), 29.2/100ep, loss = 6.18919
I1130 23:07:43.677192   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.501116 (* 2 = 1.00223 loss)
I1130 23:07:43.677203   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.18694 (* 1 = 5.18694 loss)
I1130 23:07:43.677215   125 sgd_solver.cpp:180] [0.0] Iteration 10472, lr = 1.02844e-05, m = 0.9, lrm = 0.000102844, wd = 2.5e-07, gs = 1
I1130 23:07:49.018065   125 solver.cpp:333]     [0.0] Iteration 10516 (8.23828 iter/s, 5.34092s/44 iter), 29.3/100ep, loss = 7.27992
I1130 23:07:49.018105   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.70118 (* 2 = 1.40236 loss)
I1130 23:07:49.018115   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.87754 (* 1 = 5.87754 loss)
I1130 23:07:49.018127   125 sgd_solver.cpp:180] [0.0] Iteration 10516, lr = 1.02461e-05, m = 0.9, lrm = 0.000102461, wd = 2.5e-07, gs = 1
I1130 23:07:54.363873   125 solver.cpp:333]     [0.0] Iteration 10560 (8.23074 iter/s, 5.34581s/44 iter), 29.4/100ep, loss = 6.22713
I1130 23:07:54.363917   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.346324 (* 2 = 0.692649 loss)
I1130 23:07:54.363927   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.53446 (* 1 = 5.53446 loss)
I1130 23:07:54.363940   125 sgd_solver.cpp:180] [0.0] Iteration 10560, lr = 1.02079e-05, m = 0.9, lrm = 0.000102079, wd = 2.5e-07, gs = 1
I1130 23:07:59.709085   125 solver.cpp:333]     [0.0] Iteration 10604 (8.23168 iter/s, 5.3452s/44 iter), 29.5/100ep, loss = 4.11381
I1130 23:07:59.709128   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.320658 (* 2 = 0.641317 loss)
I1130 23:07:59.709138   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.47248 (* 1 = 3.47248 loss)
I1130 23:07:59.709151   125 sgd_solver.cpp:180] [0.0] Iteration 10604, lr = 1.01699e-05, m = 0.9, lrm = 0.000101699, wd = 2.5e-07, gs = 1
I1130 23:08:05.056354   125 solver.cpp:333]     [0.0] Iteration 10648 (8.22848 iter/s, 5.34728s/44 iter), 29.7/100ep, loss = 5.73867
I1130 23:08:05.056581   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.341124 (* 2 = 0.682248 loss)
I1130 23:08:05.056594   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.05641 (* 1 = 5.05641 loss)
I1130 23:08:05.056607   125 sgd_solver.cpp:180] [0.0] Iteration 10648, lr = 1.0132e-05, m = 0.9, lrm = 0.00010132, wd = 2.5e-07, gs = 1
I1130 23:08:10.395690   125 solver.cpp:333]     [0.0] Iteration 10692 (8.24072 iter/s, 5.33934s/44 iter), 29.8/100ep, loss = 10.2855
I1130 23:08:10.395730   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.787416 (* 2 = 1.57483 loss)
I1130 23:08:10.395740   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.71067 (* 1 = 8.71067 loss)
I1130 23:08:10.395750   125 sgd_solver.cpp:180] [0.0] Iteration 10692, lr = 1.00943e-05, m = 0.9, lrm = 0.000100943, wd = 2.5e-07, gs = 1
I1130 23:08:15.742645   125 solver.cpp:333]     [0.0] Iteration 10736 (8.229 iter/s, 5.34694s/44 iter), 29.9/100ep, loss = 9.47992
I1130 23:08:15.742686   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.47432 (* 2 = 0.94864 loss)
I1130 23:08:15.742697   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.53127 (* 1 = 8.53127 loss)
I1130 23:08:15.742709   125 sgd_solver.cpp:180] [0.0] Iteration 10736, lr = 1.00567e-05, m = 0.9, lrm = 0.000100567, wd = 2.5e-07, gs = 1
I1130 23:08:16.233467   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:08:16.352654   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:08:19.749646   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_10770.caffemodel
I1130 23:08:19.801380   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_10770.solverstate
I1130 23:08:19.843938   125 solver.cpp:501] Iteration 10770, Testing net (#0)
I1130 23:08:35.549249   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:08:35.701548   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:08:37.128446   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.551415 (* 2 = 1.10283 loss)
I1130 23:08:37.128484   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.88865 (* 1 = 8.88865 loss)
I1130 23:08:37.128494   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.9389
I1130 23:08:37.128501   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 33.0866
I1130 23:08:37.128509   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 40.2089
I1130 23:08:37.128542   125 solver.cpp:271] Tests completed in 21.386s
I1130 23:08:38.469981   125 solver.cpp:333]     [0.0] Iteration 10780 (2.05742 iter/s, 21.386s/44 iter), 30/100ep, loss = 3.81946
I1130 23:08:38.470023   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.655233 (* 2 = 1.31047 loss)
I1130 23:08:38.470034   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.50898 (* 1 = 2.50898 loss)
I1130 23:08:38.470046   125 sgd_solver.cpp:180] [0.0] Iteration 10780, lr = 1.00192e-05, m = 0.9, lrm = 0.000100192, wd = 2.5e-07, gs = 1
I1130 23:08:43.814757   125 solver.cpp:333]     [0.0] Iteration 10824 (8.23234 iter/s, 5.34478s/44 iter), 30.2/100ep, loss = 11.9823
I1130 23:08:43.814797   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.926608 (* 2 = 1.85322 loss)
I1130 23:08:43.814810   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.1291 (* 1 = 10.1291 loss)
I1130 23:08:43.814821   125 sgd_solver.cpp:180] [0.0] Iteration 10824, lr = 9.9819e-06, m = 0.9, lrm = 9.9819e-05, wd = 2.5e-07, gs = 1
I1130 23:08:49.159533   125 solver.cpp:333]     [0.0] Iteration 10868 (8.23232 iter/s, 5.34479s/44 iter), 30.3/100ep, loss = 9.21965
I1130 23:08:49.159571   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.735032 (* 2 = 1.47006 loss)
I1130 23:08:49.159582   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.74958 (* 1 = 7.74958 loss)
I1130 23:08:49.159595   125 sgd_solver.cpp:180] [0.0] Iteration 10868, lr = 9.94471e-06, m = 0.9, lrm = 9.94471e-05, wd = 2.5e-07, gs = 1
I1130 23:08:54.508201   125 solver.cpp:333]     [0.0] Iteration 10912 (8.22637 iter/s, 5.34865s/44 iter), 30.4/100ep, loss = 8.4644
I1130 23:08:54.508244   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.27772 (* 2 = 2.55544 loss)
I1130 23:08:54.508253   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.90894 (* 1 = 5.90894 loss)
I1130 23:08:54.508265   125 sgd_solver.cpp:180] [0.0] Iteration 10912, lr = 9.90767e-06, m = 0.9, lrm = 9.90767e-05, wd = 2.5e-07, gs = 1
I1130 23:08:59.848423   125 solver.cpp:333]     [0.0] Iteration 10956 (8.23936 iter/s, 5.34022s/44 iter), 30.5/100ep, loss = 9.08007
I1130 23:08:59.848465   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.58234 (* 2 = 3.16468 loss)
I1130 23:08:59.848475   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.91538 (* 1 = 5.91538 loss)
I1130 23:08:59.848487   125 sgd_solver.cpp:180] [0.0] Iteration 10956, lr = 9.87076e-06, m = 0.9, lrm = 9.87076e-05, wd = 2.5e-07, gs = 1
I1130 23:09:05.193099   125 solver.cpp:333]     [0.0] Iteration 11000 (8.23247 iter/s, 5.34469s/44 iter), 30.6/100ep, loss = 9.89506
I1130 23:09:05.193141   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.738349 (* 2 = 1.4767 loss)
I1130 23:09:05.193153   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.41835 (* 1 = 8.41835 loss)
I1130 23:09:05.193166   125 sgd_solver.cpp:180] [0.0] Iteration 11000, lr = 9.83399e-06, m = 0.9, lrm = 9.83399e-05, wd = 2.5e-07, gs = 1
I1130 23:09:10.530287   125 solver.cpp:333]     [0.0] Iteration 11044 (8.24407 iter/s, 5.33717s/44 iter), 30.8/100ep, loss = 16.4292
I1130 23:09:10.530483   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.696853 (* 2 = 1.39371 loss)
I1130 23:09:10.530498   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 15.0355 (* 1 = 15.0355 loss)
I1130 23:09:10.530511   125 sgd_solver.cpp:180] [0.0] Iteration 11044, lr = 9.79736e-06, m = 0.9, lrm = 9.79735e-05, wd = 2.5e-07, gs = 1
I1130 23:09:15.871737   125 solver.cpp:333]     [0.0] Iteration 11088 (8.23747 iter/s, 5.34145s/44 iter), 30.9/100ep, loss = 16.1065
I1130 23:09:15.871779   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.935948 (* 2 = 1.8719 loss)
I1130 23:09:15.871791   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.2346 (* 1 = 14.2346 loss)
I1130 23:09:15.871803   125 sgd_solver.cpp:180] [0.0] Iteration 11088, lr = 9.76086e-06, m = 0.9, lrm = 9.76086e-05, wd = 2.5e-07, gs = 1
I1130 23:09:17.333829   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:09:17.450887   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:09:20.728708   125 solver.cpp:501] Iteration 11129, Testing net (#0)
I1130 23:09:36.341712   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:09:36.456347   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:09:37.902781   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.548632 (* 2 = 1.09726 loss)
I1130 23:09:37.902819   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.8788 (* 1 = 8.8788 loss)
I1130 23:09:37.902827   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.0247
I1130 23:09:37.902835   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 32.0222
I1130 23:09:37.902842   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 43.2596
I1130 23:09:37.902880   125 solver.cpp:271] Tests completed in 22.0312s
I1130 23:09:38.389451   125 solver.cpp:333]     [0.0] Iteration 11132 (1.99716 iter/s, 22.0312s/44 iter), 31/100ep, loss = 8.67852
I1130 23:09:38.389493   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.08264 (* 2 = 2.16529 loss)
I1130 23:09:38.389503   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.51322 (* 1 = 6.51322 loss)
I1130 23:09:38.389516   125 sgd_solver.cpp:180] [0.0] Iteration 11132, lr = 9.7245e-06, m = 0.9, lrm = 9.7245e-05, wd = 2.5e-07, gs = 1
I1130 23:09:43.729727   125 solver.cpp:333]     [0.0] Iteration 11176 (8.23931 iter/s, 5.34026s/44 iter), 31.1/100ep, loss = 8.37551
I1130 23:09:43.729892   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.805758 (* 2 = 1.61152 loss)
I1130 23:09:43.729904   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.76399 (* 1 = 6.76399 loss)
I1130 23:09:43.729915   125 sgd_solver.cpp:180] [0.0] Iteration 11176, lr = 9.68827e-06, m = 0.9, lrm = 9.68827e-05, wd = 2.5e-07, gs = 1
I1130 23:09:49.071946   125 solver.cpp:333]     [0.0] Iteration 11220 (8.23627 iter/s, 5.34222s/44 iter), 31.3/100ep, loss = 9.38468
I1130 23:09:49.071990   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.60744 (* 2 = 3.21487 loss)
I1130 23:09:49.072000   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.16979 (* 1 = 6.16979 loss)
I1130 23:09:49.072011   125 sgd_solver.cpp:180] [0.0] Iteration 11220, lr = 9.65218e-06, m = 0.9, lrm = 9.65218e-05, wd = 2.5e-07, gs = 1
I1130 23:09:54.432202   125 solver.cpp:333]     [0.0] Iteration 11264 (8.20855 iter/s, 5.36027s/44 iter), 31.4/100ep, loss = 6.21108
I1130 23:09:54.432243   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.30308 (* 2 = 0.606161 loss)
I1130 23:09:54.432252   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.60491 (* 1 = 5.60491 loss)
I1130 23:09:54.432265   125 sgd_solver.cpp:180] [0.0] Iteration 11264, lr = 9.61623e-06, m = 0.9, lrm = 9.61622e-05, wd = 2.5e-07, gs = 1
I1130 23:09:59.793000   125 solver.cpp:333]     [0.0] Iteration 11308 (8.20776 iter/s, 5.36078s/44 iter), 31.5/100ep, loss = 8.09833
I1130 23:09:59.793045   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.699234 (* 2 = 1.39847 loss)
I1130 23:09:59.793056   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.69985 (* 1 = 6.69985 loss)
I1130 23:09:59.793067   125 sgd_solver.cpp:180] [0.0] Iteration 11308, lr = 9.58041e-06, m = 0.9, lrm = 9.5804e-05, wd = 2.5e-07, gs = 1
I1130 23:10:05.155365   125 solver.cpp:333]     [0.0] Iteration 11352 (8.20533 iter/s, 5.36237s/44 iter), 31.6/100ep, loss = 4.14675
I1130 23:10:05.155409   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.441347 (* 2 = 0.882693 loss)
I1130 23:10:05.155419   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.26404 (* 1 = 3.26404 loss)
I1130 23:10:05.155431   125 sgd_solver.cpp:180] [0.0] Iteration 11352, lr = 9.54472e-06, m = 0.9, lrm = 9.54471e-05, wd = 2.5e-07, gs = 1
I1130 23:10:10.528404   125 solver.cpp:333]     [0.0] Iteration 11396 (8.18905 iter/s, 5.37303s/44 iter), 31.7/100ep, loss = 6.92774
I1130 23:10:10.528448   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.634387 (* 2 = 1.26877 loss)
I1130 23:10:10.528460   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.65895 (* 1 = 5.65895 loss)
I1130 23:10:10.528471   125 sgd_solver.cpp:180] [0.0] Iteration 11396, lr = 9.50916e-06, m = 0.9, lrm = 9.50916e-05, wd = 2.5e-07, gs = 1
I1130 23:10:15.892451   125 solver.cpp:333]     [0.0] Iteration 11440 (8.20274 iter/s, 5.36406s/44 iter), 31.9/100ep, loss = 12.5656
I1130 23:10:15.892671   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.36676 (* 2 = 2.73352 loss)
I1130 23:10:15.892684   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.83208 (* 1 = 9.83208 loss)
I1130 23:10:15.892696   125 sgd_solver.cpp:180] [0.0] Iteration 11440, lr = 9.47374e-06, m = 0.9, lrm = 9.47373e-05, wd = 2.5e-07, gs = 1
I1130 23:10:18.329232   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:10:18.453683   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:10:21.261287   125 solver.cpp:333]     [0.0] Iteration 11484 (8.19543 iter/s, 5.36884s/44 iter), 32/100ep, loss = 7.36903
I1130 23:10:21.261327   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.858611 (* 2 = 1.71722 loss)
I1130 23:10:21.261338   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.65179 (* 1 = 5.65179 loss)
I1130 23:10:21.261350   125 sgd_solver.cpp:180] [0.0] Iteration 11484, lr = 9.43845e-06, m = 0.9, lrm = 9.43844e-05, wd = 2.5e-07, gs = 1
I1130 23:10:21.626546   125 solver.cpp:501] Iteration 11488, Testing net (#0)
I1130 23:10:37.206604   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:10:37.360013   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:10:38.848913   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.555054 (* 2 = 1.11011 loss)
I1130 23:10:38.848955   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.79268 (* 1 = 8.79268 loss)
I1130 23:10:38.848963   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.119
I1130 23:10:38.848971   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 31.5795
I1130 23:10:38.848978   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 42.114
I1130 23:10:38.849014   125 solver.cpp:271] Tests completed in 17.5878s
I1130 23:10:43.847885   125 solver.cpp:333]     [0.0] Iteration 11528 (2.50173 iter/s, 17.5878s/44 iter), 32.1/100ep, loss = 5.09871
I1130 23:10:43.847928   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.325482 (* 2 = 0.650964 loss)
I1130 23:10:43.847939   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.44774 (* 1 = 4.44774 loss)
I1130 23:10:43.847949   125 sgd_solver.cpp:180] [0.0] Iteration 11528, lr = 9.40329e-06, m = 0.9, lrm = 9.40328e-05, wd = 2.5e-07, gs = 1
I1130 23:10:49.212183   125 solver.cpp:333]     [0.0] Iteration 11572 (8.20238 iter/s, 5.36429s/44 iter), 32.2/100ep, loss = 17.0179
I1130 23:10:49.212327   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.31993 (* 2 = 2.63986 loss)
I1130 23:10:49.212340   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.378 (* 1 = 14.378 loss)
I1130 23:10:49.212352   125 sgd_solver.cpp:180] [0.0] Iteration 11572, lr = 9.36826e-06, m = 0.9, lrm = 9.36826e-05, wd = 2.5e-07, gs = 1
I1130 23:10:54.572386   125 solver.cpp:333]     [0.0] Iteration 11616 (8.20865 iter/s, 5.3602s/44 iter), 32.4/100ep, loss = 10.5128
I1130 23:10:54.572427   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.453055 (* 2 = 0.90611 loss)
I1130 23:10:54.572438   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.60672 (* 1 = 9.60672 loss)
I1130 23:10:54.572450   125 sgd_solver.cpp:180] [0.0] Iteration 11616, lr = 9.33336e-06, m = 0.9, lrm = 9.33336e-05, wd = 2.5e-07, gs = 1
I1130 23:10:59.932737   125 solver.cpp:333]     [0.0] Iteration 11660 (8.20842 iter/s, 5.36035s/44 iter), 32.5/100ep, loss = 10.4667
I1130 23:10:59.932777   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.827747 (* 2 = 1.65549 loss)
I1130 23:10:59.932790   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.81122 (* 1 = 8.81122 loss)
I1130 23:10:59.932801   125 sgd_solver.cpp:180] [0.0] Iteration 11660, lr = 9.29859e-06, m = 0.9, lrm = 9.29859e-05, wd = 2.5e-07, gs = 1
I1130 23:11:05.306329   125 solver.cpp:333]     [0.0] Iteration 11704 (8.18819 iter/s, 5.3736s/44 iter), 32.6/100ep, loss = 8.51371
I1130 23:11:05.306373   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.491018 (* 2 = 0.982036 loss)
I1130 23:11:05.306383   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.53166 (* 1 = 7.53166 loss)
I1130 23:11:05.306396   125 sgd_solver.cpp:180] [0.0] Iteration 11704, lr = 9.26395e-06, m = 0.9, lrm = 9.26395e-05, wd = 2.5e-07, gs = 1
I1130 23:11:10.675531   125 solver.cpp:333]     [0.0] Iteration 11748 (8.19489 iter/s, 5.3692s/44 iter), 32.7/100ep, loss = 9.57747
I1130 23:11:10.675572   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.878233 (* 2 = 1.75647 loss)
I1130 23:11:10.675585   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.82099 (* 1 = 7.82099 loss)
I1130 23:11:10.675595   125 sgd_solver.cpp:180] [0.0] Iteration 11748, lr = 9.22944e-06, m = 0.9, lrm = 9.22944e-05, wd = 2.5e-07, gs = 1
I1130 23:11:16.049727   125 solver.cpp:333]     [0.0] Iteration 11792 (8.18726 iter/s, 5.3742s/44 iter), 32.8/100ep, loss = 6.92794
I1130 23:11:16.049767   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.82961 (* 2 = 1.65922 loss)
I1130 23:11:16.049777   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.26871 (* 1 = 5.26871 loss)
I1130 23:11:16.049788   125 sgd_solver.cpp:180] [0.0] Iteration 11792, lr = 9.19506e-06, m = 0.9, lrm = 9.19506e-05, wd = 2.5e-07, gs = 1
I1130 23:11:19.097411   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:11:19.222607   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:11:21.413132   125 solver.cpp:333]     [0.0] Iteration 11836 (8.20374 iter/s, 5.36341s/44 iter), 33/100ep, loss = 8.58236
I1130 23:11:21.413174   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.646249 (* 2 = 1.2925 loss)
I1130 23:11:21.413187   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.28985 (* 1 = 7.28985 loss)
I1130 23:11:21.413197   125 sgd_solver.cpp:180] [0.0] Iteration 11836, lr = 9.16081e-06, m = 0.9, lrm = 9.16081e-05, wd = 2.5e-07, gs = 1
I1130 23:11:22.631650   125 solver.cpp:501] Iteration 11847, Testing net (#0)
I1130 23:11:38.129513   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:11:38.243211   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:11:39.772857   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.542005 (* 2 = 1.08401 loss)
I1130 23:11:39.772895   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.74083 (* 1 = 8.74083 loss)
I1130 23:11:39.772904   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.964
I1130 23:11:39.772912   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 30.7295
I1130 23:11:39.772918   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 43.3508
I1130 23:11:39.772953   125 solver.cpp:271] Tests completed in 18.3599s
I1130 23:11:43.914316   125 solver.cpp:333]     [0.0] Iteration 11880 (2.39653 iter/s, 18.3599s/44 iter), 33.1/100ep, loss = 10.5282
I1130 23:11:43.914356   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.930336 (* 2 = 1.86067 loss)
I1130 23:11:43.914367   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.66756 (* 1 = 8.66756 loss)
I1130 23:11:43.914378   125 sgd_solver.cpp:180] [0.0] Iteration 11880, lr = 9.12668e-06, m = 0.9, lrm = 9.12668e-05, wd = 2.5e-07, gs = 1
I1130 23:11:49.281644   125 solver.cpp:333]     [0.0] Iteration 11924 (8.19775 iter/s, 5.36733s/44 iter), 33.2/100ep, loss = 7.79629
I1130 23:11:49.281783   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.643428 (* 2 = 1.28686 loss)
I1130 23:11:49.281796   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.50943 (* 1 = 6.50943 loss)
I1130 23:11:49.281810   125 sgd_solver.cpp:180] [0.0] Iteration 11924, lr = 9.09268e-06, m = 0.9, lrm = 9.09268e-05, wd = 2.5e-07, gs = 1
I1130 23:11:54.642503   125 solver.cpp:333]     [0.0] Iteration 11968 (8.20765 iter/s, 5.36085s/44 iter), 33.3/100ep, loss = 6.80824
I1130 23:11:54.642541   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.66775 (* 2 = 1.3355 loss)
I1130 23:11:54.642552   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.47273 (* 1 = 5.47273 loss)
I1130 23:11:54.642565   125 sgd_solver.cpp:180] [0.0] Iteration 11968, lr = 9.05881e-06, m = 0.9, lrm = 9.05881e-05, wd = 2.5e-07, gs = 1
I1130 23:12:00.074998   125 solver.cpp:333]     [0.0] Iteration 12012 (8.09943 iter/s, 5.43248s/44 iter), 33.5/100ep, loss = 11.3431
I1130 23:12:00.075055   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.865836 (* 2 = 1.73167 loss)
I1130 23:12:00.075073   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.61139 (* 1 = 9.61139 loss)
I1130 23:12:00.075090   125 sgd_solver.cpp:180] [0.0] Iteration 12012, lr = 9.02507e-06, m = 0.9, lrm = 9.02507e-05, wd = 2.5e-07, gs = 1
I1130 23:12:05.507076   125 solver.cpp:333]     [0.0] Iteration 12056 (8.10003 iter/s, 5.43208s/44 iter), 33.6/100ep, loss = 10.598
I1130 23:12:05.507118   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.717576 (* 2 = 1.43515 loss)
I1130 23:12:05.507129   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.1628 (* 1 = 9.1628 loss)
I1130 23:12:05.507141   125 sgd_solver.cpp:180] [0.0] Iteration 12056, lr = 8.99145e-06, m = 0.9, lrm = 8.99144e-05, wd = 2.5e-07, gs = 1
I1130 23:12:10.950323   125 solver.cpp:333]     [0.0] Iteration 12100 (8.08339 iter/s, 5.44326s/44 iter), 33.7/100ep, loss = 8.4958
I1130 23:12:10.950363   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.951601 (* 2 = 1.9032 loss)
I1130 23:12:10.950374   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.5926 (* 1 = 6.5926 loss)
I1130 23:12:10.950387   125 sgd_solver.cpp:180] [0.0] Iteration 12100, lr = 8.95795e-06, m = 0.9, lrm = 8.95795e-05, wd = 2.5e-07, gs = 1
I1130 23:12:16.398661   125 solver.cpp:333]     [0.0] Iteration 12144 (8.07585 iter/s, 5.44834s/44 iter), 33.8/100ep, loss = 9.5999
I1130 23:12:16.398705   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.06468 (* 2 = 2.12935 loss)
I1130 23:12:16.398715   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.47054 (* 1 = 7.47054 loss)
I1130 23:12:16.398726   125 sgd_solver.cpp:180] [0.0] Iteration 12144, lr = 8.92458e-06, m = 0.9, lrm = 8.92458e-05, wd = 2.5e-07, gs = 1
I1130 23:12:20.474328   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:12:20.593078   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:12:21.812835   125 solver.cpp:333]     [0.0] Iteration 12188 (8.12684 iter/s, 5.41416s/44 iter), 33.9/100ep, loss = 6.07065
I1130 23:12:21.812877   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.719118 (* 2 = 1.43824 loss)
I1130 23:12:21.812888   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.6324 (* 1 = 4.6324 loss)
I1130 23:12:21.812901   125 sgd_solver.cpp:180] [0.0] Iteration 12188, lr = 8.89134e-06, m = 0.9, lrm = 8.89133e-05, wd = 2.5e-07, gs = 1
I1130 23:12:23.885247   125 solver.cpp:501] Iteration 12206, Testing net (#0)
I1130 23:12:39.303800   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:12:39.454658   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:12:41.011827   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.540324 (* 2 = 1.08065 loss)
I1130 23:12:41.011865   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.75595 (* 1 = 8.75595 loss)
I1130 23:12:41.011874   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.5509
I1130 23:12:41.011883   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 31.5859
I1130 23:12:41.011889   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 42.9666
I1130 23:12:41.011937   125 solver.cpp:271] Tests completed in 19.1992s
I1130 23:12:44.299950   125 solver.cpp:333]     [0.0] Iteration 12232 (2.29177 iter/s, 19.1992s/44 iter), 34.1/100ep, loss = 11.4408
I1130 23:12:44.299993   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.890241 (* 2 = 1.78048 loss)
I1130 23:12:44.300004   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.66034 (* 1 = 9.66034 loss)
I1130 23:12:44.300015   125 sgd_solver.cpp:180] [0.0] Iteration 12232, lr = 8.85821e-06, m = 0.9, lrm = 8.85821e-05, wd = 2.5e-07, gs = 1
I1130 23:12:49.660152   125 solver.cpp:333]     [0.0] Iteration 12276 (8.20868 iter/s, 5.36018s/44 iter), 34.2/100ep, loss = 9.25131
I1130 23:12:49.660194   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.35196 (* 2 = 2.70391 loss)
I1130 23:12:49.660204   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.54739 (* 1 = 6.54739 loss)
I1130 23:12:49.660217   125 sgd_solver.cpp:180] [0.0] Iteration 12276, lr = 8.82522e-06, m = 0.9, lrm = 8.82521e-05, wd = 2.5e-07, gs = 1
I1130 23:12:55.024838   125 solver.cpp:333]     [0.0] Iteration 12320 (8.20176 iter/s, 5.3647s/44 iter), 34.3/100ep, loss = 5.45977
I1130 23:12:55.025030   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.69479 (* 2 = 1.38958 loss)
I1130 23:12:55.025044   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.07019 (* 1 = 4.07019 loss)
I1130 23:12:55.025056   125 sgd_solver.cpp:180] [0.0] Iteration 12320, lr = 8.79234e-06, m = 0.9, lrm = 8.79234e-05, wd = 2.5e-07, gs = 1
I1130 23:13:00.391149   125 solver.cpp:333]     [0.0] Iteration 12364 (8.19929 iter/s, 5.36632s/44 iter), 34.4/100ep, loss = 5.19042
I1130 23:13:00.391188   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.531365 (* 2 = 1.06273 loss)
I1130 23:13:00.391199   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.12768 (* 1 = 4.12768 loss)
I1130 23:13:00.391211   125 sgd_solver.cpp:180] [0.0] Iteration 12364, lr = 8.75959e-06, m = 0.9, lrm = 8.75959e-05, wd = 2.5e-07, gs = 1
I1130 23:13:05.754561   125 solver.cpp:333]     [0.0] Iteration 12408 (8.20375 iter/s, 5.3634s/44 iter), 34.6/100ep, loss = 5.06128
I1130 23:13:05.754601   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.340248 (* 2 = 0.680495 loss)
I1130 23:13:05.754611   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.38077 (* 1 = 4.38077 loss)
I1130 23:13:05.754621   125 sgd_solver.cpp:180] [0.0] Iteration 12408, lr = 8.72696e-06, m = 0.9, lrm = 8.72696e-05, wd = 2.5e-07, gs = 1
I1130 23:13:11.109426   125 solver.cpp:333]     [0.0] Iteration 12452 (8.21682 iter/s, 5.35487s/44 iter), 34.7/100ep, loss = 4.50321
I1130 23:13:11.109472   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.406807 (* 2 = 0.813613 loss)
I1130 23:13:11.109483   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.68959 (* 1 = 3.68959 loss)
I1130 23:13:11.109493   125 sgd_solver.cpp:180] [0.0] Iteration 12452, lr = 8.69445e-06, m = 0.9, lrm = 8.69445e-05, wd = 2.5e-07, gs = 1
I1130 23:13:16.461997   125 solver.cpp:333]     [0.0] Iteration 12496 (8.22034 iter/s, 5.35258s/44 iter), 34.8/100ep, loss = 11.7248
I1130 23:13:16.462038   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.764967 (* 2 = 1.52993 loss)
I1130 23:13:16.462050   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.1949 (* 1 = 10.1949 loss)
I1130 23:13:16.462062   125 sgd_solver.cpp:180] [0.0] Iteration 12496, lr = 8.66206e-06, m = 0.9, lrm = 8.66206e-05, wd = 2.5e-07, gs = 1
I1130 23:13:21.461061   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:13:21.578459   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:13:21.821993   125 solver.cpp:333]     [0.0] Iteration 12540 (8.20898 iter/s, 5.35998s/44 iter), 34.9/100ep, loss = 12.1283
I1130 23:13:21.822033   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.64691 (* 2 = 3.29381 loss)
I1130 23:13:21.822044   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.83445 (* 1 = 8.83445 loss)
I1130 23:13:21.822057   125 sgd_solver.cpp:180] [0.0] Iteration 12540, lr = 8.62979e-06, m = 0.9, lrm = 8.62979e-05, wd = 2.5e-07, gs = 1
I1130 23:13:24.747803   125 solver.cpp:501] Iteration 12565, Testing net (#0)
I1130 23:13:40.268955   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:13:40.380225   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:13:41.985560   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.532782 (* 2 = 1.06556 loss)
I1130 23:13:41.985601   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.69846 (* 1 = 8.69846 loss)
I1130 23:13:41.985610   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.307
I1130 23:13:41.985620   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.6942
I1130 23:13:41.985625   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 45.7708
I1130 23:13:41.985658   125 solver.cpp:271] Tests completed in 20.1638s
I1130 23:13:44.425278   125 solver.cpp:333]     [0.0] Iteration 12584 (2.18213 iter/s, 20.1638s/44 iter), 35.1/100ep, loss = 7.41374
I1130 23:13:44.425323   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.298063 (* 2 = 0.596127 loss)
I1130 23:13:44.425334   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.81761 (* 1 = 6.81761 loss)
I1130 23:13:44.425348   125 sgd_solver.cpp:180] [0.0] Iteration 12584, lr = 8.59764e-06, m = 0.9, lrm = 8.59764e-05, wd = 2.5e-07, gs = 1
I1130 23:13:49.801882   125 solver.cpp:333]     [0.0] Iteration 12628 (8.18363 iter/s, 5.37659s/44 iter), 35.2/100ep, loss = 10.6343
I1130 23:13:49.801930   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.675063 (* 2 = 1.35013 loss)
I1130 23:13:49.801946   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.28414 (* 1 = 9.28414 loss)
I1130 23:13:49.801962   125 sgd_solver.cpp:180] [0.0] Iteration 12628, lr = 8.56562e-06, m = 0.9, lrm = 8.56561e-05, wd = 2.5e-07, gs = 1
I1130 23:13:55.202003   125 solver.cpp:333]     [0.0] Iteration 12672 (8.14794 iter/s, 5.40014s/44 iter), 35.3/100ep, loss = 4.62153
I1130 23:13:55.202042   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.436643 (* 2 = 0.873286 loss)
I1130 23:13:55.202051   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.74823 (* 1 = 3.74823 loss)
I1130 23:13:55.202062   125 sgd_solver.cpp:180] [0.0] Iteration 12672, lr = 8.53371e-06, m = 0.9, lrm = 8.53371e-05, wd = 2.5e-07, gs = 1
I1130 23:14:00.545064   125 solver.cpp:333]     [0.0] Iteration 12716 (8.23501 iter/s, 5.34304s/44 iter), 35.4/100ep, loss = 22.3103
I1130 23:14:00.545106   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 2.14349 (* 2 = 4.28699 loss)
I1130 23:14:00.545116   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 18.0233 (* 1 = 18.0233 loss)
I1130 23:14:00.545128   125 sgd_solver.cpp:180] [0.0] Iteration 12716, lr = 8.50192e-06, m = 0.9, lrm = 8.50192e-05, wd = 2.5e-07, gs = 1
I1130 23:14:05.895681   125 solver.cpp:333]     [0.0] Iteration 12760 (8.22334 iter/s, 5.35063s/44 iter), 35.5/100ep, loss = 10.089
I1130 23:14:05.895720   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.50399 (* 2 = 3.00798 loss)
I1130 23:14:05.895730   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.08103 (* 1 = 7.08103 loss)
I1130 23:14:05.895740   125 sgd_solver.cpp:180] [0.0] Iteration 12760, lr = 8.47025e-06, m = 0.9, lrm = 8.47025e-05, wd = 2.5e-07, gs = 1
I1130 23:14:11.244218   125 solver.cpp:333]     [0.0] Iteration 12804 (8.22654 iter/s, 5.34854s/44 iter), 35.7/100ep, loss = 8.00999
I1130 23:14:11.244377   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.585692 (* 2 = 1.17138 loss)
I1130 23:14:11.244390   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.8386 (* 1 = 6.8386 loss)
I1130 23:14:11.244401   125 sgd_solver.cpp:180] [0.0] Iteration 12804, lr = 8.43869e-06, m = 0.9, lrm = 8.43869e-05, wd = 2.5e-07, gs = 1
I1130 23:14:16.588259   125 solver.cpp:333]     [0.0] Iteration 12848 (8.23349 iter/s, 5.34403s/44 iter), 35.8/100ep, loss = 4.8852
I1130 23:14:16.588302   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.62827 (* 2 = 1.25654 loss)
I1130 23:14:16.588312   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.62865 (* 1 = 3.62865 loss)
I1130 23:14:16.588325   125 sgd_solver.cpp:180] [0.0] Iteration 12848, lr = 8.40726e-06, m = 0.9, lrm = 8.40726e-05, wd = 2.5e-07, gs = 1
I1130 23:14:21.938544   125 solver.cpp:333]     [0.0] Iteration 12892 (8.22386 iter/s, 5.35029s/44 iter), 35.9/100ep, loss = 8.48294
I1130 23:14:21.938585   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.555206 (* 2 = 1.11041 loss)
I1130 23:14:21.938596   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.37252 (* 1 = 7.37252 loss)
I1130 23:14:21.938607   125 sgd_solver.cpp:180] [0.0] Iteration 12892, lr = 8.37594e-06, m = 0.9, lrm = 8.37594e-05, wd = 2.5e-07, gs = 1
I1130 23:14:22.182168   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:14:22.303397   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:14:25.708336   125 solver.cpp:501] Iteration 12924, Testing net (#0)
I1130 23:14:41.157531   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:14:41.312289   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:14:42.967898   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.534397 (* 2 = 1.06879 loss)
I1130 23:14:42.967955   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.69211 (* 1 = 8.69211 loss)
I1130 23:14:42.967964   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.4637
I1130 23:14:42.967972   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 31.0162
I1130 23:14:42.967979   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 43.3676
I1130 23:14:42.968013   125 solver.cpp:271] Tests completed in 21.0296s
I1130 23:14:44.548732   125 solver.cpp:333]     [0.0] Iteration 12936 (2.09229 iter/s, 21.0296s/44 iter), 36/100ep, loss = 9.39972
I1130 23:14:44.548772   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.673742 (* 2 = 1.34748 loss)
I1130 23:14:44.548784   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.05223 (* 1 = 8.05223 loss)
I1130 23:14:44.548794   125 sgd_solver.cpp:180] [0.0] Iteration 12936, lr = 8.34474e-06, m = 0.9, lrm = 8.34474e-05, wd = 2.5e-07, gs = 1
I1130 23:14:49.894150   125 solver.cpp:333]     [0.0] Iteration 12980 (8.23135 iter/s, 5.34542s/44 iter), 36.2/100ep, loss = 8.31918
I1130 23:14:49.894191   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.01462 (* 2 = 2.02923 loss)
I1130 23:14:49.894201   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.28993 (* 1 = 6.28993 loss)
I1130 23:14:49.894213   125 sgd_solver.cpp:180] [0.0] Iteration 12980, lr = 8.31365e-06, m = 0.9, lrm = 8.31365e-05, wd = 2.5e-07, gs = 1
I1130 23:14:55.238780   125 solver.cpp:333]     [0.0] Iteration 13024 (8.23256 iter/s, 5.34463s/44 iter), 36.3/100ep, loss = 10.6751
I1130 23:14:55.238819   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.42179 (* 2 = 2.84359 loss)
I1130 23:14:55.238831   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.83151 (* 1 = 7.83151 loss)
I1130 23:14:55.238842   125 sgd_solver.cpp:180] [0.0] Iteration 13024, lr = 8.28268e-06, m = 0.9, lrm = 8.28268e-05, wd = 2.5e-07, gs = 1
I1130 23:15:00.584949   125 solver.cpp:333]     [0.0] Iteration 13068 (8.23022 iter/s, 5.34615s/44 iter), 36.4/100ep, loss = 5.31765
I1130 23:15:00.584990   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.354404 (* 2 = 0.708808 loss)
I1130 23:15:00.585001   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.60884 (* 1 = 4.60884 loss)
I1130 23:15:00.585011   125 sgd_solver.cpp:180] [0.0] Iteration 13068, lr = 8.25183e-06, m = 0.9, lrm = 8.25183e-05, wd = 2.5e-07, gs = 1
I1130 23:15:05.931279   125 solver.cpp:333]     [0.0] Iteration 13112 (8.22993 iter/s, 5.34634s/44 iter), 36.5/100ep, loss = 8.81224
I1130 23:15:05.931316   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.0498 (* 2 = 2.09961 loss)
I1130 23:15:05.931326   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.71263 (* 1 = 6.71263 loss)
I1130 23:15:05.931337   125 sgd_solver.cpp:180] [0.0] Iteration 13112, lr = 8.22109e-06, m = 0.9, lrm = 8.22109e-05, wd = 2.5e-07, gs = 1
I1130 23:15:11.285246   125 solver.cpp:333]     [0.0] Iteration 13156 (8.21819 iter/s, 5.35398s/44 iter), 36.6/100ep, loss = 9.68382
I1130 23:15:11.285284   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.632496 (* 2 = 1.26499 loss)
I1130 23:15:11.285296   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.41882 (* 1 = 8.41882 loss)
I1130 23:15:11.285307   125 sgd_solver.cpp:180] [0.0] Iteration 13156, lr = 8.19046e-06, m = 0.9, lrm = 8.19046e-05, wd = 2.5e-07, gs = 1
I1130 23:15:16.635390   125 solver.cpp:333]     [0.0] Iteration 13200 (8.22411 iter/s, 5.35013s/44 iter), 36.8/100ep, loss = 10.5507
I1130 23:15:16.635561   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.533594 (* 2 = 1.06719 loss)
I1130 23:15:16.635576   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.48352 (* 1 = 9.48352 loss)
I1130 23:15:16.635586   125 sgd_solver.cpp:180] [0.0] Iteration 13200, lr = 8.15995e-06, m = 0.9, lrm = 8.15995e-05, wd = 2.5e-07, gs = 1
I1130 23:15:21.981449   125 solver.cpp:333]     [0.0] Iteration 13244 (8.23036 iter/s, 5.34606s/44 iter), 36.9/100ep, loss = 13.6974
I1130 23:15:21.981492   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.22699 (* 2 = 2.45397 loss)
I1130 23:15:21.981503   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.2434 (* 1 = 11.2434 loss)
I1130 23:15:21.981514   125 sgd_solver.cpp:180] [0.0] Iteration 13244, lr = 8.12956e-06, m = 0.9, lrm = 8.12955e-05, wd = 2.5e-07, gs = 1
I1130 23:15:23.201254   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:15:23.314545   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:15:26.597887   125 solver.cpp:501] Iteration 13283, Testing net (#0)
I1130 23:15:42.160518   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:15:42.276834   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:15:43.983537   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.532496 (* 2 = 1.06499 loss)
I1130 23:15:43.983577   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.7089 (* 1 = 8.7089 loss)
I1130 23:15:43.983585   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 16.792
I1130 23:15:43.983593   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.1897
I1130 23:15:43.983600   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 45.7983
I1130 23:15:43.983634   125 solver.cpp:271] Tests completed in 22.0023s
I1130 23:15:44.714964   125 solver.cpp:333]     [0.0] Iteration 13288 (1.99979 iter/s, 22.0023s/44 iter), 37/100ep, loss = 9.37902
I1130 23:15:44.715006   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.485123 (* 2 = 0.970247 loss)
I1130 23:15:44.715018   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.40876 (* 1 = 8.40876 loss)
I1130 23:15:44.715029   125 sgd_solver.cpp:180] [0.0] Iteration 13288, lr = 8.09927e-06, m = 0.9, lrm = 8.09927e-05, wd = 2.5e-07, gs = 1
I1130 23:15:50.060623   125 solver.cpp:333]     [0.0] Iteration 13332 (8.23097 iter/s, 5.34566s/44 iter), 37.1/100ep, loss = 5.45775
I1130 23:15:50.060760   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.268226 (* 2 = 0.536451 loss)
I1130 23:15:50.060772   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.92129 (* 1 = 4.92129 loss)
I1130 23:15:50.060783   125 sgd_solver.cpp:180] [0.0] Iteration 13332, lr = 8.0691e-06, m = 0.9, lrm = 8.0691e-05, wd = 2.5e-07, gs = 1
I1130 23:15:55.405370   125 solver.cpp:333]     [0.0] Iteration 13376 (8.23238 iter/s, 5.34475s/44 iter), 37.3/100ep, loss = 13.789
I1130 23:15:55.405411   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.937342 (* 2 = 1.87468 loss)
I1130 23:15:55.405422   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.9143 (* 1 = 11.9143 loss)
I1130 23:15:55.405436   125 sgd_solver.cpp:180] [0.0] Iteration 13376, lr = 8.03904e-06, m = 0.9, lrm = 8.03904e-05, wd = 2.5e-07, gs = 1
I1130 23:16:00.744304   125 solver.cpp:333]     [0.0] Iteration 13420 (8.24136 iter/s, 5.33892s/44 iter), 37.4/100ep, loss = 6.69097
I1130 23:16:00.744345   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.366177 (* 2 = 0.732353 loss)
I1130 23:16:00.744356   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.95861 (* 1 = 5.95861 loss)
I1130 23:16:00.744369   125 sgd_solver.cpp:180] [0.0] Iteration 13420, lr = 8.0091e-06, m = 0.9, lrm = 8.00909e-05, wd = 2.5e-07, gs = 1
I1130 23:16:06.088722   125 solver.cpp:333]     [0.0] Iteration 13464 (8.23289 iter/s, 5.34442s/44 iter), 37.5/100ep, loss = 13.3852
I1130 23:16:06.088763   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.01629 (* 2 = 2.03257 loss)
I1130 23:16:06.088774   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.3526 (* 1 = 11.3526 loss)
I1130 23:16:06.088785   125 sgd_solver.cpp:180] [0.0] Iteration 13464, lr = 7.97926e-06, m = 0.9, lrm = 7.97926e-05, wd = 2.5e-07, gs = 1
I1130 23:16:11.421084   125 solver.cpp:333]     [0.0] Iteration 13508 (8.2515 iter/s, 5.33237s/44 iter), 37.6/100ep, loss = 5.93561
I1130 23:16:11.421124   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.611459 (* 2 = 1.22292 loss)
I1130 23:16:11.421135   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.71269 (* 1 = 4.71269 loss)
I1130 23:16:11.421147   125 sgd_solver.cpp:180] [0.0] Iteration 13508, lr = 7.94954e-06, m = 0.9, lrm = 7.94953e-05, wd = 2.5e-07, gs = 1
I1130 23:16:16.762238   125 solver.cpp:333]     [0.0] Iteration 13552 (8.23794 iter/s, 5.34114s/44 iter), 37.7/100ep, loss = 10.4578
I1130 23:16:16.762279   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.92453 (* 2 = 1.84906 loss)
I1130 23:16:16.762290   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.60874 (* 1 = 8.60874 loss)
I1130 23:16:16.762303   125 sgd_solver.cpp:180] [0.0] Iteration 13552, lr = 7.91992e-06, m = 0.9, lrm = 7.91992e-05, wd = 2.5e-07, gs = 1
I1130 23:16:22.101975   125 solver.cpp:333]     [0.0] Iteration 13596 (8.2401 iter/s, 5.33974s/44 iter), 37.9/100ep, loss = 4.28581
I1130 23:16:22.102156   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.462808 (* 2 = 0.925616 loss)
I1130 23:16:22.102169   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.36018 (* 1 = 3.36018 loss)
I1130 23:16:22.102181   125 sgd_solver.cpp:180] [0.0] Iteration 13596, lr = 7.89042e-06, m = 0.9, lrm = 7.89042e-05, wd = 2.5e-07, gs = 1
I1130 23:16:24.286164   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:16:24.404922   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:16:27.442096   125 solver.cpp:333]     [0.0] Iteration 13640 (8.23951 iter/s, 5.34012s/44 iter), 38/100ep, loss = 5.39104
I1130 23:16:27.442137   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.469437 (* 2 = 0.938874 loss)
I1130 23:16:27.442147   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.45216 (* 1 = 4.45216 loss)
I1130 23:16:27.442158   125 sgd_solver.cpp:180] [0.0] Iteration 13640, lr = 7.86103e-06, m = 0.9, lrm = 7.86103e-05, wd = 2.5e-07, gs = 1
I1130 23:16:27.563596   125 solver.cpp:501] Iteration 13642, Testing net (#0)
I1130 23:16:42.782891   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:16:42.938468   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:16:44.677593   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.530591 (* 2 = 1.06118 loss)
I1130 23:16:44.677636   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.73413 (* 1 = 8.73413 loss)
I1130 23:16:44.677645   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.9741
I1130 23:16:44.677654   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 30.9774
I1130 23:16:44.677660   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 44.854
I1130 23:16:44.677695   125 solver.cpp:271] Tests completed in 17.2357s
I1130 23:16:49.980865   125 solver.cpp:333]     [0.0] Iteration 13684 (2.55285 iter/s, 17.2357s/44 iter), 38.1/100ep, loss = 11.2542
I1130 23:16:49.980907   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.944857 (* 2 = 1.88971 loss)
I1130 23:16:49.980918   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.36449 (* 1 = 9.36449 loss)
I1130 23:16:49.980929   125 sgd_solver.cpp:180] [0.0] Iteration 13684, lr = 7.83174e-06, m = 0.9, lrm = 7.83174e-05, wd = 2.5e-07, gs = 1
I1130 23:16:55.408577   125 solver.cpp:333]     [0.0] Iteration 13728 (8.10653 iter/s, 5.42772s/44 iter), 38.2/100ep, loss = 5.24316
I1130 23:16:55.408782   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.609928 (* 2 = 1.21986 loss)
I1130 23:16:55.408797   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.02329 (* 1 = 4.02329 loss)
I1130 23:16:55.408808   125 sgd_solver.cpp:180] [0.0] Iteration 13728, lr = 7.80257e-06, m = 0.9, lrm = 7.80257e-05, wd = 2.5e-07, gs = 1
I1130 23:17:00.818956   125 solver.cpp:333]     [0.0] Iteration 13772 (8.13254 iter/s, 5.41036s/44 iter), 38.4/100ep, loss = 12.3497
I1130 23:17:00.818994   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.512915 (* 2 = 1.02583 loss)
I1130 23:17:00.819006   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.3239 (* 1 = 11.3239 loss)
I1130 23:17:00.819018   125 sgd_solver.cpp:180] [0.0] Iteration 13772, lr = 7.7735e-06, m = 0.9, lrm = 7.7735e-05, wd = 2.5e-07, gs = 1
I1130 23:17:06.174262   125 solver.cpp:333]     [0.0] Iteration 13816 (8.21615 iter/s, 5.35531s/44 iter), 38.5/100ep, loss = 7.28098
I1130 23:17:06.174301   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.07082 (* 2 = 2.14164 loss)
I1130 23:17:06.174312   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.13933 (* 1 = 5.13933 loss)
I1130 23:17:06.174324   125 sgd_solver.cpp:180] [0.0] Iteration 13816, lr = 7.74455e-06, m = 0.9, lrm = 7.74454e-05, wd = 2.5e-07, gs = 1
I1130 23:17:11.534458   125 solver.cpp:333]     [0.0] Iteration 13860 (8.20867 iter/s, 5.36018s/44 iter), 38.6/100ep, loss = 12.029
I1130 23:17:11.534499   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.12173 (* 2 = 2.24346 loss)
I1130 23:17:11.534510   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.78549 (* 1 = 9.78549 loss)
I1130 23:17:11.534521   125 sgd_solver.cpp:180] [0.0] Iteration 13860, lr = 7.7157e-06, m = 0.9, lrm = 7.71569e-05, wd = 2.5e-07, gs = 1
I1130 23:17:16.907200   125 solver.cpp:333]     [0.0] Iteration 13904 (8.18947 iter/s, 5.37275s/44 iter), 38.7/100ep, loss = 7.85698
I1130 23:17:16.907238   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.654547 (* 2 = 1.30909 loss)
I1130 23:17:16.907249   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.54788 (* 1 = 6.54788 loss)
I1130 23:17:16.907261   125 sgd_solver.cpp:180] [0.0] Iteration 13904, lr = 7.68695e-06, m = 0.9, lrm = 7.68695e-05, wd = 2.5e-07, gs = 1
I1130 23:17:22.260665   125 solver.cpp:333]     [0.0] Iteration 13948 (8.21899 iter/s, 5.35346s/44 iter), 38.9/100ep, loss = 12.1257
I1130 23:17:22.260722   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.833596 (* 2 = 1.66719 loss)
I1130 23:17:22.260741   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.4585 (* 1 = 10.4585 loss)
I1130 23:17:22.260757   125 sgd_solver.cpp:180] [0.0] Iteration 13948, lr = 7.65832e-06, m = 0.9, lrm = 7.65832e-05, wd = 2.5e-07, gs = 1
I1130 23:17:25.115017   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:17:25.269876   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:17:27.716243   125 solver.cpp:333]     [0.0] Iteration 13992 (8.06515 iter/s, 5.45557s/44 iter), 39/100ep, loss = 5.32075
I1130 23:17:27.716437   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.552242 (* 2 = 1.10448 loss)
I1130 23:17:27.716451   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.21626 (* 1 = 4.21626 loss)
I1130 23:17:27.716464   125 sgd_solver.cpp:180] [0.0] Iteration 13992, lr = 7.62979e-06, m = 0.9, lrm = 7.62979e-05, wd = 2.5e-07, gs = 1
I1130 23:17:28.715921   125 solver.cpp:501] Iteration 14001, Testing net (#0)
I1130 23:17:44.957442   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:17:45.070909   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:17:46.870298   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.526725 (* 2 = 1.05345 loss)
I1130 23:17:46.870352   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.78444 (* 1 = 8.78444 loss)
I1130 23:17:46.870365   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 16.998
I1130 23:17:46.870378   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.5397
I1130 23:17:46.870389   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 46.3989
I1130 23:17:46.870430   125 solver.cpp:271] Tests completed in 19.1543s
I1130 23:17:51.251085   125 solver.cpp:333]     [0.0] Iteration 14036 (2.29714 iter/s, 19.1543s/44 iter), 39.1/100ep, loss = 7.8644
I1130 23:17:51.251129   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.351395 (* 2 = 0.70279 loss)
I1130 23:17:51.251140   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.1616 (* 1 = 7.1616 loss)
I1130 23:17:51.251152   125 sgd_solver.cpp:180] [0.0] Iteration 14036, lr = 7.60137e-06, m = 0.9, lrm = 7.60137e-05, wd = 2.5e-07, gs = 1
I1130 23:17:56.597265   125 solver.cpp:333]     [0.0] Iteration 14080 (8.23017 iter/s, 5.34618s/44 iter), 39.2/100ep, loss = 9.63722
I1130 23:17:56.597306   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.63611 (* 2 = 3.27223 loss)
I1130 23:17:56.597316   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.36498 (* 1 = 6.36498 loss)
I1130 23:17:56.597327   125 sgd_solver.cpp:180] [0.0] Iteration 14080, lr = 7.57305e-06, m = 0.9, lrm = 7.57305e-05, wd = 2.5e-07, gs = 1
I1130 23:18:01.940274   125 solver.cpp:333]     [0.0] Iteration 14124 (8.23506 iter/s, 5.34301s/44 iter), 39.3/100ep, loss = 8.54906
I1130 23:18:01.940459   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.93741 (* 2 = 3.87483 loss)
I1130 23:18:01.940470   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.67422 (* 1 = 4.67422 loss)
I1130 23:18:01.940482   125 sgd_solver.cpp:180] [0.0] Iteration 14124, lr = 7.54484e-06, m = 0.9, lrm = 7.54484e-05, wd = 2.5e-07, gs = 1
I1130 23:18:07.280683   125 solver.cpp:333]     [0.0] Iteration 14168 (8.23906 iter/s, 5.34041s/44 iter), 39.5/100ep, loss = 6.83004
I1130 23:18:07.280725   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.790713 (* 2 = 1.58143 loss)
I1130 23:18:07.280736   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.2486 (* 1 = 5.2486 loss)
I1130 23:18:07.280747   125 sgd_solver.cpp:180] [0.0] Iteration 14168, lr = 7.51673e-06, m = 0.9, lrm = 7.51673e-05, wd = 2.5e-07, gs = 1
I1130 23:18:12.621660   125 solver.cpp:333]     [0.0] Iteration 14212 (8.23821 iter/s, 5.34096s/44 iter), 39.6/100ep, loss = 5.14024
I1130 23:18:12.621700   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.492564 (* 2 = 0.985127 loss)
I1130 23:18:12.621711   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.1551 (* 1 = 4.1551 loss)
I1130 23:18:12.621721   125 sgd_solver.cpp:180] [0.0] Iteration 14212, lr = 7.48873e-06, m = 0.9, lrm = 7.48873e-05, wd = 2.5e-07, gs = 1
I1130 23:18:17.960839   125 solver.cpp:333]     [0.0] Iteration 14256 (8.24096 iter/s, 5.33918s/44 iter), 39.7/100ep, loss = 4.57709
I1130 23:18:17.960877   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.563602 (* 2 = 1.1272 loss)
I1130 23:18:17.960888   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.44987 (* 1 = 3.44987 loss)
I1130 23:18:17.960901   125 sgd_solver.cpp:180] [0.0] Iteration 14256, lr = 7.46084e-06, m = 0.9, lrm = 7.46083e-05, wd = 2.5e-07, gs = 1
I1130 23:18:23.299687   125 solver.cpp:333]     [0.0] Iteration 14300 (8.24148 iter/s, 5.33885s/44 iter), 39.8/100ep, loss = 16.8145
I1130 23:18:23.299731   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.06688 (* 2 = 2.13375 loss)
I1130 23:18:23.299741   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.6808 (* 1 = 14.6808 loss)
I1130 23:18:23.299752   125 sgd_solver.cpp:180] [0.0] Iteration 14300, lr = 7.43304e-06, m = 0.9, lrm = 7.43304e-05, wd = 2.5e-07, gs = 1
I1130 23:18:27.064682   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:18:27.183409   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:18:28.645953   125 solver.cpp:333]     [0.0] Iteration 14344 (8.23006 iter/s, 5.34625s/44 iter), 40/100ep, loss = 7.64698
I1130 23:18:28.645992   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.980182 (* 2 = 1.96036 loss)
I1130 23:18:28.646003   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.6866 (* 1 = 5.6866 loss)
I1130 23:18:28.646014   125 sgd_solver.cpp:180] [0.0] Iteration 14344, lr = 7.40535e-06, m = 0.9, lrm = 7.40535e-05, wd = 2.5e-07, gs = 1
I1130 23:18:30.471801   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_14360.caffemodel
I1130 23:18:30.519641   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_14360.solverstate
I1130 23:18:30.562959   125 solver.cpp:501] Iteration 14360, Testing net (#0)
I1130 23:18:45.808358   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:18:45.965173   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:18:47.797122   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.527082 (* 2 = 1.05416 loss)
I1130 23:18:47.797160   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.79207 (* 1 = 8.79207 loss)
I1130 23:18:47.797169   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.5414
I1130 23:18:47.797178   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 31.5258
I1130 23:18:47.797184   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 45.9941
I1130 23:18:47.797219   125 solver.cpp:271] Tests completed in 19.1513s
I1130 23:18:51.322557   125 solver.cpp:333]     [0.0] Iteration 14388 (2.29749 iter/s, 19.1513s/44 iter), 40.1/100ep, loss = 7.87573
I1130 23:18:51.322598   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.469998 (* 2 = 0.939996 loss)
I1130 23:18:51.322609   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.93571 (* 1 = 6.93571 loss)
I1130 23:18:51.322621   125 sgd_solver.cpp:180] [0.0] Iteration 14388, lr = 7.37777e-06, m = 0.9, lrm = 7.37777e-05, wd = 2.5e-07, gs = 1
I1130 23:18:56.671684   125 solver.cpp:333]     [0.0] Iteration 14432 (8.22566 iter/s, 5.34911s/44 iter), 40.2/100ep, loss = 6.7411
I1130 23:18:56.671725   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.40139 (* 2 = 0.802779 loss)
I1130 23:18:56.671736   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.9383 (* 1 = 5.9383 loss)
I1130 23:18:56.671747   125 sgd_solver.cpp:180] [0.0] Iteration 14432, lr = 7.35028e-06, m = 0.9, lrm = 7.35028e-05, wd = 2.5e-07, gs = 1
I1130 23:19:02.022945   125 solver.cpp:333]     [0.0] Iteration 14476 (8.22236 iter/s, 5.35126s/44 iter), 40.3/100ep, loss = 9.13185
I1130 23:19:02.022989   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.385562 (* 2 = 0.771124 loss)
I1130 23:19:02.023000   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.36071 (* 1 = 8.36071 loss)
I1130 23:19:02.023010   125 sgd_solver.cpp:180] [0.0] Iteration 14476, lr = 7.3229e-06, m = 0.9, lrm = 7.3229e-05, wd = 2.5e-07, gs = 1
I1130 23:19:07.375836   125 solver.cpp:333]     [0.0] Iteration 14520 (8.21985 iter/s, 5.3529s/44 iter), 40.4/100ep, loss = 7.60438
I1130 23:19:07.375877   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.07404 (* 2 = 2.14808 loss)
I1130 23:19:07.375887   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.45627 (* 1 = 5.45627 loss)
I1130 23:19:07.375898   125 sgd_solver.cpp:180] [0.0] Iteration 14520, lr = 7.29562e-06, m = 0.9, lrm = 7.29562e-05, wd = 2.5e-07, gs = 1
I1130 23:19:12.720463   125 solver.cpp:333]     [0.0] Iteration 14564 (8.23259 iter/s, 5.34461s/44 iter), 40.6/100ep, loss = 3.62428
I1130 23:19:12.720504   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.477257 (* 2 = 0.954515 loss)
I1130 23:19:12.720515   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.66975 (* 1 = 2.66975 loss)
I1130 23:19:12.720525   125 sgd_solver.cpp:180] [0.0] Iteration 14564, lr = 7.26845e-06, m = 0.9, lrm = 7.26845e-05, wd = 2.5e-07, gs = 1
I1130 23:19:18.064254   125 solver.cpp:333]     [0.0] Iteration 14608 (8.23386 iter/s, 5.34379s/44 iter), 40.7/100ep, loss = 8.76568
I1130 23:19:18.064445   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.825283 (* 2 = 1.65057 loss)
I1130 23:19:18.064460   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.11509 (* 1 = 7.11509 loss)
I1130 23:19:18.064471   125 sgd_solver.cpp:180] [0.0] Iteration 14608, lr = 7.24137e-06, m = 0.9, lrm = 7.24137e-05, wd = 2.5e-07, gs = 1
I1130 23:19:23.409519   125 solver.cpp:333]     [0.0] Iteration 14652 (8.23158 iter/s, 5.34527s/44 iter), 40.8/100ep, loss = 3.67124
I1130 23:19:23.409559   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.670148 (* 2 = 1.3403 loss)
I1130 23:19:23.409571   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.33093 (* 1 = 2.33093 loss)
I1130 23:19:23.409584   125 sgd_solver.cpp:180] [0.0] Iteration 14652, lr = 7.2144e-06, m = 0.9, lrm = 7.21439e-05, wd = 2.5e-07, gs = 1
I1130 23:19:28.152770   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:19:28.269392   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:19:28.754760   125 solver.cpp:333]     [0.0] Iteration 14696 (8.23163 iter/s, 5.34524s/44 iter), 40.9/100ep, loss = 10.5008
I1130 23:19:28.754801   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.12066 (* 2 = 2.24132 loss)
I1130 23:19:28.754812   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.2595 (* 1 = 8.2595 loss)
I1130 23:19:28.754822   125 sgd_solver.cpp:180] [0.0] Iteration 14696, lr = 7.18752e-06, m = 0.9, lrm = 7.18752e-05, wd = 2.5e-07, gs = 1
I1130 23:19:31.425155   125 solver.cpp:501] Iteration 14719, Testing net (#0)
I1130 23:19:46.751773   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:19:46.865244   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:19:48.749485   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.526788 (* 2 = 1.05358 loss)
I1130 23:19:48.749640   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.74522 (* 1 = 8.74522 loss)
I1130 23:19:48.749651   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.1953
I1130 23:19:48.749660   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.0581
I1130 23:19:48.749666   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 46.2185
I1130 23:19:48.749701   125 solver.cpp:271] Tests completed in 19.995s
I1130 23:19:51.447227   125 solver.cpp:333]     [0.0] Iteration 14740 (2.20055 iter/s, 19.995s/44 iter), 41.1/100ep, loss = 9.17599
I1130 23:19:51.447270   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.822616 (* 2 = 1.64523 loss)
I1130 23:19:51.447281   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.53074 (* 1 = 7.53074 loss)
I1130 23:19:51.447293   125 sgd_solver.cpp:180] [0.0] Iteration 14740, lr = 7.16075e-06, m = 0.9, lrm = 7.16074e-05, wd = 2.5e-07, gs = 1
I1130 23:19:56.798530   125 solver.cpp:333]     [0.0] Iteration 14784 (8.22232 iter/s, 5.35129s/44 iter), 41.2/100ep, loss = 11.1617
I1130 23:19:56.798571   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.22084 (* 2 = 2.44168 loss)
I1130 23:19:56.798581   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.72001 (* 1 = 8.72001 loss)
I1130 23:19:56.798593   125 sgd_solver.cpp:180] [0.0] Iteration 14784, lr = 7.13407e-06, m = 0.9, lrm = 7.13407e-05, wd = 2.5e-07, gs = 1
I1130 23:20:02.162484   125 solver.cpp:333]     [0.0] Iteration 14828 (8.20289 iter/s, 5.36396s/44 iter), 41.3/100ep, loss = 13.9999
I1130 23:20:02.162526   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.451023 (* 2 = 0.902046 loss)
I1130 23:20:02.162537   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.0978 (* 1 = 13.0978 loss)
I1130 23:20:02.162549   125 sgd_solver.cpp:180] [0.0] Iteration 14828, lr = 7.1075e-06, m = 0.9, lrm = 7.10749e-05, wd = 2.5e-07, gs = 1
I1130 23:20:07.519867   125 solver.cpp:333]     [0.0] Iteration 14872 (8.21299 iter/s, 5.35737s/44 iter), 41.4/100ep, loss = 9.86067
I1130 23:20:07.519907   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.829648 (* 2 = 1.6593 loss)
I1130 23:20:07.519918   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.20135 (* 1 = 8.20135 loss)
I1130 23:20:07.519929   125 sgd_solver.cpp:180] [0.0] Iteration 14872, lr = 7.08102e-06, m = 0.9, lrm = 7.08102e-05, wd = 2.5e-07, gs = 1
I1130 23:20:12.898748   125 solver.cpp:333]     [0.0] Iteration 14916 (8.18013 iter/s, 5.37889s/44 iter), 41.5/100ep, loss = 11.4308
I1130 23:20:12.898792   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.6085 (* 2 = 3.217 loss)
I1130 23:20:12.898802   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.21381 (* 1 = 8.21381 loss)
I1130 23:20:12.898813   125 sgd_solver.cpp:180] [0.0] Iteration 14916, lr = 7.05464e-06, m = 0.9, lrm = 7.05464e-05, wd = 2.5e-07, gs = 1
I1130 23:20:18.258301   125 solver.cpp:333]     [0.0] Iteration 14960 (8.20964 iter/s, 5.35955s/44 iter), 41.7/100ep, loss = 13.2894
I1130 23:20:18.258343   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.18683 (* 2 = 2.37367 loss)
I1130 23:20:18.258353   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.9157 (* 1 = 10.9157 loss)
I1130 23:20:18.258365   125 sgd_solver.cpp:180] [0.0] Iteration 14960, lr = 7.02836e-06, m = 0.9, lrm = 7.02836e-05, wd = 2.5e-07, gs = 1
I1130 23:20:23.616943   125 solver.cpp:333]     [0.0] Iteration 15004 (8.21106 iter/s, 5.35863s/44 iter), 41.8/100ep, loss = 9.36696
I1130 23:20:23.617121   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.87521 (* 2 = 1.75042 loss)
I1130 23:20:23.617135   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.61652 (* 1 = 7.61652 loss)
I1130 23:20:23.617147   125 sgd_solver.cpp:180] [0.0] Iteration 15004, lr = 7.00218e-06, m = 0.9, lrm = 7.00218e-05, wd = 2.5e-07, gs = 1
I1130 23:20:28.979487   125 solver.cpp:333]     [0.0] Iteration 15048 (8.20506 iter/s, 5.36255s/44 iter), 41.9/100ep, loss = 5.31457
I1130 23:20:28.979526   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.435738 (* 2 = 0.871476 loss)
I1130 23:20:28.979537   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.44308 (* 1 = 4.44308 loss)
I1130 23:20:28.979548   125 sgd_solver.cpp:180] [0.0] Iteration 15048, lr = 6.97609e-06, m = 0.9, lrm = 6.97609e-05, wd = 2.5e-07, gs = 1
I1130 23:20:28.984427   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:20:29.103441   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:20:32.510665   125 solver.cpp:501] Iteration 15078, Testing net (#0)
I1130 23:20:47.665148   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:20:47.818236   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:20:49.719579   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.532212 (* 2 = 1.06442 loss)
I1130 23:20:49.719616   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.88494 (* 1 = 8.88494 loss)
I1130 23:20:49.719624   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.3806
I1130 23:20:49.719632   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 30.3537
I1130 23:20:49.719640   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 43.4104
I1130 23:20:49.719671   125 solver.cpp:271] Tests completed in 20.7403s
I1130 23:20:51.544477   125 solver.cpp:333]     [0.0] Iteration 15092 (2.12148 iter/s, 20.7403s/44 iter), 42/100ep, loss = 9.34346
I1130 23:20:51.544523   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.31577 (* 2 = 2.63153 loss)
I1130 23:20:51.544533   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.71191 (* 1 = 6.71191 loss)
I1130 23:20:51.544544   125 sgd_solver.cpp:180] [0.0] Iteration 15092, lr = 6.95011e-06, m = 0.9, lrm = 6.95011e-05, wd = 2.5e-07, gs = 1
I1130 23:20:56.902595   125 solver.cpp:333]     [0.0] Iteration 15136 (8.21184 iter/s, 5.35812s/44 iter), 42.2/100ep, loss = 8.4156
I1130 23:20:56.902798   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.19348 (* 2 = 2.38697 loss)
I1130 23:20:56.902812   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.02861 (* 1 = 6.02861 loss)
I1130 23:20:56.902823   125 sgd_solver.cpp:180] [0.0] Iteration 15136, lr = 6.92422e-06, m = 0.9, lrm = 6.92422e-05, wd = 2.5e-07, gs = 1
I1130 23:21:02.262032   125 solver.cpp:333]     [0.0] Iteration 15180 (8.20982 iter/s, 5.35944s/44 iter), 42.3/100ep, loss = 5.92267
I1130 23:21:02.262075   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.725891 (* 2 = 1.45178 loss)
I1130 23:21:02.262087   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.47087 (* 1 = 4.47087 loss)
I1130 23:21:02.262099   125 sgd_solver.cpp:180] [0.0] Iteration 15180, lr = 6.89842e-06, m = 0.9, lrm = 6.89842e-05, wd = 2.5e-07, gs = 1
I1130 23:21:07.628119   125 solver.cpp:333]     [0.0] Iteration 15224 (8.19967 iter/s, 5.36607s/44 iter), 42.4/100ep, loss = 4.9235
I1130 23:21:07.628160   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.181916 (* 2 = 0.363833 loss)
I1130 23:21:07.628171   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.55965 (* 1 = 4.55965 loss)
I1130 23:21:07.628182   125 sgd_solver.cpp:180] [0.0] Iteration 15224, lr = 6.87273e-06, m = 0.9, lrm = 6.87272e-05, wd = 2.5e-07, gs = 1
I1130 23:21:12.990908   125 solver.cpp:333]     [0.0] Iteration 15268 (8.20468 iter/s, 5.36279s/44 iter), 42.5/100ep, loss = 5.28329
I1130 23:21:12.990952   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.346602 (* 2 = 0.693204 loss)
I1130 23:21:12.990962   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.59007 (* 1 = 4.59007 loss)
I1130 23:21:12.990973   125 sgd_solver.cpp:180] [0.0] Iteration 15268, lr = 6.84712e-06, m = 0.9, lrm = 6.84712e-05, wd = 2.5e-07, gs = 1
I1130 23:21:18.358597   125 solver.cpp:333]     [0.0] Iteration 15312 (8.1972 iter/s, 5.36769s/44 iter), 42.7/100ep, loss = 5.95613
I1130 23:21:18.358640   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.367274 (* 2 = 0.734549 loss)
I1130 23:21:18.358651   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.22157 (* 1 = 5.22157 loss)
I1130 23:21:18.358662   125 sgd_solver.cpp:180] [0.0] Iteration 15312, lr = 6.82162e-06, m = 0.9, lrm = 6.82162e-05, wd = 2.5e-07, gs = 1
I1130 23:21:23.721686   125 solver.cpp:333]     [0.0] Iteration 15356 (8.20425 iter/s, 5.36307s/44 iter), 42.8/100ep, loss = 5.51682
I1130 23:21:23.721729   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.377722 (* 2 = 0.755445 loss)
I1130 23:21:23.721740   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.76136 (* 1 = 4.76136 loss)
I1130 23:21:23.721751   125 sgd_solver.cpp:180] [0.0] Iteration 15356, lr = 6.79621e-06, m = 0.9, lrm = 6.7962e-05, wd = 2.5e-07, gs = 1
I1130 23:21:29.082036   125 solver.cpp:333]     [0.0] Iteration 15400 (8.2084 iter/s, 5.36037s/44 iter), 42.9/100ep, loss = 10.5594
I1130 23:21:29.082238   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.64747 (* 2 = 3.29494 loss)
I1130 23:21:29.082252   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.26449 (* 1 = 7.26449 loss)
I1130 23:21:29.082263   125 sgd_solver.cpp:180] [0.0] Iteration 15400, lr = 6.77089e-06, m = 0.9, lrm = 6.77089e-05, wd = 2.5e-07, gs = 1
I1130 23:21:30.060725   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:21:30.173257   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:21:33.463640   125 solver.cpp:501] Iteration 15437, Testing net (#0)
I1130 23:21:48.699592   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:21:48.812542   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:21:50.760020   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.521147 (* 2 = 1.04229 loss)
I1130 23:21:50.760061   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.71966 (* 1 = 8.71966 loss)
I1130 23:21:50.760068   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.3423
I1130 23:21:50.760076   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.2304
I1130 23:21:50.760083   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.2003
I1130 23:21:50.760118   125 solver.cpp:271] Tests completed in 21.6782s
I1130 23:21:51.740370   125 solver.cpp:333]     [0.0] Iteration 15444 (2.02969 iter/s, 21.6782s/44 iter), 43/100ep, loss = 9.08235
I1130 23:21:51.740412   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.742395 (* 2 = 1.48479 loss)
I1130 23:21:51.740423   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.59754 (* 1 = 7.59754 loss)
I1130 23:21:51.740435   125 sgd_solver.cpp:180] [0.0] Iteration 15444, lr = 6.74567e-06, m = 0.9, lrm = 6.74566e-05, wd = 2.5e-07, gs = 1
I1130 23:21:57.091914   125 solver.cpp:333]     [0.0] Iteration 15488 (8.22193 iter/s, 5.35154s/44 iter), 43.1/100ep, loss = 10.8868
I1130 23:21:57.091958   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.692757 (* 2 = 1.38551 loss)
I1130 23:21:57.091969   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.5013 (* 1 = 9.5013 loss)
I1130 23:21:57.091980   125 sgd_solver.cpp:180] [0.0] Iteration 15488, lr = 6.72054e-06, m = 0.9, lrm = 6.72054e-05, wd = 2.5e-07, gs = 1
I1130 23:22:02.452769   125 solver.cpp:333]     [0.0] Iteration 15532 (8.20763 iter/s, 5.36086s/44 iter), 43.3/100ep, loss = 3.42796
I1130 23:22:02.452920   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.462514 (* 2 = 0.925028 loss)
I1130 23:22:02.452934   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.50292 (* 1 = 2.50292 loss)
I1130 23:22:02.452945   125 sgd_solver.cpp:180] [0.0] Iteration 15532, lr = 6.6955e-06, m = 0.9, lrm = 6.6955e-05, wd = 2.5e-07, gs = 1
I1130 23:22:07.819392   125 solver.cpp:333]     [0.0] Iteration 15576 (8.19885 iter/s, 5.36661s/44 iter), 43.4/100ep, loss = 7.86676
I1130 23:22:07.819433   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.469508 (* 2 = 0.939016 loss)
I1130 23:22:07.819443   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.92772 (* 1 = 6.92772 loss)
I1130 23:22:07.819455   125 sgd_solver.cpp:180] [0.0] Iteration 15576, lr = 6.67056e-06, m = 0.9, lrm = 6.67056e-05, wd = 2.5e-07, gs = 1
I1130 23:22:13.178781   125 solver.cpp:333]     [0.0] Iteration 15620 (8.20988 iter/s, 5.3594s/44 iter), 43.5/100ep, loss = 3.5927
I1130 23:22:13.178822   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.296665 (* 2 = 0.593329 loss)
I1130 23:22:13.178833   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.99936 (* 1 = 2.99936 loss)
I1130 23:22:13.178843   125 sgd_solver.cpp:180] [0.0] Iteration 15620, lr = 6.64571e-06, m = 0.9, lrm = 6.64571e-05, wd = 2.5e-07, gs = 1
I1130 23:22:18.537701   125 solver.cpp:333]     [0.0] Iteration 15664 (8.21064 iter/s, 5.3589s/44 iter), 43.6/100ep, loss = 5.92024
I1130 23:22:18.537742   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.651873 (* 2 = 1.30375 loss)
I1130 23:22:18.537753   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.61648 (* 1 = 4.61648 loss)
I1130 23:22:18.537765   125 sgd_solver.cpp:180] [0.0] Iteration 15664, lr = 6.62095e-06, m = 0.9, lrm = 6.62095e-05, wd = 2.5e-07, gs = 1
I1130 23:22:23.896317   125 solver.cpp:333]     [0.0] Iteration 15708 (8.21103 iter/s, 5.35864s/44 iter), 43.8/100ep, loss = 3.64455
I1130 23:22:23.896355   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.465975 (* 2 = 0.93195 loss)
I1130 23:22:23.896365   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.71259 (* 1 = 2.71259 loss)
I1130 23:22:23.896376   125 sgd_solver.cpp:180] [0.0] Iteration 15708, lr = 6.59629e-06, m = 0.9, lrm = 6.59629e-05, wd = 2.5e-07, gs = 1
I1130 23:22:29.253341   125 solver.cpp:333]     [0.0] Iteration 15752 (8.2133 iter/s, 5.35716s/44 iter), 43.9/100ep, loss = 4.82637
I1130 23:22:29.253382   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.514183 (* 2 = 1.02837 loss)
I1130 23:22:29.253393   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.79799 (* 1 = 3.79799 loss)
I1130 23:22:29.253406   125 sgd_solver.cpp:180] [0.0] Iteration 15752, lr = 6.57172e-06, m = 0.9, lrm = 6.57172e-05, wd = 2.5e-07, gs = 1
I1130 23:22:31.208406   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:22:31.329740   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:22:34.491719   125 solver.cpp:501] Iteration 15796, Testing net (#0)
I1130 23:22:49.529125   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:22:49.680701   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:22:51.687702   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.520563 (* 2 = 1.04113 loss)
I1130 23:22:51.687743   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.76311 (* 1 = 8.76311 loss)
I1130 23:22:51.687752   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.5806
I1130 23:22:51.687760   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 30.0798
I1130 23:22:51.687768   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 46.6197
I1130 23:22:51.687803   125 solver.cpp:271] Tests completed in 22.4351s
I1130 23:22:51.810257   125 solver.cpp:333]     [0.0] Iteration 15796 (1.96121 iter/s, 22.4351s/44 iter), 44/100ep, loss = 9.87278
I1130 23:22:51.810300   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.657121 (* 2 = 1.31424 loss)
I1130 23:22:51.810312   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.55852 (* 1 = 8.55852 loss)
I1130 23:22:51.810323   125 sgd_solver.cpp:180] [0.0] Iteration 15796, lr = 6.54724e-06, m = 0.9, lrm = 6.54724e-05, wd = 2.5e-07, gs = 1
I1130 23:22:57.172600   125 solver.cpp:333]     [0.0] Iteration 15840 (8.20518 iter/s, 5.36246s/44 iter), 44.1/100ep, loss = 10.2684
I1130 23:22:57.172641   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.765512 (* 2 = 1.53102 loss)
I1130 23:22:57.172653   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.73731 (* 1 = 8.73731 loss)
I1130 23:22:57.172664   125 sgd_solver.cpp:180] [0.0] Iteration 15840, lr = 6.52285e-06, m = 0.9, lrm = 6.52285e-05, wd = 2.5e-07, gs = 1
I1130 23:23:02.537622   125 solver.cpp:333]     [0.0] Iteration 15884 (8.20109 iter/s, 5.36514s/44 iter), 44.2/100ep, loss = 5.81401
I1130 23:23:02.537665   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.578759 (* 2 = 1.15752 loss)
I1130 23:23:02.537676   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.65647 (* 1 = 4.65647 loss)
I1130 23:23:02.537688   125 sgd_solver.cpp:180] [0.0] Iteration 15884, lr = 6.49855e-06, m = 0.9, lrm = 6.49855e-05, wd = 2.5e-07, gs = 1
I1130 23:23:07.901836   125 solver.cpp:333]     [0.0] Iteration 15928 (8.2023 iter/s, 5.36435s/44 iter), 44.4/100ep, loss = 5.92224
I1130 23:23:07.902005   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.367292 (* 2 = 0.734585 loss)
I1130 23:23:07.902019   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.18763 (* 1 = 5.18763 loss)
I1130 23:23:07.902029   125 sgd_solver.cpp:180] [0.0] Iteration 15928, lr = 6.47434e-06, m = 0.9, lrm = 6.47434e-05, wd = 2.5e-07, gs = 1
I1130 23:23:13.267308   125 solver.cpp:333]     [0.0] Iteration 15972 (8.2004 iter/s, 5.36559s/44 iter), 44.5/100ep, loss = 8.35803
I1130 23:23:13.267352   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.16393 (* 2 = 2.32786 loss)
I1130 23:23:13.267362   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.03015 (* 1 = 6.03015 loss)
I1130 23:23:13.267374   125 sgd_solver.cpp:180] [0.0] Iteration 15972, lr = 6.45022e-06, m = 0.9, lrm = 6.45022e-05, wd = 2.5e-07, gs = 1
I1130 23:23:18.649900   125 solver.cpp:333]     [0.0] Iteration 16016 (8.17432 iter/s, 5.38271s/44 iter), 44.6/100ep, loss = 9.37555
I1130 23:23:18.649943   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.35637 (* 2 = 2.71273 loss)
I1130 23:23:18.649955   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.6628 (* 1 = 6.6628 loss)
I1130 23:23:18.649966   125 sgd_solver.cpp:180] [0.0] Iteration 16016, lr = 6.42619e-06, m = 0.9, lrm = 6.42619e-05, wd = 2.5e-07, gs = 1
I1130 23:23:24.033550   125 solver.cpp:333]     [0.0] Iteration 16060 (8.1727 iter/s, 5.38378s/44 iter), 44.7/100ep, loss = 9.66096
I1130 23:23:24.033592   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.47096 (* 2 = 0.94192 loss)
I1130 23:23:24.033602   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.71902 (* 1 = 8.71902 loss)
I1130 23:23:24.033614   125 sgd_solver.cpp:180] [0.0] Iteration 16060, lr = 6.40226e-06, m = 0.9, lrm = 6.40225e-05, wd = 2.5e-07, gs = 1
I1130 23:23:29.485844   125 solver.cpp:333]     [0.0] Iteration 16104 (8.06983 iter/s, 5.45241s/44 iter), 44.9/100ep, loss = 4.89562
I1130 23:23:29.485900   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.440736 (* 2 = 0.881472 loss)
I1130 23:23:29.485918   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.01413 (* 1 = 4.01413 loss)
I1130 23:23:29.485934   125 sgd_solver.cpp:180] [0.0] Iteration 16104, lr = 6.37841e-06, m = 0.9, lrm = 6.3784e-05, wd = 2.5e-07, gs = 1
I1130 23:23:32.080781   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:23:32.206784   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:23:34.878571   125 solver.cpp:333]     [0.0] Iteration 16148 (8.15894 iter/s, 5.39286s/44 iter), 45/100ep, loss = 18.1697
I1130 23:23:34.878607   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.63853 (* 2 = 3.27706 loss)
I1130 23:23:34.878618   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.8926 (* 1 = 14.8926 loss)
I1130 23:23:34.878629   125 sgd_solver.cpp:180] [0.0] Iteration 16148, lr = 6.35465e-06, m = 0.9, lrm = 6.35464e-05, wd = 2.5e-07, gs = 1
I1130 23:23:35.606701   125 solver.cpp:501] Iteration 16155, Testing net (#0)
I1130 23:23:52.566444   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:23:52.683879   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:23:54.678776   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.524325 (* 2 = 1.04865 loss)
I1130 23:23:54.678814   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.8456 (* 1 = 8.8456 loss)
I1130 23:23:54.678823   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 16.8104
I1130 23:23:54.678831   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 26.3208
I1130 23:23:54.678838   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 45.6674
I1130 23:23:54.678874   125 solver.cpp:271] Tests completed in 19.8008s
I1130 23:23:59.290674   125 solver.cpp:333]     [0.0] Iteration 16192 (2.22213 iter/s, 19.8008s/44 iter), 45.1/100ep, loss = 4.4146
I1130 23:23:59.290716   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.237369 (* 2 = 0.474738 loss)
I1130 23:23:59.290726   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.93985 (* 1 = 3.93985 loss)
I1130 23:23:59.290737   125 sgd_solver.cpp:180] [0.0] Iteration 16192, lr = 6.33097e-06, m = 0.9, lrm = 6.33097e-05, wd = 2.5e-07, gs = 1
I1130 23:24:04.638715   125 solver.cpp:333]     [0.0] Iteration 16236 (8.22718 iter/s, 5.34813s/44 iter), 45.2/100ep, loss = 15.4846
I1130 23:24:04.638758   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 3.23446 (* 2 = 6.46892 loss)
I1130 23:24:04.638768   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.01567 (* 1 = 9.01567 loss)
I1130 23:24:04.638780   125 sgd_solver.cpp:180] [0.0] Iteration 16236, lr = 6.30739e-06, m = 0.9, lrm = 6.30739e-05, wd = 2.5e-07, gs = 1
I1130 23:24:09.983727   125 solver.cpp:333]     [0.0] Iteration 16280 (8.23178 iter/s, 5.34514s/44 iter), 45.3/100ep, loss = 11.6286
I1130 23:24:09.983768   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.661909 (* 2 = 1.32382 loss)
I1130 23:24:09.983779   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.3048 (* 1 = 10.3048 loss)
I1130 23:24:09.983791   125 sgd_solver.cpp:180] [0.0] Iteration 16280, lr = 6.28389e-06, m = 0.9, lrm = 6.28389e-05, wd = 2.5e-07, gs = 1
I1130 23:24:15.327551   125 solver.cpp:333]     [0.0] Iteration 16324 (8.23363 iter/s, 5.34394s/44 iter), 45.5/100ep, loss = 13.3992
I1130 23:24:15.327592   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.926092 (* 2 = 1.85218 loss)
I1130 23:24:15.327603   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.547 (* 1 = 11.547 loss)
I1130 23:24:15.327615   125 sgd_solver.cpp:180] [0.0] Iteration 16324, lr = 6.26048e-06, m = 0.9, lrm = 6.26048e-05, wd = 2.5e-07, gs = 1
I1130 23:24:20.670075   125 solver.cpp:333]     [0.0] Iteration 16368 (8.23566 iter/s, 5.34262s/44 iter), 45.6/100ep, loss = 6.03272
I1130 23:24:20.670114   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.47519 (* 2 = 0.95038 loss)
I1130 23:24:20.670125   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.08232 (* 1 = 5.08232 loss)
I1130 23:24:20.670135   125 sgd_solver.cpp:180] [0.0] Iteration 16368, lr = 6.23716e-06, m = 0.9, lrm = 6.23716e-05, wd = 2.5e-07, gs = 1
I1130 23:24:26.016352   125 solver.cpp:333]     [0.0] Iteration 16412 (8.22985 iter/s, 5.34639s/44 iter), 45.7/100ep, loss = 5.73044
I1130 23:24:26.016525   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.419697 (* 2 = 0.839394 loss)
I1130 23:24:26.016536   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.89103 (* 1 = 4.89103 loss)
I1130 23:24:26.016548   125 sgd_solver.cpp:180] [0.0] Iteration 16412, lr = 6.21393e-06, m = 0.9, lrm = 6.21393e-05, wd = 2.5e-07, gs = 1
I1130 23:24:31.357548   125 solver.cpp:333]     [0.0] Iteration 16456 (8.23768 iter/s, 5.34131s/44 iter), 45.8/100ep, loss = 4.21546
I1130 23:24:31.357587   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.584728 (* 2 = 1.16946 loss)
I1130 23:24:31.357599   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.04598 (* 1 = 3.04598 loss)
I1130 23:24:31.357609   125 sgd_solver.cpp:180] [0.0] Iteration 16456, lr = 6.19078e-06, m = 0.9, lrm = 6.19078e-05, wd = 2.5e-07, gs = 1
I1130 23:24:34.884210   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:24:35.004930   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:24:36.707923   125 solver.cpp:333]     [0.0] Iteration 16500 (8.22358 iter/s, 5.35047s/44 iter), 46/100ep, loss = 11.2301
I1130 23:24:36.707962   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.736318 (* 2 = 1.47264 loss)
I1130 23:24:36.707973   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.75742 (* 1 = 9.75742 loss)
I1130 23:24:36.707984   125 sgd_solver.cpp:180] [0.0] Iteration 16500, lr = 6.16772e-06, m = 0.9, lrm = 6.16772e-05, wd = 2.5e-07, gs = 1
I1130 23:24:38.284909   125 solver.cpp:501] Iteration 16514, Testing net (#0)
I1130 23:24:53.172140   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:24:53.329349   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:24:55.429342   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.519755 (* 2 = 1.03951 loss)
I1130 23:24:55.429380   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.68805 (* 1 = 8.68805 loss)
I1130 23:24:55.429388   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.6031
I1130 23:24:55.429396   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.4726
I1130 23:24:55.429404   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.0519
I1130 23:24:55.429440   125 solver.cpp:271] Tests completed in 18.722s
I1130 23:24:59.197394   125 solver.cpp:333]     [0.0] Iteration 16544 (2.35018 iter/s, 18.722s/44 iter), 46.1/100ep, loss = 12.1723
I1130 23:24:59.197589   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.19839 (* 2 = 2.39678 loss)
I1130 23:24:59.197603   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.77553 (* 1 = 9.77553 loss)
I1130 23:24:59.197615   125 sgd_solver.cpp:180] [0.0] Iteration 16544, lr = 6.14474e-06, m = 0.9, lrm = 6.14474e-05, wd = 2.5e-07, gs = 1
I1130 23:25:04.549751   125 solver.cpp:333]     [0.0] Iteration 16588 (8.22053 iter/s, 5.35245s/44 iter), 46.2/100ep, loss = 4.58311
I1130 23:25:04.549790   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.687891 (* 2 = 1.37578 loss)
I1130 23:25:04.549801   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.20731 (* 1 = 3.20731 loss)
I1130 23:25:04.549813   125 sgd_solver.cpp:180] [0.0] Iteration 16588, lr = 6.12185e-06, m = 0.9, lrm = 6.12185e-05, wd = 2.5e-07, gs = 1
I1130 23:25:09.899067   125 solver.cpp:333]     [0.0] Iteration 16632 (8.2252 iter/s, 5.34941s/44 iter), 46.3/100ep, loss = 14.7109
I1130 23:25:09.899106   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.923692 (* 2 = 1.84738 loss)
I1130 23:25:09.899118   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.8635 (* 1 = 12.8635 loss)
I1130 23:25:09.899129   125 sgd_solver.cpp:180] [0.0] Iteration 16632, lr = 6.09905e-06, m = 0.9, lrm = 6.09905e-05, wd = 2.5e-07, gs = 1
I1130 23:25:15.256603   125 solver.cpp:333]     [0.0] Iteration 16676 (8.21257 iter/s, 5.35764s/44 iter), 46.5/100ep, loss = 6.96343
I1130 23:25:15.256640   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.755737 (* 2 = 1.51147 loss)
I1130 23:25:15.256652   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.45194 (* 1 = 5.45194 loss)
I1130 23:25:15.256664   125 sgd_solver.cpp:180] [0.0] Iteration 16676, lr = 6.07633e-06, m = 0.9, lrm = 6.07633e-05, wd = 2.5e-07, gs = 1
I1130 23:25:20.599062   125 solver.cpp:333]     [0.0] Iteration 16720 (8.23577 iter/s, 5.34255s/44 iter), 46.6/100ep, loss = 9.46078
I1130 23:25:20.599102   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.880537 (* 2 = 1.76107 loss)
I1130 23:25:20.599113   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.69969 (* 1 = 7.69969 loss)
I1130 23:25:20.599125   125 sgd_solver.cpp:180] [0.0] Iteration 16720, lr = 6.05369e-06, m = 0.9, lrm = 6.05369e-05, wd = 2.5e-07, gs = 1
I1130 23:25:25.938169   125 solver.cpp:333]     [0.0] Iteration 16764 (8.24092 iter/s, 5.33921s/44 iter), 46.7/100ep, loss = 8.67044
I1130 23:25:25.938210   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.10342 (* 2 = 2.20684 loss)
I1130 23:25:25.938220   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.46358 (* 1 = 6.46358 loss)
I1130 23:25:25.938231   125 sgd_solver.cpp:180] [0.0] Iteration 16764, lr = 6.03114e-06, m = 0.9, lrm = 6.03114e-05, wd = 2.5e-07, gs = 1
I1130 23:25:31.279435   125 solver.cpp:333]     [0.0] Iteration 16808 (8.23759 iter/s, 5.34137s/44 iter), 46.8/100ep, loss = 5.04339
I1130 23:25:31.279594   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.298397 (* 2 = 0.596794 loss)
I1130 23:25:31.279608   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.44658 (* 1 = 4.44658 loss)
I1130 23:25:31.279619   125 sgd_solver.cpp:180] [0.0] Iteration 16808, lr = 6.00868e-06, m = 0.9, lrm = 6.00867e-05, wd = 2.5e-07, gs = 1
I1130 23:25:35.777878   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:25:35.896868   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:25:36.624518   125 solver.cpp:333]     [0.0] Iteration 16852 (8.23173 iter/s, 5.34517s/44 iter), 46.9/100ep, loss = 6.14479
I1130 23:25:36.624557   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.629441 (* 2 = 1.25888 loss)
I1130 23:25:36.624567   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.88588 (* 1 = 4.88588 loss)
I1130 23:25:36.624579   125 sgd_solver.cpp:180] [0.0] Iteration 16852, lr = 5.98629e-06, m = 0.9, lrm = 5.98629e-05, wd = 2.5e-07, gs = 1
I1130 23:25:39.056259   125 solver.cpp:501] Iteration 16873, Testing net (#0)
I1130 23:25:54.077550   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:25:54.193365   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:25:56.301539   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.516277 (* 2 = 1.03255 loss)
I1130 23:25:56.301579   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.65489 (* 1 = 8.65489 loss)
I1130 23:25:56.301587   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.018
I1130 23:25:56.301596   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 26.4109
I1130 23:25:56.301602   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 47.7903
I1130 23:25:56.301637   125 solver.cpp:271] Tests completed in 19.6776s
I1130 23:25:59.221331   125 solver.cpp:333]     [0.0] Iteration 16896 (2.23605 iter/s, 19.6776s/44 iter), 47.1/100ep, loss = 4.09655
I1130 23:25:59.221375   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.270339 (* 2 = 0.540678 loss)
I1130 23:25:59.221385   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.55584 (* 1 = 3.55584 loss)
I1130 23:25:59.221398   125 sgd_solver.cpp:180] [0.0] Iteration 16896, lr = 5.96399e-06, m = 0.9, lrm = 5.96399e-05, wd = 2.5e-07, gs = 1
I1130 23:26:04.579073   125 solver.cpp:333]     [0.0] Iteration 16940 (8.21228 iter/s, 5.35783s/44 iter), 47.2/100ep, loss = 4.54407
I1130 23:26:04.579207   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.252275 (* 2 = 0.504549 loss)
I1130 23:26:04.579219   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.0395 (* 1 = 4.0395 loss)
I1130 23:26:04.579231   125 sgd_solver.cpp:180] [0.0] Iteration 16940, lr = 5.94178e-06, m = 0.9, lrm = 5.94177e-05, wd = 2.5e-07, gs = 1
I1130 23:26:09.929709   125 solver.cpp:333]     [0.0] Iteration 16984 (8.22318 iter/s, 5.35073s/44 iter), 47.3/100ep, loss = 7.76229
I1130 23:26:09.929749   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.58802 (* 2 = 3.17604 loss)
I1130 23:26:09.929759   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.58623 (* 1 = 4.58623 loss)
I1130 23:26:09.929771   125 sgd_solver.cpp:180] [0.0] Iteration 16984, lr = 5.91964e-06, m = 0.9, lrm = 5.91964e-05, wd = 2.5e-07, gs = 1
I1130 23:26:15.291393   125 solver.cpp:333]     [0.0] Iteration 17028 (8.20622 iter/s, 5.36178s/44 iter), 47.4/100ep, loss = 4.90373
I1130 23:26:15.291435   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.872199 (* 2 = 1.7444 loss)
I1130 23:26:15.291445   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.15931 (* 1 = 3.15931 loss)
I1130 23:26:15.291456   125 sgd_solver.cpp:180] [0.0] Iteration 17028, lr = 5.89759e-06, m = 0.9, lrm = 5.89759e-05, wd = 2.5e-07, gs = 1
I1130 23:26:20.638852   125 solver.cpp:333]     [0.0] Iteration 17072 (8.2281 iter/s, 5.34753s/44 iter), 47.6/100ep, loss = 9.08694
I1130 23:26:20.638892   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.28943 (* 2 = 2.57885 loss)
I1130 23:26:20.638903   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.50807 (* 1 = 6.50807 loss)
I1130 23:26:20.638916   125 sgd_solver.cpp:180] [0.0] Iteration 17072, lr = 5.87562e-06, m = 0.9, lrm = 5.87562e-05, wd = 2.5e-07, gs = 1
I1130 23:26:25.987031   125 solver.cpp:333]     [0.0] Iteration 17116 (8.22694 iter/s, 5.34828s/44 iter), 47.7/100ep, loss = 3.24718
I1130 23:26:25.987072   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.452728 (* 2 = 0.905457 loss)
I1130 23:26:25.987083   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.3417 (* 1 = 2.3417 loss)
I1130 23:26:25.987094   125 sgd_solver.cpp:180] [0.0] Iteration 17116, lr = 5.85373e-06, m = 0.9, lrm = 5.85373e-05, wd = 2.5e-07, gs = 1
I1130 23:26:31.340670   125 solver.cpp:333]     [0.0] Iteration 17160 (8.21857 iter/s, 5.35373s/44 iter), 47.8/100ep, loss = 9.84796
I1130 23:26:31.340711   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.802848 (* 2 = 1.6057 loss)
I1130 23:26:31.340723   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.24224 (* 1 = 8.24224 loss)
I1130 23:26:31.340734   125 sgd_solver.cpp:180] [0.0] Iteration 17160, lr = 5.83193e-06, m = 0.9, lrm = 5.83192e-05, wd = 2.5e-07, gs = 1
I1130 23:26:36.451252   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:26:36.570569   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:26:36.689674   125 solver.cpp:333]     [0.0] Iteration 17204 (8.22571 iter/s, 5.34908s/44 iter), 47.9/100ep, loss = 4.55354
I1130 23:26:36.689710   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.571493 (* 2 = 1.14299 loss)
I1130 23:26:36.689721   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.41054 (* 1 = 3.41054 loss)
I1130 23:26:36.689733   125 sgd_solver.cpp:180] [0.0] Iteration 17204, lr = 5.8102e-06, m = 0.9, lrm = 5.8102e-05, wd = 2.5e-07, gs = 1
I1130 23:26:39.970176   125 solver.cpp:501] Iteration 17232, Testing net (#0)
I1130 23:26:42.384634   151 blocking_queue.cpp:40] Data layer prefetch queue empty
I1130 23:26:54.989639   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:26:55.144582   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:26:57.310951   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.515819 (* 2 = 1.03164 loss)
I1130 23:26:57.310992   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.70151 (* 1 = 8.70151 loss)
I1130 23:26:57.311000   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.6785
I1130 23:26:57.311008   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.7078
I1130 23:26:57.311015   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.6775
I1130 23:26:57.311049   125 solver.cpp:271] Tests completed in 20.6218s
I1130 23:26:59.380652   125 solver.cpp:333]     [0.0] Iteration 17248 (2.13366 iter/s, 20.6218s/44 iter), 48/100ep, loss = 9.14378
I1130 23:26:59.380693   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.450461 (* 2 = 0.900922 loss)
I1130 23:26:59.380703   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.24284 (* 1 = 8.24284 loss)
I1130 23:26:59.380715   125 sgd_solver.cpp:180] [0.0] Iteration 17248, lr = 5.78856e-06, m = 0.9, lrm = 5.78856e-05, wd = 2.5e-07, gs = 1
I1130 23:27:04.735024   125 solver.cpp:333]     [0.0] Iteration 17292 (8.21749 iter/s, 5.35443s/44 iter), 48.2/100ep, loss = 13.2312
I1130 23:27:04.735065   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.9774 (* 2 = 3.9548 loss)
I1130 23:27:04.735075   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.27642 (* 1 = 9.27642 loss)
I1130 23:27:04.735087   125 sgd_solver.cpp:180] [0.0] Iteration 17292, lr = 5.76699e-06, m = 0.9, lrm = 5.76699e-05, wd = 2.5e-07, gs = 1
I1130 23:27:10.077762   125 solver.cpp:333]     [0.0] Iteration 17336 (8.23533 iter/s, 5.34283s/44 iter), 48.3/100ep, loss = 4.64765
I1130 23:27:10.077949   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.403696 (* 2 = 0.807392 loss)
I1130 23:27:10.077961   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.84024 (* 1 = 3.84024 loss)
I1130 23:27:10.077972   125 sgd_solver.cpp:180] [0.0] Iteration 17336, lr = 5.74551e-06, m = 0.9, lrm = 5.74551e-05, wd = 2.5e-07, gs = 1
I1130 23:27:15.446770   125 solver.cpp:333]     [0.0] Iteration 17380 (8.19505 iter/s, 5.36909s/44 iter), 48.4/100ep, loss = 7.53216
I1130 23:27:15.446811   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.906847 (* 2 = 1.81369 loss)
I1130 23:27:15.446822   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.71844 (* 1 = 5.71844 loss)
I1130 23:27:15.446835   125 sgd_solver.cpp:180] [0.0] Iteration 17380, lr = 5.72411e-06, m = 0.9, lrm = 5.72411e-05, wd = 2.5e-07, gs = 1
I1130 23:27:20.875967   125 solver.cpp:333]     [0.0] Iteration 17424 (8.10423 iter/s, 5.42926s/44 iter), 48.5/100ep, loss = 4.21968
I1130 23:27:20.876021   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.311806 (* 2 = 0.623612 loss)
I1130 23:27:20.876036   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.59604 (* 1 = 3.59604 loss)
I1130 23:27:20.876054   125 sgd_solver.cpp:180] [0.0] Iteration 17424, lr = 5.70278e-06, m = 0.9, lrm = 5.70278e-05, wd = 2.5e-07, gs = 1
I1130 23:27:26.377965   125 solver.cpp:333]     [0.0] Iteration 17468 (7.99695 iter/s, 5.5021s/44 iter), 48.7/100ep, loss = 8.8826
I1130 23:27:26.378006   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.651508 (* 2 = 1.30302 loss)
I1130 23:27:26.378017   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.57956 (* 1 = 7.57956 loss)
I1130 23:27:26.378029   125 sgd_solver.cpp:180] [0.0] Iteration 17468, lr = 5.68154e-06, m = 0.9, lrm = 5.68154e-05, wd = 2.5e-07, gs = 1
I1130 23:27:31.788352   125 solver.cpp:333]     [0.0] Iteration 17512 (8.1324 iter/s, 5.41046s/44 iter), 48.8/100ep, loss = 3.60549
I1130 23:27:31.788393   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.504682 (* 2 = 1.00936 loss)
I1130 23:27:31.788403   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.59611 (* 1 = 2.59611 loss)
I1130 23:27:31.788415   125 sgd_solver.cpp:180] [0.0] Iteration 17512, lr = 5.66038e-06, m = 0.9, lrm = 5.66037e-05, wd = 2.5e-07, gs = 1
I1130 23:27:37.152009   125 solver.cpp:333]     [0.0] Iteration 17556 (8.20324 iter/s, 5.36374s/44 iter), 48.9/100ep, loss = 5.13503
I1130 23:27:37.152051   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.499212 (* 2 = 0.998424 loss)
I1130 23:27:37.152062   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.13658 (* 1 = 4.13658 loss)
I1130 23:27:37.152073   125 sgd_solver.cpp:180] [0.0] Iteration 17556, lr = 5.63929e-06, m = 0.9, lrm = 5.63929e-05, wd = 2.5e-07, gs = 1
I1130 23:27:37.889443   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:27:38.000815   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:27:41.298444   125 solver.cpp:501] Iteration 17591, Testing net (#0)
I1130 23:27:56.287408   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:27:56.401667   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:27:58.571702   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.51424 (* 2 = 1.02848 loss)
I1130 23:27:58.571743   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.68153 (* 1 = 8.68153 loss)
I1130 23:27:58.571753   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.3726
I1130 23:27:58.571760   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 26.6165
I1130 23:27:58.571768   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 47.8455
I1130 23:27:58.571800   125 solver.cpp:271] Tests completed in 21.4202s
I1130 23:27:59.791757   125 solver.cpp:333]     [0.0] Iteration 17600 (2.05414 iter/s, 21.4202s/44 iter), 49/100ep, loss = 7.39492
I1130 23:27:59.791801   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.422415 (* 2 = 0.844831 loss)
I1130 23:27:59.791812   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.55007 (* 1 = 6.55007 loss)
I1130 23:27:59.791824   125 sgd_solver.cpp:180] [0.0] Iteration 17600, lr = 5.61828e-06, m = 0.9, lrm = 5.61828e-05, wd = 2.5e-07, gs = 1
I1130 23:28:05.159538   125 solver.cpp:333]     [0.0] Iteration 17644 (8.19692 iter/s, 5.36787s/44 iter), 49.1/100ep, loss = 9.18701
I1130 23:28:05.159579   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.08671 (* 2 = 2.17341 loss)
I1130 23:28:05.159590   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.01357 (* 1 = 7.01357 loss)
I1130 23:28:05.159600   125 sgd_solver.cpp:180] [0.0] Iteration 17644, lr = 5.59735e-06, m = 0.9, lrm = 5.59735e-05, wd = 2.5e-07, gs = 1
I1130 23:28:10.522617   125 solver.cpp:333]     [0.0] Iteration 17688 (8.20412 iter/s, 5.36316s/44 iter), 49.3/100ep, loss = 15.2615
I1130 23:28:10.522657   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.26525 (* 2 = 2.53049 loss)
I1130 23:28:10.522668   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.731 (* 1 = 12.731 loss)
I1130 23:28:10.522680   125 sgd_solver.cpp:180] [0.0] Iteration 17688, lr = 5.5765e-06, m = 0.9, lrm = 5.5765e-05, wd = 2.5e-07, gs = 1
I1130 23:28:15.888715   125 solver.cpp:333]     [0.0] Iteration 17732 (8.19954 iter/s, 5.36616s/44 iter), 49.4/100ep, loss = 6.17864
I1130 23:28:15.888885   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.374719 (* 2 = 0.749439 loss)
I1130 23:28:15.888900   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.42917 (* 1 = 5.42917 loss)
I1130 23:28:15.888911   125 sgd_solver.cpp:180] [0.0] Iteration 17732, lr = 5.55573e-06, m = 0.9, lrm = 5.55573e-05, wd = 2.5e-07, gs = 1
I1130 23:28:21.252893   125 solver.cpp:333]     [0.0] Iteration 17776 (8.20244 iter/s, 5.36426s/44 iter), 49.5/100ep, loss = 10.9097
I1130 23:28:21.252935   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.55212 (* 2 = 3.10423 loss)
I1130 23:28:21.252945   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.8054 (* 1 = 7.8054 loss)
I1130 23:28:21.252955   125 sgd_solver.cpp:180] [0.0] Iteration 17776, lr = 5.53503e-06, m = 0.9, lrm = 5.53503e-05, wd = 2.5e-07, gs = 1
I1130 23:28:26.615368   125 solver.cpp:333]     [0.0] Iteration 17820 (8.20508 iter/s, 5.36253s/44 iter), 49.6/100ep, loss = 6.41789
I1130 23:28:26.615411   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.71982 (* 2 = 1.43964 loss)
I1130 23:28:26.615422   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.97822 (* 1 = 4.97822 loss)
I1130 23:28:26.615433   125 sgd_solver.cpp:180] [0.0] Iteration 17820, lr = 5.51441e-06, m = 0.9, lrm = 5.51441e-05, wd = 2.5e-07, gs = 1
I1130 23:28:31.986564   125 solver.cpp:333]     [0.0] Iteration 17864 (8.19172 iter/s, 5.37127s/44 iter), 49.8/100ep, loss = 4.54651
I1130 23:28:31.986604   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.236872 (* 2 = 0.473743 loss)
I1130 23:28:31.986616   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.07275 (* 1 = 4.07275 loss)
I1130 23:28:31.986627   125 sgd_solver.cpp:180] [0.0] Iteration 17864, lr = 5.49387e-06, m = 0.9, lrm = 5.49387e-05, wd = 2.5e-07, gs = 1
I1130 23:28:37.345705   125 solver.cpp:333]     [0.0] Iteration 17908 (8.21016 iter/s, 5.35922s/44 iter), 49.9/100ep, loss = 4.57108
I1130 23:28:37.345746   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.363647 (* 2 = 0.727294 loss)
I1130 23:28:37.345757   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.84376 (* 1 = 3.84376 loss)
I1130 23:28:37.345767   125 sgd_solver.cpp:180] [0.0] Iteration 17908, lr = 5.47341e-06, m = 0.9, lrm = 5.47341e-05, wd = 2.5e-07, gs = 1
I1130 23:28:39.051702   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:28:39.173187   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:28:42.340515   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_17950.caffemodel
I1130 23:28:42.389911   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_17950.solverstate
I1130 23:28:42.430950   125 solver.cpp:501] Iteration 17950, Testing net (#0)
I1130 23:28:57.206197   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:28:57.356020   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:28:59.587673   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.515704 (* 2 = 1.03141 loss)
I1130 23:28:59.587713   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.73727 (* 1 = 8.73727 loss)
I1130 23:28:59.587720   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.0835
I1130 23:28:59.587728   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.1179
I1130 23:28:59.587735   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 47.6348
I1130 23:28:59.587770   125 solver.cpp:271] Tests completed in 22.2424s
I1130 23:28:59.959008   125 solver.cpp:333]     [0.0] Iteration 17952 (1.9782 iter/s, 22.2424s/44 iter), 50/100ep, loss = 5.44337
I1130 23:28:59.959050   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.576587 (* 2 = 1.15317 loss)
I1130 23:28:59.959062   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.29017 (* 1 = 4.29017 loss)
I1130 23:28:59.959074   125 sgd_solver.cpp:180] [0.0] Iteration 17952, lr = 5.45302e-06, m = 0.9, lrm = 5.45302e-05, wd = 2.5e-07, gs = 1
I1130 23:29:05.319923   125 solver.cpp:333]     [0.0] Iteration 17996 (8.20744 iter/s, 5.36099s/44 iter), 50.1/100ep, loss = 9.76981
I1130 23:29:05.319962   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.41427 (* 2 = 2.82855 loss)
I1130 23:29:05.319972   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.94123 (* 1 = 6.94123 loss)
I1130 23:29:05.319983   125 sgd_solver.cpp:180] [0.0] Iteration 17996, lr = 5.4327e-06, m = 0.9, lrm = 5.4327e-05, wd = 2.5e-07, gs = 1
I1130 23:29:10.681725   125 solver.cpp:333]     [0.0] Iteration 18040 (8.20611 iter/s, 5.36186s/44 iter), 50.3/100ep, loss = 4.19512
I1130 23:29:10.681761   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.545539 (* 2 = 1.09108 loss)
I1130 23:29:10.681772   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.10402 (* 1 = 3.10402 loss)
I1130 23:29:10.681784   125 sgd_solver.cpp:180] [0.0] Iteration 18040, lr = 5.41247e-06, m = 0.9, lrm = 5.41246e-05, wd = 2.5e-07, gs = 1
I1130 23:29:16.039942   125 solver.cpp:333]     [0.0] Iteration 18084 (8.21159 iter/s, 5.35828s/44 iter), 50.4/100ep, loss = 7.00507
I1130 23:29:16.039983   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.36694 (* 2 = 0.73388 loss)
I1130 23:29:16.039993   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.27117 (* 1 = 6.27117 loss)
I1130 23:29:16.040004   125 sgd_solver.cpp:180] [0.0] Iteration 18084, lr = 5.3923e-06, m = 0.9, lrm = 5.3923e-05, wd = 2.5e-07, gs = 1
I1130 23:29:21.405282   125 solver.cpp:333]     [0.0] Iteration 18128 (8.20067 iter/s, 5.36542s/44 iter), 50.5/100ep, loss = 7.6935
I1130 23:29:21.405323   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.605693 (* 2 = 1.21139 loss)
I1130 23:29:21.405334   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.48209 (* 1 = 6.48209 loss)
I1130 23:29:21.405345   125 sgd_solver.cpp:180] [0.0] Iteration 18128, lr = 5.37222e-06, m = 0.9, lrm = 5.37222e-05, wd = 2.5e-07, gs = 1
I1130 23:29:26.772579   125 solver.cpp:333]     [0.0] Iteration 18172 (8.19771 iter/s, 5.36735s/44 iter), 50.6/100ep, loss = 4.97498
I1130 23:29:26.772619   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.362012 (* 2 = 0.724023 loss)
I1130 23:29:26.772629   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.25094 (* 1 = 4.25094 loss)
I1130 23:29:26.772640   125 sgd_solver.cpp:180] [0.0] Iteration 18172, lr = 5.3522e-06, m = 0.9, lrm = 5.3522e-05, wd = 2.5e-07, gs = 1
I1130 23:29:32.135627   125 solver.cpp:333]     [0.0] Iteration 18216 (8.20419 iter/s, 5.36311s/44 iter), 50.7/100ep, loss = 4.97236
I1130 23:29:32.135813   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.525998 (* 2 = 1.052 loss)
I1130 23:29:32.135828   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.92035 (* 1 = 3.92035 loss)
I1130 23:29:32.135840   125 sgd_solver.cpp:180] [0.0] Iteration 18216, lr = 5.33227e-06, m = 0.9, lrm = 5.33227e-05, wd = 2.5e-07, gs = 1
I1130 23:29:37.506135   125 solver.cpp:333]     [0.0] Iteration 18260 (8.19277 iter/s, 5.37059s/44 iter), 50.9/100ep, loss = 9.79723
I1130 23:29:37.506177   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.874522 (* 2 = 1.74904 loss)
I1130 23:29:37.506188   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.04817 (* 1 = 8.04817 loss)
I1130 23:29:37.506201   125 sgd_solver.cpp:180] [0.0] Iteration 18260, lr = 5.3124e-06, m = 0.9, lrm = 5.3124e-05, wd = 2.5e-07, gs = 1
I1130 23:29:39.827136   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:29:39.945014   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:29:42.870285   125 solver.cpp:333]     [0.0] Iteration 18304 (8.20253 iter/s, 5.3642s/44 iter), 51/100ep, loss = 8.42382
I1130 23:29:42.870326   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.759454 (* 2 = 1.51891 loss)
I1130 23:29:42.870337   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.90489 (* 1 = 6.90489 loss)
I1130 23:29:42.870347   125 sgd_solver.cpp:180] [0.0] Iteration 18304, lr = 5.29261e-06, m = 0.9, lrm = 5.29261e-05, wd = 2.5e-07, gs = 1
I1130 23:29:43.358192   125 solver.cpp:501] Iteration 18309, Testing net (#0)
I1130 23:29:58.136132   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:29:58.248683   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:30:00.503242   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.515061 (* 2 = 1.03012 loss)
I1130 23:30:00.503283   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.74076 (* 1 = 8.74076 loss)
I1130 23:30:00.503291   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.0517
I1130 23:30:00.503299   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.1846
I1130 23:30:00.503306   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.3509
I1130 23:30:00.503347   125 solver.cpp:271] Tests completed in 17.6334s
I1130 23:30:05.388411   125 solver.cpp:333]     [0.0] Iteration 18348 (2.49527 iter/s, 17.6334s/44 iter), 51.1/100ep, loss = 6.91825
I1130 23:30:05.388564   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.12472 (* 2 = 2.24944 loss)
I1130 23:30:05.388578   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.66879 (* 1 = 4.66879 loss)
I1130 23:30:05.388590   125 sgd_solver.cpp:180] [0.0] Iteration 18348, lr = 5.2729e-06, m = 0.9, lrm = 5.2729e-05, wd = 2.5e-07, gs = 1
I1130 23:30:10.758023   125 solver.cpp:333]     [0.0] Iteration 18392 (8.19418 iter/s, 5.36967s/44 iter), 51.2/100ep, loss = 7.97972
I1130 23:30:10.758062   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.578422 (* 2 = 1.15684 loss)
I1130 23:30:10.758074   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.82286 (* 1 = 6.82286 loss)
I1130 23:30:10.758085   125 sgd_solver.cpp:180] [0.0] Iteration 18392, lr = 5.25325e-06, m = 0.9, lrm = 5.25325e-05, wd = 2.5e-07, gs = 1
I1130 23:30:16.135027   125 solver.cpp:333]     [0.0] Iteration 18436 (8.18289 iter/s, 5.37707s/44 iter), 51.4/100ep, loss = 9.42803
I1130 23:30:16.135071   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.447795 (* 2 = 0.89559 loss)
I1130 23:30:16.135082   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.53242 (* 1 = 8.53242 loss)
I1130 23:30:16.135093   125 sgd_solver.cpp:180] [0.0] Iteration 18436, lr = 5.23369e-06, m = 0.9, lrm = 5.23368e-05, wd = 2.5e-07, gs = 1
I1130 23:30:21.499027   125 solver.cpp:333]     [0.0] Iteration 18480 (8.20273 iter/s, 5.36407s/44 iter), 51.5/100ep, loss = 11.7114
I1130 23:30:21.499068   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.69489 (* 2 = 3.38977 loss)
I1130 23:30:21.499078   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.32158 (* 1 = 8.32158 loss)
I1130 23:30:21.499090   125 sgd_solver.cpp:180] [0.0] Iteration 18480, lr = 5.21419e-06, m = 0.9, lrm = 5.21419e-05, wd = 2.5e-07, gs = 1
I1130 23:30:26.862327   125 solver.cpp:333]     [0.0] Iteration 18524 (8.20384 iter/s, 5.36335s/44 iter), 51.6/100ep, loss = 5.67962
I1130 23:30:26.862370   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.650319 (* 2 = 1.30064 loss)
I1130 23:30:26.862381   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.37896 (* 1 = 4.37896 loss)
I1130 23:30:26.862392   125 sgd_solver.cpp:180] [0.0] Iteration 18524, lr = 5.19477e-06, m = 0.9, lrm = 5.19476e-05, wd = 2.5e-07, gs = 1
I1130 23:30:32.226179   125 solver.cpp:333]     [0.0] Iteration 18568 (8.20298 iter/s, 5.36391s/44 iter), 51.7/100ep, loss = 4.05975
I1130 23:30:32.226218   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.459057 (* 2 = 0.918114 loss)
I1130 23:30:32.226228   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.14162 (* 1 = 3.14162 loss)
I1130 23:30:32.226239   125 sgd_solver.cpp:180] [0.0] Iteration 18568, lr = 5.17541e-06, m = 0.9, lrm = 5.17541e-05, wd = 2.5e-07, gs = 1
I1130 23:30:37.598276   125 solver.cpp:333]     [0.0] Iteration 18612 (8.1904 iter/s, 5.37214s/44 iter), 51.8/100ep, loss = 11.2564
I1130 23:30:37.598443   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.808397 (* 2 = 1.61679 loss)
I1130 23:30:37.598457   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.63959 (* 1 = 9.63959 loss)
I1130 23:30:37.598469   125 sgd_solver.cpp:180] [0.0] Iteration 18612, lr = 5.15613e-06, m = 0.9, lrm = 5.15613e-05, wd = 2.5e-07, gs = 1
I1130 23:30:40.893076   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:30:41.012163   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:30:42.967262   125 solver.cpp:333]     [0.0] Iteration 18656 (8.19512 iter/s, 5.36905s/44 iter), 52/100ep, loss = 6.68603
I1130 23:30:42.967301   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.591754 (* 2 = 1.18351 loss)
I1130 23:30:42.967314   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.5025 (* 1 = 5.5025 loss)
I1130 23:30:42.967325   125 sgd_solver.cpp:180] [0.0] Iteration 18656, lr = 5.13693e-06, m = 0.9, lrm = 5.13693e-05, wd = 2.5e-07, gs = 1
I1130 23:30:44.313539   125 solver.cpp:501] Iteration 18668, Testing net (#0)
I1130 23:31:00.984256   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:31:01.160135   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:31:03.799691   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.510288 (* 2 = 1.02058 loss)
I1130 23:31:03.799742   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.68074 (* 1 = 8.68074 loss)
I1130 23:31:03.799755   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.7392
I1130 23:31:03.799768   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.7947
I1130 23:31:03.799779   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.9229
I1130 23:31:03.799818   125 solver.cpp:271] Tests completed in 20.8329s
I1130 23:31:07.895233   125 solver.cpp:333]     [0.0] Iteration 18700 (2.11205 iter/s, 20.8329s/44 iter), 52.1/100ep, loss = 8.74433
I1130 23:31:07.895438   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.643581 (* 2 = 1.28716 loss)
I1130 23:31:07.895452   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.45715 (* 1 = 7.45715 loss)
I1130 23:31:07.895464   125 sgd_solver.cpp:180] [0.0] Iteration 18700, lr = 5.11779e-06, m = 0.9, lrm = 5.11779e-05, wd = 2.5e-07, gs = 1
I1130 23:31:13.362572   125 solver.cpp:333]     [0.0] Iteration 18744 (8.04769 iter/s, 5.46741s/44 iter), 52.2/100ep, loss = 2.65063
I1130 23:31:13.362617   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.229652 (* 2 = 0.459303 loss)
I1130 23:31:13.362628   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.1913 (* 1 = 2.1913 loss)
I1130 23:31:13.362641   125 sgd_solver.cpp:180] [0.0] Iteration 18744, lr = 5.09873e-06, m = 0.9, lrm = 5.09873e-05, wd = 2.5e-07, gs = 1
I1130 23:31:18.805848   125 solver.cpp:333]     [0.0] Iteration 18788 (8.08331 iter/s, 5.44331s/44 iter), 52.3/100ep, loss = 5.9186
I1130 23:31:18.805900   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.756641 (* 2 = 1.51328 loss)
I1130 23:31:18.805918   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.4053 (* 1 = 4.4053 loss)
I1130 23:31:18.805935   125 sgd_solver.cpp:180] [0.0] Iteration 18788, lr = 5.07973e-06, m = 0.9, lrm = 5.07973e-05, wd = 2.5e-07, gs = 1
I1130 23:31:24.250249   125 solver.cpp:333]     [0.0] Iteration 18832 (8.0816 iter/s, 5.44447s/44 iter), 52.5/100ep, loss = 8.02644
I1130 23:31:24.250294   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.875895 (* 2 = 1.75179 loss)
I1130 23:31:24.250305   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.27463 (* 1 = 6.27463 loss)
I1130 23:31:24.250317   125 sgd_solver.cpp:180] [0.0] Iteration 18832, lr = 5.06081e-06, m = 0.9, lrm = 5.06081e-05, wd = 2.5e-07, gs = 1
I1130 23:31:29.703542   125 solver.cpp:333]     [0.0] Iteration 18876 (8.06846 iter/s, 5.45333s/44 iter), 52.6/100ep, loss = 6.58555
I1130 23:31:29.703585   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.424026 (* 2 = 0.848051 loss)
I1130 23:31:29.703596   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.73748 (* 1 = 5.73748 loss)
I1130 23:31:29.703608   125 sgd_solver.cpp:180] [0.0] Iteration 18876, lr = 5.04196e-06, m = 0.9, lrm = 5.04196e-05, wd = 2.5e-07, gs = 1
I1130 23:31:35.145928   125 solver.cpp:333]     [0.0] Iteration 18920 (8.0846 iter/s, 5.44244s/44 iter), 52.7/100ep, loss = 4.49456
I1130 23:31:35.145985   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.315031 (* 2 = 0.630062 loss)
I1130 23:31:35.146001   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.86448 (* 1 = 3.86448 loss)
I1130 23:31:35.146019   125 sgd_solver.cpp:180] [0.0] Iteration 18920, lr = 5.02318e-06, m = 0.9, lrm = 5.02317e-05, wd = 2.5e-07, gs = 1
I1130 23:31:40.588580   125 solver.cpp:333]     [0.0] Iteration 18964 (8.08422 iter/s, 5.4427s/44 iter), 52.8/100ep, loss = 4.44974
I1130 23:31:40.588716   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.412707 (* 2 = 0.825414 loss)
I1130 23:31:40.588728   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.62431 (* 1 = 3.62431 loss)
I1130 23:31:40.588740   125 sgd_solver.cpp:180] [0.0] Iteration 18964, lr = 5.00446e-06, m = 0.9, lrm = 5.00446e-05, wd = 2.5e-07, gs = 1
I1130 23:31:44.923131   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:31:45.043607   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:31:46.044179   125 solver.cpp:333]     [0.0] Iteration 19008 (8.06501 iter/s, 5.45567s/44 iter), 52.9/100ep, loss = 7.57039
I1130 23:31:46.044220   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.866847 (* 2 = 1.73369 loss)
I1130 23:31:46.044231   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.83667 (* 1 = 5.83667 loss)
I1130 23:31:46.044242   125 sgd_solver.cpp:180] [0.0] Iteration 19008, lr = 4.98582e-06, m = 0.9, lrm = 4.98582e-05, wd = 2.5e-07, gs = 1
I1130 23:31:48.262842   125 solver.cpp:501] Iteration 19027, Testing net (#0)
I1130 23:32:02.989344   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:32:03.102244   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:32:05.464222   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.517079 (* 2 = 1.03416 loss)
I1130 23:32:05.464263   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.81083 (* 1 = 8.81083 loss)
I1130 23:32:05.464273   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.6427
I1130 23:32:05.464280   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.5326
I1130 23:32:05.464287   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 46.8453
I1130 23:32:05.464323   125 solver.cpp:271] Tests completed in 19.4204s
I1130 23:32:08.635164   125 solver.cpp:333]     [0.0] Iteration 19052 (2.26566 iter/s, 19.4204s/44 iter), 53.1/100ep, loss = 6.44023
I1130 23:32:08.635202   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.08504 (* 2 = 2.17007 loss)
I1130 23:32:08.635212   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.27013 (* 1 = 4.27013 loss)
I1130 23:32:08.635226   125 sgd_solver.cpp:180] [0.0] Iteration 19052, lr = 4.96725e-06, m = 0.9, lrm = 4.96725e-05, wd = 2.5e-07, gs = 1
I1130 23:32:14.002954   125 solver.cpp:333]     [0.0] Iteration 19096 (8.19696 iter/s, 5.36784s/44 iter), 53.2/100ep, loss = 16.7596
I1130 23:32:14.003109   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 3.86534 (* 2 = 7.73068 loss)
I1130 23:32:14.003123   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.02885 (* 1 = 9.02885 loss)
I1130 23:32:14.003135   125 sgd_solver.cpp:180] [0.0] Iteration 19096, lr = 4.94874e-06, m = 0.9, lrm = 4.94874e-05, wd = 2.5e-07, gs = 1
I1130 23:32:19.370170   125 solver.cpp:333]     [0.0] Iteration 19140 (8.19784 iter/s, 5.36727s/44 iter), 53.3/100ep, loss = 9.01136
I1130 23:32:19.370213   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.885704 (* 2 = 1.77141 loss)
I1130 23:32:19.370224   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.23993 (* 1 = 7.23993 loss)
I1130 23:32:19.370236   125 sgd_solver.cpp:180] [0.0] Iteration 19140, lr = 4.93031e-06, m = 0.9, lrm = 4.93031e-05, wd = 2.5e-07, gs = 1
I1130 23:32:24.739230   125 solver.cpp:333]     [0.0] Iteration 19184 (8.19503 iter/s, 5.36911s/44 iter), 53.4/100ep, loss = 9.85036
I1130 23:32:24.739269   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.871614 (* 2 = 1.74323 loss)
I1130 23:32:24.739279   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.10711 (* 1 = 8.10711 loss)
I1130 23:32:24.739291   125 sgd_solver.cpp:180] [0.0] Iteration 19184, lr = 4.91194e-06, m = 0.9, lrm = 4.91194e-05, wd = 2.5e-07, gs = 1
I1130 23:32:30.102028   125 solver.cpp:333]     [0.0] Iteration 19228 (8.20459 iter/s, 5.36285s/44 iter), 53.6/100ep, loss = 5.97815
I1130 23:32:30.102067   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.445097 (* 2 = 0.890193 loss)
I1130 23:32:30.102077   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.08794 (* 1 = 5.08794 loss)
I1130 23:32:30.102088   125 sgd_solver.cpp:180] [0.0] Iteration 19228, lr = 4.89365e-06, m = 0.9, lrm = 4.89364e-05, wd = 2.5e-07, gs = 1
I1130 23:32:35.465346   125 solver.cpp:333]     [0.0] Iteration 19272 (8.20379 iter/s, 5.36337s/44 iter), 53.7/100ep, loss = 3.64218
I1130 23:32:35.465387   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.179426 (* 2 = 0.358852 loss)
I1130 23:32:35.465399   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.28331 (* 1 = 3.28331 loss)
I1130 23:32:35.465410   125 sgd_solver.cpp:180] [0.0] Iteration 19272, lr = 4.87542e-06, m = 0.9, lrm = 4.87541e-05, wd = 2.5e-07, gs = 1
I1130 23:32:40.829886   125 solver.cpp:333]     [0.0] Iteration 19316 (8.20196 iter/s, 5.36457s/44 iter), 53.8/100ep, loss = 5.64411
I1130 23:32:40.829929   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.749844 (* 2 = 1.49969 loss)
I1130 23:32:40.829939   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.1444 (* 1 = 4.1444 loss)
I1130 23:32:40.829952   125 sgd_solver.cpp:180] [0.0] Iteration 19316, lr = 4.85725e-06, m = 0.9, lrm = 4.85725e-05, wd = 2.5e-07, gs = 1
I1130 23:32:45.711652   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:32:45.831908   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:32:46.193713   125 solver.cpp:333]     [0.0] Iteration 19360 (8.20302 iter/s, 5.36388s/44 iter), 53.9/100ep, loss = 8.72663
I1130 23:32:46.193754   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.702645 (* 2 = 1.40529 loss)
I1130 23:32:46.193765   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.32132 (* 1 = 7.32132 loss)
I1130 23:32:46.193776   125 sgd_solver.cpp:180] [0.0] Iteration 19360, lr = 4.83916e-06, m = 0.9, lrm = 4.83916e-05, wd = 2.5e-07, gs = 1
I1130 23:32:49.240968   125 solver.cpp:501] Iteration 19386, Testing net (#0)
I1130 23:33:03.851624   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:33:04.005834   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:33:06.429337   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.510638 (* 2 = 1.02128 loss)
I1130 23:33:06.429375   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.70466 (* 1 = 8.70466 loss)
I1130 23:33:06.429384   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.4323
I1130 23:33:06.429392   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.214
I1130 23:33:06.429399   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 49.362
I1130 23:33:06.429435   125 solver.cpp:271] Tests completed in 20.236s
I1130 23:33:08.744837   125 solver.cpp:333]     [0.0] Iteration 19404 (2.17434 iter/s, 20.236s/44 iter), 54.1/100ep, loss = 10.8661
I1130 23:33:08.744880   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.758547 (* 2 = 1.51709 loss)
I1130 23:33:08.744891   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.34895 (* 1 = 9.34895 loss)
I1130 23:33:08.744904   125 sgd_solver.cpp:180] [0.0] Iteration 19404, lr = 4.82113e-06, m = 0.9, lrm = 4.82113e-05, wd = 2.5e-07, gs = 1
I1130 23:33:14.109387   125 solver.cpp:333]     [0.0] Iteration 19448 (8.20189 iter/s, 5.36461s/44 iter), 54.2/100ep, loss = 7.53939
I1130 23:33:14.109427   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.982471 (* 2 = 1.96494 loss)
I1130 23:33:14.109438   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.57443 (* 1 = 5.57443 loss)
I1130 23:33:14.109449   125 sgd_solver.cpp:180] [0.0] Iteration 19448, lr = 4.80317e-06, m = 0.9, lrm = 4.80317e-05, wd = 2.5e-07, gs = 1
I1130 23:33:19.471071   125 solver.cpp:333]     [0.0] Iteration 19492 (8.2063 iter/s, 5.36173s/44 iter), 54.3/100ep, loss = 12.0685
I1130 23:33:19.471223   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.945825 (* 2 = 1.89165 loss)
I1130 23:33:19.471237   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.1768 (* 1 = 10.1768 loss)
I1130 23:33:19.471248   125 sgd_solver.cpp:180] [0.0] Iteration 19492, lr = 4.78528e-06, m = 0.9, lrm = 4.78528e-05, wd = 2.5e-07, gs = 1
I1130 23:33:24.833178   125 solver.cpp:333]     [0.0] Iteration 19536 (8.20568 iter/s, 5.36214s/44 iter), 54.4/100ep, loss = 7.24235
I1130 23:33:24.833215   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.376242 (* 2 = 0.752485 loss)
I1130 23:33:24.833226   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.48984 (* 1 = 6.48984 loss)
I1130 23:33:24.833236   125 sgd_solver.cpp:180] [0.0] Iteration 19536, lr = 4.76745e-06, m = 0.9, lrm = 4.76745e-05, wd = 2.5e-07, gs = 1
I1130 23:33:30.195603   125 solver.cpp:333]     [0.0] Iteration 19580 (8.20516 iter/s, 5.36248s/44 iter), 54.5/100ep, loss = 9.7911
I1130 23:33:30.195647   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.881316 (* 2 = 1.76263 loss)
I1130 23:33:30.195658   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.02845 (* 1 = 8.02845 loss)
I1130 23:33:30.195669   125 sgd_solver.cpp:180] [0.0] Iteration 19580, lr = 4.7497e-06, m = 0.9, lrm = 4.74969e-05, wd = 2.5e-07, gs = 1
I1130 23:33:35.561727   125 solver.cpp:333]     [0.0] Iteration 19624 (8.19951 iter/s, 5.36617s/44 iter), 54.7/100ep, loss = 10.2595
I1130 23:33:35.561769   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.24625 (* 2 = 2.4925 loss)
I1130 23:33:35.561779   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.76694 (* 1 = 7.76694 loss)
I1130 23:33:35.561789   125 sgd_solver.cpp:180] [0.0] Iteration 19624, lr = 4.732e-06, m = 0.9, lrm = 4.732e-05, wd = 2.5e-07, gs = 1
I1130 23:33:40.918294   125 solver.cpp:333]     [0.0] Iteration 19668 (8.21416 iter/s, 5.3566s/44 iter), 54.8/100ep, loss = 7.1914
I1130 23:33:40.918334   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.613942 (* 2 = 1.22788 loss)
I1130 23:33:40.918344   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.96349 (* 1 = 5.96349 loss)
I1130 23:33:40.918354   125 sgd_solver.cpp:180] [0.0] Iteration 19668, lr = 4.71437e-06, m = 0.9, lrm = 4.71437e-05, wd = 2.5e-07, gs = 1
I1130 23:33:46.282820   125 solver.cpp:333]     [0.0] Iteration 19712 (8.20195 iter/s, 5.36458s/44 iter), 54.9/100ep, loss = 7.48339
I1130 23:33:46.282862   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.551019 (* 2 = 1.10204 loss)
I1130 23:33:46.282872   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.38133 (* 1 = 6.38133 loss)
I1130 23:33:46.282884   125 sgd_solver.cpp:180] [0.0] Iteration 19712, lr = 4.69681e-06, m = 0.9, lrm = 4.69681e-05, wd = 2.5e-07, gs = 1
I1130 23:33:46.774505   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:33:46.887735   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:33:50.177871   125 solver.cpp:501] Iteration 19745, Testing net (#0)
I1130 23:34:04.748915   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:34:04.860813   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:34:07.307447   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.507762 (* 2 = 1.01552 loss)
I1130 23:34:07.307487   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.72772 (* 1 = 8.72772 loss)
I1130 23:34:07.307494   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.2599
I1130 23:34:07.307503   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.2956
I1130 23:34:07.307510   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 49.5824
I1130 23:34:07.307543   125 solver.cpp:271] Tests completed in 21.025s
I1130 23:34:08.773591   125 solver.cpp:333]     [0.0] Iteration 19756 (2.09275 iter/s, 21.025s/44 iter), 55/100ep, loss = 3.4853
I1130 23:34:08.773634   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.226264 (* 2 = 0.452528 loss)
I1130 23:34:08.773645   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.03275 (* 1 = 3.03275 loss)
I1130 23:34:08.773655   125 sgd_solver.cpp:180] [0.0] Iteration 19756, lr = 4.67932e-06, m = 0.9, lrm = 4.67931e-05, wd = 2.5e-07, gs = 1
I1130 23:34:14.123654   125 solver.cpp:333]     [0.0] Iteration 19800 (8.22413 iter/s, 5.35011s/44 iter), 55.2/100ep, loss = 4.90462
I1130 23:34:14.123698   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.46152 (* 2 = 0.923039 loss)
I1130 23:34:14.123708   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.98156 (* 1 = 3.98156 loss)
I1130 23:34:14.123719   125 sgd_solver.cpp:180] [0.0] Iteration 19800, lr = 4.66188e-06, m = 0.9, lrm = 4.66188e-05, wd = 2.5e-07, gs = 1
I1130 23:34:19.477435   125 solver.cpp:333]     [0.0] Iteration 19844 (8.21842 iter/s, 5.35383s/44 iter), 55.3/100ep, loss = 7.03899
I1130 23:34:19.477473   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.594587 (* 2 = 1.18917 loss)
I1130 23:34:19.477483   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.84979 (* 1 = 5.84979 loss)
I1130 23:34:19.477495   125 sgd_solver.cpp:180] [0.0] Iteration 19844, lr = 4.64452e-06, m = 0.9, lrm = 4.64452e-05, wd = 2.5e-07, gs = 1
I1130 23:34:24.826475   125 solver.cpp:333]     [0.0] Iteration 19888 (8.22572 iter/s, 5.34907s/44 iter), 55.4/100ep, loss = 5.14481
I1130 23:34:24.826638   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.834378 (* 2 = 1.66876 loss)
I1130 23:34:24.826653   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.47604 (* 1 = 3.47604 loss)
I1130 23:34:24.826663   125 sgd_solver.cpp:180] [0.0] Iteration 19888, lr = 4.62722e-06, m = 0.9, lrm = 4.62722e-05, wd = 2.5e-07, gs = 1
I1130 23:34:30.170297   125 solver.cpp:333]     [0.0] Iteration 19932 (8.23374 iter/s, 5.34387s/44 iter), 55.5/100ep, loss = 7.39134
I1130 23:34:30.170338   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.367284 (* 2 = 0.734568 loss)
I1130 23:34:30.170349   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.65675 (* 1 = 6.65675 loss)
I1130 23:34:30.170361   125 sgd_solver.cpp:180] [0.0] Iteration 19932, lr = 4.60998e-06, m = 0.9, lrm = 4.60998e-05, wd = 2.5e-07, gs = 1
I1130 23:34:35.521242   125 solver.cpp:333]     [0.0] Iteration 19976 (8.22278 iter/s, 5.35099s/44 iter), 55.6/100ep, loss = 2.01794
I1130 23:34:35.521284   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.216155 (* 2 = 0.43231 loss)
I1130 23:34:35.521296   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.58561 (* 1 = 1.58561 loss)
I1130 23:34:35.521306   125 sgd_solver.cpp:180] [0.0] Iteration 19976, lr = 4.59281e-06, m = 0.9, lrm = 4.59281e-05, wd = 2.5e-07, gs = 1
I1130 23:34:40.867151   125 solver.cpp:333]     [0.0] Iteration 20020 (8.23054 iter/s, 5.34594s/44 iter), 55.8/100ep, loss = 7.53038
I1130 23:34:40.867192   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.730368 (* 2 = 1.46074 loss)
I1130 23:34:40.867202   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.06962 (* 1 = 6.06962 loss)
I1130 23:34:40.867213   125 sgd_solver.cpp:180] [0.0] Iteration 20020, lr = 4.5757e-06, m = 0.9, lrm = 4.5757e-05, wd = 2.5e-07, gs = 1
I1130 23:34:46.211845   125 solver.cpp:333]     [0.0] Iteration 20064 (8.23239 iter/s, 5.34474s/44 iter), 55.9/100ep, loss = 4.01445
I1130 23:34:46.211885   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.35697 (* 2 = 0.71394 loss)
I1130 23:34:46.211896   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.30049 (* 1 = 3.30049 loss)
I1130 23:34:46.211908   125 sgd_solver.cpp:180] [0.0] Iteration 20064, lr = 4.55865e-06, m = 0.9, lrm = 4.55865e-05, wd = 2.5e-07, gs = 1
I1130 23:34:47.668953   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:34:47.789903   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:34:50.946089   125 solver.cpp:501] Iteration 20104, Testing net (#0)
I1130 23:35:07.282621   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:35:07.436486   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:35:09.930035   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.512497 (* 2 = 1.02499 loss)
I1130 23:35:09.930078   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.79729 (* 1 = 8.79729 loss)
I1130 23:35:09.930085   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.5517
I1130 23:35:09.930094   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.6332
I1130 23:35:09.930100   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.1582
I1130 23:35:09.930133   125 solver.cpp:271] Tests completed in 23.7186s
I1130 23:35:10.546201   125 solver.cpp:333]     [0.0] Iteration 20108 (1.85509 iter/s, 23.7186s/44 iter), 56/100ep, loss = 2.0517
I1130 23:35:10.546244   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.19796 (* 2 = 0.39592 loss)
I1130 23:35:10.546255   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.65576 (* 1 = 1.65576 loss)
I1130 23:35:10.546267   125 sgd_solver.cpp:180] [0.0] Iteration 20108, lr = 4.54167e-06, m = 0.9, lrm = 4.54167e-05, wd = 2.5e-07, gs = 1
I1130 23:35:15.915329   125 solver.cpp:333]     [0.0] Iteration 20152 (8.19496 iter/s, 5.36916s/44 iter), 56.1/100ep, loss = 12.3999
I1130 23:35:15.915370   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.95056 (* 2 = 3.90113 loss)
I1130 23:35:15.915380   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.49873 (* 1 = 8.49873 loss)
I1130 23:35:15.915392   125 sgd_solver.cpp:180] [0.0] Iteration 20152, lr = 4.52475e-06, m = 0.9, lrm = 4.52475e-05, wd = 2.5e-07, gs = 1
I1130 23:35:21.278283   125 solver.cpp:333]     [0.0] Iteration 20196 (8.20436 iter/s, 5.363s/44 iter), 56.3/100ep, loss = 7.24536
I1130 23:35:21.278321   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.740016 (* 2 = 1.48003 loss)
I1130 23:35:21.278332   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.76531 (* 1 = 5.76531 loss)
I1130 23:35:21.278344   125 sgd_solver.cpp:180] [0.0] Iteration 20196, lr = 4.5079e-06, m = 0.9, lrm = 4.5079e-05, wd = 2.5e-07, gs = 1
I1130 23:35:26.638515   125 solver.cpp:333]     [0.0] Iteration 20240 (8.20856 iter/s, 5.36026s/44 iter), 56.4/100ep, loss = 10.8677
I1130 23:35:26.638558   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.716354 (* 2 = 1.43271 loss)
I1130 23:35:26.638571   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.43496 (* 1 = 9.43496 loss)
I1130 23:35:26.638583   125 sgd_solver.cpp:180] [0.0] Iteration 20240, lr = 4.4911e-06, m = 0.9, lrm = 4.4911e-05, wd = 2.5e-07, gs = 1
I1130 23:35:32.006508   125 solver.cpp:333]     [0.0] Iteration 20284 (8.19666 iter/s, 5.36804s/44 iter), 56.5/100ep, loss = 4.9035
I1130 23:35:32.006547   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.376501 (* 2 = 0.753002 loss)
I1130 23:35:32.006558   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.15047 (* 1 = 4.15047 loss)
I1130 23:35:32.006570   125 sgd_solver.cpp:180] [0.0] Iteration 20284, lr = 4.47437e-06, m = 0.9, lrm = 4.47437e-05, wd = 2.5e-07, gs = 1
I1130 23:35:37.372532   125 solver.cpp:333]     [0.0] Iteration 20328 (8.19967 iter/s, 5.36607s/44 iter), 56.6/100ep, loss = 6.91146
I1130 23:35:37.372710   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.873778 (* 2 = 1.74756 loss)
I1130 23:35:37.372725   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.16388 (* 1 = 5.16388 loss)
I1130 23:35:37.372737   125 sgd_solver.cpp:180] [0.0] Iteration 20328, lr = 4.45771e-06, m = 0.9, lrm = 4.45771e-05, wd = 2.5e-07, gs = 1
I1130 23:35:42.741736   125 solver.cpp:333]     [0.0] Iteration 20372 (8.19485 iter/s, 5.36923s/44 iter), 56.7/100ep, loss = 9.66167
I1130 23:35:42.741778   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.661099 (* 2 = 1.3222 loss)
I1130 23:35:42.741789   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.33945 (* 1 = 8.33945 loss)
I1130 23:35:42.741802   125 sgd_solver.cpp:180] [0.0] Iteration 20372, lr = 4.4411e-06, m = 0.9, lrm = 4.4411e-05, wd = 2.5e-07, gs = 1
I1130 23:35:48.102099   125 solver.cpp:333]     [0.0] Iteration 20416 (8.20834 iter/s, 5.3604s/44 iter), 56.9/100ep, loss = 4.10423
I1130 23:35:48.102141   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.427356 (* 2 = 0.854712 loss)
I1130 23:35:48.102152   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.2495 (* 1 = 3.2495 loss)
I1130 23:35:48.102164   125 sgd_solver.cpp:180] [0.0] Iteration 20416, lr = 4.42456e-06, m = 0.9, lrm = 4.42456e-05, wd = 2.5e-07, gs = 1
I1130 23:35:50.177402   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:35:50.293869   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:35:53.457280   125 solver.cpp:333]     [0.0] Iteration 20460 (8.21627 iter/s, 5.35523s/44 iter), 57/100ep, loss = 7.45691
I1130 23:35:53.457320   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.854252 (* 2 = 1.7085 loss)
I1130 23:35:53.457331   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.74839 (* 1 = 5.74839 loss)
I1130 23:35:53.457343   125 sgd_solver.cpp:180] [0.0] Iteration 20460, lr = 4.40807e-06, m = 0.9, lrm = 4.40807e-05, wd = 2.5e-07, gs = 1
I1130 23:35:53.700843   125 solver.cpp:501] Iteration 20463, Testing net (#0)
I1130 23:36:08.256763   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:36:08.372540   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:36:10.917357   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.510356 (* 2 = 1.02071 loss)
I1130 23:36:10.917397   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.91834 (* 1 = 8.91834 loss)
I1130 23:36:10.917407   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.165
I1130 23:36:10.917413   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.3695
I1130 23:36:10.917420   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.197
I1130 23:36:10.917454   125 solver.cpp:271] Tests completed in 17.4604s
I1130 23:36:16.098305   125 solver.cpp:333]     [0.0] Iteration 20504 (2.51999 iter/s, 17.4604s/44 iter), 57.1/100ep, loss = 1.50739
I1130 23:36:16.098345   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.194873 (* 2 = 0.389746 loss)
I1130 23:36:16.098356   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.11762 (* 1 = 1.11762 loss)
I1130 23:36:16.098367   125 sgd_solver.cpp:180] [0.0] Iteration 20504, lr = 4.39165e-06, m = 0.9, lrm = 4.39165e-05, wd = 2.5e-07, gs = 1
I1130 23:36:21.539527   125 solver.cpp:333]     [0.0] Iteration 20548 (8.08636 iter/s, 5.44126s/44 iter), 57.2/100ep, loss = 14.7034
I1130 23:36:21.539567   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.2698 (* 2 = 2.53959 loss)
I1130 23:36:21.539578   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.1638 (* 1 = 12.1638 loss)
I1130 23:36:21.539594   125 sgd_solver.cpp:180] [0.0] Iteration 20548, lr = 4.37529e-06, m = 0.9, lrm = 4.37529e-05, wd = 2.5e-07, gs = 1
I1130 23:36:26.953709   125 solver.cpp:333]     [0.0] Iteration 20592 (8.12676 iter/s, 5.41421s/44 iter), 57.4/100ep, loss = 5.00107
I1130 23:36:26.953748   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.444913 (* 2 = 0.889826 loss)
I1130 23:36:26.953758   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.11123 (* 1 = 4.11123 loss)
I1130 23:36:26.953769   125 sgd_solver.cpp:180] [0.0] Iteration 20592, lr = 4.359e-06, m = 0.9, lrm = 4.35899e-05, wd = 2.5e-07, gs = 1
I1130 23:36:32.390333   125 solver.cpp:333]     [0.0] Iteration 20636 (8.0932 iter/s, 5.43666s/44 iter), 57.5/100ep, loss = 8.45971
I1130 23:36:32.390374   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.594415 (* 2 = 1.18883 loss)
I1130 23:36:32.390385   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.27086 (* 1 = 7.27086 loss)
I1130 23:36:32.390396   125 sgd_solver.cpp:180] [0.0] Iteration 20636, lr = 4.34276e-06, m = 0.9, lrm = 4.34276e-05, wd = 2.5e-07, gs = 1
I1130 23:36:37.826301   125 solver.cpp:333]     [0.0] Iteration 20680 (8.0942 iter/s, 5.43599s/44 iter), 57.6/100ep, loss = 5.74865
I1130 23:36:37.826342   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.785591 (* 2 = 1.57118 loss)
I1130 23:36:37.826354   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.17745 (* 1 = 4.17745 loss)
I1130 23:36:37.826364   125 sgd_solver.cpp:180] [0.0] Iteration 20680, lr = 4.32658e-06, m = 0.9, lrm = 4.32658e-05, wd = 2.5e-07, gs = 1
I1130 23:36:43.187742   125 solver.cpp:333]     [0.0] Iteration 20724 (8.20669 iter/s, 5.36148s/44 iter), 57.7/100ep, loss = 8.9284
I1130 23:36:43.187925   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.445004 (* 2 = 0.890008 loss)
I1130 23:36:43.187938   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.03837 (* 1 = 8.03837 loss)
I1130 23:36:43.187952   125 sgd_solver.cpp:180] [0.0] Iteration 20724, lr = 4.31046e-06, m = 0.9, lrm = 4.31046e-05, wd = 2.5e-07, gs = 1
I1130 23:36:48.539579   125 solver.cpp:333]     [0.0] Iteration 20768 (8.22142 iter/s, 5.35187s/44 iter), 57.8/100ep, loss = 2.8252
I1130 23:36:48.539623   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.257443 (* 2 = 0.514885 loss)
I1130 23:36:48.539633   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.3103 (* 1 = 2.3103 loss)
I1130 23:36:48.539644   125 sgd_solver.cpp:180] [0.0] Iteration 20768, lr = 4.29441e-06, m = 0.9, lrm = 4.2944e-05, wd = 2.5e-07, gs = 1
I1130 23:36:51.583196   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:36:51.696789   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:36:53.887686   125 solver.cpp:333]     [0.0] Iteration 20812 (8.22717 iter/s, 5.34813s/44 iter), 58/100ep, loss = 6.62233
I1130 23:36:53.887727   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.590384 (* 2 = 1.18077 loss)
I1130 23:36:53.887739   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.44154 (* 1 = 5.44154 loss)
I1130 23:36:53.887750   125 sgd_solver.cpp:180] [0.0] Iteration 20812, lr = 4.27841e-06, m = 0.9, lrm = 4.27841e-05, wd = 2.5e-07, gs = 1
I1130 23:36:54.980669   125 solver.cpp:501] Iteration 20822, Testing net (#0)
I1130 23:37:09.513370   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:37:09.665925   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:37:12.258626   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.512079 (* 2 = 1.02416 loss)
I1130 23:37:12.258663   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.87064 (* 1 = 8.87064 loss)
I1130 23:37:12.258673   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 17.4765
I1130 23:37:12.258682   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.6364
I1130 23:37:12.258688   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 47.2082
I1130 23:37:12.258726   125 solver.cpp:271] Tests completed in 18.3712s
I1130 23:37:16.509496   125 solver.cpp:333]     [0.0] Iteration 20856 (2.39505 iter/s, 18.3712s/44 iter), 58.1/100ep, loss = 8.01374
I1130 23:37:16.509641   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.714849 (* 2 = 1.4297 loss)
I1130 23:37:16.509654   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.58402 (* 1 = 6.58402 loss)
I1130 23:37:16.509665   125 sgd_solver.cpp:180] [0.0] Iteration 20856, lr = 4.26247e-06, m = 0.9, lrm = 4.26247e-05, wd = 2.5e-07, gs = 1
I1130 23:37:21.851868   125 solver.cpp:333]     [0.0] Iteration 20900 (8.236 iter/s, 5.3424s/44 iter), 58.2/100ep, loss = 5.0391
I1130 23:37:21.851908   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.251131 (* 2 = 0.502262 loss)
I1130 23:37:21.851918   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.53682 (* 1 = 4.53682 loss)
I1130 23:37:21.851928   125 sgd_solver.cpp:180] [0.0] Iteration 20900, lr = 4.24659e-06, m = 0.9, lrm = 4.24659e-05, wd = 2.5e-07, gs = 1
I1130 23:37:27.193333   125 solver.cpp:333]     [0.0] Iteration 20944 (8.23738 iter/s, 5.3415s/44 iter), 58.3/100ep, loss = 4.20791
I1130 23:37:27.193372   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.359598 (* 2 = 0.719195 loss)
I1130 23:37:27.193382   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.4887 (* 1 = 3.4887 loss)
I1130 23:37:27.193392   125 sgd_solver.cpp:180] [0.0] Iteration 20944, lr = 4.23077e-06, m = 0.9, lrm = 4.23077e-05, wd = 2.5e-07, gs = 1
I1130 23:37:32.540661   125 solver.cpp:333]     [0.0] Iteration 20988 (8.22836 iter/s, 5.34736s/44 iter), 58.5/100ep, loss = 4.83574
I1130 23:37:32.540704   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.298307 (* 2 = 0.596614 loss)
I1130 23:37:32.540714   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.2391 (* 1 = 4.2391 loss)
I1130 23:37:32.540725   125 sgd_solver.cpp:180] [0.0] Iteration 20988, lr = 4.21501e-06, m = 0.9, lrm = 4.21501e-05, wd = 2.5e-07, gs = 1
I1130 23:37:37.887373   125 solver.cpp:333]     [0.0] Iteration 21032 (8.22932 iter/s, 5.34674s/44 iter), 58.6/100ep, loss = 8.72806
I1130 23:37:37.887413   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.46304 (* 2 = 0.926081 loss)
I1130 23:37:37.887423   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.80196 (* 1 = 7.80196 loss)
I1130 23:37:37.887432   125 sgd_solver.cpp:180] [0.0] Iteration 21032, lr = 4.19931e-06, m = 0.9, lrm = 4.19931e-05, wd = 2.5e-07, gs = 1
I1130 23:37:43.236927   125 solver.cpp:333]     [0.0] Iteration 21076 (8.22493 iter/s, 5.34959s/44 iter), 58.7/100ep, loss = 3.78842
I1130 23:37:43.236968   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.478315 (* 2 = 0.95663 loss)
I1130 23:37:43.236977   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.83177 (* 1 = 2.83177 loss)
I1130 23:37:43.236989   125 sgd_solver.cpp:180] [0.0] Iteration 21076, lr = 4.18367e-06, m = 0.9, lrm = 4.18367e-05, wd = 2.5e-07, gs = 1
I1130 23:37:48.579720   125 solver.cpp:333]     [0.0] Iteration 21120 (8.23534 iter/s, 5.34283s/44 iter), 58.8/100ep, loss = 10.3615
I1130 23:37:48.579898   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.882015 (* 2 = 1.76403 loss)
I1130 23:37:48.579912   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.59748 (* 1 = 8.59748 loss)
I1130 23:37:48.579923   125 sgd_solver.cpp:180] [0.0] Iteration 21120, lr = 4.16808e-06, m = 0.9, lrm = 4.16808e-05, wd = 2.5e-07, gs = 1
I1130 23:37:52.592384   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:37:52.710956   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:37:53.926998   125 solver.cpp:333]     [0.0] Iteration 21164 (8.22845 iter/s, 5.3473s/44 iter), 59/100ep, loss = 7.31971
I1130 23:37:53.927038   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.543121 (* 2 = 1.08624 loss)
I1130 23:37:53.927049   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.23345 (* 1 = 6.23345 loss)
I1130 23:37:53.927060   125 sgd_solver.cpp:180] [0.0] Iteration 21164, lr = 4.15256e-06, m = 0.9, lrm = 4.15255e-05, wd = 2.5e-07, gs = 1
I1130 23:37:55.872980   125 solver.cpp:501] Iteration 21181, Testing net (#0)
I1130 23:38:10.353067   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:38:10.464867   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:38:13.040266   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.506968 (* 2 = 1.01394 loss)
I1130 23:38:13.040304   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.83542 (* 1 = 8.83542 loss)
I1130 23:38:13.040313   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.8646
I1130 23:38:13.040321   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.079
I1130 23:38:13.040328   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 49.2756
I1130 23:38:13.040361   125 solver.cpp:271] Tests completed in 19.1136s
I1130 23:38:16.440338   125 solver.cpp:333]     [0.0] Iteration 21208 (2.30203 iter/s, 19.1136s/44 iter), 59.1/100ep, loss = 6.99694
I1130 23:38:16.440376   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.29527 (* 2 = 2.59054 loss)
I1130 23:38:16.440387   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.40639 (* 1 = 4.40639 loss)
I1130 23:38:16.440398   125 sgd_solver.cpp:180] [0.0] Iteration 21208, lr = 4.13709e-06, m = 0.9, lrm = 4.13709e-05, wd = 2.5e-07, gs = 1
I1130 23:38:21.780068   125 solver.cpp:333]     [0.0] Iteration 21252 (8.24009 iter/s, 5.33975s/44 iter), 59.2/100ep, loss = 9.49367
I1130 23:38:21.780148   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.259317 (* 2 = 0.518635 loss)
I1130 23:38:21.780158   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.97502 (* 1 = 8.97502 loss)
I1130 23:38:21.780170   125 sgd_solver.cpp:180] [0.0] Iteration 21252, lr = 4.12168e-06, m = 0.9, lrm = 4.12167e-05, wd = 2.5e-07, gs = 1
I1130 23:38:27.113840   125 solver.cpp:333]     [0.0] Iteration 21296 (8.24927 iter/s, 5.33381s/44 iter), 59.3/100ep, loss = 6.36667
I1130 23:38:27.113883   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.636379 (* 2 = 1.27276 loss)
I1130 23:38:27.113894   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.0939 (* 1 = 5.0939 loss)
I1130 23:38:27.113905   125 sgd_solver.cpp:180] [0.0] Iteration 21296, lr = 4.10632e-06, m = 0.9, lrm = 4.10632e-05, wd = 2.5e-07, gs = 1
I1130 23:38:32.452510   125 solver.cpp:333]     [0.0] Iteration 21340 (8.2417 iter/s, 5.3387s/44 iter), 59.4/100ep, loss = 11.5322
I1130 23:38:32.452553   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.72673 (* 2 = 3.45346 loss)
I1130 23:38:32.452563   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.07875 (* 1 = 8.07875 loss)
I1130 23:38:32.452574   125 sgd_solver.cpp:180] [0.0] Iteration 21340, lr = 4.09102e-06, m = 0.9, lrm = 4.09102e-05, wd = 2.5e-07, gs = 1
I1130 23:38:37.792421   125 solver.cpp:333]     [0.0] Iteration 21384 (8.23982 iter/s, 5.33993s/44 iter), 59.6/100ep, loss = 5.81758
I1130 23:38:37.792460   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.624232 (* 2 = 1.24846 loss)
I1130 23:38:37.792472   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.5691 (* 1 = 4.5691 loss)
I1130 23:38:37.792484   125 sgd_solver.cpp:180] [0.0] Iteration 21384, lr = 4.07579e-06, m = 0.9, lrm = 4.07578e-05, wd = 2.5e-07, gs = 1
I1130 23:38:43.137348   125 solver.cpp:333]     [0.0] Iteration 21428 (8.23206 iter/s, 5.34496s/44 iter), 59.7/100ep, loss = 6.28093
I1130 23:38:43.137389   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.678539 (* 2 = 1.35708 loss)
I1130 23:38:43.137400   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.92384 (* 1 = 4.92384 loss)
I1130 23:38:43.137411   125 sgd_solver.cpp:180] [0.0] Iteration 21428, lr = 4.0606e-06, m = 0.9, lrm = 4.0606e-05, wd = 2.5e-07, gs = 1
I1130 23:38:48.488373   125 solver.cpp:333]     [0.0] Iteration 21472 (8.22266 iter/s, 5.35106s/44 iter), 59.8/100ep, loss = 9.08732
I1130 23:38:48.488416   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.907824 (* 2 = 1.81565 loss)
I1130 23:38:48.488427   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.27165 (* 1 = 7.27165 loss)
I1130 23:38:48.488438   125 sgd_solver.cpp:180] [0.0] Iteration 21472, lr = 4.04548e-06, m = 0.9, lrm = 4.04547e-05, wd = 2.5e-07, gs = 1
I1130 23:38:53.104337   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:38:53.227515   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:38:53.833822   125 solver.cpp:333]     [0.0] Iteration 21516 (8.23127 iter/s, 5.34547s/44 iter), 59.9/100ep, loss = 7.88956
I1130 23:38:53.833864   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.371567 (* 2 = 0.743134 loss)
I1130 23:38:53.833874   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.14641 (* 1 = 7.14641 loss)
I1130 23:38:53.833885   125 sgd_solver.cpp:180] [0.0] Iteration 21516, lr = 4.03041e-06, m = 0.9, lrm = 4.0304e-05, wd = 2.5e-07, gs = 1
I1130 23:38:56.629590   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_21540.caffemodel
I1130 23:38:56.677345   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_21540.solverstate
I1130 23:38:56.718076   125 solver.cpp:501] Iteration 21540, Testing net (#0)
I1130 23:39:11.090988   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:39:11.244426   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:39:13.895730   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.507496 (* 2 = 1.01499 loss)
I1130 23:39:13.895766   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.91908 (* 1 = 8.91908 loss)
I1130 23:39:13.895774   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.8976
I1130 23:39:13.895783   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.9148
I1130 23:39:13.895789   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 49.7432
I1130 23:39:13.895823   125 solver.cpp:271] Tests completed in 20.0622s
I1130 23:39:16.449717   125 solver.cpp:333]     [0.0] Iteration 21560 (2.19318 iter/s, 20.0622s/44 iter), 60.1/100ep, loss = 4.34453
I1130 23:39:16.449761   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.378425 (* 2 = 0.75685 loss)
I1130 23:39:16.449771   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.58766 (* 1 = 3.58766 loss)
I1130 23:39:16.449784   125 sgd_solver.cpp:180] [0.0] Iteration 21560, lr = 4.01539e-06, m = 0.9, lrm = 4.01539e-05, wd = 2.5e-07, gs = 1
I1130 23:39:21.795814   125 solver.cpp:333]     [0.0] Iteration 21604 (8.23027 iter/s, 5.34612s/44 iter), 60.2/100ep, loss = 2.83151
I1130 23:39:21.795855   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.21483 (* 2 = 0.42966 loss)
I1130 23:39:21.795866   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.40183 (* 1 = 2.40183 loss)
I1130 23:39:21.795876   125 sgd_solver.cpp:180] [0.0] Iteration 21604, lr = 4.00043e-06, m = 0.9, lrm = 4.00043e-05, wd = 2.5e-07, gs = 1
I1130 23:39:27.153331   125 solver.cpp:333]     [0.0] Iteration 21648 (8.2127 iter/s, 5.35756s/44 iter), 60.3/100ep, loss = 6.35148
I1130 23:39:27.153511   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.611798 (* 2 = 1.2236 loss)
I1130 23:39:27.153523   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.12786 (* 1 = 5.12786 loss)
I1130 23:39:27.153535   125 sgd_solver.cpp:180] [0.0] Iteration 21648, lr = 3.98553e-06, m = 0.9, lrm = 3.98553e-05, wd = 2.5e-07, gs = 1
I1130 23:39:32.503335   125 solver.cpp:333]     [0.0] Iteration 21692 (8.22425 iter/s, 5.35003s/44 iter), 60.4/100ep, loss = 5.69577
I1130 23:39:32.503377   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.43764 (* 2 = 2.87529 loss)
I1130 23:39:32.503386   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.82046 (* 1 = 2.82046 loss)
I1130 23:39:32.503397   125 sgd_solver.cpp:180] [0.0] Iteration 21692, lr = 3.97068e-06, m = 0.9, lrm = 3.97068e-05, wd = 2.5e-07, gs = 1
I1130 23:39:37.851532   125 solver.cpp:333]     [0.0] Iteration 21736 (8.22703 iter/s, 5.34822s/44 iter), 60.5/100ep, loss = 6.97128
I1130 23:39:37.851573   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.433508 (* 2 = 0.867016 loss)
I1130 23:39:37.851583   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.10424 (* 1 = 6.10424 loss)
I1130 23:39:37.851594   125 sgd_solver.cpp:180] [0.0] Iteration 21736, lr = 3.95589e-06, m = 0.9, lrm = 3.95589e-05, wd = 2.5e-07, gs = 1
I1130 23:39:43.198966   125 solver.cpp:333]     [0.0] Iteration 21780 (8.2282 iter/s, 5.34746s/44 iter), 60.7/100ep, loss = 4.60879
I1130 23:39:43.199005   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.493231 (* 2 = 0.986461 loss)
I1130 23:39:43.199015   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.62232 (* 1 = 3.62232 loss)
I1130 23:39:43.199026   125 sgd_solver.cpp:180] [0.0] Iteration 21780, lr = 3.94116e-06, m = 0.9, lrm = 3.94116e-05, wd = 2.5e-07, gs = 1
I1130 23:39:48.550314   125 solver.cpp:333]     [0.0] Iteration 21824 (8.22219 iter/s, 5.35137s/44 iter), 60.8/100ep, loss = 8.55417
I1130 23:39:48.550359   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.684515 (* 2 = 1.36903 loss)
I1130 23:39:48.550369   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.18512 (* 1 = 7.18512 loss)
I1130 23:39:48.550380   125 sgd_solver.cpp:180] [0.0] Iteration 21824, lr = 3.92648e-06, m = 0.9, lrm = 3.92647e-05, wd = 2.5e-07, gs = 1
I1130 23:39:53.915333   125 solver.cpp:333]     [0.0] Iteration 21868 (8.20124 iter/s, 5.36504s/44 iter), 60.9/100ep, loss = 6.60287
I1130 23:39:53.915374   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.908664 (* 2 = 1.81733 loss)
I1130 23:39:53.915385   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.78552 (* 1 = 4.78552 loss)
I1130 23:39:53.915395   125 sgd_solver.cpp:180] [0.0] Iteration 21868, lr = 3.91185e-06, m = 0.9, lrm = 3.91185e-05, wd = 2.5e-07, gs = 1
I1130 23:39:54.163730   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:39:54.274649   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:39:57.570920   125 solver.cpp:501] Iteration 21899, Testing net (#0)
I1130 23:40:12.014613   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:40:12.128468   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:40:14.837739   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.507224 (* 2 = 1.01445 loss)
I1130 23:40:14.837780   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.8189 (* 1 = 8.8189 loss)
I1130 23:40:14.837788   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.1411
I1130 23:40:14.837796   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.0665
I1130 23:40:14.837803   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.9322
I1130 23:40:14.837839   125 solver.cpp:271] Tests completed in 20.9227s
I1130 23:40:16.545897   125 solver.cpp:333]     [0.0] Iteration 21912 (2.10298 iter/s, 20.9227s/44 iter), 61/100ep, loss = 3.80914
I1130 23:40:16.545940   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.329938 (* 2 = 0.659877 loss)
I1130 23:40:16.545951   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.14925 (* 1 = 3.14925 loss)
I1130 23:40:16.545963   125 sgd_solver.cpp:180] [0.0] Iteration 21912, lr = 3.89728e-06, m = 0.9, lrm = 3.89728e-05, wd = 2.5e-07, gs = 1
I1130 23:40:21.911476   125 solver.cpp:333]     [0.0] Iteration 21956 (8.20039 iter/s, 5.3656s/44 iter), 61.2/100ep, loss = 5.70761
I1130 23:40:21.911520   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.637701 (* 2 = 1.2754 loss)
I1130 23:40:21.911530   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.4322 (* 1 = 4.4322 loss)
I1130 23:40:21.911542   125 sgd_solver.cpp:180] [0.0] Iteration 21956, lr = 3.88276e-06, m = 0.9, lrm = 3.88276e-05, wd = 2.5e-07, gs = 1
I1130 23:40:27.277822   125 solver.cpp:333]     [0.0] Iteration 22000 (8.1992 iter/s, 5.36638s/44 iter), 61.3/100ep, loss = 8.26869
I1130 23:40:27.277863   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.881933 (* 2 = 1.76387 loss)
I1130 23:40:27.277874   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.50482 (* 1 = 6.50482 loss)
I1130 23:40:27.277886   125 sgd_solver.cpp:180] [0.0] Iteration 22000, lr = 3.86829e-06, m = 0.9, lrm = 3.86829e-05, wd = 2.5e-07, gs = 1
I1130 23:40:32.638149   125 solver.cpp:333]     [0.0] Iteration 22044 (8.20843 iter/s, 5.36035s/44 iter), 61.4/100ep, loss = 2.16081
I1130 23:40:32.638289   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.203093 (* 2 = 0.406186 loss)
I1130 23:40:32.638303   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.75461 (* 1 = 1.75461 loss)
I1130 23:40:32.638314   125 sgd_solver.cpp:180] [0.0] Iteration 22044, lr = 3.85388e-06, m = 0.9, lrm = 3.85388e-05, wd = 2.5e-07, gs = 1
I1130 23:40:37.996484   125 solver.cpp:333]     [0.0] Iteration 22088 (8.21145 iter/s, 5.35837s/44 iter), 61.5/100ep, loss = 10.4516
I1130 23:40:37.996526   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.851473 (* 2 = 1.70295 loss)
I1130 23:40:37.996537   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.74864 (* 1 = 8.74864 loss)
I1130 23:40:37.996548   125 sgd_solver.cpp:180] [0.0] Iteration 22088, lr = 3.83953e-06, m = 0.9, lrm = 3.83953e-05, wd = 2.5e-07, gs = 1
I1130 23:40:43.354321   125 solver.cpp:333]     [0.0] Iteration 22132 (8.21223 iter/s, 5.35786s/44 iter), 61.6/100ep, loss = 3.24179
I1130 23:40:43.354360   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.197874 (* 2 = 0.395748 loss)
I1130 23:40:43.354372   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.84603 (* 1 = 2.84603 loss)
I1130 23:40:43.354382   125 sgd_solver.cpp:180] [0.0] Iteration 22132, lr = 3.82523e-06, m = 0.9, lrm = 3.82522e-05, wd = 2.5e-07, gs = 1
I1130 23:40:48.716145   125 solver.cpp:333]     [0.0] Iteration 22176 (8.20614 iter/s, 5.36184s/44 iter), 61.8/100ep, loss = 14.5116
I1130 23:40:48.716188   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.17445 (* 2 = 2.34889 loss)
I1130 23:40:48.716199   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.1627 (* 1 = 12.1627 loss)
I1130 23:40:48.716212   125 sgd_solver.cpp:180] [0.0] Iteration 22176, lr = 3.81098e-06, m = 0.9, lrm = 3.81097e-05, wd = 2.5e-07, gs = 1
I1130 23:40:54.067656   125 solver.cpp:333]     [0.0] Iteration 22220 (8.22192 iter/s, 5.35154s/44 iter), 61.9/100ep, loss = 6.14858
I1130 23:40:54.067697   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.813762 (* 2 = 1.62752 loss)
I1130 23:40:54.067708   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.52104 (* 1 = 4.52104 loss)
I1130 23:40:54.067719   125 sgd_solver.cpp:180] [0.0] Iteration 22220, lr = 3.79678e-06, m = 0.9, lrm = 3.79678e-05, wd = 2.5e-07, gs = 1
I1130 23:40:55.290318   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:40:55.405467   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:40:58.618609   125 solver.cpp:501] Iteration 22258, Testing net (#0)
I1130 23:41:12.964620   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:41:13.118182   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:41:15.844377   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.504239 (* 2 = 1.00848 loss)
I1130 23:41:15.844418   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.82661 (* 1 = 8.82661 loss)
I1130 23:41:15.844425   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.3758
I1130 23:41:15.844434   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.6646
I1130 23:41:15.844440   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.4809
I1130 23:41:15.844473   125 solver.cpp:271] Tests completed in 21.777s
I1130 23:41:16.721966   125 solver.cpp:333]     [0.0] Iteration 22264 (2.02048 iter/s, 21.777s/44 iter), 62/100ep, loss = 11.8267
I1130 23:41:16.722007   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.748192 (* 2 = 1.49638 loss)
I1130 23:41:16.722018   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.3303 (* 1 = 10.3303 loss)
I1130 23:41:16.722028   125 sgd_solver.cpp:180] [0.0] Iteration 22264, lr = 3.78264e-06, m = 0.9, lrm = 3.78263e-05, wd = 2.5e-07, gs = 1
I1130 23:41:22.094347   125 solver.cpp:333]     [0.0] Iteration 22308 (8.19002 iter/s, 5.37239s/44 iter), 62.1/100ep, loss = 8.85882
I1130 23:41:22.094400   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.719144 (* 2 = 1.43829 loss)
I1130 23:41:22.094419   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.42051 (* 1 = 7.42051 loss)
I1130 23:41:22.094435   125 sgd_solver.cpp:180] [0.0] Iteration 22308, lr = 3.76854e-06, m = 0.9, lrm = 3.76854e-05, wd = 2.5e-07, gs = 1
I1130 23:41:27.530720   125 solver.cpp:333]     [0.0] Iteration 22352 (8.09356 iter/s, 5.43642s/44 iter), 62.3/100ep, loss = 3.97265
I1130 23:41:27.530762   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.199321 (* 2 = 0.398642 loss)
I1130 23:41:27.530773   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.574 (* 1 = 3.574 loss)
I1130 23:41:27.530786   125 sgd_solver.cpp:180] [0.0] Iteration 22352, lr = 3.75451e-06, m = 0.9, lrm = 3.7545e-05, wd = 2.5e-07, gs = 1
I1130 23:41:32.990037   125 solver.cpp:333]     [0.0] Iteration 22396 (8.05959 iter/s, 5.45933s/44 iter), 62.4/100ep, loss = 5.8086
I1130 23:41:32.990078   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.364657 (* 2 = 0.729314 loss)
I1130 23:41:32.990089   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.07927 (* 1 = 5.07927 loss)
I1130 23:41:32.990100   125 sgd_solver.cpp:180] [0.0] Iteration 22396, lr = 3.74052e-06, m = 0.9, lrm = 3.74052e-05, wd = 2.5e-07, gs = 1
I1130 23:41:38.437165   125 solver.cpp:333]     [0.0] Iteration 22440 (8.07762 iter/s, 5.44715s/44 iter), 62.5/100ep, loss = 11.0702
I1130 23:41:38.437219   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.3298 (* 2 = 2.6596 loss)
I1130 23:41:38.437237   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.41056 (* 1 = 8.41056 loss)
I1130 23:41:38.437253   125 sgd_solver.cpp:180] [0.0] Iteration 22440, lr = 3.72659e-06, m = 0.9, lrm = 3.72658e-05, wd = 2.5e-07, gs = 1
I1130 23:41:43.883707   125 solver.cpp:333]     [0.0] Iteration 22484 (8.07855 iter/s, 5.44652s/44 iter), 62.6/100ep, loss = 10.5015
I1130 23:41:43.883986   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.746592 (* 2 = 1.49318 loss)
I1130 23:41:43.884017   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.00834 (* 1 = 9.00834 loss)
I1130 23:41:43.884047   125 sgd_solver.cpp:180] [0.0] Iteration 22484, lr = 3.7127e-06, m = 0.9, lrm = 3.7127e-05, wd = 2.5e-07, gs = 1
I1130 23:41:49.296528   125 solver.cpp:333]     [0.0] Iteration 22528 (8.12877 iter/s, 5.41287s/44 iter), 62.8/100ep, loss = 6.79371
I1130 23:41:49.296569   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.653043 (* 2 = 1.30609 loss)
I1130 23:41:49.296581   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.4876 (* 1 = 5.4876 loss)
I1130 23:41:49.296592   125 sgd_solver.cpp:180] [0.0] Iteration 22528, lr = 3.69887e-06, m = 0.9, lrm = 3.69887e-05, wd = 2.5e-07, gs = 1
I1130 23:41:54.645397   125 solver.cpp:333]     [0.0] Iteration 22572 (8.22603 iter/s, 5.34888s/44 iter), 62.9/100ep, loss = 5.97408
I1130 23:41:54.645437   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.836942 (* 2 = 1.67388 loss)
I1130 23:41:54.645448   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.30018 (* 1 = 4.30018 loss)
I1130 23:41:54.645459   125 sgd_solver.cpp:180] [0.0] Iteration 22572, lr = 3.68509e-06, m = 0.9, lrm = 3.68509e-05, wd = 2.5e-07, gs = 1
I1130 23:41:56.471446   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:41:56.589262   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:41:59.986660   125 solver.cpp:333]     [0.0] Iteration 22616 (8.23771 iter/s, 5.34129s/44 iter), 63/100ep, loss = 6.21606
I1130 23:41:59.986699   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.547728 (* 2 = 1.09546 loss)
I1130 23:41:59.986709   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.12059 (* 1 = 5.12059 loss)
I1130 23:41:59.986721   125 sgd_solver.cpp:180] [0.0] Iteration 22616, lr = 3.67137e-06, m = 0.9, lrm = 3.67137e-05, wd = 2.5e-07, gs = 1
I1130 23:41:59.986732   125 solver.cpp:501] Iteration 22617, Testing net (#0)
I1130 23:42:14.260504   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:42:14.374752   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:42:17.139127   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.504494 (* 2 = 1.00899 loss)
I1130 23:42:17.139164   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.71563 (* 1 = 8.71563 loss)
I1130 23:42:17.139173   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.2949
I1130 23:42:17.139181   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.3512
I1130 23:42:17.139187   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.7991
I1130 23:42:17.139220   125 solver.cpp:271] Tests completed in 17.1527s
I1130 23:42:22.482661   125 solver.cpp:333]     [0.0] Iteration 22660 (2.56519 iter/s, 17.1527s/44 iter), 63.1/100ep, loss = 5.54705
I1130 23:42:22.482702   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.459625 (* 2 = 0.919249 loss)
I1130 23:42:22.482712   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.62778 (* 1 = 4.62778 loss)
I1130 23:42:22.482723   125 sgd_solver.cpp:180] [0.0] Iteration 22660, lr = 3.65769e-06, m = 0.9, lrm = 3.65769e-05, wd = 2.5e-07, gs = 1
I1130 23:42:27.858990   125 solver.cpp:333]     [0.0] Iteration 22704 (8.18407 iter/s, 5.3763s/44 iter), 63.2/100ep, loss = 4.21359
I1130 23:42:27.859066   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.270401 (* 2 = 0.540803 loss)
I1130 23:42:27.859091   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.67277 (* 1 = 3.67277 loss)
I1130 23:42:27.859118   125 sgd_solver.cpp:180] [0.0] Iteration 22704, lr = 3.64406e-06, m = 0.9, lrm = 3.64406e-05, wd = 2.5e-07, gs = 1
I1130 23:42:33.293226   125 solver.cpp:333]     [0.0] Iteration 22748 (8.09675 iter/s, 5.43428s/44 iter), 63.4/100ep, loss = 4.19619
I1130 23:42:33.293269   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.33051 (* 2 = 0.661021 loss)
I1130 23:42:33.293279   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.53515 (* 1 = 3.53515 loss)
I1130 23:42:33.293292   125 sgd_solver.cpp:180] [0.0] Iteration 22748, lr = 3.63049e-06, m = 0.9, lrm = 3.63049e-05, wd = 2.5e-07, gs = 1
I1130 23:42:38.645773   125 solver.cpp:333]     [0.0] Iteration 22792 (8.22037 iter/s, 5.35256s/44 iter), 63.5/100ep, loss = 8.82171
I1130 23:42:38.645818   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.384138 (* 2 = 0.768276 loss)
I1130 23:42:38.645828   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.05342 (* 1 = 8.05342 loss)
I1130 23:42:38.645841   125 sgd_solver.cpp:180] [0.0] Iteration 22792, lr = 3.61697e-06, m = 0.9, lrm = 3.61696e-05, wd = 2.5e-07, gs = 1
I1130 23:42:44.002882   125 solver.cpp:333]     [0.0] Iteration 22836 (8.21333 iter/s, 5.35715s/44 iter), 63.6/100ep, loss = 9.99804
I1130 23:42:44.002923   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.900807 (* 2 = 1.80161 loss)
I1130 23:42:44.002934   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.19641 (* 1 = 8.19641 loss)
I1130 23:42:44.002946   125 sgd_solver.cpp:180] [0.0] Iteration 22836, lr = 3.60349e-06, m = 0.9, lrm = 3.60349e-05, wd = 2.5e-07, gs = 1
I1130 23:42:49.355880   125 solver.cpp:333]     [0.0] Iteration 22880 (8.21966 iter/s, 5.35302s/44 iter), 63.7/100ep, loss = 3.78332
I1130 23:42:49.356065   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.338638 (* 2 = 0.677275 loss)
I1130 23:42:49.356078   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.10603 (* 1 = 3.10603 loss)
I1130 23:42:49.356091   125 sgd_solver.cpp:180] [0.0] Iteration 22880, lr = 3.59007e-06, m = 0.9, lrm = 3.59007e-05, wd = 2.5e-07, gs = 1
I1130 23:42:54.718333   125 solver.cpp:333]     [0.0] Iteration 22924 (8.20517 iter/s, 5.36247s/44 iter), 63.9/100ep, loss = 3.62919
I1130 23:42:54.718372   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.354813 (* 2 = 0.709626 loss)
I1130 23:42:54.718382   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.91955 (* 1 = 2.91955 loss)
I1130 23:42:54.718394   125 sgd_solver.cpp:180] [0.0] Iteration 22924, lr = 3.57669e-06, m = 0.9, lrm = 3.57669e-05, wd = 2.5e-07, gs = 1
I1130 23:42:57.514189   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:42:57.633035   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:43:00.064683   125 solver.cpp:333]     [0.0] Iteration 22968 (8.22987 iter/s, 5.34638s/44 iter), 64/100ep, loss = 9.3007
I1130 23:43:00.064725   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.612336 (* 2 = 1.22467 loss)
I1130 23:43:00.064736   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.07601 (* 1 = 8.07601 loss)
I1130 23:43:00.064748   125 sgd_solver.cpp:180] [0.0] Iteration 22968, lr = 3.56337e-06, m = 0.9, lrm = 3.56337e-05, wd = 2.5e-07, gs = 1
I1130 23:43:00.915815   125 solver.cpp:501] Iteration 22976, Testing net (#0)
I1130 23:43:15.328984   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:43:15.481700   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:43:18.275787   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.502023 (* 2 = 1.00405 loss)
I1130 23:43:18.275826   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.71507 (* 1 = 8.71507 loss)
I1130 23:43:18.275835   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.4443
I1130 23:43:18.275843   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.1728
I1130 23:43:18.275849   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.5606
I1130 23:43:18.275882   125 solver.cpp:271] Tests completed in 18.2114s
I1130 23:43:22.772734   125 solver.cpp:333]     [0.0] Iteration 23012 (2.41607 iter/s, 18.2114s/44 iter), 64.1/100ep, loss = 14.1142
I1130 23:43:22.772898   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.28639 (* 2 = 2.57278 loss)
I1130 23:43:22.772910   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.5414 (* 1 = 11.5414 loss)
I1130 23:43:22.772922   125 sgd_solver.cpp:180] [0.0] Iteration 23012, lr = 3.5501e-06, m = 0.9, lrm = 3.5501e-05, wd = 2.5e-07, gs = 1
I1130 23:43:28.117751   125 solver.cpp:333]     [0.0] Iteration 23056 (8.23192 iter/s, 5.34504s/44 iter), 64.2/100ep, loss = 6.24449
I1130 23:43:28.117791   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.727788 (* 2 = 1.45558 loss)
I1130 23:43:28.117802   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.78889 (* 1 = 4.78889 loss)
I1130 23:43:28.117813   125 sgd_solver.cpp:180] [0.0] Iteration 23056, lr = 3.53687e-06, m = 0.9, lrm = 3.53687e-05, wd = 2.5e-07, gs = 1
I1130 23:43:33.472543   125 solver.cpp:333]     [0.0] Iteration 23100 (8.21689 iter/s, 5.35482s/44 iter), 64.3/100ep, loss = 7.90345
I1130 23:43:33.472584   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.704723 (* 2 = 1.40945 loss)
I1130 23:43:33.472595   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.49398 (* 1 = 6.49398 loss)
I1130 23:43:33.472605   125 sgd_solver.cpp:180] [0.0] Iteration 23100, lr = 3.5237e-06, m = 0.9, lrm = 3.5237e-05, wd = 2.5e-07, gs = 1
I1130 23:43:38.830411   125 solver.cpp:333]     [0.0] Iteration 23144 (8.21223 iter/s, 5.35786s/44 iter), 64.5/100ep, loss = 5.0435
I1130 23:43:38.830469   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.345842 (* 2 = 0.691684 loss)
I1130 23:43:38.830484   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.3518 (* 1 = 4.3518 loss)
I1130 23:43:38.830502   125 sgd_solver.cpp:180] [0.0] Iteration 23144, lr = 3.51057e-06, m = 0.9, lrm = 3.51057e-05, wd = 2.5e-07, gs = 1
I1130 23:43:44.222761   125 solver.cpp:333]     [0.0] Iteration 23188 (8.15966 iter/s, 5.39238s/44 iter), 64.6/100ep, loss = 7.67448
I1130 23:43:44.222803   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.8588 (* 2 = 1.7176 loss)
I1130 23:43:44.222815   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.95686 (* 1 = 5.95686 loss)
I1130 23:43:44.222826   125 sgd_solver.cpp:180] [0.0] Iteration 23188, lr = 3.49749e-06, m = 0.9, lrm = 3.49749e-05, wd = 2.5e-07, gs = 1
I1130 23:43:49.605010   125 solver.cpp:333]     [0.0] Iteration 23232 (8.17498 iter/s, 5.38228s/44 iter), 64.7/100ep, loss = 4.03897
I1130 23:43:49.605052   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.373947 (* 2 = 0.747893 loss)
I1130 23:43:49.605062   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.29106 (* 1 = 3.29106 loss)
I1130 23:43:49.605073   125 sgd_solver.cpp:180] [0.0] Iteration 23232, lr = 3.48446e-06, m = 0.9, lrm = 3.48446e-05, wd = 2.5e-07, gs = 1
I1130 23:43:55.015851   125 solver.cpp:333]     [0.0] Iteration 23276 (8.1318 iter/s, 5.41086s/44 iter), 64.8/100ep, loss = 7.6427
I1130 23:43:55.016067   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.616035 (* 2 = 1.23207 loss)
I1130 23:43:55.016082   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.41061 (* 1 = 6.41061 loss)
I1130 23:43:55.016093   125 sgd_solver.cpp:180] [0.0] Iteration 23276, lr = 3.47148e-06, m = 0.9, lrm = 3.47148e-05, wd = 2.5e-07, gs = 1
I1130 23:43:58.795646   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:43:58.913254   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:44:00.374927   125 solver.cpp:333]     [0.0] Iteration 23320 (8.21033 iter/s, 5.3591s/44 iter), 65/100ep, loss = 6.78929
I1130 23:44:00.374963   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.806614 (* 2 = 1.61323 loss)
I1130 23:44:00.374975   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.17604 (* 1 = 5.17604 loss)
I1130 23:44:00.374986   125 sgd_solver.cpp:180] [0.0] Iteration 23320, lr = 3.45855e-06, m = 0.9, lrm = 3.45855e-05, wd = 2.5e-07, gs = 1
I1130 23:44:02.082216   125 solver.cpp:501] Iteration 23335, Testing net (#0)
I1130 23:44:16.185351   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:44:16.299151   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:44:19.124650   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.502735 (* 2 = 1.00547 loss)
I1130 23:44:19.124691   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.7414 (* 1 = 8.7414 loss)
I1130 23:44:19.124699   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.4151
I1130 23:44:19.124707   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.5949
I1130 23:44:19.124714   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 49.8329
I1130 23:44:19.124747   125 solver.cpp:271] Tests completed in 18.75s
I1130 23:44:22.779937   125 solver.cpp:333]     [0.0] Iteration 23364 (2.34667 iter/s, 18.75s/44 iter), 65.1/100ep, loss = 9.11304
I1130 23:44:22.779975   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.266 (* 2 = 2.532 loss)
I1130 23:44:22.779985   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.58103 (* 1 = 6.58103 loss)
I1130 23:44:22.779995   125 sgd_solver.cpp:180] [0.0] Iteration 23364, lr = 3.44567e-06, m = 0.9, lrm = 3.44567e-05, wd = 2.5e-07, gs = 1
I1130 23:44:28.139364   125 solver.cpp:333]     [0.0] Iteration 23408 (8.20979 iter/s, 5.35945s/44 iter), 65.2/100ep, loss = 10.0942
I1130 23:44:28.139505   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.52876 (* 2 = 1.05752 loss)
I1130 23:44:28.139519   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.03663 (* 1 = 9.03663 loss)
I1130 23:44:28.139531   125 sgd_solver.cpp:180] [0.0] Iteration 23408, lr = 3.43283e-06, m = 0.9, lrm = 3.43283e-05, wd = 2.5e-07, gs = 1
I1130 23:44:33.510512   125 solver.cpp:333]     [0.0] Iteration 23452 (8.19187 iter/s, 5.37118s/44 iter), 65.3/100ep, loss = 5.08188
I1130 23:44:33.510555   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.479045 (* 2 = 0.958089 loss)
I1130 23:44:33.510566   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.12377 (* 1 = 4.12377 loss)
I1130 23:44:33.510576   125 sgd_solver.cpp:180] [0.0] Iteration 23452, lr = 3.42004e-06, m = 0.9, lrm = 3.42004e-05, wd = 2.5e-07, gs = 1
I1130 23:44:38.857514   125 solver.cpp:333]     [0.0] Iteration 23496 (8.2289 iter/s, 5.34701s/44 iter), 65.4/100ep, loss = 10.6355
I1130 23:44:38.857551   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.904953 (* 2 = 1.80991 loss)
I1130 23:44:38.857563   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.82562 (* 1 = 8.82562 loss)
I1130 23:44:38.857573   125 sgd_solver.cpp:180] [0.0] Iteration 23496, lr = 3.4073e-06, m = 0.9, lrm = 3.4073e-05, wd = 2.5e-07, gs = 1
I1130 23:44:44.196514   125 solver.cpp:333]     [0.0] Iteration 23540 (8.24121 iter/s, 5.33902s/44 iter), 65.6/100ep, loss = 6.39321
I1130 23:44:44.196555   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.453459 (* 2 = 0.906918 loss)
I1130 23:44:44.196566   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.48627 (* 1 = 5.48627 loss)
I1130 23:44:44.196578   125 sgd_solver.cpp:180] [0.0] Iteration 23540, lr = 3.39461e-06, m = 0.9, lrm = 3.39461e-05, wd = 2.5e-07, gs = 1
I1130 23:44:49.539201   125 solver.cpp:333]     [0.0] Iteration 23584 (8.23553 iter/s, 5.34271s/44 iter), 65.7/100ep, loss = 7.0395
I1130 23:44:49.539242   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.418174 (* 2 = 0.836347 loss)
I1130 23:44:49.539252   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.20313 (* 1 = 6.20313 loss)
I1130 23:44:49.539263   125 sgd_solver.cpp:180] [0.0] Iteration 23584, lr = 3.38197e-06, m = 0.9, lrm = 3.38197e-05, wd = 2.5e-07, gs = 1
I1130 23:44:54.881433   125 solver.cpp:333]     [0.0] Iteration 23628 (8.23623 iter/s, 5.34225s/44 iter), 65.8/100ep, loss = 2.9752
I1130 23:44:54.881474   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.223725 (* 2 = 0.44745 loss)
I1130 23:44:54.881484   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.52773 (* 1 = 2.52773 loss)
I1130 23:44:54.881496   125 sgd_solver.cpp:180] [0.0] Iteration 23628, lr = 3.36937e-06, m = 0.9, lrm = 3.36937e-05, wd = 2.5e-07, gs = 1
I1130 23:44:59.256701   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:44:59.375121   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:45:00.224308   125 solver.cpp:333]     [0.0] Iteration 23672 (8.23523 iter/s, 5.3429s/44 iter), 65.9/100ep, loss = 11.0599
I1130 23:45:00.224349   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.975461 (* 2 = 1.95092 loss)
I1130 23:45:00.224359   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.10894 (* 1 = 9.10894 loss)
I1130 23:45:00.224370   125 sgd_solver.cpp:180] [0.0] Iteration 23672, lr = 3.35682e-06, m = 0.9, lrm = 3.35682e-05, wd = 2.5e-07, gs = 1
I1130 23:45:02.774821   125 solver.cpp:501] Iteration 23694, Testing net (#0)
I1130 23:45:17.598460   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:45:17.749720   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:45:20.645526   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.503445 (* 2 = 1.00689 loss)
I1130 23:45:20.645567   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.75131 (* 1 = 8.75131 loss)
I1130 23:45:20.645576   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.2541
I1130 23:45:20.645583   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 29.6631
I1130 23:45:20.645591   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 50.3138
I1130 23:45:20.645627   125 solver.cpp:271] Tests completed in 20.4215s
I1130 23:45:23.451346   125 solver.cpp:333]     [0.0] Iteration 23716 (2.15459 iter/s, 20.4215s/44 iter), 66.1/100ep, loss = 6.39692
I1130 23:45:23.451390   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.636116 (* 2 = 1.27223 loss)
I1130 23:45:23.451401   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.12466 (* 1 = 5.12466 loss)
I1130 23:45:23.451413   125 sgd_solver.cpp:180] [0.0] Iteration 23716, lr = 3.34431e-06, m = 0.9, lrm = 3.34431e-05, wd = 2.5e-07, gs = 1
I1130 23:45:28.805063   125 solver.cpp:333]     [0.0] Iteration 23760 (8.21859 iter/s, 5.35372s/44 iter), 66.2/100ep, loss = 6.14735
I1130 23:45:28.805105   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.42755 (* 2 = 2.85509 loss)
I1130 23:45:28.805115   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.29223 (* 1 = 3.29223 loss)
I1130 23:45:28.805127   125 sgd_solver.cpp:180] [0.0] Iteration 23760, lr = 3.33185e-06, m = 0.9, lrm = 3.33185e-05, wd = 2.5e-07, gs = 1
I1130 23:45:34.160507   125 solver.cpp:333]     [0.0] Iteration 23804 (8.21589 iter/s, 5.35548s/44 iter), 66.3/100ep, loss = 8.01916
I1130 23:45:34.160670   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.788622 (* 2 = 1.57724 loss)
I1130 23:45:34.160684   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.44189 (* 1 = 6.44189 loss)
I1130 23:45:34.160696   125 sgd_solver.cpp:180] [0.0] Iteration 23804, lr = 3.31944e-06, m = 0.9, lrm = 3.31944e-05, wd = 2.5e-07, gs = 1
I1130 23:45:39.517274   125 solver.cpp:333]     [0.0] Iteration 23848 (8.21387 iter/s, 5.35679s/44 iter), 66.4/100ep, loss = 4.31836
I1130 23:45:39.517313   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.30269 (* 2 = 0.60538 loss)
I1130 23:45:39.517323   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.71296 (* 1 = 3.71296 loss)
I1130 23:45:39.517334   125 sgd_solver.cpp:180] [0.0] Iteration 23848, lr = 3.30708e-06, m = 0.9, lrm = 3.30708e-05, wd = 2.5e-07, gs = 1
I1130 23:45:44.872524   125 solver.cpp:333]     [0.0] Iteration 23892 (8.21625 iter/s, 5.35524s/44 iter), 66.6/100ep, loss = 9.25924
I1130 23:45:44.872567   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.297635 (* 2 = 0.595271 loss)
I1130 23:45:44.872578   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.66395 (* 1 = 8.66395 loss)
I1130 23:45:44.872591   125 sgd_solver.cpp:180] [0.0] Iteration 23892, lr = 3.29476e-06, m = 0.9, lrm = 3.29476e-05, wd = 2.5e-07, gs = 1
I1130 23:45:50.227161   125 solver.cpp:333]     [0.0] Iteration 23936 (8.21712 iter/s, 5.35467s/44 iter), 66.7/100ep, loss = 5.52669
I1130 23:45:50.227203   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.357823 (* 2 = 0.715646 loss)
I1130 23:45:50.227213   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.81102 (* 1 = 4.81102 loss)
I1130 23:45:50.227226   125 sgd_solver.cpp:180] [0.0] Iteration 23936, lr = 3.28248e-06, m = 0.9, lrm = 3.28248e-05, wd = 2.5e-07, gs = 1
I1130 23:45:55.581140   125 solver.cpp:333]     [0.0] Iteration 23980 (8.21814 iter/s, 5.35401s/44 iter), 66.8/100ep, loss = 10.5149
I1130 23:45:55.581179   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.810729 (* 2 = 1.62146 loss)
I1130 23:45:55.581190   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.89346 (* 1 = 8.89346 loss)
I1130 23:45:55.581202   125 sgd_solver.cpp:180] [0.0] Iteration 23980, lr = 3.27026e-06, m = 0.9, lrm = 3.27025e-05, wd = 2.5e-07, gs = 1
I1130 23:46:00.996399   125 solver.cpp:333]     [0.0] Iteration 24024 (8.12518 iter/s, 5.41526s/44 iter), 66.9/100ep, loss = 4.65669
I1130 23:46:00.996443   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.280122 (* 2 = 0.560244 loss)
I1130 23:46:00.996454   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.09642 (* 1 = 4.09642 loss)
I1130 23:46:00.996466   125 sgd_solver.cpp:180] [0.0] Iteration 24024, lr = 3.25807e-06, m = 0.9, lrm = 3.25807e-05, wd = 2.5e-07, gs = 1
I1130 23:46:00.996881   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:46:01.114207   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:46:04.424026   125 solver.cpp:501] Iteration 24053, Testing net (#0)
I1130 23:46:18.558387   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:46:18.672283   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:46:21.613981   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.497649 (* 2 = 0.995297 loss)
I1130 23:46:21.614020   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.69978 (* 1 = 8.69978 loss)
I1130 23:46:21.614028   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.1775
I1130 23:46:21.614037   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.8984
I1130 23:46:21.614043   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.5348
I1130 23:46:21.614076   125 solver.cpp:271] Tests completed in 20.6178s
I1130 23:46:23.561905   125 solver.cpp:333]     [0.0] Iteration 24068 (2.13407 iter/s, 20.6178s/44 iter), 67/100ep, loss = 7.59501
I1130 23:46:23.561950   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.487031 (* 2 = 0.974062 loss)
I1130 23:46:23.561961   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.62092 (* 1 = 6.62092 loss)
I1130 23:46:23.561974   125 sgd_solver.cpp:180] [0.0] Iteration 24068, lr = 3.24594e-06, m = 0.9, lrm = 3.24594e-05, wd = 2.5e-07, gs = 1
I1130 23:46:28.920866   125 solver.cpp:333]     [0.0] Iteration 24112 (8.21054 iter/s, 5.35897s/44 iter), 67.2/100ep, loss = 5.27525
I1130 23:46:28.920909   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.243916 (* 2 = 0.487831 loss)
I1130 23:46:28.920920   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.78739 (* 1 = 4.78739 loss)
I1130 23:46:28.920931   125 sgd_solver.cpp:180] [0.0] Iteration 24112, lr = 3.23384e-06, m = 0.9, lrm = 3.23384e-05, wd = 2.5e-07, gs = 1
I1130 23:46:34.275180   125 solver.cpp:333]     [0.0] Iteration 24156 (8.21763 iter/s, 5.35434s/44 iter), 67.3/100ep, loss = 5.88709
I1130 23:46:34.275221   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.648323 (* 2 = 1.29665 loss)
I1130 23:46:34.275233   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.59042 (* 1 = 4.59042 loss)
I1130 23:46:34.275243   125 sgd_solver.cpp:180] [0.0] Iteration 24156, lr = 3.2218e-06, m = 0.9, lrm = 3.2218e-05, wd = 2.5e-07, gs = 1
I1130 23:46:39.627313   125 solver.cpp:333]     [0.0] Iteration 24200 (8.22099 iter/s, 5.35215s/44 iter), 67.4/100ep, loss = 7.583
I1130 23:46:39.627485   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.470991 (* 2 = 0.941982 loss)
I1130 23:46:39.627498   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.641 (* 1 = 6.641 loss)
I1130 23:46:39.627511   125 sgd_solver.cpp:180] [0.0] Iteration 24200, lr = 3.2098e-06, m = 0.9, lrm = 3.2098e-05, wd = 2.5e-07, gs = 1
I1130 23:46:44.984606   125 solver.cpp:333]     [0.0] Iteration 24244 (8.21309 iter/s, 5.3573s/44 iter), 67.5/100ep, loss = 5.15573
I1130 23:46:44.984642   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.58423 (* 2 = 1.16846 loss)
I1130 23:46:44.984652   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.98724 (* 1 = 3.98724 loss)
I1130 23:46:44.984664   125 sgd_solver.cpp:180] [0.0] Iteration 24244, lr = 3.19784e-06, m = 0.9, lrm = 3.19784e-05, wd = 2.5e-07, gs = 1
I1130 23:46:50.347851   125 solver.cpp:333]     [0.0] Iteration 24288 (8.20396 iter/s, 5.36326s/44 iter), 67.7/100ep, loss = 3.66879
I1130 23:46:50.347892   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.350513 (* 2 = 0.701025 loss)
I1130 23:46:50.347903   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.96774 (* 1 = 2.96774 loss)
I1130 23:46:50.347914   125 sgd_solver.cpp:180] [0.0] Iteration 24288, lr = 3.18593e-06, m = 0.9, lrm = 3.18593e-05, wd = 2.5e-07, gs = 1
I1130 23:46:55.709369   125 solver.cpp:333]     [0.0] Iteration 24332 (8.20661 iter/s, 5.36153s/44 iter), 67.8/100ep, loss = 4.69682
I1130 23:46:55.709414   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.300139 (* 2 = 0.600277 loss)
I1130 23:46:55.709427   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.09651 (* 1 = 4.09651 loss)
I1130 23:46:55.709439   125 sgd_solver.cpp:180] [0.0] Iteration 24332, lr = 3.17406e-06, m = 0.9, lrm = 3.17406e-05, wd = 2.5e-07, gs = 1
I1130 23:47:01.066201   125 solver.cpp:333]     [0.0] Iteration 24376 (8.21377 iter/s, 5.35686s/44 iter), 67.9/100ep, loss = 5.83713
I1130 23:47:01.066243   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.369171 (* 2 = 0.738341 loss)
I1130 23:47:01.066253   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.09876 (* 1 = 5.09876 loss)
I1130 23:47:01.066265   125 sgd_solver.cpp:180] [0.0] Iteration 24376, lr = 3.16223e-06, m = 0.9, lrm = 3.16223e-05, wd = 2.5e-07, gs = 1
I1130 23:47:02.046540   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:47:02.165236   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:47:05.326714   125 solver.cpp:501] Iteration 24412, Testing net (#0)
I1130 23:47:19.546072   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:47:19.698611   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:47:22.695703   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.502001 (* 2 = 1.004 loss)
I1130 23:47:22.695744   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.76349 (* 1 = 8.76349 loss)
I1130 23:47:22.695753   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.3452
I1130 23:47:22.695761   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 29.3979
I1130 23:47:22.695768   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 50.0312
I1130 23:47:22.695802   125 solver.cpp:271] Tests completed in 21.6298s
I1130 23:47:23.800493   125 solver.cpp:333]     [0.0] Iteration 24420 (2.03424 iter/s, 21.6298s/44 iter), 68/100ep, loss = 3.94682
I1130 23:47:23.800536   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.408187 (* 2 = 0.816375 loss)
I1130 23:47:23.800547   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.13042 (* 1 = 3.13042 loss)
I1130 23:47:23.800557   125 sgd_solver.cpp:180] [0.0] Iteration 24420, lr = 3.15045e-06, m = 0.9, lrm = 3.15045e-05, wd = 2.5e-07, gs = 1
I1130 23:47:29.160765   125 solver.cpp:333]     [0.0] Iteration 24464 (8.20852 iter/s, 5.36029s/44 iter), 68.1/100ep, loss = 1.80901
I1130 23:47:29.160809   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.133337 (* 2 = 0.266675 loss)
I1130 23:47:29.160820   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.54231 (* 1 = 1.54231 loss)
I1130 23:47:29.160830   125 sgd_solver.cpp:180] [0.0] Iteration 24464, lr = 3.13872e-06, m = 0.9, lrm = 3.13872e-05, wd = 2.5e-07, gs = 1
I1130 23:47:34.518576   125 solver.cpp:333]     [0.0] Iteration 24508 (8.21226 iter/s, 5.35784s/44 iter), 68.3/100ep, loss = 5.29341
I1130 23:47:34.518612   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.534545 (* 2 = 1.06909 loss)
I1130 23:47:34.518623   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.2243 (* 1 = 4.2243 loss)
I1130 23:47:34.518635   125 sgd_solver.cpp:180] [0.0] Iteration 24508, lr = 3.12703e-06, m = 0.9, lrm = 3.12703e-05, wd = 2.5e-07, gs = 1
I1130 23:47:39.870759   125 solver.cpp:333]     [0.0] Iteration 24552 (8.22094 iter/s, 5.35219s/44 iter), 68.4/100ep, loss = 0.419355
I1130 23:47:39.870802   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.0869249 (* 2 = 0.17385 loss)
I1130 23:47:39.870812   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 0.24548 (* 1 = 0.24548 loss)
I1130 23:47:39.870823   125 sgd_solver.cpp:180] [0.0] Iteration 24552, lr = 3.11538e-06, m = 0.9, lrm = 3.11538e-05, wd = 2.5e-07, gs = 1
I1130 23:47:45.243541   125 solver.cpp:333]     [0.0] Iteration 24596 (8.18941 iter/s, 5.3728s/44 iter), 68.5/100ep, loss = 6.19593
I1130 23:47:45.243584   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.877488 (* 2 = 1.75498 loss)
I1130 23:47:45.243595   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.44093 (* 1 = 4.44093 loss)
I1130 23:47:45.243607   125 sgd_solver.cpp:180] [0.0] Iteration 24596, lr = 3.10377e-06, m = 0.9, lrm = 3.10377e-05, wd = 2.5e-07, gs = 1
I1130 23:47:50.602852   125 solver.cpp:333]     [0.0] Iteration 24640 (8.20997 iter/s, 5.35934s/44 iter), 68.6/100ep, loss = 4.13899
I1130 23:47:50.602983   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.470125 (* 2 = 0.94025 loss)
I1130 23:47:50.602996   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.19871 (* 1 = 3.19871 loss)
I1130 23:47:50.603008   125 sgd_solver.cpp:180] [0.0] Iteration 24640, lr = 3.09221e-06, m = 0.9, lrm = 3.09221e-05, wd = 2.5e-07, gs = 1
I1130 23:47:55.962126   125 solver.cpp:333]     [0.0] Iteration 24684 (8.21006 iter/s, 5.35928s/44 iter), 68.8/100ep, loss = 15.6785
I1130 23:47:55.962169   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.881267 (* 2 = 1.76253 loss)
I1130 23:47:55.962182   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.9159 (* 1 = 13.9159 loss)
I1130 23:47:55.962193   125 sgd_solver.cpp:180] [0.0] Iteration 24684, lr = 3.08069e-06, m = 0.9, lrm = 3.08069e-05, wd = 2.5e-07, gs = 1
I1130 23:48:01.323153   125 solver.cpp:333]     [0.0] Iteration 24728 (8.20734 iter/s, 5.36105s/44 iter), 68.9/100ep, loss = 5.67712
I1130 23:48:01.323195   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.574678 (* 2 = 1.14936 loss)
I1130 23:48:01.323206   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.52773 (* 1 = 4.52773 loss)
I1130 23:48:01.323218   125 sgd_solver.cpp:180] [0.0] Iteration 24728, lr = 3.06922e-06, m = 0.9, lrm = 3.06921e-05, wd = 2.5e-07, gs = 1
I1130 23:48:02.911947   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:48:03.032093   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:48:06.440171   125 solver.cpp:501] Iteration 24771, Testing net (#0)
I1130 23:48:20.409291   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:48:20.522506   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:48:23.545150   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.500367 (* 2 = 1.00073 loss)
I1130 23:48:23.545300   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.7286 (* 1 = 8.7286 loss)
I1130 23:48:23.545310   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.4723
I1130 23:48:23.545320   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.1375
I1130 23:48:23.545326   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 50.1525
I1130 23:48:23.545358   125 solver.cpp:271] Tests completed in 22.2224s
I1130 23:48:23.789813   125 solver.cpp:333]     [0.0] Iteration 24772 (1.97999 iter/s, 22.2224s/44 iter), 69/100ep, loss = 3.90626
I1130 23:48:23.789857   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.344469 (* 2 = 0.688938 loss)
I1130 23:48:23.789867   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.21729 (* 1 = 3.21729 loss)
I1130 23:48:23.789880   125 sgd_solver.cpp:180] [0.0] Iteration 24772, lr = 3.05778e-06, m = 0.9, lrm = 3.05778e-05, wd = 2.5e-07, gs = 1
I1130 23:48:29.154202   125 solver.cpp:333]     [0.0] Iteration 24816 (8.2022 iter/s, 5.36441s/44 iter), 69.1/100ep, loss = 8.61209
I1130 23:48:29.154242   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.558601 (* 2 = 1.1172 loss)
I1130 23:48:29.154253   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.49486 (* 1 = 7.49486 loss)
I1130 23:48:29.154265   125 sgd_solver.cpp:180] [0.0] Iteration 24816, lr = 3.04639e-06, m = 0.9, lrm = 3.04639e-05, wd = 2.5e-07, gs = 1
I1130 23:48:34.516197   125 solver.cpp:333]     [0.0] Iteration 24860 (8.20587 iter/s, 5.36202s/44 iter), 69.2/100ep, loss = 8.01308
I1130 23:48:34.516237   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.06505 (* 2 = 2.1301 loss)
I1130 23:48:34.516248   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.88295 (* 1 = 5.88295 loss)
I1130 23:48:34.516260   125 sgd_solver.cpp:180] [0.0] Iteration 24860, lr = 3.03504e-06, m = 0.9, lrm = 3.03504e-05, wd = 2.5e-07, gs = 1
I1130 23:48:39.872913   125 solver.cpp:333]     [0.0] Iteration 24904 (8.21397 iter/s, 5.35673s/44 iter), 69.4/100ep, loss = 1.99585
I1130 23:48:39.872956   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.219752 (* 2 = 0.439504 loss)
I1130 23:48:39.872967   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.55632 (* 1 = 1.55632 loss)
I1130 23:48:39.872977   125 sgd_solver.cpp:180] [0.0] Iteration 24904, lr = 3.02374e-06, m = 0.9, lrm = 3.02374e-05, wd = 2.5e-07, gs = 1
I1130 23:48:45.233566   125 solver.cpp:333]     [0.0] Iteration 24948 (8.20792 iter/s, 5.36067s/44 iter), 69.5/100ep, loss = 9.77969
I1130 23:48:45.233608   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.672491 (* 2 = 1.34498 loss)
I1130 23:48:45.233620   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.43468 (* 1 = 8.43468 loss)
I1130 23:48:45.233631   125 sgd_solver.cpp:180] [0.0] Iteration 24948, lr = 3.01247e-06, m = 0.9, lrm = 3.01247e-05, wd = 2.5e-07, gs = 1
I1130 23:48:50.641656   125 solver.cpp:333]     [0.0] Iteration 24992 (8.13592 iter/s, 5.40812s/44 iter), 69.6/100ep, loss = 8.46294
I1130 23:48:50.641698   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.697736 (* 2 = 1.39547 loss)
I1130 23:48:50.641710   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.06744 (* 1 = 7.06744 loss)
I1130 23:48:50.641721   125 sgd_solver.cpp:180] [0.0] Iteration 24992, lr = 3.00125e-06, m = 0.9, lrm = 3.00125e-05, wd = 2.5e-07, gs = 1
I1130 23:48:55.995489   125 solver.cpp:333]     [0.0] Iteration 25036 (8.21841 iter/s, 5.35384s/44 iter), 69.7/100ep, loss = 14.3639
I1130 23:48:55.995672   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.02101 (* 2 = 2.04202 loss)
I1130 23:48:55.995687   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.3218 (* 1 = 12.3218 loss)
I1130 23:48:55.995699   125 sgd_solver.cpp:180] [0.0] Iteration 25036, lr = 2.99007e-06, m = 0.9, lrm = 2.99007e-05, wd = 2.5e-07, gs = 1
I1130 23:49:01.392860   125 solver.cpp:333]     [0.0] Iteration 25080 (8.15212 iter/s, 5.39737s/44 iter), 69.9/100ep, loss = 2.26738
I1130 23:49:01.392942   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.292345 (* 2 = 0.58469 loss)
I1130 23:49:01.392976   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.68267 (* 1 = 1.68267 loss)
I1130 23:49:01.393008   125 sgd_solver.cpp:180] [0.0] Iteration 25080, lr = 2.97893e-06, m = 0.9, lrm = 2.97893e-05, wd = 2.5e-07, gs = 1
I1130 23:49:03.979851   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:49:04.132552   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:49:06.829921   125 solver.cpp:333]     [0.0] Iteration 25124 (8.09257 iter/s, 5.43709s/44 iter), 70/100ep, loss = 9.14974
I1130 23:49:06.829962   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.17857 (* 2 = 2.35714 loss)
I1130 23:49:06.829972   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.79257 (* 1 = 6.79257 loss)
I1130 23:49:06.829985   125 sgd_solver.cpp:180] [0.0] Iteration 25124, lr = 2.96784e-06, m = 0.9, lrm = 2.96783e-05, wd = 2.5e-07, gs = 1
I1130 23:49:07.462796   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_25130.caffemodel
I1130 23:49:07.513690   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_25130.solverstate
I1130 23:49:07.554689   125 solver.cpp:501] Iteration 25130, Testing net (#0)
I1130 23:49:21.464946   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:49:21.617874   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:49:24.687100   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.499635 (* 2 = 0.99927 loss)
I1130 23:49:24.687139   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.84076 (* 1 = 8.84076 loss)
I1130 23:49:24.687149   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.9722
I1130 23:49:24.687156   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.4051
I1130 23:49:24.687163   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.0504
I1130 23:49:24.687194   125 solver.cpp:271] Tests completed in 17.8574s
I1130 23:49:29.433080   125 solver.cpp:333]     [0.0] Iteration 25168 (2.46396 iter/s, 17.8574s/44 iter), 70.1/100ep, loss = 8.65991
I1130 23:49:29.433218   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.695286 (* 2 = 1.39057 loss)
I1130 23:49:29.433233   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.26932 (* 1 = 7.26932 loss)
I1130 23:49:29.433243   125 sgd_solver.cpp:180] [0.0] Iteration 25168, lr = 2.95678e-06, m = 0.9, lrm = 2.95678e-05, wd = 2.5e-07, gs = 1
I1130 23:49:34.791402   125 solver.cpp:333]     [0.0] Iteration 25212 (8.21151 iter/s, 5.35833s/44 iter), 70.2/100ep, loss = 5.19757
I1130 23:49:34.791443   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.433108 (* 2 = 0.866217 loss)
I1130 23:49:34.791455   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.33133 (* 1 = 4.33133 loss)
I1130 23:49:34.791465   125 sgd_solver.cpp:180] [0.0] Iteration 25212, lr = 2.94577e-06, m = 0.9, lrm = 2.94576e-05, wd = 2.5e-07, gs = 1
I1130 23:49:40.127822   125 solver.cpp:333]     [0.0] Iteration 25256 (8.2452 iter/s, 5.33644s/44 iter), 70.4/100ep, loss = 2.82917
I1130 23:49:40.127864   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.196402 (* 2 = 0.392805 loss)
I1130 23:49:40.127876   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.43634 (* 1 = 2.43634 loss)
I1130 23:49:40.127887   125 sgd_solver.cpp:180] [0.0] Iteration 25256, lr = 2.93479e-06, m = 0.9, lrm = 2.93479e-05, wd = 2.5e-07, gs = 1
I1130 23:49:45.469761   125 solver.cpp:333]     [0.0] Iteration 25300 (8.23667 iter/s, 5.34196s/44 iter), 70.5/100ep, loss = 11.8591
I1130 23:49:45.469801   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.26204 (* 2 = 2.52408 loss)
I1130 23:49:45.469811   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.33501 (* 1 = 9.33501 loss)
I1130 23:49:45.469821   125 sgd_solver.cpp:180] [0.0] Iteration 25300, lr = 2.92386e-06, m = 0.9, lrm = 2.92386e-05, wd = 2.5e-07, gs = 1
I1130 23:49:50.804060   125 solver.cpp:333]     [0.0] Iteration 25344 (8.2485 iter/s, 5.3343s/44 iter), 70.6/100ep, loss = 10.4831
I1130 23:49:50.804102   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.671215 (* 2 = 1.34243 loss)
I1130 23:49:50.804112   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.14067 (* 1 = 9.14067 loss)
I1130 23:49:50.804124   125 sgd_solver.cpp:180] [0.0] Iteration 25344, lr = 2.91297e-06, m = 0.9, lrm = 2.91297e-05, wd = 2.5e-07, gs = 1
I1130 23:49:56.142110   125 solver.cpp:333]     [0.0] Iteration 25388 (8.24267 iter/s, 5.33807s/44 iter), 70.7/100ep, loss = 5.14941
I1130 23:49:56.142151   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.41283 (* 2 = 2.82566 loss)
I1130 23:49:56.142160   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.32372 (* 1 = 2.32372 loss)
I1130 23:49:56.142171   125 sgd_solver.cpp:180] [0.0] Iteration 25388, lr = 2.90212e-06, m = 0.9, lrm = 2.90212e-05, wd = 2.5e-07, gs = 1
I1130 23:50:01.490679   125 solver.cpp:333]     [0.0] Iteration 25432 (8.22647 iter/s, 5.34859s/44 iter), 70.8/100ep, loss = 5.54606
I1130 23:50:01.490871   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.701518 (* 2 = 1.40304 loss)
I1130 23:50:01.490885   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.14299 (* 1 = 4.14299 loss)
I1130 23:50:01.490896   125 sgd_solver.cpp:180] [0.0] Iteration 25432, lr = 2.89131e-06, m = 0.9, lrm = 2.8913e-05, wd = 2.5e-07, gs = 1
I1130 23:50:05.028193   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:50:05.148198   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:50:06.849896   125 solver.cpp:333]     [0.0] Iteration 25476 (8.21014 iter/s, 5.35923s/44 iter), 71/100ep, loss = 8.2163
I1130 23:50:06.849939   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.529662 (* 2 = 1.05932 loss)
I1130 23:50:06.849951   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.15695 (* 1 = 7.15695 loss)
I1130 23:50:06.849962   125 sgd_solver.cpp:180] [0.0] Iteration 25476, lr = 2.88053e-06, m = 0.9, lrm = 2.88053e-05, wd = 2.5e-07, gs = 1
I1130 23:50:08.311491   125 solver.cpp:501] Iteration 25489, Testing net (#0)
I1130 23:50:20.808795   151 blocking_queue.cpp:40] Data layer prefetch queue empty
I1130 23:50:22.272958   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:50:22.387234   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:50:25.490459   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.503192 (* 2 = 1.00638 loss)
I1130 23:50:25.490500   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.85184 (* 1 = 8.85184 loss)
I1130 23:50:25.490509   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.1254
I1130 23:50:25.490517   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.2694
I1130 23:50:25.490525   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 50.2387
I1130 23:50:25.490559   125 solver.cpp:271] Tests completed in 18.6408s
I1130 23:50:29.394096   125 solver.cpp:333]     [0.0] Iteration 25520 (2.36041 iter/s, 18.6408s/44 iter), 71.1/100ep, loss = 6.0908
I1130 23:50:29.394140   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.388791 (* 2 = 0.777581 loss)
I1130 23:50:29.394150   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.31319 (* 1 = 5.31319 loss)
I1130 23:50:29.394161   125 sgd_solver.cpp:180] [0.0] Iteration 25520, lr = 2.8698e-06, m = 0.9, lrm = 2.8698e-05, wd = 2.5e-07, gs = 1
I1130 23:50:34.759220   125 solver.cpp:333]     [0.0] Iteration 25564 (8.2011 iter/s, 5.36513s/44 iter), 71.2/100ep, loss = 4.1341
I1130 23:50:34.759413   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.24404 (* 2 = 0.488079 loss)
I1130 23:50:34.759426   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.646 (* 1 = 3.646 loss)
I1130 23:50:34.759438   125 sgd_solver.cpp:180] [0.0] Iteration 25564, lr = 2.85911e-06, m = 0.9, lrm = 2.85911e-05, wd = 2.5e-07, gs = 1
I1130 23:50:40.119554   125 solver.cpp:333]     [0.0] Iteration 25608 (8.20841 iter/s, 5.36036s/44 iter), 71.3/100ep, loss = 5.88387
I1130 23:50:40.119594   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.334057 (* 2 = 0.668114 loss)
I1130 23:50:40.119604   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.21573 (* 1 = 5.21573 loss)
I1130 23:50:40.119616   125 sgd_solver.cpp:180] [0.0] Iteration 25608, lr = 2.84846e-06, m = 0.9, lrm = 2.84846e-05, wd = 2.5e-07, gs = 1
I1130 23:50:45.484297   125 solver.cpp:333]     [0.0] Iteration 25652 (8.20166 iter/s, 5.36476s/44 iter), 71.5/100ep, loss = 7.02045
I1130 23:50:45.484333   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.507781 (* 2 = 1.01556 loss)
I1130 23:50:45.484344   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.00486 (* 1 = 6.00486 loss)
I1130 23:50:45.484355   125 sgd_solver.cpp:180] [0.0] Iteration 25652, lr = 2.83785e-06, m = 0.9, lrm = 2.83785e-05, wd = 2.5e-07, gs = 1
I1130 23:50:50.843017   125 solver.cpp:333]     [0.0] Iteration 25696 (8.21093 iter/s, 5.35871s/44 iter), 71.6/100ep, loss = 10.3593
I1130 23:50:50.843060   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.944819 (* 2 = 1.88964 loss)
I1130 23:50:50.843070   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.46963 (* 1 = 8.46963 loss)
I1130 23:50:50.843082   125 sgd_solver.cpp:180] [0.0] Iteration 25696, lr = 2.82728e-06, m = 0.9, lrm = 2.82728e-05, wd = 2.5e-07, gs = 1
I1130 23:50:56.196853   125 solver.cpp:333]     [0.0] Iteration 25740 (8.21836 iter/s, 5.35387s/44 iter), 71.7/100ep, loss = 3.39598
I1130 23:50:56.196898   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.471123 (* 2 = 0.942246 loss)
I1130 23:50:56.196908   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.45371 (* 1 = 2.45371 loss)
I1130 23:50:56.196920   125 sgd_solver.cpp:180] [0.0] Iteration 25740, lr = 2.81675e-06, m = 0.9, lrm = 2.81675e-05, wd = 2.5e-07, gs = 1
I1130 23:51:01.569424   125 solver.cpp:333]     [0.0] Iteration 25784 (8.18972 iter/s, 5.37259s/44 iter), 71.8/100ep, loss = 3.67951
I1130 23:51:01.569461   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.392345 (* 2 = 0.78469 loss)
I1130 23:51:01.569471   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.89479 (* 1 = 2.89479 loss)
I1130 23:51:01.569483   125 sgd_solver.cpp:180] [0.0] Iteration 25784, lr = 2.80626e-06, m = 0.9, lrm = 2.80625e-05, wd = 2.5e-07, gs = 1
I1130 23:51:05.760859   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:51:05.878332   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:51:06.993988   125 solver.cpp:333]     [0.0] Iteration 25828 (8.11123 iter/s, 5.42458s/44 iter), 71.9/100ep, loss = 8.14382
I1130 23:51:06.994031   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.574469 (* 2 = 1.14894 loss)
I1130 23:51:06.994042   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.99486 (* 1 = 6.99486 loss)
I1130 23:51:06.994055   125 sgd_solver.cpp:180] [0.0] Iteration 25828, lr = 2.7958e-06, m = 0.9, lrm = 2.7958e-05, wd = 2.5e-07, gs = 1
I1130 23:51:09.340456   125 solver.cpp:501] Iteration 25848, Testing net (#0)
I1130 23:51:23.102989   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:51:23.253871   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:51:26.365860   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.497471 (* 2 = 0.994942 loss)
I1130 23:51:26.365900   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.83371 (* 1 = 8.83371 loss)
I1130 23:51:26.365908   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.9976
I1130 23:51:26.365916   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.8003
I1130 23:51:26.365923   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 50.1029
I1130 23:51:26.365959   125 solver.cpp:271] Tests completed in 19.3721s
I1130 23:51:29.460446   125 solver.cpp:333]     [0.0] Iteration 25872 (2.27131 iter/s, 19.3721s/44 iter), 72.1/100ep, loss = 1.70595
I1130 23:51:29.460505   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.100823 (* 2 = 0.201646 loss)
I1130 23:51:29.460521   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.50427 (* 1 = 1.50427 loss)
I1130 23:51:29.460539   125 sgd_solver.cpp:180] [0.0] Iteration 25872, lr = 2.78539e-06, m = 0.9, lrm = 2.78539e-05, wd = 2.5e-07, gs = 1
I1130 23:51:34.892979   125 solver.cpp:333]     [0.0] Iteration 25916 (8.09934 iter/s, 5.43254s/44 iter), 72.2/100ep, loss = 4.61322
I1130 23:51:34.893023   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.904593 (* 2 = 1.80919 loss)
I1130 23:51:34.893033   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.80401 (* 1 = 2.80401 loss)
I1130 23:51:34.893046   125 sgd_solver.cpp:180] [0.0] Iteration 25916, lr = 2.77501e-06, m = 0.9, lrm = 2.77501e-05, wd = 2.5e-07, gs = 1
I1130 23:51:40.346834   125 solver.cpp:333]     [0.0] Iteration 25960 (8.06767 iter/s, 5.45387s/44 iter), 72.3/100ep, loss = 6.98269
I1130 23:51:40.346977   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.581263 (* 2 = 1.16253 loss)
I1130 23:51:40.346998   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.82013 (* 1 = 5.82013 loss)
I1130 23:51:40.347014   125 sgd_solver.cpp:180] [0.0] Iteration 25960, lr = 2.76467e-06, m = 0.9, lrm = 2.76467e-05, wd = 2.5e-07, gs = 1
I1130 23:51:45.716871   125 solver.cpp:333]     [0.0] Iteration 26004 (8.19359 iter/s, 5.37005s/44 iter), 72.4/100ep, loss = 5.57366
I1130 23:51:45.716909   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.329258 (* 2 = 0.658516 loss)
I1130 23:51:45.716919   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.91512 (* 1 = 4.91512 loss)
I1130 23:51:45.716930   125 sgd_solver.cpp:180] [0.0] Iteration 26004, lr = 2.75437e-06, m = 0.9, lrm = 2.75437e-05, wd = 2.5e-07, gs = 1
I1130 23:51:51.061439   125 solver.cpp:333]     [0.0] Iteration 26048 (8.23264 iter/s, 5.34458s/44 iter), 72.6/100ep, loss = 6.71563
I1130 23:51:51.061480   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.06542 (* 2 = 2.13084 loss)
I1130 23:51:51.061491   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.58476 (* 1 = 4.58476 loss)
I1130 23:51:51.061502   125 sgd_solver.cpp:180] [0.0] Iteration 26048, lr = 2.74411e-06, m = 0.9, lrm = 2.74411e-05, wd = 2.5e-07, gs = 1
I1130 23:51:56.414765   125 solver.cpp:333]     [0.0] Iteration 26092 (8.21914 iter/s, 5.35336s/44 iter), 72.7/100ep, loss = 3.9749
I1130 23:51:56.414808   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.383361 (* 2 = 0.766722 loss)
I1130 23:51:56.414819   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.20815 (* 1 = 3.20815 loss)
I1130 23:51:56.414830   125 sgd_solver.cpp:180] [0.0] Iteration 26092, lr = 2.73389e-06, m = 0.9, lrm = 2.73389e-05, wd = 2.5e-07, gs = 1
I1130 23:52:01.770624   125 solver.cpp:333]     [0.0] Iteration 26136 (8.2153 iter/s, 5.35586s/44 iter), 72.8/100ep, loss = 3.75321
I1130 23:52:01.770668   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.335361 (* 2 = 0.670721 loss)
I1130 23:52:01.770678   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.08247 (* 1 = 3.08247 loss)
I1130 23:52:01.770690   125 sgd_solver.cpp:180] [0.0] Iteration 26136, lr = 2.72371e-06, m = 0.9, lrm = 2.72371e-05, wd = 2.5e-07, gs = 1
I1130 23:52:06.890137   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:52:07.005408   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:52:07.128677   125 solver.cpp:333]     [0.0] Iteration 26180 (8.2119 iter/s, 5.35808s/44 iter), 72.9/100ep, loss = 9.13522
I1130 23:52:07.128720   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.398996 (* 2 = 0.797993 loss)
I1130 23:52:07.128731   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.3372 (* 1 = 8.3372 loss)
I1130 23:52:07.128742   125 sgd_solver.cpp:180] [0.0] Iteration 26180, lr = 2.71356e-06, m = 0.9, lrm = 2.71356e-05, wd = 2.5e-07, gs = 1
I1130 23:52:10.296679   125 solver.cpp:501] Iteration 26207, Testing net (#0)
I1130 23:52:24.173526   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:52:24.289281   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:52:27.452199   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.498687 (* 2 = 0.997375 loss)
I1130 23:52:27.452241   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.72516 (* 1 = 8.72516 loss)
I1130 23:52:27.452250   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.3726
I1130 23:52:27.452257   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.288
I1130 23:52:27.452265   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 49.6371
I1130 23:52:27.452298   125 solver.cpp:271] Tests completed in 20.3238s
I1130 23:52:29.646064   125 solver.cpp:333]     [0.0] Iteration 26224 (2.16495 iter/s, 20.3238s/44 iter), 73/100ep, loss = 8.49839
I1130 23:52:29.646108   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.10121 (* 2 = 2.20242 loss)
I1130 23:52:29.646117   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.29594 (* 1 = 6.29594 loss)
I1130 23:52:29.646131   125 sgd_solver.cpp:180] [0.0] Iteration 26224, lr = 2.70345e-06, m = 0.9, lrm = 2.70345e-05, wd = 2.5e-07, gs = 1
I1130 23:52:35.005760   125 solver.cpp:333]     [0.0] Iteration 26268 (8.20942 iter/s, 5.3597s/44 iter), 73.2/100ep, loss = 6.21872
I1130 23:52:35.005803   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.383474 (* 2 = 0.766947 loss)
I1130 23:52:35.005813   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.45174 (* 1 = 5.45174 loss)
I1130 23:52:35.005825   125 sgd_solver.cpp:180] [0.0] Iteration 26268, lr = 2.69338e-06, m = 0.9, lrm = 2.69338e-05, wd = 2.5e-07, gs = 1
I1130 23:52:40.362665   125 solver.cpp:333]     [0.0] Iteration 26312 (8.21366 iter/s, 5.35693s/44 iter), 73.3/100ep, loss = 6.18278
I1130 23:52:40.362709   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.637213 (* 2 = 1.27443 loss)
I1130 23:52:40.362720   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.90833 (* 1 = 4.90833 loss)
I1130 23:52:40.362732   125 sgd_solver.cpp:180] [0.0] Iteration 26312, lr = 2.68335e-06, m = 0.9, lrm = 2.68335e-05, wd = 2.5e-07, gs = 1
I1130 23:52:45.730098   125 solver.cpp:333]     [0.0] Iteration 26356 (8.19759 iter/s, 5.36743s/44 iter), 73.4/100ep, loss = 9.23082
I1130 23:52:45.730139   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.818132 (* 2 = 1.63626 loss)
I1130 23:52:45.730149   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.59453 (* 1 = 7.59453 loss)
I1130 23:52:45.730161   125 sgd_solver.cpp:180] [0.0] Iteration 26356, lr = 2.67335e-06, m = 0.9, lrm = 2.67335e-05, wd = 2.5e-07, gs = 1
I1130 23:52:51.085808   125 solver.cpp:333]     [0.0] Iteration 26400 (8.21549 iter/s, 5.35574s/44 iter), 73.5/100ep, loss = 9.53707
I1130 23:52:51.085847   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.701655 (* 2 = 1.40331 loss)
I1130 23:52:51.085858   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.13373 (* 1 = 8.13373 loss)
I1130 23:52:51.085871   125 sgd_solver.cpp:180] [0.0] Iteration 26400, lr = 2.66339e-06, m = 0.9, lrm = 2.66339e-05, wd = 2.5e-07, gs = 1
I1130 23:52:56.463060   125 solver.cpp:333]     [0.0] Iteration 26444 (8.18259 iter/s, 5.37727s/44 iter), 73.7/100ep, loss = 4.77172
I1130 23:52:56.464349   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.317878 (* 2 = 0.635757 loss)
I1130 23:52:56.464365   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.13594 (* 1 = 4.13594 loss)
I1130 23:52:56.464378   125 sgd_solver.cpp:180] [0.0] Iteration 26444, lr = 2.65347e-06, m = 0.9, lrm = 2.65347e-05, wd = 2.5e-07, gs = 1
I1130 23:53:01.888625   125 solver.cpp:333]     [0.0] Iteration 26488 (8.10975 iter/s, 5.42557s/44 iter), 73.8/100ep, loss = 3.48813
I1130 23:53:01.888681   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.28861 (* 2 = 0.577219 loss)
I1130 23:53:01.888698   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.91089 (* 1 = 2.91089 loss)
I1130 23:53:01.888716   125 sgd_solver.cpp:180] [0.0] Iteration 26488, lr = 2.64359e-06, m = 0.9, lrm = 2.64359e-05, wd = 2.5e-07, gs = 1
I1130 23:53:07.409402   125 solver.cpp:333]     [0.0] Iteration 26532 (7.96985 iter/s, 5.52081s/44 iter), 73.9/100ep, loss = 10.9462
I1130 23:53:07.409442   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.43172 (* 2 = 2.86344 loss)
I1130 23:53:07.409452   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.0827 (* 1 = 8.0827 loss)
I1130 23:53:07.409464   125 sgd_solver.cpp:180] [0.0] Iteration 26532, lr = 2.63374e-06, m = 0.9, lrm = 2.63374e-05, wd = 2.5e-07, gs = 1
I1130 23:53:08.169908   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:53:08.303457   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:53:11.471194   125 solver.cpp:501] Iteration 26566, Testing net (#0)
I1130 23:53:25.123713   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:53:25.275693   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:53:28.473215   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.500396 (* 2 = 1.00079 loss)
I1130 23:53:28.473374   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.75135 (* 1 = 8.75135 loss)
I1130 23:53:28.473387   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.5805
I1130 23:53:28.473394   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.2048
I1130 23:53:28.473400   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 50.4627
I1130 23:53:28.473433   125 solver.cpp:271] Tests completed in 21.0642s
I1130 23:53:29.820080   125 solver.cpp:333]     [0.0] Iteration 26576 (2.08885 iter/s, 21.0642s/44 iter), 74/100ep, loss = 3.71641
I1130 23:53:29.820123   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.647794 (* 2 = 1.29559 loss)
I1130 23:53:29.820134   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.4208 (* 1 = 2.4208 loss)
I1130 23:53:29.820147   125 sgd_solver.cpp:180] [0.0] Iteration 26576, lr = 2.62393e-06, m = 0.9, lrm = 2.62393e-05, wd = 2.5e-07, gs = 1
I1130 23:53:35.181038   125 solver.cpp:333]     [0.0] Iteration 26620 (8.20745 iter/s, 5.36098s/44 iter), 74.2/100ep, loss = 4.63943
I1130 23:53:35.181082   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.861782 (* 2 = 1.72356 loss)
I1130 23:53:35.181092   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.91584 (* 1 = 2.91584 loss)
I1130 23:53:35.181104   125 sgd_solver.cpp:180] [0.0] Iteration 26620, lr = 2.61415e-06, m = 0.9, lrm = 2.61415e-05, wd = 2.5e-07, gs = 1
I1130 23:53:40.538174   125 solver.cpp:333]     [0.0] Iteration 26664 (8.21331 iter/s, 5.35716s/44 iter), 74.3/100ep, loss = 6.23147
I1130 23:53:40.538216   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.411456 (* 2 = 0.822912 loss)
I1130 23:53:40.538226   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.40853 (* 1 = 5.40853 loss)
I1130 23:53:40.538239   125 sgd_solver.cpp:180] [0.0] Iteration 26664, lr = 2.60442e-06, m = 0.9, lrm = 2.60442e-05, wd = 2.5e-07, gs = 1
I1130 23:53:45.891046   125 solver.cpp:333]     [0.0] Iteration 26708 (8.21988 iter/s, 5.35288s/44 iter), 74.4/100ep, loss = 8.08121
I1130 23:53:45.891085   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.06376 (* 2 = 2.12752 loss)
I1130 23:53:45.891095   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.95366 (* 1 = 5.95366 loss)
I1130 23:53:45.891106   125 sgd_solver.cpp:180] [0.0] Iteration 26708, lr = 2.59471e-06, m = 0.9, lrm = 2.59471e-05, wd = 2.5e-07, gs = 1
I1130 23:53:51.250037   125 solver.cpp:333]     [0.0] Iteration 26752 (8.21047 iter/s, 5.35901s/44 iter), 74.5/100ep, loss = 8.51378
I1130 23:53:51.250080   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.306624 (* 2 = 0.613247 loss)
I1130 23:53:51.250092   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.90051 (* 1 = 7.90051 loss)
I1130 23:53:51.250102   125 sgd_solver.cpp:180] [0.0] Iteration 26752, lr = 2.58505e-06, m = 0.9, lrm = 2.58505e-05, wd = 2.5e-07, gs = 1
I1130 23:53:56.612329   125 solver.cpp:333]     [0.0] Iteration 26796 (8.20542 iter/s, 5.36231s/44 iter), 74.6/100ep, loss = 7.67751
I1130 23:53:56.612367   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.541757 (* 2 = 1.08351 loss)
I1130 23:53:56.612378   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.59397 (* 1 = 6.59397 loss)
I1130 23:53:56.612390   125 sgd_solver.cpp:180] [0.0] Iteration 26796, lr = 2.57542e-06, m = 0.9, lrm = 2.57542e-05, wd = 2.5e-07, gs = 1
I1130 23:54:01.973963   125 solver.cpp:333]     [0.0] Iteration 26840 (8.20646 iter/s, 5.36163s/44 iter), 74.8/100ep, loss = 10.8202
I1130 23:54:01.974138   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.604273 (* 2 = 1.20855 loss)
I1130 23:54:01.974153   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.61165 (* 1 = 9.61165 loss)
I1130 23:54:01.974165   125 sgd_solver.cpp:180] [0.0] Iteration 26840, lr = 2.56582e-06, m = 0.9, lrm = 2.56582e-05, wd = 2.5e-07, gs = 1
I1130 23:54:07.336462   125 solver.cpp:333]     [0.0] Iteration 26884 (8.20508 iter/s, 5.36253s/44 iter), 74.9/100ep, loss = 4.76173
I1130 23:54:07.336503   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.267368 (* 2 = 0.534737 loss)
I1130 23:54:07.336513   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.22698 (* 1 = 4.22698 loss)
I1130 23:54:07.336525   125 sgd_solver.cpp:180] [0.0] Iteration 26884, lr = 2.55627e-06, m = 0.9, lrm = 2.55627e-05, wd = 2.5e-07, gs = 1
I1130 23:54:08.681846   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:54:08.800184   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:54:12.209677   125 solver.cpp:501] Iteration 26925, Testing net (#0)
I1130 23:54:25.988565   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:54:26.102205   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:54:29.375056   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.499453 (* 2 = 0.998907 loss)
I1130 23:54:29.375097   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.80201 (* 1 = 8.80201 loss)
I1130 23:54:29.375104   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.3344
I1130 23:54:29.375113   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.6271
I1130 23:54:29.375120   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 48.7328
I1130 23:54:29.375152   125 solver.cpp:271] Tests completed in 22.0388s
I1130 23:54:29.876708   125 solver.cpp:333]     [0.0] Iteration 26928 (1.99648 iter/s, 22.0388s/44 iter), 75/100ep, loss = 5.66798
I1130 23:54:29.876752   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.2864 (* 2 = 0.572801 loss)
I1130 23:54:29.876762   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.09515 (* 1 = 5.09515 loss)
I1130 23:54:29.876773   125 sgd_solver.cpp:180] [0.0] Iteration 26928, lr = 2.54674e-06, m = 0.9, lrm = 2.54674e-05, wd = 2.5e-07, gs = 1
I1130 23:54:35.245393   125 solver.cpp:333]     [0.0] Iteration 26972 (8.19565 iter/s, 5.3687s/44 iter), 75.1/100ep, loss = 6.69637
I1130 23:54:35.245571   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.717114 (* 2 = 1.43423 loss)
I1130 23:54:35.245586   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.26212 (* 1 = 5.26212 loss)
I1130 23:54:35.245599   125 sgd_solver.cpp:180] [0.0] Iteration 26972, lr = 2.53726e-06, m = 0.9, lrm = 2.53726e-05, wd = 2.5e-07, gs = 1
I1130 23:54:40.602813   125 solver.cpp:333]     [0.0] Iteration 27016 (8.21287 iter/s, 5.35744s/44 iter), 75.3/100ep, loss = 6.00415
I1130 23:54:40.602856   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.611797 (* 2 = 1.22359 loss)
I1130 23:54:40.602867   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.78053 (* 1 = 4.78053 loss)
I1130 23:54:40.602880   125 sgd_solver.cpp:180] [0.0] Iteration 27016, lr = 2.52781e-06, m = 0.9, lrm = 2.5278e-05, wd = 2.5e-07, gs = 1
I1130 23:54:45.959753   125 solver.cpp:333]     [0.0] Iteration 27060 (8.21365 iter/s, 5.35694s/44 iter), 75.4/100ep, loss = 10.2528
I1130 23:54:45.959794   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.74625 (* 2 = 3.49251 loss)
I1130 23:54:45.959805   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.76022 (* 1 = 6.76022 loss)
I1130 23:54:45.959816   125 sgd_solver.cpp:180] [0.0] Iteration 27060, lr = 2.51839e-06, m = 0.9, lrm = 2.51839e-05, wd = 2.5e-07, gs = 1
I1130 23:54:51.323215   125 solver.cpp:333]     [0.0] Iteration 27104 (8.20362 iter/s, 5.36348s/44 iter), 75.5/100ep, loss = 5.45547
I1130 23:54:51.323257   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.575079 (* 2 = 1.15016 loss)
I1130 23:54:51.323268   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.30529 (* 1 = 4.30529 loss)
I1130 23:54:51.323280   125 sgd_solver.cpp:180] [0.0] Iteration 27104, lr = 2.50901e-06, m = 0.9, lrm = 2.50901e-05, wd = 2.5e-07, gs = 1
I1130 23:54:56.686041   125 solver.cpp:333]     [0.0] Iteration 27148 (8.20459 iter/s, 5.36285s/44 iter), 75.6/100ep, loss = 5.0325
I1130 23:54:56.686082   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.361795 (* 2 = 0.72359 loss)
I1130 23:54:56.686094   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.30889 (* 1 = 4.30889 loss)
I1130 23:54:56.686103   125 sgd_solver.cpp:180] [0.0] Iteration 27148, lr = 2.49966e-06, m = 0.9, lrm = 2.49966e-05, wd = 2.5e-07, gs = 1
I1130 23:55:02.050223   125 solver.cpp:333]     [0.0] Iteration 27192 (8.20256 iter/s, 5.36418s/44 iter), 75.7/100ep, loss = 3.02458
I1130 23:55:02.050272   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.36676 (* 2 = 0.733519 loss)
I1130 23:55:02.050283   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.29103 (* 1 = 2.29103 loss)
I1130 23:55:02.050295   125 sgd_solver.cpp:180] [0.0] Iteration 27192, lr = 2.49035e-06, m = 0.9, lrm = 2.49035e-05, wd = 2.5e-07, gs = 1
I1130 23:55:07.416091   125 solver.cpp:333]     [0.0] Iteration 27236 (8.19994 iter/s, 5.36589s/44 iter), 75.9/100ep, loss = 10.3769
I1130 23:55:07.416276   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.39251 (* 2 = 2.78501 loss)
I1130 23:55:07.416290   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.59189 (* 1 = 7.59189 loss)
I1130 23:55:07.416301   125 sgd_solver.cpp:180] [0.0] Iteration 27236, lr = 2.48107e-06, m = 0.9, lrm = 2.48107e-05, wd = 2.5e-07, gs = 1
I1130 23:55:09.734319   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:55:09.851361   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:55:12.785370   125 solver.cpp:333]     [0.0] Iteration 27280 (8.19476 iter/s, 5.36928s/44 iter), 76/100ep, loss = 4.44635
I1130 23:55:12.785409   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.449626 (* 2 = 0.899253 loss)
I1130 23:55:12.785419   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.54707 (* 1 = 3.54707 loss)
I1130 23:55:12.785431   125 sgd_solver.cpp:180] [0.0] Iteration 27280, lr = 2.47183e-06, m = 0.9, lrm = 2.47183e-05, wd = 2.5e-07, gs = 1
I1130 23:55:13.151254   125 solver.cpp:501] Iteration 27284, Testing net (#0)
I1130 23:55:26.854945   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:55:27.009682   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:55:30.322309   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.49871 (* 2 = 0.99742 loss)
I1130 23:55:30.322350   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.75094 (* 1 = 8.75094 loss)
I1130 23:55:30.322357   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.6798
I1130 23:55:30.322365   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.6431
I1130 23:55:30.322372   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 52.1859
I1130 23:55:30.322408   125 solver.cpp:271] Tests completed in 17.5372s
I1130 23:55:35.330761   125 solver.cpp:333]     [0.0] Iteration 27324 (2.50896 iter/s, 17.5372s/44 iter), 76.1/100ep, loss = 5.86177
I1130 23:55:35.330803   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.09208 (* 2 = 2.18416 loss)
I1130 23:55:35.330814   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.67759 (* 1 = 3.67759 loss)
I1130 23:55:35.330826   125 sgd_solver.cpp:180] [0.0] Iteration 27324, lr = 2.46262e-06, m = 0.9, lrm = 2.46262e-05, wd = 2.5e-07, gs = 1
I1130 23:55:40.701962   125 solver.cpp:333]     [0.0] Iteration 27368 (8.19184 iter/s, 5.3712s/44 iter), 76.2/100ep, loss = 13.2945
I1130 23:55:40.702131   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.29695 (* 2 = 2.5939 loss)
I1130 23:55:40.702145   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.7005 (* 1 = 10.7005 loss)
I1130 23:55:40.702157   125 sgd_solver.cpp:180] [0.0] Iteration 27368, lr = 2.45345e-06, m = 0.9, lrm = 2.45345e-05, wd = 2.5e-07, gs = 1
I1130 23:55:46.069947   125 solver.cpp:333]     [0.0] Iteration 27412 (8.1967 iter/s, 5.36801s/44 iter), 76.4/100ep, loss = 0.616569
I1130 23:55:46.069993   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.0968705 (* 2 = 0.193741 loss)
I1130 23:55:46.070003   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 0.422807 (* 1 = 0.422807 loss)
I1130 23:55:46.070015   125 sgd_solver.cpp:180] [0.0] Iteration 27412, lr = 2.44431e-06, m = 0.9, lrm = 2.44431e-05, wd = 2.5e-07, gs = 1
I1130 23:55:51.436537   125 solver.cpp:333]     [0.0] Iteration 27456 (8.19886 iter/s, 5.3666s/44 iter), 76.5/100ep, loss = 7.23491
I1130 23:55:51.436579   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.97391 (* 2 = 1.94782 loss)
I1130 23:55:51.436590   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.28707 (* 1 = 5.28707 loss)
I1130 23:55:51.436602   125 sgd_solver.cpp:180] [0.0] Iteration 27456, lr = 2.4352e-06, m = 0.9, lrm = 2.4352e-05, wd = 2.5e-07, gs = 1
I1130 23:55:56.804435   125 solver.cpp:333]     [0.0] Iteration 27500 (8.19686 iter/s, 5.36791s/44 iter), 76.6/100ep, loss = 7.62685
I1130 23:55:56.804474   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.429183 (* 2 = 0.858366 loss)
I1130 23:55:56.804486   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.76846 (* 1 = 6.76846 loss)
I1130 23:55:56.804497   125 sgd_solver.cpp:180] [0.0] Iteration 27500, lr = 2.42613e-06, m = 0.9, lrm = 2.42613e-05, wd = 2.5e-07, gs = 1
I1130 23:56:02.173503   125 solver.cpp:333]     [0.0] Iteration 27544 (8.19506 iter/s, 5.36909s/44 iter), 76.7/100ep, loss = 14.9216
I1130 23:56:02.173542   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.832462 (* 2 = 1.66492 loss)
I1130 23:56:02.173554   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 13.2567 (* 1 = 13.2567 loss)
I1130 23:56:02.173565   125 sgd_solver.cpp:180] [0.0] Iteration 27544, lr = 2.41709e-06, m = 0.9, lrm = 2.41709e-05, wd = 2.5e-07, gs = 1
I1130 23:56:07.535909   125 solver.cpp:333]     [0.0] Iteration 27588 (8.20525 iter/s, 5.36242s/44 iter), 76.8/100ep, loss = 5.51017
I1130 23:56:07.535949   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.07893 (* 2 = 2.15787 loss)
I1130 23:56:07.535960   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.35228 (* 1 = 3.35228 loss)
I1130 23:56:07.535971   125 sgd_solver.cpp:180] [0.0] Iteration 27588, lr = 2.40809e-06, m = 0.9, lrm = 2.40809e-05, wd = 2.5e-07, gs = 1
I1130 23:56:10.831766   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:56:10.951337   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:56:12.900990   125 solver.cpp:333]     [0.0] Iteration 27632 (8.20117 iter/s, 5.36509s/44 iter), 77/100ep, loss = 6.34509
I1130 23:56:12.901032   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.631127 (* 2 = 1.26225 loss)
I1130 23:56:12.901043   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.08281 (* 1 = 5.08281 loss)
I1130 23:56:12.901055   125 sgd_solver.cpp:180] [0.0] Iteration 27632, lr = 2.39912e-06, m = 0.9, lrm = 2.39912e-05, wd = 2.5e-07, gs = 1
I1130 23:56:14.123919   125 solver.cpp:501] Iteration 27643, Testing net (#0)
I1130 23:56:27.759979   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:56:27.873003   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:56:31.193377   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.501678 (* 2 = 1.00336 loss)
I1130 23:56:31.193416   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.79168 (* 1 = 8.79168 loss)
I1130 23:56:31.193425   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.1237
I1130 23:56:31.193433   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.2707
I1130 23:56:31.193439   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 50.5239
I1130 23:56:31.193476   125 solver.cpp:271] Tests completed in 18.2926s
I1130 23:56:35.337888   125 solver.cpp:333]     [0.0] Iteration 27676 (2.40534 iter/s, 18.2926s/44 iter), 77.1/100ep, loss = 5.94834
I1130 23:56:35.337929   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.482675 (* 2 = 0.965349 loss)
I1130 23:56:35.337940   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.98297 (* 1 = 4.98297 loss)
I1130 23:56:35.337954   125 sgd_solver.cpp:180] [0.0] Iteration 27676, lr = 2.39018e-06, m = 0.9, lrm = 2.39018e-05, wd = 2.5e-07, gs = 1
I1130 23:56:40.694543   125 solver.cpp:333]     [0.0] Iteration 27720 (8.21399 iter/s, 5.35672s/44 iter), 77.2/100ep, loss = 17.3148
I1130 23:56:40.694583   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.52627 (* 2 = 3.05254 loss)
I1130 23:56:40.694593   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 14.2622 (* 1 = 14.2622 loss)
I1130 23:56:40.694605   125 sgd_solver.cpp:180] [0.0] Iteration 27720, lr = 2.38128e-06, m = 0.9, lrm = 2.38128e-05, wd = 2.5e-07, gs = 1
I1130 23:56:46.049757   125 solver.cpp:333]     [0.0] Iteration 27764 (8.21623 iter/s, 5.35525s/44 iter), 77.3/100ep, loss = 5.32572
I1130 23:56:46.049969   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.635559 (* 2 = 1.27112 loss)
I1130 23:56:46.049983   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.05458 (* 1 = 4.05458 loss)
I1130 23:56:46.049995   125 sgd_solver.cpp:180] [0.0] Iteration 27764, lr = 2.37241e-06, m = 0.9, lrm = 2.37241e-05, wd = 2.5e-07, gs = 1
I1130 23:56:51.411679   125 solver.cpp:333]     [0.0] Iteration 27808 (8.20594 iter/s, 5.36197s/44 iter), 77.5/100ep, loss = 11.2562
I1130 23:56:51.411722   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.659401 (* 2 = 1.3188 loss)
I1130 23:56:51.411733   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.93738 (* 1 = 9.93738 loss)
I1130 23:56:51.411746   125 sgd_solver.cpp:180] [0.0] Iteration 27808, lr = 2.36357e-06, m = 0.9, lrm = 2.36357e-05, wd = 2.5e-07, gs = 1
I1130 23:56:56.758769   125 solver.cpp:333]     [0.0] Iteration 27852 (8.22871 iter/s, 5.34713s/44 iter), 77.6/100ep, loss = 8.57289
I1130 23:56:56.758811   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.661805 (* 2 = 1.32361 loss)
I1130 23:56:56.758822   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.24926 (* 1 = 7.24926 loss)
I1130 23:56:56.758836   125 sgd_solver.cpp:180] [0.0] Iteration 27852, lr = 2.35477e-06, m = 0.9, lrm = 2.35476e-05, wd = 2.5e-07, gs = 1
I1130 23:57:02.097784   125 solver.cpp:333]     [0.0] Iteration 27896 (8.24114 iter/s, 5.33907s/44 iter), 77.7/100ep, loss = 6.51322
I1130 23:57:02.097824   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.844351 (* 2 = 1.6887 loss)
I1130 23:57:02.097836   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.82449 (* 1 = 4.82449 loss)
I1130 23:57:02.097848   125 sgd_solver.cpp:180] [0.0] Iteration 27896, lr = 2.34599e-06, m = 0.9, lrm = 2.34599e-05, wd = 2.5e-07, gs = 1
I1130 23:57:07.442669   125 solver.cpp:333]     [0.0] Iteration 27940 (8.23208 iter/s, 5.34494s/44 iter), 77.8/100ep, loss = 3.1152
I1130 23:57:07.442711   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.30124 (* 2 = 0.602479 loss)
I1130 23:57:07.442723   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.51269 (* 1 = 2.51269 loss)
I1130 23:57:07.442734   125 sgd_solver.cpp:180] [0.0] Iteration 27940, lr = 2.33725e-06, m = 0.9, lrm = 2.33725e-05, wd = 2.5e-07, gs = 1
I1130 23:57:11.332000   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:57:11.456571   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:57:12.782050   125 solver.cpp:333]     [0.0] Iteration 27984 (8.24059 iter/s, 5.33942s/44 iter), 77.9/100ep, loss = 3.38305
I1130 23:57:12.782089   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.548493 (* 2 = 1.09699 loss)
I1130 23:57:12.782100   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.28604 (* 1 = 2.28604 loss)
I1130 23:57:12.782110   125 sgd_solver.cpp:180] [0.0] Iteration 27984, lr = 2.32855e-06, m = 0.9, lrm = 2.32855e-05, wd = 2.5e-07, gs = 1
I1130 23:57:14.846576   125 solver.cpp:501] Iteration 28002, Testing net (#0)
I1130 23:57:28.462674   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:57:28.613626   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:57:32.022027   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.497636 (* 2 = 0.995272 loss)
I1130 23:57:32.022066   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.76333 (* 1 = 8.76333 loss)
I1130 23:57:32.022075   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.2886
I1130 23:57:32.022083   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.867
I1130 23:57:32.022089   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.0715
I1130 23:57:32.022122   125 solver.cpp:271] Tests completed in 19.2403s
I1130 23:57:35.369266   125 solver.cpp:333]     [0.0] Iteration 28028 (2.28686 iter/s, 19.2403s/44 iter), 78.1/100ep, loss = 8.5709
I1130 23:57:35.369305   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.795591 (* 2 = 1.59118 loss)
I1130 23:57:35.369316   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.97969 (* 1 = 6.97969 loss)
I1130 23:57:35.369328   125 sgd_solver.cpp:180] [0.0] Iteration 28028, lr = 2.31987e-06, m = 0.9, lrm = 2.31987e-05, wd = 2.5e-07, gs = 1
I1130 23:57:40.805280   125 solver.cpp:333]     [0.0] Iteration 28072 (8.09414 iter/s, 5.43603s/44 iter), 78.2/100ep, loss = 6.35943
I1130 23:57:40.805336   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.453752 (* 2 = 0.907505 loss)
I1130 23:57:40.805352   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.4519 (* 1 = 5.4519 loss)
I1130 23:57:40.805368   125 sgd_solver.cpp:180] [0.0] Iteration 28072, lr = 2.31123e-06, m = 0.9, lrm = 2.31123e-05, wd = 2.5e-07, gs = 1
I1130 23:57:46.195230   125 solver.cpp:333]     [0.0] Iteration 28116 (8.16324 iter/s, 5.39002s/44 iter), 78.3/100ep, loss = 8.64655
I1130 23:57:46.195271   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.573213 (* 2 = 1.14643 loss)
I1130 23:57:46.195282   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.50009 (* 1 = 7.50009 loss)
I1130 23:57:46.195294   125 sgd_solver.cpp:180] [0.0] Iteration 28116, lr = 2.30262e-06, m = 0.9, lrm = 2.30262e-05, wd = 2.5e-07, gs = 1
I1130 23:57:51.578969   125 solver.cpp:333]     [0.0] Iteration 28160 (8.17268 iter/s, 5.38379s/44 iter), 78.4/100ep, loss = 4.7029
I1130 23:57:51.579010   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.493401 (* 2 = 0.986802 loss)
I1130 23:57:51.579020   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.71607 (* 1 = 3.71607 loss)
I1130 23:57:51.579030   125 sgd_solver.cpp:180] [0.0] Iteration 28160, lr = 2.29404e-06, m = 0.9, lrm = 2.29404e-05, wd = 2.5e-07, gs = 1
I1130 23:57:56.924087   125 solver.cpp:333]     [0.0] Iteration 28204 (8.23176 iter/s, 5.34515s/44 iter), 78.6/100ep, loss = 7.32133
I1130 23:57:56.924129   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.628875 (* 2 = 1.25775 loss)
I1130 23:57:56.924139   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.06355 (* 1 = 6.06355 loss)
I1130 23:57:56.924151   125 sgd_solver.cpp:180] [0.0] Iteration 28204, lr = 2.2855e-06, m = 0.9, lrm = 2.2855e-05, wd = 2.5e-07, gs = 1
I1130 23:58:02.264771   125 solver.cpp:333]     [0.0] Iteration 28248 (8.23858 iter/s, 5.34072s/44 iter), 78.7/100ep, loss = 5.06102
I1130 23:58:02.264936   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.355105 (* 2 = 0.71021 loss)
I1130 23:58:02.264950   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.35078 (* 1 = 4.35078 loss)
I1130 23:58:02.264961   125 sgd_solver.cpp:180] [0.0] Iteration 28248, lr = 2.27698e-06, m = 0.9, lrm = 2.27698e-05, wd = 2.5e-07, gs = 1
I1130 23:58:07.609395   125 solver.cpp:333]     [0.0] Iteration 28292 (8.23247 iter/s, 5.34469s/44 iter), 78.8/100ep, loss = 8.41731
I1130 23:58:07.609431   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.624445 (* 2 = 1.24889 loss)
I1130 23:58:07.609442   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.16839 (* 1 = 7.16839 loss)
I1130 23:58:07.609452   125 sgd_solver.cpp:180] [0.0] Iteration 28292, lr = 2.2685e-06, m = 0.9, lrm = 2.2685e-05, wd = 2.5e-07, gs = 1
I1130 23:58:12.473773   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:58:12.585927   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:58:12.954767   125 solver.cpp:333]     [0.0] Iteration 28336 (8.23138 iter/s, 5.3454s/44 iter), 78.9/100ep, loss = 8.23243
I1130 23:58:12.954805   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.554399 (* 2 = 1.1088 loss)
I1130 23:58:12.954818   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.12361 (* 1 = 7.12361 loss)
I1130 23:58:12.954829   125 sgd_solver.cpp:180] [0.0] Iteration 28336, lr = 2.26005e-06, m = 0.9, lrm = 2.26005e-05, wd = 2.5e-07, gs = 1
I1130 23:58:15.870743   125 solver.cpp:501] Iteration 28361, Testing net (#0)
I1130 23:58:29.541309   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:58:29.655171   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:58:33.102859   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.496854 (* 2 = 0.993709 loss)
I1130 23:58:33.103056   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.80273 (* 1 = 8.80273 loss)
I1130 23:58:33.103067   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.4694
I1130 23:58:33.103076   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.6154
I1130 23:58:33.103083   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.0358
I1130 23:58:33.103118   125 solver.cpp:271] Tests completed in 20.1486s
I1130 23:58:35.536392   125 solver.cpp:333]     [0.0] Iteration 28380 (2.18377 iter/s, 20.1486s/44 iter), 79.1/100ep, loss = 2.25463
I1130 23:58:35.536433   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.247226 (* 2 = 0.494451 loss)
I1130 23:58:35.536444   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.76015 (* 1 = 1.76015 loss)
I1130 23:58:35.536455   125 sgd_solver.cpp:180] [0.0] Iteration 28380, lr = 2.25163e-06, m = 0.9, lrm = 2.25163e-05, wd = 2.5e-07, gs = 1
I1130 23:58:40.891083   125 solver.cpp:333]     [0.0] Iteration 28424 (8.21705 iter/s, 5.35472s/44 iter), 79.2/100ep, loss = 9.45767
I1130 23:58:40.891121   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.595814 (* 2 = 1.19163 loss)
I1130 23:58:40.891132   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.26601 (* 1 = 8.26601 loss)
I1130 23:58:40.891144   125 sgd_solver.cpp:180] [0.0] Iteration 28424, lr = 2.24325e-06, m = 0.9, lrm = 2.24324e-05, wd = 2.5e-07, gs = 1
I1130 23:58:46.234335   125 solver.cpp:333]     [0.0] Iteration 28468 (8.23461 iter/s, 5.3433s/44 iter), 79.3/100ep, loss = 6.78551
I1130 23:58:46.234377   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.394958 (* 2 = 0.789917 loss)
I1130 23:58:46.234387   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.99557 (* 1 = 5.99557 loss)
I1130 23:58:46.234398   125 sgd_solver.cpp:180] [0.0] Iteration 28468, lr = 2.23489e-06, m = 0.9, lrm = 2.23489e-05, wd = 2.5e-07, gs = 1
I1130 23:58:51.578887   125 solver.cpp:333]     [0.0] Iteration 28512 (8.23262 iter/s, 5.34459s/44 iter), 79.4/100ep, loss = 11.8492
I1130 23:58:51.578928   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.09839 (* 2 = 2.19679 loss)
I1130 23:58:51.578938   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.65241 (* 1 = 9.65241 loss)
I1130 23:58:51.578949   125 sgd_solver.cpp:180] [0.0] Iteration 28512, lr = 2.22656e-06, m = 0.9, lrm = 2.22656e-05, wd = 2.5e-07, gs = 1
I1130 23:58:56.926751   125 solver.cpp:333]     [0.0] Iteration 28556 (8.22752 iter/s, 5.3479s/44 iter), 79.5/100ep, loss = 7.6184
I1130 23:58:56.926795   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.31682 (* 2 = 2.63363 loss)
I1130 23:58:56.926805   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.98474 (* 1 = 4.98474 loss)
I1130 23:58:56.926815   125 sgd_solver.cpp:180] [0.0] Iteration 28556, lr = 2.21827e-06, m = 0.9, lrm = 2.21827e-05, wd = 2.5e-07, gs = 1
I1130 23:59:02.276863   125 solver.cpp:333]     [0.0] Iteration 28600 (8.22406 iter/s, 5.35016s/44 iter), 79.7/100ep, loss = 3.45165
I1130 23:59:02.276906   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.531843 (* 2 = 1.06369 loss)
I1130 23:59:02.276916   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.38793 (* 1 = 2.38793 loss)
I1130 23:59:02.276926   125 sgd_solver.cpp:180] [0.0] Iteration 28600, lr = 2.21001e-06, m = 0.9, lrm = 2.21001e-05, wd = 2.5e-07, gs = 1
I1130 23:59:07.625572   125 solver.cpp:333]     [0.0] Iteration 28644 (8.22621 iter/s, 5.34876s/44 iter), 79.8/100ep, loss = 2.91434
I1130 23:59:07.625746   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.255338 (* 2 = 0.510675 loss)
I1130 23:59:07.625758   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.40363 (* 1 = 2.40363 loss)
I1130 23:59:07.625769   125 sgd_solver.cpp:180] [0.0] Iteration 28644, lr = 2.20177e-06, m = 0.9, lrm = 2.20177e-05, wd = 2.5e-07, gs = 1
I1130 23:59:12.975554   125 solver.cpp:333]     [0.0] Iteration 28688 (8.22428 iter/s, 5.35001s/44 iter), 79.9/100ep, loss = 5.75649
I1130 23:59:12.975595   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.409721 (* 2 = 0.819442 loss)
I1130 23:59:12.975605   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.93702 (* 1 = 4.93702 loss)
I1130 23:59:12.975617   125 sgd_solver.cpp:180] [0.0] Iteration 28688, lr = 2.19357e-06, m = 0.9, lrm = 2.19357e-05, wd = 2.5e-07, gs = 1
I1130 23:59:13.462275   167 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:59:13.582983   169 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:59:16.740212   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_28720.caffemodel
I1130 23:59:16.787781   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_28720.solverstate
I1130 23:59:16.828141   125 solver.cpp:501] Iteration 28720, Testing net (#0)
I1130 23:59:30.354930   152 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:59:30.511046   149 data_reader.cpp:321] Restarting data pre-fetching
I1130 23:59:33.975261   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.496165 (* 2 = 0.992329 loss)
I1130 23:59:33.975301   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.77763 (* 1 = 8.77763 loss)
I1130 23:59:33.975311   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.6596
I1130 23:59:33.975317   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 29.2951
I1130 23:59:33.975324   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 52.2286
I1130 23:59:33.975356   125 solver.cpp:271] Tests completed in 21.0001s
I1130 23:59:35.555660   125 solver.cpp:333]     [0.0] Iteration 28732 (2.09523 iter/s, 21.0001s/44 iter), 80/100ep, loss = 1.69609
I1130 23:59:35.555702   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.0897225 (* 2 = 0.179445 loss)
I1130 23:59:35.555712   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.51662 (* 1 = 1.51662 loss)
I1130 23:59:35.555723   125 sgd_solver.cpp:180] [0.0] Iteration 28732, lr = 2.1854e-06, m = 0.9, lrm = 2.1854e-05, wd = 2.5e-07, gs = 1
I1130 23:59:40.893652   125 solver.cpp:333]     [0.0] Iteration 28776 (8.24276 iter/s, 5.33802s/44 iter), 80.2/100ep, loss = 9.33558
I1130 23:59:40.893775   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.04104 (* 2 = 2.08209 loss)
I1130 23:59:40.893786   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.25346 (* 1 = 7.25346 loss)
I1130 23:59:40.893797   125 sgd_solver.cpp:180] [0.0] Iteration 28776, lr = 2.17726e-06, m = 0.9, lrm = 2.17726e-05, wd = 2.5e-07, gs = 1
I1130 23:59:46.233222   125 solver.cpp:333]     [0.0] Iteration 28820 (8.24028 iter/s, 5.33962s/44 iter), 80.3/100ep, loss = 8.51741
I1130 23:59:46.233263   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.16135 (* 2 = 2.32271 loss)
I1130 23:59:46.233273   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.19468 (* 1 = 6.19468 loss)
I1130 23:59:46.233284   125 sgd_solver.cpp:180] [0.0] Iteration 28820, lr = 2.16915e-06, m = 0.9, lrm = 2.16915e-05, wd = 2.5e-07, gs = 1
I1130 23:59:51.575181   125 solver.cpp:333]     [0.0] Iteration 28864 (8.23661 iter/s, 5.342s/44 iter), 80.4/100ep, loss = 4.72823
I1130 23:59:51.575219   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.333004 (* 2 = 0.666007 loss)
I1130 23:59:51.575229   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.0622 (* 1 = 4.0622 loss)
I1130 23:59:51.575240   125 sgd_solver.cpp:180] [0.0] Iteration 28864, lr = 2.16107e-06, m = 0.9, lrm = 2.16107e-05, wd = 2.5e-07, gs = 1
I1130 23:59:56.919097   125 solver.cpp:333]     [0.0] Iteration 28908 (8.23362 iter/s, 5.34394s/44 iter), 80.5/100ep, loss = 6.37289
I1130 23:59:56.919137   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.352822 (* 2 = 0.705644 loss)
I1130 23:59:56.919148   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.66722 (* 1 = 5.66722 loss)
I1130 23:59:56.919159   125 sgd_solver.cpp:180] [0.0] Iteration 28908, lr = 2.15302e-06, m = 0.9, lrm = 2.15302e-05, wd = 2.5e-07, gs = 1
I1201 00:00:02.266522   125 solver.cpp:333]     [0.0] Iteration 28952 (8.22819 iter/s, 5.34747s/44 iter), 80.6/100ep, loss = 7.00631
I1201 00:00:02.266564   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.599009 (* 2 = 1.19802 loss)
I1201 00:00:02.266575   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.80827 (* 1 = 5.80827 loss)
I1201 00:00:02.266587   125 sgd_solver.cpp:180] [0.0] Iteration 28952, lr = 2.145e-06, m = 0.9, lrm = 2.145e-05, wd = 2.5e-07, gs = 1
I1201 00:00:07.609383   125 solver.cpp:333]     [0.0] Iteration 28996 (8.23521 iter/s, 5.34291s/44 iter), 80.8/100ep, loss = 3.08257
I1201 00:00:07.609422   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.303736 (* 2 = 0.607472 loss)
I1201 00:00:07.609436   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.47507 (* 1 = 2.47507 loss)
I1201 00:00:07.609447   125 sgd_solver.cpp:180] [0.0] Iteration 28996, lr = 2.13701e-06, m = 0.9, lrm = 2.13701e-05, wd = 2.5e-07, gs = 1
I1201 00:00:12.956079   125 solver.cpp:333]     [0.0] Iteration 29040 (8.22934 iter/s, 5.34672s/44 iter), 80.9/100ep, loss = 6.46243
I1201 00:00:12.956241   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.557734 (* 2 = 1.11547 loss)
I1201 00:00:12.956254   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.34693 (* 1 = 5.34693 loss)
I1201 00:00:12.956266   125 sgd_solver.cpp:180] [0.0] Iteration 29040, lr = 2.12905e-06, m = 0.9, lrm = 2.12904e-05, wd = 2.5e-07, gs = 1
I1201 00:00:14.050711   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:00:14.174911   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:00:17.576539   125 solver.cpp:501] Iteration 29079, Testing net (#0)
I1201 00:00:31.208554   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:00:31.320747   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:00:34.832754   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.496194 (* 2 = 0.992389 loss)
I1201 00:00:34.832794   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.75349 (* 1 = 8.75349 loss)
I1201 00:00:34.832803   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.2315
I1201 00:00:34.832811   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.1818
I1201 00:00:34.832818   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.8965
I1201 00:00:34.832854   125 solver.cpp:271] Tests completed in 21.877s
I1201 00:00:35.562826   125 solver.cpp:333]     [0.0] Iteration 29084 (2.01124 iter/s, 21.877s/44 iter), 81/100ep, loss = 6.68496
I1201 00:00:35.562867   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.402212 (* 2 = 0.804424 loss)
I1201 00:00:35.562878   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.88051 (* 1 = 5.88051 loss)
I1201 00:00:35.562889   125 sgd_solver.cpp:180] [0.0] Iteration 29084, lr = 2.12111e-06, m = 0.9, lrm = 2.12111e-05, wd = 2.5e-07, gs = 1
I1201 00:00:40.906852   125 solver.cpp:333]     [0.0] Iteration 29128 (8.23346 iter/s, 5.34405s/44 iter), 81.1/100ep, loss = 7.9432
I1201 00:00:40.906894   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.433889 (* 2 = 0.867778 loss)
I1201 00:00:40.906904   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.0754 (* 1 = 7.0754 loss)
I1201 00:00:40.906916   125 sgd_solver.cpp:180] [0.0] Iteration 29128, lr = 2.11321e-06, m = 0.9, lrm = 2.11321e-05, wd = 2.5e-07, gs = 1
I1201 00:00:46.254247   125 solver.cpp:333]     [0.0] Iteration 29172 (8.22823 iter/s, 5.34745s/44 iter), 81.3/100ep, loss = 6.55888
I1201 00:00:46.254393   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.527835 (* 2 = 1.05567 loss)
I1201 00:00:46.254406   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.50319 (* 1 = 5.50319 loss)
I1201 00:00:46.254418   125 sgd_solver.cpp:180] [0.0] Iteration 29172, lr = 2.10534e-06, m = 0.9, lrm = 2.10534e-05, wd = 2.5e-07, gs = 1
I1201 00:00:51.592825   125 solver.cpp:333]     [0.0] Iteration 29216 (8.24183 iter/s, 5.33862s/44 iter), 81.4/100ep, loss = 5.93324
I1201 00:00:51.592866   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.300235 (* 2 = 0.60047 loss)
I1201 00:00:51.592876   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.33275 (* 1 = 5.33275 loss)
I1201 00:00:51.592887   125 sgd_solver.cpp:180] [0.0] Iteration 29216, lr = 2.0975e-06, m = 0.9, lrm = 2.0975e-05, wd = 2.5e-07, gs = 1
I1201 00:00:56.935376   125 solver.cpp:333]     [0.0] Iteration 29260 (8.23573 iter/s, 5.34257s/44 iter), 81.5/100ep, loss = 10.6181
I1201 00:00:56.935418   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.8366 (* 2 = 1.6732 loss)
I1201 00:00:56.935429   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.94483 (* 1 = 8.94483 loss)
I1201 00:00:56.935441   125 sgd_solver.cpp:180] [0.0] Iteration 29260, lr = 2.08968e-06, m = 0.9, lrm = 2.08968e-05, wd = 2.5e-07, gs = 1
I1201 00:01:02.281841   125 solver.cpp:333]     [0.0] Iteration 29304 (8.22967 iter/s, 5.34651s/44 iter), 81.6/100ep, loss = 1.30994
I1201 00:01:02.281883   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.139529 (* 2 = 0.279058 loss)
I1201 00:01:02.281894   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.03085 (* 1 = 1.03085 loss)
I1201 00:01:02.281905   125 sgd_solver.cpp:180] [0.0] Iteration 29304, lr = 2.0819e-06, m = 0.9, lrm = 2.0819e-05, wd = 2.5e-07, gs = 1
I1201 00:01:07.625428   125 solver.cpp:333]     [0.0] Iteration 29348 (8.23411 iter/s, 5.34363s/44 iter), 81.7/100ep, loss = 10.0712
I1201 00:01:07.625469   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.795518 (* 2 = 1.59104 loss)
I1201 00:01:07.625481   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.48014 (* 1 = 8.48014 loss)
I1201 00:01:07.625494   125 sgd_solver.cpp:180] [0.0] Iteration 29348, lr = 2.07414e-06, m = 0.9, lrm = 2.07414e-05, wd = 2.5e-07, gs = 1
I1201 00:01:12.973721   125 solver.cpp:333]     [0.0] Iteration 29392 (8.22689 iter/s, 5.34831s/44 iter), 81.9/100ep, loss = 11.7251
I1201 00:01:12.973759   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.54366 (* 2 = 3.08732 loss)
I1201 00:01:12.973770   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.63776 (* 1 = 8.63776 loss)
I1201 00:01:12.973781   125 sgd_solver.cpp:180] [0.0] Iteration 29392, lr = 2.06642e-06, m = 0.9, lrm = 2.06642e-05, wd = 2.5e-07, gs = 1
I1201 00:01:15.043049   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:01:15.156216   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:01:18.312345   125 solver.cpp:333]     [0.0] Iteration 29436 (8.24175 iter/s, 5.33867s/44 iter), 82/100ep, loss = 7.79742
I1201 00:01:18.312470   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.659787 (* 2 = 1.31957 loss)
I1201 00:01:18.312484   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.47782 (* 1 = 6.47782 loss)
I1201 00:01:18.312495   125 sgd_solver.cpp:180] [0.0] Iteration 29436, lr = 2.05872e-06, m = 0.9, lrm = 2.05872e-05, wd = 2.5e-07, gs = 1
I1201 00:01:18.433709   125 solver.cpp:501] Iteration 29438, Testing net (#0)
I1201 00:01:32.791558   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:01:32.944430   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:01:36.479447   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.500025 (* 2 = 1.00005 loss)
I1201 00:01:36.479485   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.86073 (* 1 = 8.86073 loss)
I1201 00:01:36.479495   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 18.838
I1201 00:01:36.479502   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.0731
I1201 00:01:36.479509   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 50.6578
I1201 00:01:36.479545   125 solver.cpp:271] Tests completed in 18.1674s
I1201 00:01:41.729418   125 solver.cpp:333]     [0.0] Iteration 29480 (2.42192 iter/s, 18.1674s/44 iter), 82.1/100ep, loss = 9.50538
I1201 00:01:41.729460   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.887437 (* 2 = 1.77487 loss)
I1201 00:01:41.729471   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.73048 (* 1 = 7.73048 loss)
I1201 00:01:41.729483   125 sgd_solver.cpp:180] [0.0] Iteration 29480, lr = 2.05105e-06, m = 0.9, lrm = 2.05105e-05, wd = 2.5e-07, gs = 1
I1201 00:01:47.066164   125 solver.cpp:333]     [0.0] Iteration 29524 (8.24466 iter/s, 5.33679s/44 iter), 82.2/100ep, loss = 7.16031
I1201 00:01:47.066202   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.384552 (* 2 = 0.769104 loss)
I1201 00:01:47.066213   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.39118 (* 1 = 6.39118 loss)
I1201 00:01:47.066226   125 sgd_solver.cpp:180] [0.0] Iteration 29524, lr = 2.04341e-06, m = 0.9, lrm = 2.04341e-05, wd = 2.5e-07, gs = 1
I1201 00:01:52.413894   125 solver.cpp:333]     [0.0] Iteration 29568 (8.22773 iter/s, 5.34777s/44 iter), 82.4/100ep, loss = 3.91896
I1201 00:01:52.414057   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.32974 (* 2 = 0.65948 loss)
I1201 00:01:52.414070   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.25945 (* 1 = 3.25945 loss)
I1201 00:01:52.414081   125 sgd_solver.cpp:180] [0.0] Iteration 29568, lr = 2.0358e-06, m = 0.9, lrm = 2.0358e-05, wd = 2.5e-07, gs = 1
I1201 00:01:57.764544   125 solver.cpp:333]     [0.0] Iteration 29612 (8.22326 iter/s, 5.35068s/44 iter), 82.5/100ep, loss = 6.6224
I1201 00:01:57.764585   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.02951 (* 2 = 2.05901 loss)
I1201 00:01:57.764595   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.56336 (* 1 = 4.56336 loss)
I1201 00:01:57.764606   125 sgd_solver.cpp:180] [0.0] Iteration 29612, lr = 2.02822e-06, m = 0.9, lrm = 2.02821e-05, wd = 2.5e-07, gs = 1
I1201 00:02:03.112221   125 solver.cpp:333]     [0.0] Iteration 29656 (8.22782 iter/s, 5.34771s/44 iter), 82.6/100ep, loss = 5.4508
I1201 00:02:03.112262   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.495327 (* 2 = 0.990654 loss)
I1201 00:02:03.112272   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.46012 (* 1 = 4.46012 loss)
I1201 00:02:03.112283   125 sgd_solver.cpp:180] [0.0] Iteration 29656, lr = 2.02066e-06, m = 0.9, lrm = 2.02066e-05, wd = 2.5e-07, gs = 1
I1201 00:02:08.456638   125 solver.cpp:333]     [0.0] Iteration 29700 (8.23282 iter/s, 5.34446s/44 iter), 82.7/100ep, loss = 6.7696
I1201 00:02:08.456679   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.618615 (* 2 = 1.23723 loss)
I1201 00:02:08.456691   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.53234 (* 1 = 5.53234 loss)
I1201 00:02:08.456703   125 sgd_solver.cpp:180] [0.0] Iteration 29700, lr = 2.01313e-06, m = 0.9, lrm = 2.01313e-05, wd = 2.5e-07, gs = 1
I1201 00:02:13.806572   125 solver.cpp:333]     [0.0] Iteration 29744 (8.22438 iter/s, 5.34995s/44 iter), 82.9/100ep, loss = 11.5119
I1201 00:02:13.806615   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.739645 (* 2 = 1.47929 loss)
I1201 00:02:13.806627   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.0326 (* 1 = 10.0326 loss)
I1201 00:02:13.806639   125 sgd_solver.cpp:180] [0.0] Iteration 29744, lr = 2.00563e-06, m = 0.9, lrm = 2.00563e-05, wd = 2.5e-07, gs = 1
I1201 00:02:16.847925   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:02:16.963317   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:02:19.150686   125 solver.cpp:333]     [0.0] Iteration 29788 (8.23328 iter/s, 5.34417s/44 iter), 83/100ep, loss = 4.55146
I1201 00:02:19.150727   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.234235 (* 2 = 0.46847 loss)
I1201 00:02:19.150737   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.08297 (* 1 = 4.08297 loss)
I1201 00:02:19.150748   125 sgd_solver.cpp:180] [0.0] Iteration 29788, lr = 1.99816e-06, m = 0.9, lrm = 1.99816e-05, wd = 2.5e-07, gs = 1
I1201 00:02:20.125510   125 solver.cpp:501] Iteration 29797, Testing net (#0)
I1201 00:02:33.505007   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:02:33.616336   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:02:37.199203   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.496623 (* 2 = 0.993245 loss)
I1201 00:02:37.199242   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.81745 (* 1 = 8.81745 loss)
I1201 00:02:37.199251   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.0926
I1201 00:02:37.199259   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.5589
I1201 00:02:37.199265   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 49.7535
I1201 00:02:37.199302   125 solver.cpp:271] Tests completed in 18.0488s
I1201 00:02:41.576481   125 solver.cpp:333]     [0.0] Iteration 29832 (2.43783 iter/s, 18.0488s/44 iter), 83.1/100ep, loss = 5.60623
I1201 00:02:41.576521   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.381065 (* 2 = 0.76213 loss)
I1201 00:02:41.576531   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.84407 (* 1 = 4.84407 loss)
I1201 00:02:41.576544   125 sgd_solver.cpp:180] [0.0] Iteration 29832, lr = 1.99072e-06, m = 0.9, lrm = 1.99072e-05, wd = 2.5e-07, gs = 1
I1201 00:02:46.922461   125 solver.cpp:333]     [0.0] Iteration 29876 (8.23045 iter/s, 5.346s/44 iter), 83.2/100ep, loss = 9.00347
I1201 00:02:46.922498   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.54051 (* 2 = 3.08103 loss)
I1201 00:02:46.922508   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.92242 (* 1 = 5.92242 loss)
I1201 00:02:46.922520   125 sgd_solver.cpp:180] [0.0] Iteration 29876, lr = 1.9833e-06, m = 0.9, lrm = 1.9833e-05, wd = 2.5e-07, gs = 1
I1201 00:02:52.274415   125 solver.cpp:333]     [0.0] Iteration 29920 (8.22124 iter/s, 5.35199s/44 iter), 83.3/100ep, loss = 9.55523
I1201 00:02:52.274451   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.35175 (* 2 = 2.7035 loss)
I1201 00:02:52.274461   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.8517 (* 1 = 6.8517 loss)
I1201 00:02:52.274472   125 sgd_solver.cpp:180] [0.0] Iteration 29920, lr = 1.97591e-06, m = 0.9, lrm = 1.97591e-05, wd = 2.5e-07, gs = 1
I1201 00:02:57.619087   125 solver.cpp:333]     [0.0] Iteration 29964 (8.23243 iter/s, 5.34472s/44 iter), 83.5/100ep, loss = 7.71892
I1201 00:02:57.619127   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.52908 (* 2 = 1.05816 loss)
I1201 00:02:57.619138   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.66073 (* 1 = 6.66073 loss)
I1201 00:02:57.619149   125 sgd_solver.cpp:180] [0.0] Iteration 29964, lr = 1.96855e-06, m = 0.9, lrm = 1.96855e-05, wd = 2.5e-07, gs = 1
I1201 00:03:02.969112   125 solver.cpp:333]     [0.0] Iteration 30008 (8.22423 iter/s, 5.35004s/44 iter), 83.6/100ep, loss = 3.5399
I1201 00:03:02.969154   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.398944 (* 2 = 0.797888 loss)
I1201 00:03:02.969164   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.74199 (* 1 = 2.74199 loss)
I1201 00:03:02.969177   125 sgd_solver.cpp:180] [0.0] Iteration 30008, lr = 1.96122e-06, m = 0.9, lrm = 1.96122e-05, wd = 2.5e-07, gs = 1
I1201 00:03:08.312758   125 solver.cpp:333]     [0.0] Iteration 30052 (8.23402 iter/s, 5.34369s/44 iter), 83.7/100ep, loss = 3.51977
I1201 00:03:08.312940   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.334133 (* 2 = 0.668265 loss)
I1201 00:03:08.312952   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.85148 (* 1 = 2.85148 loss)
I1201 00:03:08.312964   125 sgd_solver.cpp:180] [0.0] Iteration 30052, lr = 1.95391e-06, m = 0.9, lrm = 1.95391e-05, wd = 2.5e-07, gs = 1
I1201 00:03:13.654635   125 solver.cpp:333]     [0.0] Iteration 30096 (8.23674 iter/s, 5.34192s/44 iter), 83.8/100ep, loss = 15.9085
I1201 00:03:13.654675   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.91614 (* 2 = 3.83229 loss)
I1201 00:03:13.654685   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.0761 (* 1 = 12.0761 loss)
I1201 00:03:13.654696   125 sgd_solver.cpp:180] [0.0] Iteration 30096, lr = 1.94664e-06, m = 0.9, lrm = 1.94664e-05, wd = 2.5e-07, gs = 1
I1201 00:03:17.303846   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:03:17.425307   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:03:18.998493   125 solver.cpp:333]     [0.0] Iteration 30140 (8.23373 iter/s, 5.34387s/44 iter), 84/100ep, loss = 5.17761
I1201 00:03:18.998535   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.698268 (* 2 = 1.39654 loss)
I1201 00:03:18.998546   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.78105 (* 1 = 3.78105 loss)
I1201 00:03:18.998558   125 sgd_solver.cpp:180] [0.0] Iteration 30140, lr = 1.93938e-06, m = 0.9, lrm = 1.93938e-05, wd = 2.5e-07, gs = 1
I1201 00:03:20.822252   125 solver.cpp:501] Iteration 30156, Testing net (#0)
I1201 00:03:34.283596   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:03:34.438447   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:03:38.098551   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.495961 (* 2 = 0.991921 loss)
I1201 00:03:38.098589   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.7358 (* 1 = 8.7358 loss)
I1201 00:03:38.098599   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.1379
I1201 00:03:38.098606   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.3294
I1201 00:03:38.098613   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 52.4091
I1201 00:03:38.098645   125 solver.cpp:271] Tests completed in 19.1004s
I1201 00:03:41.631042   125 solver.cpp:333]     [0.0] Iteration 30184 (2.30362 iter/s, 19.1004s/44 iter), 84.1/100ep, loss = 6.96713
I1201 00:03:41.631176   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.37951 (* 2 = 2.75902 loss)
I1201 00:03:41.631188   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.20809 (* 1 = 4.20809 loss)
I1201 00:03:41.631201   125 sgd_solver.cpp:180] [0.0] Iteration 30184, lr = 1.93216e-06, m = 0.9, lrm = 1.93216e-05, wd = 2.5e-07, gs = 1
I1201 00:03:46.979370   125 solver.cpp:333]     [0.0] Iteration 30228 (8.22684 iter/s, 5.34835s/44 iter), 84.2/100ep, loss = 5.77062
I1201 00:03:46.979409   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.513143 (* 2 = 1.02629 loss)
I1201 00:03:46.979420   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.74431 (* 1 = 4.74431 loss)
I1201 00:03:46.979431   125 sgd_solver.cpp:180] [0.0] Iteration 30228, lr = 1.92496e-06, m = 0.9, lrm = 1.92496e-05, wd = 2.5e-07, gs = 1
I1201 00:03:52.320894   125 solver.cpp:333]     [0.0] Iteration 30272 (8.23729 iter/s, 5.34156s/44 iter), 84.3/100ep, loss = 7.64085
I1201 00:03:52.320936   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.37174 (* 2 = 0.743481 loss)
I1201 00:03:52.320946   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.89735 (* 1 = 6.89735 loss)
I1201 00:03:52.320958   125 sgd_solver.cpp:180] [0.0] Iteration 30272, lr = 1.91779e-06, m = 0.9, lrm = 1.91779e-05, wd = 2.5e-07, gs = 1
I1201 00:03:57.679924   125 solver.cpp:333]     [0.0] Iteration 30316 (8.21039 iter/s, 5.35906s/44 iter), 84.4/100ep, loss = 8.51158
I1201 00:03:57.679967   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.1952 (* 2 = 2.3904 loss)
I1201 00:03:57.679977   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.12116 (* 1 = 6.12116 loss)
I1201 00:03:57.679988   125 sgd_solver.cpp:180] [0.0] Iteration 30316, lr = 1.91065e-06, m = 0.9, lrm = 1.91065e-05, wd = 2.5e-07, gs = 1
I1201 00:04:03.105177   125 solver.cpp:333]     [0.0] Iteration 30360 (8.11019 iter/s, 5.42527s/44 iter), 84.6/100ep, loss = 4.17068
I1201 00:04:03.105221   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.241826 (* 2 = 0.483652 loss)
I1201 00:04:03.105232   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.687 (* 1 = 3.687 loss)
I1201 00:04:03.105242   125 sgd_solver.cpp:180] [0.0] Iteration 30360, lr = 1.90353e-06, m = 0.9, lrm = 1.90353e-05, wd = 2.5e-07, gs = 1
I1201 00:04:08.515292   125 solver.cpp:333]     [0.0] Iteration 30404 (8.13286 iter/s, 5.41015s/44 iter), 84.7/100ep, loss = 7.28811
I1201 00:04:08.515334   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.726572 (* 2 = 1.45314 loss)
I1201 00:04:08.515345   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.83494 (* 1 = 5.83494 loss)
I1201 00:04:08.515357   125 sgd_solver.cpp:180] [0.0] Iteration 30404, lr = 1.89644e-06, m = 0.9, lrm = 1.89644e-05, wd = 2.5e-07, gs = 1
I1201 00:04:13.858449   125 solver.cpp:333]     [0.0] Iteration 30448 (8.23479 iter/s, 5.34319s/44 iter), 84.8/100ep, loss = 5.80444
I1201 00:04:13.858618   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.38659 (* 2 = 2.77318 loss)
I1201 00:04:13.858629   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.03123 (* 1 = 3.03123 loss)
I1201 00:04:13.858640   125 sgd_solver.cpp:180] [0.0] Iteration 30448, lr = 1.88937e-06, m = 0.9, lrm = 1.88937e-05, wd = 2.5e-07, gs = 1
I1201 00:04:18.476887   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:04:18.590435   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:04:19.201050   125 solver.cpp:333]     [0.0] Iteration 30492 (8.23563 iter/s, 5.34264s/44 iter), 84.9/100ep, loss = 7.58054
I1201 00:04:19.201089   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.27305 (* 2 = 2.54609 loss)
I1201 00:04:19.201100   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.03443 (* 1 = 5.03443 loss)
I1201 00:04:19.201112   125 sgd_solver.cpp:180] [0.0] Iteration 30492, lr = 1.88234e-06, m = 0.9, lrm = 1.88234e-05, wd = 2.5e-07, gs = 1
I1201 00:04:21.880579   125 solver.cpp:501] Iteration 30515, Testing net (#0)
I1201 00:04:35.282284   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:04:35.398113   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:04:39.088656   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.494287 (* 2 = 0.988575 loss)
I1201 00:04:39.088693   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.8555 (* 1 = 8.8555 loss)
I1201 00:04:39.088702   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.3525
I1201 00:04:39.088711   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.6624
I1201 00:04:39.088717   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.6251
I1201 00:04:39.088749   125 solver.cpp:271] Tests completed in 19.8879s
I1201 00:04:41.760754   125 solver.cpp:333]     [0.0] Iteration 30536 (2.2124 iter/s, 19.8879s/44 iter), 85.1/100ep, loss = 7.88647
I1201 00:04:41.760795   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.810615 (* 2 = 1.62123 loss)
I1201 00:04:41.760807   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.26522 (* 1 = 6.26522 loss)
I1201 00:04:41.760818   125 sgd_solver.cpp:180] [0.0] Iteration 30536, lr = 1.87532e-06, m = 0.9, lrm = 1.87532e-05, wd = 2.5e-07, gs = 1
I1201 00:04:47.100682   125 solver.cpp:333]     [0.0] Iteration 30580 (8.23975 iter/s, 5.33997s/44 iter), 85.2/100ep, loss = 14.5926
I1201 00:04:47.100860   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.5572 (* 2 = 3.11439 loss)
I1201 00:04:47.100873   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.4781 (* 1 = 11.4781 loss)
I1201 00:04:47.100884   125 sgd_solver.cpp:180] [0.0] Iteration 30580, lr = 1.86834e-06, m = 0.9, lrm = 1.86834e-05, wd = 2.5e-07, gs = 1
I1201 00:04:52.445509   125 solver.cpp:333]     [0.0] Iteration 30624 (8.23221 iter/s, 5.34486s/44 iter), 85.3/100ep, loss = 5.35188
I1201 00:04:52.445551   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.267404 (* 2 = 0.534808 loss)
I1201 00:04:52.445561   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.81705 (* 1 = 4.81705 loss)
I1201 00:04:52.445572   125 sgd_solver.cpp:180] [0.0] Iteration 30624, lr = 1.86138e-06, m = 0.9, lrm = 1.86138e-05, wd = 2.5e-07, gs = 1
I1201 00:04:57.785470   125 solver.cpp:333]     [0.0] Iteration 30668 (8.23973 iter/s, 5.33998s/44 iter), 85.4/100ep, loss = 8.21775
I1201 00:04:57.785512   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.761837 (* 2 = 1.52367 loss)
I1201 00:04:57.785523   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.69405 (* 1 = 6.69405 loss)
I1201 00:04:57.785535   125 sgd_solver.cpp:180] [0.0] Iteration 30668, lr = 1.85444e-06, m = 0.9, lrm = 1.85444e-05, wd = 2.5e-07, gs = 1
I1201 00:05:03.126329   125 solver.cpp:333]     [0.0] Iteration 30712 (8.23832 iter/s, 5.3409s/44 iter), 85.5/100ep, loss = 7.61046
I1201 00:05:03.126369   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.645161 (* 2 = 1.29032 loss)
I1201 00:05:03.126381   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.32011 (* 1 = 6.32011 loss)
I1201 00:05:03.126392   125 sgd_solver.cpp:180] [0.0] Iteration 30712, lr = 1.84754e-06, m = 0.9, lrm = 1.84754e-05, wd = 2.5e-07, gs = 1
I1201 00:05:08.468480   125 solver.cpp:333]     [0.0] Iteration 30756 (8.23633 iter/s, 5.34218s/44 iter), 85.7/100ep, loss = 6.65225
I1201 00:05:08.468520   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.451286 (* 2 = 0.902572 loss)
I1201 00:05:08.468531   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.74965 (* 1 = 5.74965 loss)
I1201 00:05:08.468542   125 sgd_solver.cpp:180] [0.0] Iteration 30756, lr = 1.84065e-06, m = 0.9, lrm = 1.84065e-05, wd = 2.5e-07, gs = 1
I1201 00:05:13.823786   125 solver.cpp:333]     [0.0] Iteration 30800 (8.21613 iter/s, 5.35532s/44 iter), 85.8/100ep, loss = 6.65636
I1201 00:05:13.823824   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.706791 (* 2 = 1.41358 loss)
I1201 00:05:13.823835   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.24275 (* 1 = 5.24275 loss)
I1201 00:05:13.823845   125 sgd_solver.cpp:180] [0.0] Iteration 30800, lr = 1.8338e-06, m = 0.9, lrm = 1.8338e-05, wd = 2.5e-07, gs = 1
I1201 00:05:19.171739   125 solver.cpp:333]     [0.0] Iteration 30844 (8.22739 iter/s, 5.34799s/44 iter), 85.9/100ep, loss = 4.07909
I1201 00:05:19.171876   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.568372 (* 2 = 1.13674 loss)
I1201 00:05:19.171890   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.94232 (* 1 = 2.94232 loss)
I1201 00:05:19.171900   125 sgd_solver.cpp:180] [0.0] Iteration 30844, lr = 1.82697e-06, m = 0.9, lrm = 1.82697e-05, wd = 2.5e-07, gs = 1
I1201 00:05:19.419342   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:05:19.540249   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:05:22.691928   125 solver.cpp:501] Iteration 30874, Testing net (#0)
I1201 00:05:36.856590   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:05:37.009865   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:05:40.768862   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.494559 (* 2 = 0.989119 loss)
I1201 00:05:40.768904   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.75727 (* 1 = 8.75727 loss)
I1201 00:05:40.768913   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.363
I1201 00:05:40.768921   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.642
I1201 00:05:40.768929   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.999
I1201 00:05:40.768965   125 solver.cpp:271] Tests completed in 21.5974s
I1201 00:05:42.617239   125 solver.cpp:333]     [0.0] Iteration 30888 (2.03728 iter/s, 21.5974s/44 iter), 86/100ep, loss = 5.57102
I1201 00:05:42.617280   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.650984 (* 2 = 1.30197 loss)
I1201 00:05:42.617291   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.26903 (* 1 = 4.26903 loss)
I1201 00:05:42.617303   125 sgd_solver.cpp:180] [0.0] Iteration 30888, lr = 1.82016e-06, m = 0.9, lrm = 1.82016e-05, wd = 2.5e-07, gs = 1
I1201 00:05:48.002712   125 solver.cpp:333]     [0.0] Iteration 30932 (8.17009 iter/s, 5.38549s/44 iter), 86.2/100ep, loss = 6.63629
I1201 00:05:48.002753   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.09447 (* 2 = 2.18894 loss)
I1201 00:05:48.002764   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.44732 (* 1 = 4.44732 loss)
I1201 00:05:48.002775   125 sgd_solver.cpp:180] [0.0] Iteration 30932, lr = 1.81338e-06, m = 0.9, lrm = 1.81338e-05, wd = 2.5e-07, gs = 1
I1201 00:05:53.360261   125 solver.cpp:333]     [0.0] Iteration 30976 (8.21266 iter/s, 5.35758s/44 iter), 86.3/100ep, loss = 8.85237
I1201 00:05:53.360455   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.592273 (* 2 = 1.18455 loss)
I1201 00:05:53.360471   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.6678 (* 1 = 7.6678 loss)
I1201 00:05:53.360482   125 sgd_solver.cpp:180] [0.0] Iteration 30976, lr = 1.80662e-06, m = 0.9, lrm = 1.80662e-05, wd = 2.5e-07, gs = 1
I1201 00:05:58.717363   125 solver.cpp:333]     [0.0] Iteration 31020 (8.21335 iter/s, 5.35713s/44 iter), 86.4/100ep, loss = 10.0186
I1201 00:05:58.717406   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.582339 (* 2 = 1.16468 loss)
I1201 00:05:58.717418   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.85393 (* 1 = 8.85393 loss)
I1201 00:05:58.717432   125 sgd_solver.cpp:180] [0.0] Iteration 31020, lr = 1.79989e-06, m = 0.9, lrm = 1.79989e-05, wd = 2.5e-07, gs = 1
I1201 00:06:04.080479   125 solver.cpp:333]     [0.0] Iteration 31064 (8.20415 iter/s, 5.36314s/44 iter), 86.5/100ep, loss = 2.76055
I1201 00:06:04.080521   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.278659 (* 2 = 0.557319 loss)
I1201 00:06:04.080533   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.2032 (* 1 = 2.2032 loss)
I1201 00:06:04.080544   125 sgd_solver.cpp:180] [0.0] Iteration 31064, lr = 1.79319e-06, m = 0.9, lrm = 1.79319e-05, wd = 2.5e-07, gs = 1
I1201 00:06:09.439412   125 solver.cpp:333]     [0.0] Iteration 31108 (8.21053 iter/s, 5.35897s/44 iter), 86.7/100ep, loss = 5.52338
I1201 00:06:09.439453   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.365723 (* 2 = 0.731447 loss)
I1201 00:06:09.439465   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.79191 (* 1 = 4.79191 loss)
I1201 00:06:09.439476   125 sgd_solver.cpp:180] [0.0] Iteration 31108, lr = 1.78651e-06, m = 0.9, lrm = 1.78651e-05, wd = 2.5e-07, gs = 1
I1201 00:06:14.802137   125 solver.cpp:333]     [0.0] Iteration 31152 (8.20477 iter/s, 5.36274s/44 iter), 86.8/100ep, loss = 4.89826
I1201 00:06:14.802177   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.442649 (* 2 = 0.885298 loss)
I1201 00:06:14.802188   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.01294 (* 1 = 4.01294 loss)
I1201 00:06:14.802201   125 sgd_solver.cpp:180] [0.0] Iteration 31152, lr = 1.77985e-06, m = 0.9, lrm = 1.77985e-05, wd = 2.5e-07, gs = 1
I1201 00:06:20.163166   125 solver.cpp:333]     [0.0] Iteration 31196 (8.20732 iter/s, 5.36107s/44 iter), 86.9/100ep, loss = 10.8548
I1201 00:06:20.163206   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.42918 (* 2 = 2.85836 loss)
I1201 00:06:20.163218   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.99646 (* 1 = 7.99646 loss)
I1201 00:06:20.163229   125 sgd_solver.cpp:180] [0.0] Iteration 31196, lr = 1.77322e-06, m = 0.9, lrm = 1.77322e-05, wd = 2.5e-07, gs = 1
I1201 00:06:21.017936   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:06:21.139760   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:06:24.550014   125 solver.cpp:501] Iteration 31233, Testing net (#0)
I1201 00:06:37.828024   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:06:37.941238   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:06:41.679054   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.495098 (* 2 = 0.990197 loss)
I1201 00:06:41.679095   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.84883 (* 1 = 8.84883 loss)
I1201 00:06:41.679103   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 20.225
I1201 00:06:41.679111   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 29.4159
I1201 00:06:41.679118   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 52.4788
I1201 00:06:41.679152   125 solver.cpp:271] Tests completed in 21.5162s
I1201 00:06:42.654896   125 solver.cpp:333]     [0.0] Iteration 31240 (2.04497 iter/s, 21.5162s/44 iter), 87/100ep, loss = 1.71029
I1201 00:06:42.654939   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.248029 (* 2 = 0.496058 loss)
I1201 00:06:42.654949   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.21421 (* 1 = 1.21421 loss)
I1201 00:06:42.654963   125 sgd_solver.cpp:180] [0.0] Iteration 31240, lr = 1.76662e-06, m = 0.9, lrm = 1.76662e-05, wd = 2.5e-07, gs = 1
I1201 00:06:48.016080   125 solver.cpp:333]     [0.0] Iteration 31284 (8.20711 iter/s, 5.3612s/44 iter), 87.1/100ep, loss = 7.06651
I1201 00:06:48.016121   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.816608 (* 2 = 1.63322 loss)
I1201 00:06:48.016132   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.43327 (* 1 = 5.43327 loss)
I1201 00:06:48.016144   125 sgd_solver.cpp:180] [0.0] Iteration 31284, lr = 1.76004e-06, m = 0.9, lrm = 1.76004e-05, wd = 2.5e-07, gs = 1
I1201 00:06:53.387187   125 solver.cpp:333]     [0.0] Iteration 31328 (8.19193 iter/s, 5.37114s/44 iter), 87.3/100ep, loss = 4.0278
I1201 00:06:53.387225   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.443142 (* 2 = 0.886283 loss)
I1201 00:06:53.387235   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.14149 (* 1 = 3.14149 loss)
I1201 00:06:53.387246   125 sgd_solver.cpp:180] [0.0] Iteration 31328, lr = 1.75348e-06, m = 0.9, lrm = 1.75348e-05, wd = 2.5e-07, gs = 1
I1201 00:06:58.747635   125 solver.cpp:333]     [0.0] Iteration 31372 (8.20822 iter/s, 5.36048s/44 iter), 87.4/100ep, loss = 15.1132
I1201 00:06:58.747788   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.35201 (* 2 = 2.70403 loss)
I1201 00:06:58.747802   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 12.4092 (* 1 = 12.4092 loss)
I1201 00:06:58.747813   125 sgd_solver.cpp:180] [0.0] Iteration 31372, lr = 1.74695e-06, m = 0.9, lrm = 1.74695e-05, wd = 2.5e-07, gs = 1
I1201 00:07:04.110038   125 solver.cpp:333]     [0.0] Iteration 31416 (8.20525 iter/s, 5.36242s/44 iter), 87.5/100ep, loss = 5.64879
I1201 00:07:04.110080   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.40216 (* 2 = 0.80432 loss)
I1201 00:07:04.110090   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.84444 (* 1 = 4.84444 loss)
I1201 00:07:04.110102   125 sgd_solver.cpp:180] [0.0] Iteration 31416, lr = 1.74044e-06, m = 0.9, lrm = 1.74044e-05, wd = 2.5e-07, gs = 1
I1201 00:07:09.468662   125 solver.cpp:333]     [0.0] Iteration 31460 (8.21101 iter/s, 5.35866s/44 iter), 87.6/100ep, loss = 5.31269
I1201 00:07:09.468703   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.643772 (* 2 = 1.28754 loss)
I1201 00:07:09.468713   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.02512 (* 1 = 4.02512 loss)
I1201 00:07:09.468731   125 sgd_solver.cpp:180] [0.0] Iteration 31460, lr = 1.73396e-06, m = 0.9, lrm = 1.73396e-05, wd = 2.5e-07, gs = 1
I1201 00:07:14.826222   125 solver.cpp:333]     [0.0] Iteration 31504 (8.21268 iter/s, 5.35757s/44 iter), 87.8/100ep, loss = 3.28858
I1201 00:07:14.826263   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.275431 (* 2 = 0.550861 loss)
I1201 00:07:14.826273   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.73769 (* 1 = 2.73769 loss)
I1201 00:07:14.826285   125 sgd_solver.cpp:180] [0.0] Iteration 31504, lr = 1.7275e-06, m = 0.9, lrm = 1.7275e-05, wd = 2.5e-07, gs = 1
I1201 00:07:20.192457   125 solver.cpp:333]     [0.0] Iteration 31548 (8.19936 iter/s, 5.36627s/44 iter), 87.9/100ep, loss = 3.8442
I1201 00:07:20.192499   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.383217 (* 2 = 0.766435 loss)
I1201 00:07:20.192510   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.07773 (* 1 = 3.07773 loss)
I1201 00:07:20.192523   125 sgd_solver.cpp:180] [0.0] Iteration 31548, lr = 1.72106e-06, m = 0.9, lrm = 1.72106e-05, wd = 2.5e-07, gs = 1
I1201 00:07:22.026823   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:07:22.138458   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:07:25.439136   125 solver.cpp:501] Iteration 31592, Testing net (#0)
I1201 00:07:38.612210   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:07:38.762611   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:07:42.576566   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.491614 (* 2 = 0.983228 loss)
I1201 00:07:42.576604   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.71838 (* 1 = 8.71838 loss)
I1201 00:07:42.576614   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.189
I1201 00:07:42.576622   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.2125
I1201 00:07:42.576628   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 53.5177
I1201 00:07:42.576663   125 solver.cpp:271] Tests completed in 22.3844s
I1201 00:07:42.699059   125 solver.cpp:333]     [0.0] Iteration 31592 (1.96565 iter/s, 22.3844s/44 iter), 88/100ep, loss = 6.94365
I1201 00:07:42.699102   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.580855 (* 2 = 1.16171 loss)
I1201 00:07:42.699113   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.78191 (* 1 = 5.78191 loss)
I1201 00:07:42.699126   125 sgd_solver.cpp:180] [0.0] Iteration 31592, lr = 1.71465e-06, m = 0.9, lrm = 1.71465e-05, wd = 2.5e-07, gs = 1
I1201 00:07:48.063520   125 solver.cpp:333]     [0.0] Iteration 31636 (8.20211 iter/s, 5.36447s/44 iter), 88.1/100ep, loss = 10.0554
I1201 00:07:48.063562   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.24306 (* 2 = 2.48612 loss)
I1201 00:07:48.063572   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.56921 (* 1 = 7.56921 loss)
I1201 00:07:48.063585   125 sgd_solver.cpp:180] [0.0] Iteration 31636, lr = 1.70827e-06, m = 0.9, lrm = 1.70826e-05, wd = 2.5e-07, gs = 1
I1201 00:07:53.435715   125 solver.cpp:333]     [0.0] Iteration 31680 (8.19028 iter/s, 5.37222s/44 iter), 88.2/100ep, loss = 7.6109
I1201 00:07:53.435758   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.629635 (* 2 = 1.25927 loss)
I1201 00:07:53.435770   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.3516 (* 1 = 6.3516 loss)
I1201 00:07:53.435781   125 sgd_solver.cpp:180] [0.0] Iteration 31680, lr = 1.7019e-06, m = 0.9, lrm = 1.7019e-05, wd = 2.5e-07, gs = 1
I1201 00:07:58.803427   125 solver.cpp:333]     [0.0] Iteration 31724 (8.19713 iter/s, 5.36773s/44 iter), 88.4/100ep, loss = 3.62269
I1201 00:07:58.803470   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.320789 (* 2 = 0.641579 loss)
I1201 00:07:58.803480   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.98108 (* 1 = 2.98108 loss)
I1201 00:07:58.803493   125 sgd_solver.cpp:180] [0.0] Iteration 31724, lr = 1.69556e-06, m = 0.9, lrm = 1.69556e-05, wd = 2.5e-07, gs = 1
I1201 00:08:04.168576   125 solver.cpp:333]     [0.0] Iteration 31768 (8.20102 iter/s, 5.36519s/44 iter), 88.5/100ep, loss = 6.61892
I1201 00:08:04.168617   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.29311 (* 2 = 0.586219 loss)
I1201 00:08:04.168627   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.03267 (* 1 = 6.03267 loss)
I1201 00:08:04.168637   125 sgd_solver.cpp:180] [0.0] Iteration 31768, lr = 1.68925e-06, m = 0.9, lrm = 1.68925e-05, wd = 2.5e-07, gs = 1
I1201 00:08:09.533218   125 solver.cpp:333]     [0.0] Iteration 31812 (8.20182 iter/s, 5.36466s/44 iter), 88.6/100ep, loss = 6.77947
I1201 00:08:09.533413   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.547918 (* 2 = 1.09584 loss)
I1201 00:08:09.533427   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.6836 (* 1 = 5.6836 loss)
I1201 00:08:09.533439   125 sgd_solver.cpp:180] [0.0] Iteration 31812, lr = 1.68295e-06, m = 0.9, lrm = 1.68295e-05, wd = 2.5e-07, gs = 1
I1201 00:08:14.904273   125 solver.cpp:333]     [0.0] Iteration 31856 (8.19202 iter/s, 5.37108s/44 iter), 88.7/100ep, loss = 9.93127
I1201 00:08:14.904314   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.46146 (* 2 = 0.92292 loss)
I1201 00:08:14.904325   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.00832 (* 1 = 9.00832 loss)
I1201 00:08:14.904337   125 sgd_solver.cpp:180] [0.0] Iteration 31856, lr = 1.67668e-06, m = 0.9, lrm = 1.67668e-05, wd = 2.5e-07, gs = 1
I1201 00:08:20.269994   125 solver.cpp:333]     [0.0] Iteration 31900 (8.20015 iter/s, 5.36575s/44 iter), 88.9/100ep, loss = 8.72655
I1201 00:08:20.270031   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.550225 (* 2 = 1.10045 loss)
I1201 00:08:20.270041   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.62607 (* 1 = 7.62607 loss)
I1201 00:08:20.270053   125 sgd_solver.cpp:180] [0.0] Iteration 31900, lr = 1.67044e-06, m = 0.9, lrm = 1.67044e-05, wd = 2.5e-07, gs = 1
I1201 00:08:23.082947   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:08:23.198622   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:08:25.639791   125 solver.cpp:333]     [0.0] Iteration 31944 (8.19393 iter/s, 5.36983s/44 iter), 89/100ep, loss = 6.17815
I1201 00:08:25.639833   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.465318 (* 2 = 0.930635 loss)
I1201 00:08:25.639845   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.24748 (* 1 = 5.24748 loss)
I1201 00:08:25.639856   125 sgd_solver.cpp:180] [0.0] Iteration 31944, lr = 1.66422e-06, m = 0.9, lrm = 1.66421e-05, wd = 2.5e-07, gs = 1
I1201 00:08:26.371953   125 solver.cpp:501] Iteration 31951, Testing net (#0)
I1201 00:08:39.692477   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:08:39.807562   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:08:43.647179   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.494654 (* 2 = 0.989309 loss)
I1201 00:08:43.647214   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.88437 (* 1 = 8.88437 loss)
I1201 00:08:43.647222   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.7233
I1201 00:08:43.647231   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 29.1999
I1201 00:08:43.647238   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.5081
I1201 00:08:43.647272   125 solver.cpp:271] Tests completed in 18.0076s
I1201 00:08:48.278378   125 solver.cpp:333]     [0.0] Iteration 31988 (2.44341 iter/s, 18.0076s/44 iter), 89.1/100ep, loss = 2.88745
I1201 00:08:48.278421   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.227949 (* 2 = 0.455897 loss)
I1201 00:08:48.278431   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.43153 (* 1 = 2.43153 loss)
I1201 00:08:48.278443   125 sgd_solver.cpp:180] [0.0] Iteration 31988, lr = 1.65802e-06, m = 0.9, lrm = 1.65802e-05, wd = 2.5e-07, gs = 1
I1201 00:08:53.637789   125 solver.cpp:333]     [0.0] Iteration 32032 (8.20982 iter/s, 5.35944s/44 iter), 89.2/100ep, loss = 6.09722
I1201 00:08:53.637831   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.444148 (* 2 = 0.888296 loss)
I1201 00:08:53.637841   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.20889 (* 1 = 5.20889 loss)
I1201 00:08:53.637852   125 sgd_solver.cpp:180] [0.0] Iteration 32032, lr = 1.65184e-06, m = 0.9, lrm = 1.65184e-05, wd = 2.5e-07, gs = 1
I1201 00:08:59.004833   125 solver.cpp:333]     [0.0] Iteration 32076 (8.19816 iter/s, 5.36706s/44 iter), 89.3/100ep, loss = 5.43995
I1201 00:08:59.004875   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.40025 (* 2 = 0.8005 loss)
I1201 00:08:59.004885   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.63942 (* 1 = 4.63942 loss)
I1201 00:08:59.004896   125 sgd_solver.cpp:180] [0.0] Iteration 32076, lr = 1.64569e-06, m = 0.9, lrm = 1.64569e-05, wd = 2.5e-07, gs = 1
I1201 00:09:04.372895   125 solver.cpp:333]     [0.0] Iteration 32120 (8.19657 iter/s, 5.3681s/44 iter), 89.5/100ep, loss = 9.18312
I1201 00:09:04.372934   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.813072 (* 2 = 1.62614 loss)
I1201 00:09:04.372946   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.55694 (* 1 = 7.55694 loss)
I1201 00:09:04.372956   125 sgd_solver.cpp:180] [0.0] Iteration 32120, lr = 1.63956e-06, m = 0.9, lrm = 1.63955e-05, wd = 2.5e-07, gs = 1
I1201 00:09:09.736958   125 solver.cpp:333]     [0.0] Iteration 32164 (8.2027 iter/s, 5.36409s/44 iter), 89.6/100ep, loss = 1.25782
I1201 00:09:09.737139   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.15921 (* 2 = 0.31842 loss)
I1201 00:09:09.737152   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 0.939366 (* 1 = 0.939366 loss)
I1201 00:09:09.737165   125 sgd_solver.cpp:180] [0.0] Iteration 32164, lr = 1.63345e-06, m = 0.9, lrm = 1.63345e-05, wd = 2.5e-07, gs = 1
I1201 00:09:15.096680   125 solver.cpp:333]     [0.0] Iteration 32208 (8.20935 iter/s, 5.35974s/44 iter), 89.7/100ep, loss = 4.39851
I1201 00:09:15.096721   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.63567 (* 2 = 1.27134 loss)
I1201 00:09:15.096732   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.12713 (* 1 = 3.12713 loss)
I1201 00:09:15.096745   125 sgd_solver.cpp:180] [0.0] Iteration 32208, lr = 1.62736e-06, m = 0.9, lrm = 1.62736e-05, wd = 2.5e-07, gs = 1
I1201 00:09:20.451938   125 solver.cpp:333]     [0.0] Iteration 32252 (8.21618 iter/s, 5.35529s/44 iter), 89.8/100ep, loss = 3.46538
I1201 00:09:20.451982   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.55427 (* 2 = 1.10854 loss)
I1201 00:09:20.451993   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.35681 (* 1 = 2.35681 loss)
I1201 00:09:20.452005   125 sgd_solver.cpp:180] [0.0] Iteration 32252, lr = 1.6213e-06, m = 0.9, lrm = 1.6213e-05, wd = 2.5e-07, gs = 1
I1201 00:09:23.864888   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:09:23.987475   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:09:25.810284   125 solver.cpp:333]     [0.0] Iteration 32296 (8.21146 iter/s, 5.35837s/44 iter), 90/100ep, loss = 6.83403
I1201 00:09:25.810325   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.612466 (* 2 = 1.22493 loss)
I1201 00:09:25.810336   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.60907 (* 1 = 5.60907 loss)
I1201 00:09:25.810348   125 sgd_solver.cpp:180] [0.0] Iteration 32296, lr = 1.61526e-06, m = 0.9, lrm = 1.61526e-05, wd = 2.5e-07, gs = 1
I1201 00:09:27.392659   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_32310.caffemodel
I1201 00:09:27.441679   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_32310.solverstate
I1201 00:09:27.482497   125 solver.cpp:501] Iteration 32310, Testing net (#0)
I1201 00:09:40.563113   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:09:40.713579   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:09:44.596696   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.493519 (* 2 = 0.987038 loss)
I1201 00:09:44.596737   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.79898 (* 1 = 8.79898 loss)
I1201 00:09:44.596746   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.3842
I1201 00:09:44.596755   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.6881
I1201 00:09:44.596761   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 52.1223
I1201 00:09:44.596797   125 solver.cpp:271] Tests completed in 18.7867s
I1201 00:09:48.383363   125 solver.cpp:333]     [0.0] Iteration 32340 (2.34208 iter/s, 18.7867s/44 iter), 90.1/100ep, loss = 5.98725
I1201 00:09:48.383404   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.607973 (* 2 = 1.21595 loss)
I1201 00:09:48.383414   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.77127 (* 1 = 4.77127 loss)
I1201 00:09:48.383425   125 sgd_solver.cpp:180] [0.0] Iteration 32340, lr = 1.60924e-06, m = 0.9, lrm = 1.60924e-05, wd = 2.5e-07, gs = 1
I1201 00:09:53.741552   125 solver.cpp:333]     [0.0] Iteration 32384 (8.21169 iter/s, 5.35822s/44 iter), 90.2/100ep, loss = 4.45235
I1201 00:09:53.741592   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.633827 (* 2 = 1.26765 loss)
I1201 00:09:53.741603   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.18467 (* 1 = 3.18467 loss)
I1201 00:09:53.741616   125 sgd_solver.cpp:180] [0.0] Iteration 32384, lr = 1.60325e-06, m = 0.9, lrm = 1.60325e-05, wd = 2.5e-07, gs = 1
I1201 00:09:59.104074   125 solver.cpp:333]     [0.0] Iteration 32428 (8.20508 iter/s, 5.36253s/44 iter), 90.3/100ep, loss = 4.15381
I1201 00:09:59.104115   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.317965 (* 2 = 0.635929 loss)
I1201 00:09:59.104125   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.51784 (* 1 = 3.51784 loss)
I1201 00:09:59.104137   125 sgd_solver.cpp:180] [0.0] Iteration 32428, lr = 1.59728e-06, m = 0.9, lrm = 1.59728e-05, wd = 2.5e-07, gs = 1
I1201 00:10:04.462522   125 solver.cpp:333]     [0.0] Iteration 32472 (8.21128 iter/s, 5.35848s/44 iter), 90.5/100ep, loss = 3.2932
I1201 00:10:04.462563   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.29307 (* 2 = 0.58614 loss)
I1201 00:10:04.462574   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.70702 (* 1 = 2.70702 loss)
I1201 00:10:04.462584   125 sgd_solver.cpp:180] [0.0] Iteration 32472, lr = 1.59133e-06, m = 0.9, lrm = 1.59133e-05, wd = 2.5e-07, gs = 1
I1201 00:10:09.813280   125 solver.cpp:333]     [0.0] Iteration 32516 (8.22313 iter/s, 5.35076s/44 iter), 90.6/100ep, loss = 9.37319
I1201 00:10:09.813324   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.870243 (* 2 = 1.74049 loss)
I1201 00:10:09.813335   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.63266 (* 1 = 7.63266 loss)
I1201 00:10:09.813347   125 sgd_solver.cpp:180] [0.0] Iteration 32516, lr = 1.5854e-06, m = 0.9, lrm = 1.5854e-05, wd = 2.5e-07, gs = 1
I1201 00:10:15.196924   125 solver.cpp:333]     [0.0] Iteration 32560 (8.17284 iter/s, 5.38368s/44 iter), 90.7/100ep, loss = 6.63968
I1201 00:10:15.197114   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.533586 (* 2 = 1.06717 loss)
I1201 00:10:15.197129   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.57247 (* 1 = 5.57247 loss)
I1201 00:10:15.197139   125 sgd_solver.cpp:180] [0.0] Iteration 32560, lr = 1.57949e-06, m = 0.9, lrm = 1.57949e-05, wd = 2.5e-07, gs = 1
I1201 00:10:20.551478   125 solver.cpp:333]     [0.0] Iteration 32604 (8.21726 iter/s, 5.35458s/44 iter), 90.8/100ep, loss = 9.11998
I1201 00:10:20.551520   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.15884 (* 2 = 2.31768 loss)
I1201 00:10:20.551530   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.80227 (* 1 = 6.80227 loss)
I1201 00:10:20.551542   125 sgd_solver.cpp:180] [0.0] Iteration 32604, lr = 1.57361e-06, m = 0.9, lrm = 1.57361e-05, wd = 2.5e-07, gs = 1
I1201 00:10:24.951424   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:10:25.063127   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:10:25.920779   125 solver.cpp:333]     [0.0] Iteration 32648 (8.19471 iter/s, 5.36931s/44 iter), 90.9/100ep, loss = 5.44862
I1201 00:10:25.920819   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.563448 (* 2 = 1.1269 loss)
I1201 00:10:25.920831   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.32169 (* 1 = 4.32169 loss)
I1201 00:10:25.920843   125 sgd_solver.cpp:180] [0.0] Iteration 32648, lr = 1.56775e-06, m = 0.9, lrm = 1.56775e-05, wd = 2.5e-07, gs = 1
I1201 00:10:28.354857   125 solver.cpp:501] Iteration 32669, Testing net (#0)
I1201 00:10:41.491463   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:10:41.606189   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:10:45.503372   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.495062 (* 2 = 0.990123 loss)
I1201 00:10:45.503455   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.78621 (* 1 = 8.78621 loss)
I1201 00:10:45.503464   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.8191
I1201 00:10:45.503474   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.4931
I1201 00:10:45.503480   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 53.1556
I1201 00:10:45.503515   125 solver.cpp:271] Tests completed in 19.5829s
I1201 00:10:48.429730   125 solver.cpp:333]     [0.0] Iteration 32692 (2.24686 iter/s, 19.5829s/44 iter), 91.1/100ep, loss = 5.59946
I1201 00:10:48.429775   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.427082 (* 2 = 0.854164 loss)
I1201 00:10:48.429786   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.74527 (* 1 = 4.74527 loss)
I1201 00:10:48.429798   125 sgd_solver.cpp:180] [0.0] Iteration 32692, lr = 1.56191e-06, m = 0.9, lrm = 1.56191e-05, wd = 2.5e-07, gs = 1
I1201 00:10:53.789503   125 solver.cpp:333]     [0.0] Iteration 32736 (8.20929 iter/s, 5.35978s/44 iter), 91.2/100ep, loss = 3.9365
I1201 00:10:53.789543   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.225422 (* 2 = 0.450844 loss)
I1201 00:10:53.789554   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.48562 (* 1 = 3.48562 loss)
I1201 00:10:53.789564   125 sgd_solver.cpp:180] [0.0] Iteration 32736, lr = 1.55609e-06, m = 0.9, lrm = 1.55609e-05, wd = 2.5e-07, gs = 1
I1201 00:10:59.148766   125 solver.cpp:333]     [0.0] Iteration 32780 (8.21005 iter/s, 5.35929s/44 iter), 91.3/100ep, loss = 7.14877
I1201 00:10:59.148819   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.59189 (* 2 = 3.18377 loss)
I1201 00:10:59.148840   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.96497 (* 1 = 3.96497 loss)
I1201 00:10:59.148859   125 sgd_solver.cpp:180] [0.0] Iteration 32780, lr = 1.55029e-06, m = 0.9, lrm = 1.55029e-05, wd = 2.5e-07, gs = 1
I1201 00:11:04.515812   125 solver.cpp:333]     [0.0] Iteration 32824 (8.19813 iter/s, 5.36708s/44 iter), 91.4/100ep, loss = 6.63205
I1201 00:11:04.515853   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.532858 (* 2 = 1.06572 loss)
I1201 00:11:04.515864   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.5663 (* 1 = 5.5663 loss)
I1201 00:11:04.515875   125 sgd_solver.cpp:180] [0.0] Iteration 32824, lr = 1.54452e-06, m = 0.9, lrm = 1.54452e-05, wd = 2.5e-07, gs = 1
I1201 00:11:09.877993   125 solver.cpp:333]     [0.0] Iteration 32868 (8.20559 iter/s, 5.3622s/44 iter), 91.6/100ep, loss = 7.73552
I1201 00:11:09.878033   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.555068 (* 2 = 1.11014 loss)
I1201 00:11:09.878044   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.62535 (* 1 = 6.62535 loss)
I1201 00:11:09.878056   125 sgd_solver.cpp:180] [0.0] Iteration 32868, lr = 1.53876e-06, m = 0.9, lrm = 1.53876e-05, wd = 2.5e-07, gs = 1
I1201 00:11:15.241034   125 solver.cpp:333]     [0.0] Iteration 32912 (8.20427 iter/s, 5.36306s/44 iter), 91.7/100ep, loss = 3.38067
I1201 00:11:15.241075   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.553749 (* 2 = 1.1075 loss)
I1201 00:11:15.241086   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.27314 (* 1 = 2.27314 loss)
I1201 00:11:15.241097   125 sgd_solver.cpp:180] [0.0] Iteration 32912, lr = 1.53303e-06, m = 0.9, lrm = 1.53303e-05, wd = 2.5e-07, gs = 1
I1201 00:11:20.596156   125 solver.cpp:333]     [0.0] Iteration 32956 (8.21637 iter/s, 5.35516s/44 iter), 91.8/100ep, loss = 15.3408
I1201 00:11:20.596331   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 2.0291 (* 2 = 4.05821 loss)
I1201 00:11:20.596345   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 11.2825 (* 1 = 11.2825 loss)
I1201 00:11:20.596357   125 sgd_solver.cpp:180] [0.0] Iteration 32956, lr = 1.52732e-06, m = 0.9, lrm = 1.52732e-05, wd = 2.5e-07, gs = 1
I1201 00:11:25.960295   125 solver.cpp:333]     [0.0] Iteration 33000 (8.20259 iter/s, 5.36416s/44 iter), 91.9/100ep, loss = 5.59444
I1201 00:11:25.960338   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.426182 (* 2 = 0.852364 loss)
I1201 00:11:25.960348   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.74204 (* 1 = 4.74204 loss)
I1201 00:11:25.960358   125 sgd_solver.cpp:180] [0.0] Iteration 33000, lr = 1.52163e-06, m = 0.9, lrm = 1.52163e-05, wd = 2.5e-07, gs = 1
I1201 00:11:25.965358   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:11:26.082926   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:11:29.252339   125 solver.cpp:501] Iteration 33028, Testing net (#0)
I1201 00:11:42.204066   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:11:42.357079   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:11:46.328863   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.491376 (* 2 = 0.982751 loss)
I1201 00:11:46.328903   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.79523 (* 1 = 8.79523 loss)
I1201 00:11:46.328912   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.8046
I1201 00:11:46.328919   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.9514
I1201 00:11:46.328927   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 53.4513
I1201 00:11:46.328963   125 solver.cpp:271] Tests completed in 20.3688s
I1201 00:11:48.399175   125 solver.cpp:333]     [0.0] Iteration 33044 (2.16016 iter/s, 20.3688s/44 iter), 92/100ep, loss = 4.50278
I1201 00:11:48.399215   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.431907 (* 2 = 0.863815 loss)
I1201 00:11:48.399226   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.63893 (* 1 = 3.63893 loss)
I1201 00:11:48.399238   125 sgd_solver.cpp:180] [0.0] Iteration 33044, lr = 1.51596e-06, m = 0.9, lrm = 1.51596e-05, wd = 2.5e-07, gs = 1
I1201 00:11:53.767282   125 solver.cpp:333]     [0.0] Iteration 33088 (8.19652 iter/s, 5.36813s/44 iter), 92.2/100ep, loss = 5.23748
I1201 00:11:53.767447   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.654416 (* 2 = 1.30883 loss)
I1201 00:11:53.767462   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.92861 (* 1 = 3.92861 loss)
I1201 00:11:53.767474   125 sgd_solver.cpp:180] [0.0] Iteration 33088, lr = 1.51032e-06, m = 0.9, lrm = 1.51031e-05, wd = 2.5e-07, gs = 1
I1201 00:11:59.130487   125 solver.cpp:333]     [0.0] Iteration 33132 (8.20403 iter/s, 5.36322s/44 iter), 92.3/100ep, loss = 5.44634
I1201 00:11:59.130525   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.923352 (* 2 = 1.8467 loss)
I1201 00:11:59.130538   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.5996 (* 1 = 3.5996 loss)
I1201 00:11:59.130549   125 sgd_solver.cpp:180] [0.0] Iteration 33132, lr = 1.50469e-06, m = 0.9, lrm = 1.50469e-05, wd = 2.5e-07, gs = 1
I1201 00:12:04.498675   125 solver.cpp:333]     [0.0] Iteration 33176 (8.19639 iter/s, 5.36821s/44 iter), 92.4/100ep, loss = 7.67241
I1201 00:12:04.498718   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.98306 (* 2 = 1.96612 loss)
I1201 00:12:04.498728   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.70626 (* 1 = 5.70626 loss)
I1201 00:12:04.498740   125 sgd_solver.cpp:180] [0.0] Iteration 33176, lr = 1.49908e-06, m = 0.9, lrm = 1.49908e-05, wd = 2.5e-07, gs = 1
I1201 00:12:09.854140   125 solver.cpp:333]     [0.0] Iteration 33220 (8.21589 iter/s, 5.35548s/44 iter), 92.5/100ep, loss = 4.02874
I1201 00:12:09.854182   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.25688 (* 2 = 0.513759 loss)
I1201 00:12:09.854193   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.51495 (* 1 = 3.51495 loss)
I1201 00:12:09.854204   125 sgd_solver.cpp:180] [0.0] Iteration 33220, lr = 1.4935e-06, m = 0.9, lrm = 1.4935e-05, wd = 2.5e-07, gs = 1
I1201 00:12:15.204481   125 solver.cpp:333]     [0.0] Iteration 33264 (8.22373 iter/s, 5.35037s/44 iter), 92.7/100ep, loss = 7.66639
I1201 00:12:15.204521   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.559017 (* 2 = 1.11803 loss)
I1201 00:12:15.204532   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.54832 (* 1 = 6.54832 loss)
I1201 00:12:15.204543   125 sgd_solver.cpp:180] [0.0] Iteration 33264, lr = 1.48794e-06, m = 0.9, lrm = 1.48794e-05, wd = 2.5e-07, gs = 1
I1201 00:12:20.560281   125 solver.cpp:333]     [0.0] Iteration 33308 (8.21535 iter/s, 5.35583s/44 iter), 92.8/100ep, loss = 2.96226
I1201 00:12:20.560322   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.467906 (* 2 = 0.935812 loss)
I1201 00:12:20.560333   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.02642 (* 1 = 2.02642 loss)
I1201 00:12:20.560344   125 sgd_solver.cpp:180] [0.0] Iteration 33308, lr = 1.48239e-06, m = 0.9, lrm = 1.48239e-05, wd = 2.5e-07, gs = 1
I1201 00:12:25.916258   125 solver.cpp:333]     [0.0] Iteration 33352 (8.2151 iter/s, 5.35599s/44 iter), 92.9/100ep, loss = 6.8893
I1201 00:12:25.916386   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.37505 (* 2 = 2.7501 loss)
I1201 00:12:25.916399   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.13917 (* 1 = 4.13917 loss)
I1201 00:12:25.916410   125 sgd_solver.cpp:180] [0.0] Iteration 33352, lr = 1.47687e-06, m = 0.9, lrm = 1.47687e-05, wd = 2.5e-07, gs = 1
I1201 00:12:26.531002   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:12:26.648732   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:12:30.058293   125 solver.cpp:501] Iteration 33387, Testing net (#0)
I1201 00:12:43.023669   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:12:43.135056   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:12:47.102233   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.491692 (* 2 = 0.983384 loss)
I1201 00:12:47.102273   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.77598 (* 1 = 8.77598 loss)
I1201 00:12:47.102283   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.2495
I1201 00:12:47.102290   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 27.7128
I1201 00:12:47.102296   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 52.7951
I1201 00:12:47.102332   125 solver.cpp:271] Tests completed in 21.1863s
I1201 00:12:48.337695   125 solver.cpp:333]     [0.0] Iteration 33396 (2.07682 iter/s, 21.1863s/44 iter), 93/100ep, loss = 5.42812
I1201 00:12:48.337754   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.427591 (* 2 = 0.855182 loss)
I1201 00:12:48.337770   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.5729 (* 1 = 4.5729 loss)
I1201 00:12:48.337788   125 sgd_solver.cpp:180] [0.0] Iteration 33396, lr = 1.47137e-06, m = 0.9, lrm = 1.47137e-05, wd = 2.5e-07, gs = 1
I1201 00:12:53.769060   125 solver.cpp:333]     [0.0] Iteration 33440 (8.10103 iter/s, 5.43141s/44 iter), 93.1/100ep, loss = 7.94514
I1201 00:12:53.769098   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.14815 (* 2 = 2.2963 loss)
I1201 00:12:53.769109   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.6488 (* 1 = 5.6488 loss)
I1201 00:12:53.769120   125 sgd_solver.cpp:180] [0.0] Iteration 33440, lr = 1.46589e-06, m = 0.9, lrm = 1.46589e-05, wd = 2.5e-07, gs = 1
I1201 00:12:59.222910   125 solver.cpp:333]     [0.0] Iteration 33484 (8.06769 iter/s, 5.45386s/44 iter), 93.3/100ep, loss = 3.54948
I1201 00:12:59.223080   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.279422 (* 2 = 0.558844 loss)
I1201 00:12:59.223093   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.9906 (* 1 = 2.9906 loss)
I1201 00:12:59.223105   125 sgd_solver.cpp:180] [0.0] Iteration 33484, lr = 1.46043e-06, m = 0.9, lrm = 1.46043e-05, wd = 2.5e-07, gs = 1
I1201 00:13:04.611441   125 solver.cpp:333]     [0.0] Iteration 33528 (8.16543 iter/s, 5.38857s/44 iter), 93.4/100ep, loss = 10.7996
I1201 00:13:04.611485   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.980468 (* 2 = 1.96094 loss)
I1201 00:13:04.611496   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.83859 (* 1 = 8.83859 loss)
I1201 00:13:04.611508   125 sgd_solver.cpp:180] [0.0] Iteration 33528, lr = 1.45499e-06, m = 0.9, lrm = 1.45499e-05, wd = 2.5e-07, gs = 1
I1201 00:13:09.968801   125 solver.cpp:333]     [0.0] Iteration 33572 (8.213 iter/s, 5.35736s/44 iter), 93.5/100ep, loss = 9.44979
I1201 00:13:09.968842   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.44668 (* 2 = 2.89336 loss)
I1201 00:13:09.968852   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.55639 (* 1 = 6.55639 loss)
I1201 00:13:09.968865   125 sgd_solver.cpp:180] [0.0] Iteration 33572, lr = 1.44957e-06, m = 0.9, lrm = 1.44957e-05, wd = 2.5e-07, gs = 1
I1201 00:13:15.319061   125 solver.cpp:333]     [0.0] Iteration 33616 (8.22385 iter/s, 5.35029s/44 iter), 93.6/100ep, loss = 5.51245
I1201 00:13:15.319103   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.428912 (* 2 = 0.857825 loss)
I1201 00:13:15.319113   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.6546 (* 1 = 4.6546 loss)
I1201 00:13:15.319126   125 sgd_solver.cpp:180] [0.0] Iteration 33616, lr = 1.44417e-06, m = 0.9, lrm = 1.44417e-05, wd = 2.5e-07, gs = 1
I1201 00:13:20.670990   125 solver.cpp:333]     [0.0] Iteration 33660 (8.2213 iter/s, 5.35195s/44 iter), 93.8/100ep, loss = 8.11538
I1201 00:13:20.671032   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.422864 (* 2 = 0.845729 loss)
I1201 00:13:20.671042   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 7.26962 (* 1 = 7.26962 loss)
I1201 00:13:20.671056   125 sgd_solver.cpp:180] [0.0] Iteration 33660, lr = 1.43879e-06, m = 0.9, lrm = 1.43879e-05, wd = 2.5e-07, gs = 1
I1201 00:13:26.028486   125 solver.cpp:333]     [0.0] Iteration 33704 (8.21278 iter/s, 5.3575s/44 iter), 93.9/100ep, loss = 4.54096
I1201 00:13:26.028530   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.369553 (* 2 = 0.739105 loss)
I1201 00:13:26.028540   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.80182 (* 1 = 3.80182 loss)
I1201 00:13:26.028554   125 sgd_solver.cpp:180] [0.0] Iteration 33704, lr = 1.43343e-06, m = 0.9, lrm = 1.43343e-05, wd = 2.5e-07, gs = 1
I1201 00:13:27.614470   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:13:27.726120   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:13:31.018975   125 solver.cpp:501] Iteration 33746, Testing net (#0)
I1201 00:13:44.033190   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:13:44.184720   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:13:48.269265   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.492392 (* 2 = 0.984785 loss)
I1201 00:13:48.269304   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.79288 (* 1 = 8.79288 loss)
I1201 00:13:48.269313   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.4435
I1201 00:13:48.269321   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.8136
I1201 00:13:48.269327   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 52.9613
I1201 00:13:48.269361   125 solver.cpp:271] Tests completed in 22.2411s
I1201 00:13:48.637596   125 solver.cpp:333]     [0.0] Iteration 33748 (1.97832 iter/s, 22.2411s/44 iter), 94/100ep, loss = 4.57431
I1201 00:13:48.637637   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.604966 (* 2 = 1.20993 loss)
I1201 00:13:48.637648   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.36435 (* 1 = 3.36435 loss)
I1201 00:13:48.637660   125 sgd_solver.cpp:180] [0.0] Iteration 33748, lr = 1.42809e-06, m = 0.9, lrm = 1.42809e-05, wd = 2.5e-07, gs = 1
I1201 00:13:53.992041   125 solver.cpp:333]     [0.0] Iteration 33792 (8.21744 iter/s, 5.35446s/44 iter), 94.1/100ep, loss = 4.22399
I1201 00:13:53.992082   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.447576 (* 2 = 0.895152 loss)
I1201 00:13:53.992092   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.3288 (* 1 = 3.3288 loss)
I1201 00:13:53.992103   125 sgd_solver.cpp:180] [0.0] Iteration 33792, lr = 1.42277e-06, m = 0.9, lrm = 1.42277e-05, wd = 2.5e-07, gs = 1
I1201 00:13:59.353353   125 solver.cpp:333]     [0.0] Iteration 33836 (8.20691 iter/s, 5.36134s/44 iter), 94.3/100ep, loss = 3.51751
I1201 00:13:59.353395   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.445885 (* 2 = 0.891769 loss)
I1201 00:13:59.353405   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.62571 (* 1 = 2.62571 loss)
I1201 00:13:59.353416   125 sgd_solver.cpp:180] [0.0] Iteration 33836, lr = 1.41747e-06, m = 0.9, lrm = 1.41747e-05, wd = 2.5e-07, gs = 1
I1201 00:14:04.723489   125 solver.cpp:333]     [0.0] Iteration 33880 (8.19343 iter/s, 5.37016s/44 iter), 94.4/100ep, loss = 10.2934
I1201 00:14:04.723640   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.617211 (* 2 = 1.23442 loss)
I1201 00:14:04.723654   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.05894 (* 1 = 9.05894 loss)
I1201 00:14:04.723666   125 sgd_solver.cpp:180] [0.0] Iteration 33880, lr = 1.41219e-06, m = 0.9, lrm = 1.41219e-05, wd = 2.5e-07, gs = 1
I1201 00:14:10.084427   125 solver.cpp:333]     [0.0] Iteration 33924 (8.20749 iter/s, 5.36095s/44 iter), 94.5/100ep, loss = 6.35221
I1201 00:14:10.084468   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.67119 (* 2 = 1.34238 loss)
I1201 00:14:10.084480   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.0098 (* 1 = 5.0098 loss)
I1201 00:14:10.084491   125 sgd_solver.cpp:180] [0.0] Iteration 33924, lr = 1.40693e-06, m = 0.9, lrm = 1.40693e-05, wd = 2.5e-07, gs = 1
I1201 00:14:15.443122   125 solver.cpp:333]     [0.0] Iteration 33968 (8.21091 iter/s, 5.35872s/44 iter), 94.6/100ep, loss = 4.17307
I1201 00:14:15.443164   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.360916 (* 2 = 0.721833 loss)
I1201 00:14:15.443174   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.45121 (* 1 = 3.45121 loss)
I1201 00:14:15.443186   125 sgd_solver.cpp:180] [0.0] Iteration 33968, lr = 1.40169e-06, m = 0.9, lrm = 1.40169e-05, wd = 2.5e-07, gs = 1
I1201 00:14:20.796484   125 solver.cpp:333]     [0.0] Iteration 34012 (8.21912 iter/s, 5.35337s/44 iter), 94.7/100ep, loss = 5.15405
I1201 00:14:20.796524   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.445746 (* 2 = 0.891492 loss)
I1201 00:14:20.796535   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.26253 (* 1 = 4.26253 loss)
I1201 00:14:20.796545   125 sgd_solver.cpp:180] [0.0] Iteration 34012, lr = 1.39646e-06, m = 0.9, lrm = 1.39646e-05, wd = 2.5e-07, gs = 1
I1201 00:14:26.160392   125 solver.cpp:333]     [0.0] Iteration 34056 (8.20293 iter/s, 5.36393s/44 iter), 94.9/100ep, loss = 7.16255
I1201 00:14:26.160430   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.462447 (* 2 = 0.924894 loss)
I1201 00:14:26.160440   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.23763 (* 1 = 6.23763 loss)
I1201 00:14:26.160452   125 sgd_solver.cpp:180] [0.0] Iteration 34056, lr = 1.39126e-06, m = 0.9, lrm = 1.39126e-05, wd = 2.5e-07, gs = 1
I1201 00:14:28.722287   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:14:28.838109   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:14:31.517915   125 solver.cpp:333]     [0.0] Iteration 34100 (8.2127 iter/s, 5.35755s/44 iter), 95/100ep, loss = 6.79801
I1201 00:14:31.517956   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.75444 (* 2 = 1.50888 loss)
I1201 00:14:31.517967   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.2891 (* 1 = 5.2891 loss)
I1201 00:14:31.517978   125 sgd_solver.cpp:180] [0.0] Iteration 34100, lr = 1.38608e-06, m = 0.9, lrm = 1.38608e-05, wd = 2.5e-07, gs = 1
I1201 00:14:32.006677   125 solver.cpp:501] Iteration 34105, Testing net (#0)
I1201 00:14:37.411968   148 blocking_queue.cpp:40] Data layer prefetch queue empty
I1201 00:14:44.948494   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:14:45.061256   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:14:49.123234   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.492772 (* 2 = 0.985545 loss)
I1201 00:14:49.123272   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.87474 (* 1 = 8.87474 loss)
I1201 00:14:49.123281   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 20.1803
I1201 00:14:49.123289   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 29.6754
I1201 00:14:49.123296   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.6228
I1201 00:14:49.123329   125 solver.cpp:271] Tests completed in 17.6056s
I1201 00:14:54.049409   125 solver.cpp:333]     [0.0] Iteration 34144 (2.49921 iter/s, 17.6056s/44 iter), 95.1/100ep, loss = 6.4974
I1201 00:14:54.049449   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.718289 (* 2 = 1.43658 loss)
I1201 00:14:54.049461   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.06079 (* 1 = 5.06079 loss)
I1201 00:14:54.049473   125 sgd_solver.cpp:180] [0.0] Iteration 34144, lr = 1.38092e-06, m = 0.9, lrm = 1.38092e-05, wd = 2.5e-07, gs = 1
I1201 00:14:59.481214   125 solver.cpp:333]     [0.0] Iteration 34188 (8.1004 iter/s, 5.43183s/44 iter), 95.2/100ep, loss = 5.32856
I1201 00:14:59.481253   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.850263 (* 2 = 1.70053 loss)
I1201 00:14:59.481264   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.62801 (* 1 = 3.62801 loss)
I1201 00:14:59.481276   125 sgd_solver.cpp:180] [0.0] Iteration 34188, lr = 1.37577e-06, m = 0.9, lrm = 1.37577e-05, wd = 2.5e-07, gs = 1
I1201 00:15:04.827090   125 solver.cpp:333]     [0.0] Iteration 34232 (8.23062 iter/s, 5.34589s/44 iter), 95.4/100ep, loss = 7.18717
I1201 00:15:04.827129   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.421168 (* 2 = 0.842335 loss)
I1201 00:15:04.827139   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.34481 (* 1 = 6.34481 loss)
I1201 00:15:04.827149   125 sgd_solver.cpp:180] [0.0] Iteration 34232, lr = 1.37065e-06, m = 0.9, lrm = 1.37065e-05, wd = 2.5e-07, gs = 1
I1201 00:15:10.264045   125 solver.cpp:333]     [0.0] Iteration 34276 (8.09272 iter/s, 5.43699s/44 iter), 95.5/100ep, loss = 5.39598
I1201 00:15:10.264230   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.383081 (* 2 = 0.766163 loss)
I1201 00:15:10.264243   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.62979 (* 1 = 4.62979 loss)
I1201 00:15:10.264256   125 sgd_solver.cpp:180] [0.0] Iteration 34276, lr = 1.36554e-06, m = 0.9, lrm = 1.36554e-05, wd = 2.5e-07, gs = 1
I1201 00:15:15.714244   125 solver.cpp:333]     [0.0] Iteration 34320 (8.07307 iter/s, 5.45022s/44 iter), 95.6/100ep, loss = 8.14916
I1201 00:15:15.714298   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.92944 (* 2 = 1.85888 loss)
I1201 00:15:15.714314   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.29025 (* 1 = 6.29025 loss)
I1201 00:15:15.714332   125 sgd_solver.cpp:180] [0.0] Iteration 34320, lr = 1.36045e-06, m = 0.9, lrm = 1.36045e-05, wd = 2.5e-07, gs = 1
I1201 00:15:21.114292   125 solver.cpp:333]     [0.0] Iteration 34364 (8.14804 iter/s, 5.40007s/44 iter), 95.7/100ep, loss = 3.2518
I1201 00:15:21.114334   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.44275 (* 2 = 0.885499 loss)
I1201 00:15:21.114346   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.36627 (* 1 = 2.36627 loss)
I1201 00:15:21.114356   125 sgd_solver.cpp:180] [0.0] Iteration 34364, lr = 1.35539e-06, m = 0.9, lrm = 1.35539e-05, wd = 2.5e-07, gs = 1
I1201 00:15:26.458425   125 solver.cpp:333]     [0.0] Iteration 34408 (8.23328 iter/s, 5.34416s/44 iter), 95.8/100ep, loss = 5.07865
I1201 00:15:26.458464   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.330157 (* 2 = 0.660315 loss)
I1201 00:15:26.458474   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.4183 (* 1 = 4.4183 loss)
I1201 00:15:26.458484   125 sgd_solver.cpp:180] [0.0] Iteration 34408, lr = 1.35034e-06, m = 0.9, lrm = 1.35034e-05, wd = 2.5e-07, gs = 1
I1201 00:15:29.617969   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:15:29.737496   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:15:31.796787   125 solver.cpp:333]     [0.0] Iteration 34452 (8.2422 iter/s, 5.33838s/44 iter), 96/100ep, loss = 11.926
I1201 00:15:31.796828   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.637105 (* 2 = 1.27421 loss)
I1201 00:15:31.796840   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 10.6517 (* 1 = 10.6517 loss)
I1201 00:15:31.796852   125 sgd_solver.cpp:180] [0.0] Iteration 34452, lr = 1.34531e-06, m = 0.9, lrm = 1.34531e-05, wd = 2.5e-07, gs = 1
I1201 00:15:33.134469   125 solver.cpp:501] Iteration 34464, Testing net (#0)
I1201 00:15:47.695008   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:15:47.868921   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:15:52.434080   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.494827 (* 2 = 0.989654 loss)
I1201 00:15:52.434121   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.7746 (* 1 = 8.7746 loss)
I1201 00:15:52.434130   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.2552
I1201 00:15:52.434139   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.5773
I1201 00:15:52.434145   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 52.6719
I1201 00:15:52.434180   125 solver.cpp:271] Tests completed in 20.6376s
I1201 00:15:56.466625   125 solver.cpp:333]     [0.0] Iteration 34496 (2.13204 iter/s, 20.6376s/44 iter), 96.1/100ep, loss = 9.93222
I1201 00:15:56.466670   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.70406 (* 2 = 1.40812 loss)
I1201 00:15:56.466681   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.52407 (* 1 = 8.52407 loss)
I1201 00:15:56.466692   125 sgd_solver.cpp:180] [0.0] Iteration 34496, lr = 1.3403e-06, m = 0.9, lrm = 1.3403e-05, wd = 2.5e-07, gs = 1
I1201 00:16:01.813637   125 solver.cpp:333]     [0.0] Iteration 34540 (8.22887 iter/s, 5.34703s/44 iter), 96.2/100ep, loss = 7.56469
I1201 00:16:01.813679   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.600849 (* 2 = 1.2017 loss)
I1201 00:16:01.813690   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.36296 (* 1 = 6.36296 loss)
I1201 00:16:01.813702   125 sgd_solver.cpp:180] [0.0] Iteration 34540, lr = 1.3353e-06, m = 0.9, lrm = 1.3353e-05, wd = 2.5e-07, gs = 1
I1201 00:16:07.153790   125 solver.cpp:333]     [0.0] Iteration 34584 (8.23942 iter/s, 5.34018s/44 iter), 96.3/100ep, loss = 6.75128
I1201 00:16:07.153829   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.564548 (* 2 = 1.1291 loss)
I1201 00:16:07.153841   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.62215 (* 1 = 5.62215 loss)
I1201 00:16:07.153851   125 sgd_solver.cpp:180] [0.0] Iteration 34584, lr = 1.33033e-06, m = 0.9, lrm = 1.33033e-05, wd = 2.5e-07, gs = 1
I1201 00:16:12.498073   125 solver.cpp:333]     [0.0] Iteration 34628 (8.23306 iter/s, 5.34431s/44 iter), 96.5/100ep, loss = 8.17355
I1201 00:16:12.498116   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.823933 (* 2 = 1.64787 loss)
I1201 00:16:12.498126   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.52565 (* 1 = 6.52565 loss)
I1201 00:16:12.498136   125 sgd_solver.cpp:180] [0.0] Iteration 34628, lr = 1.32537e-06, m = 0.9, lrm = 1.32537e-05, wd = 2.5e-07, gs = 1
I1201 00:16:17.843482   125 solver.cpp:333]     [0.0] Iteration 34672 (8.23134 iter/s, 5.34542s/44 iter), 96.6/100ep, loss = 7.15376
I1201 00:16:17.843645   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.533744 (* 2 = 1.06749 loss)
I1201 00:16:17.843658   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.08624 (* 1 = 6.08624 loss)
I1201 00:16:17.843669   125 sgd_solver.cpp:180] [0.0] Iteration 34672, lr = 1.32044e-06, m = 0.9, lrm = 1.32044e-05, wd = 2.5e-07, gs = 1
I1201 00:16:23.183480   125 solver.cpp:333]     [0.0] Iteration 34716 (8.23966 iter/s, 5.34002s/44 iter), 96.7/100ep, loss = 4.48258
I1201 00:16:23.183521   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.496042 (* 2 = 0.992083 loss)
I1201 00:16:23.183531   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.49046 (* 1 = 3.49046 loss)
I1201 00:16:23.183542   125 sgd_solver.cpp:180] [0.0] Iteration 34716, lr = 1.31552e-06, m = 0.9, lrm = 1.31552e-05, wd = 2.5e-07, gs = 1
I1201 00:16:28.525490   125 solver.cpp:333]     [0.0] Iteration 34760 (8.23657 iter/s, 5.34203s/44 iter), 96.8/100ep, loss = 4.65552
I1201 00:16:28.525530   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.391705 (* 2 = 0.783411 loss)
I1201 00:16:28.525542   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.87208 (* 1 = 3.87208 loss)
I1201 00:16:28.525552   125 sgd_solver.cpp:180] [0.0] Iteration 34760, lr = 1.31062e-06, m = 0.9, lrm = 1.31062e-05, wd = 2.5e-07, gs = 1
I1201 00:16:32.659301   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:16:32.769835   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:16:33.869709   125 solver.cpp:333]     [0.0] Iteration 34804 (8.23317 iter/s, 5.34424s/44 iter), 96.9/100ep, loss = 5.8762
I1201 00:16:33.869750   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.487009 (* 2 = 0.974018 loss)
I1201 00:16:33.869760   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.90216 (* 1 = 4.90216 loss)
I1201 00:16:33.869771   125 sgd_solver.cpp:180] [0.0] Iteration 34804, lr = 1.30573e-06, m = 0.9, lrm = 1.30573e-05, wd = 2.5e-07, gs = 1
I1201 00:16:36.055550   125 solver.cpp:501] Iteration 34823, Testing net (#0)
I1201 00:16:48.939800   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:16:49.055721   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:16:53.258895   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.489678 (* 2 = 0.979357 loss)
I1201 00:16:53.258937   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.76034 (* 1 = 8.76034 loss)
I1201 00:16:53.258945   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 20.2303
I1201 00:16:53.258954   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.6134
I1201 00:16:53.258961   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 54.6749
I1201 00:16:53.258996   125 solver.cpp:271] Tests completed in 19.3894s
I1201 00:16:56.418203   125 solver.cpp:333]     [0.0] Iteration 34848 (2.26928 iter/s, 19.3894s/44 iter), 97.1/100ep, loss = 4.81362
I1201 00:16:56.418242   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.420143 (* 2 = 0.840286 loss)
I1201 00:16:56.418253   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.97331 (* 1 = 3.97331 loss)
I1201 00:16:56.418264   125 sgd_solver.cpp:180] [0.0] Iteration 34848, lr = 1.30087e-06, m = 0.9, lrm = 1.30087e-05, wd = 2.5e-07, gs = 1
I1201 00:17:01.761373   125 solver.cpp:333]     [0.0] Iteration 34892 (8.23479 iter/s, 5.34318s/44 iter), 97.2/100ep, loss = 14.1739
I1201 00:17:01.761411   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 3.02764 (* 2 = 6.05527 loss)
I1201 00:17:01.761422   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.11864 (* 1 = 8.11864 loss)
I1201 00:17:01.761435   125 sgd_solver.cpp:180] [0.0] Iteration 34892, lr = 1.29602e-06, m = 0.9, lrm = 1.29602e-05, wd = 2.5e-07, gs = 1
I1201 00:17:07.112195   125 solver.cpp:333]     [0.0] Iteration 34936 (8.22301 iter/s, 5.35084s/44 iter), 97.3/100ep, loss = 7.7019
I1201 00:17:07.112234   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.456749 (* 2 = 0.913499 loss)
I1201 00:17:07.112246   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.78837 (* 1 = 6.78837 loss)
I1201 00:17:07.112255   125 sgd_solver.cpp:180] [0.0] Iteration 34936, lr = 1.2912e-06, m = 0.9, lrm = 1.2912e-05, wd = 2.5e-07, gs = 1
I1201 00:17:12.450350   125 solver.cpp:333]     [0.0] Iteration 34980 (8.24251 iter/s, 5.33818s/44 iter), 97.4/100ep, loss = 7.96443
I1201 00:17:12.450392   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.578028 (* 2 = 1.15606 loss)
I1201 00:17:12.450404   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.80834 (* 1 = 6.80834 loss)
I1201 00:17:12.450415   125 sgd_solver.cpp:180] [0.0] Iteration 34980, lr = 1.28639e-06, m = 0.9, lrm = 1.28639e-05, wd = 2.5e-07, gs = 1
I1201 00:17:17.787761   125 solver.cpp:333]     [0.0] Iteration 35024 (8.24366 iter/s, 5.33744s/44 iter), 97.6/100ep, loss = 6.46736
I1201 00:17:17.787799   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.477977 (* 2 = 0.955953 loss)
I1201 00:17:17.787811   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 5.51138 (* 1 = 5.51138 loss)
I1201 00:17:17.787820   125 sgd_solver.cpp:180] [0.0] Iteration 35024, lr = 1.28159e-06, m = 0.9, lrm = 1.28159e-05, wd = 2.5e-07, gs = 1
I1201 00:17:23.131103   125 solver.cpp:333]     [0.0] Iteration 35068 (8.23454 iter/s, 5.34335s/44 iter), 97.7/100ep, loss = 4.70093
I1201 00:17:23.131235   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.876849 (* 2 = 1.7537 loss)
I1201 00:17:23.131249   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.9472 (* 1 = 2.9472 loss)
I1201 00:17:23.131260   125 sgd_solver.cpp:180] [0.0] Iteration 35068, lr = 1.27682e-06, m = 0.9, lrm = 1.27682e-05, wd = 2.5e-07, gs = 1
I1201 00:17:28.468858   125 solver.cpp:333]     [0.0] Iteration 35112 (8.24312 iter/s, 5.33778s/44 iter), 97.8/100ep, loss = 5.60606
I1201 00:17:28.468899   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.676841 (* 2 = 1.35368 loss)
I1201 00:17:28.468911   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.25235 (* 1 = 4.25235 loss)
I1201 00:17:28.468922   125 sgd_solver.cpp:180] [0.0] Iteration 35112, lr = 1.27206e-06, m = 0.9, lrm = 1.27206e-05, wd = 2.5e-07, gs = 1
I1201 00:17:33.565753   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:17:33.683969   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:17:33.803238   125 solver.cpp:333]     [0.0] Iteration 35156 (8.24834 iter/s, 5.3344s/44 iter), 97.9/100ep, loss = 10.3469
I1201 00:17:33.803278   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.666609 (* 2 = 1.33322 loss)
I1201 00:17:33.803289   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 9.01363 (* 1 = 9.01363 loss)
I1201 00:17:33.803301   125 sgd_solver.cpp:180] [0.0] Iteration 35156, lr = 1.26733e-06, m = 0.9, lrm = 1.26732e-05, wd = 2.5e-07, gs = 1
I1201 00:17:36.834389   125 solver.cpp:501] Iteration 35182, Testing net (#0)
I1201 00:17:49.585096   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:17:49.734967   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:17:53.981737   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.49658 (* 2 = 0.993159 loss)
I1201 00:17:53.981899   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.84361 (* 1 = 8.84361 loss)
I1201 00:17:53.981909   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.7694
I1201 00:17:53.981917   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 29.2655
I1201 00:17:53.981923   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 51.6203
I1201 00:17:53.981956   125 solver.cpp:271] Tests completed in 20.1789s
I1201 00:17:56.317778   125 solver.cpp:333]     [0.0] Iteration 35200 (2.1805 iter/s, 20.1789s/44 iter), 98.1/100ep, loss = 6.06292
I1201 00:17:56.317819   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.617211 (* 2 = 1.23442 loss)
I1201 00:17:56.317831   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.82847 (* 1 = 4.82847 loss)
I1201 00:17:56.317843   125 sgd_solver.cpp:180] [0.0] Iteration 35200, lr = 1.2626e-06, m = 0.9, lrm = 1.2626e-05, wd = 2.5e-07, gs = 1
I1201 00:18:01.769938   125 solver.cpp:333]     [0.0] Iteration 35244 (8.07014 iter/s, 5.4522s/44 iter), 98.2/100ep, loss = 5.19628
I1201 00:18:01.769979   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.446114 (* 2 = 0.892228 loss)
I1201 00:18:01.769989   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.30402 (* 1 = 4.30402 loss)
I1201 00:18:01.769999   125 sgd_solver.cpp:180] [0.0] Iteration 35244, lr = 1.2579e-06, m = 0.9, lrm = 1.2579e-05, wd = 2.5e-07, gs = 1
I1201 00:18:07.198843   125 solver.cpp:333]     [0.0] Iteration 35288 (8.10476 iter/s, 5.42891s/44 iter), 98.3/100ep, loss = 10.5202
I1201 00:18:07.198886   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.864516 (* 2 = 1.72903 loss)
I1201 00:18:07.198897   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 8.7911 (* 1 = 8.7911 loss)
I1201 00:18:07.198909   125 sgd_solver.cpp:180] [0.0] Iteration 35288, lr = 1.25321e-06, m = 0.9, lrm = 1.25321e-05, wd = 2.5e-07, gs = 1
I1201 00:18:12.589840   125 solver.cpp:333]     [0.0] Iteration 35332 (8.16171 iter/s, 5.39103s/44 iter), 98.4/100ep, loss = 3.35246
I1201 00:18:12.589881   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.301508 (* 2 = 0.603016 loss)
I1201 00:18:12.589891   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.74941 (* 1 = 2.74941 loss)
I1201 00:18:12.589905   125 sgd_solver.cpp:180] [0.0] Iteration 35332, lr = 1.24855e-06, m = 0.9, lrm = 1.24855e-05, wd = 2.5e-07, gs = 1
I1201 00:18:17.938410   125 solver.cpp:333]     [0.0] Iteration 35376 (8.22649 iter/s, 5.34858s/44 iter), 98.5/100ep, loss = 8.38464
I1201 00:18:17.938452   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.718461 (* 2 = 1.43692 loss)
I1201 00:18:17.938463   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.94769 (* 1 = 6.94769 loss)
I1201 00:18:17.938477   125 sgd_solver.cpp:180] [0.0] Iteration 35376, lr = 1.2439e-06, m = 0.9, lrm = 1.24389e-05, wd = 2.5e-07, gs = 1
I1201 00:18:23.274722   125 solver.cpp:333]     [0.0] Iteration 35420 (8.24535 iter/s, 5.33634s/44 iter), 98.7/100ep, loss = 8.2803
I1201 00:18:23.274762   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.00689 (* 2 = 2.01378 loss)
I1201 00:18:23.274772   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.26649 (* 1 = 6.26649 loss)
I1201 00:18:23.274785   125 sgd_solver.cpp:180] [0.0] Iteration 35420, lr = 1.23926e-06, m = 0.9, lrm = 1.23926e-05, wd = 2.5e-07, gs = 1
I1201 00:18:28.611728   125 solver.cpp:333]     [0.0] Iteration 35464 (8.24429 iter/s, 5.33703s/44 iter), 98.8/100ep, loss = 9.02422
I1201 00:18:28.611917   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 1.16799 (* 2 = 2.33598 loss)
I1201 00:18:28.611929   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.68822 (* 1 = 6.68822 loss)
I1201 00:18:28.611943   125 sgd_solver.cpp:180] [0.0] Iteration 35464, lr = 1.23465e-06, m = 0.9, lrm = 1.23464e-05, wd = 2.5e-07, gs = 1
I1201 00:18:33.953236   125 solver.cpp:333]     [0.0] Iteration 35508 (8.23736 iter/s, 5.34152s/44 iter), 98.9/100ep, loss = 4.19925
I1201 00:18:33.953275   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.29082 (* 2 = 0.58164 loss)
I1201 00:18:33.953285   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.61758 (* 1 = 3.61758 loss)
I1201 00:18:33.953297   125 sgd_solver.cpp:180] [0.0] Iteration 35508, lr = 1.23005e-06, m = 0.9, lrm = 1.23005e-05, wd = 2.5e-07, gs = 1
I1201 00:18:34.318923   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:18:34.441545   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:18:37.850337   125 solver.cpp:501] Iteration 35541, Testing net (#0)
I1201 00:18:50.616902   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:18:50.729156   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:18:55.117393   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.488461 (* 2 = 0.976923 loss)
I1201 00:18:55.117466   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.76418 (* 1 = 8.76418 loss)
I1201 00:18:55.117491   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 20.5983
I1201 00:18:55.117511   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 29.1933
I1201 00:18:55.117530   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 54.5507
I1201 00:18:55.117594   125 solver.cpp:271] Tests completed in 21.1645s
I1201 00:18:56.593658   125 solver.cpp:333]     [0.0] Iteration 35552 (2.07895 iter/s, 21.1645s/44 iter), 99/100ep, loss = 2.981
I1201 00:18:56.593701   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.220508 (* 2 = 0.441016 loss)
I1201 00:18:56.593711   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.53995 (* 1 = 2.53995 loss)
I1201 00:18:56.593722   125 sgd_solver.cpp:180] [0.0] Iteration 35552, lr = 1.22546e-06, m = 0.9, lrm = 1.22546e-05, wd = 2.5e-07, gs = 1
I1201 00:19:01.948302   125 solver.cpp:333]     [0.0] Iteration 35596 (8.21715 iter/s, 5.35465s/44 iter), 99.2/100ep, loss = 5.10575
I1201 00:19:01.948463   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.297725 (* 2 = 0.595451 loss)
I1201 00:19:01.948477   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.51027 (* 1 = 4.51027 loss)
I1201 00:19:01.948488   125 sgd_solver.cpp:180] [0.0] Iteration 35596, lr = 1.2209e-06, m = 0.9, lrm = 1.2209e-05, wd = 2.5e-07, gs = 1
I1201 00:19:07.303441   125 solver.cpp:333]     [0.0] Iteration 35640 (8.21638 iter/s, 5.35515s/44 iter), 99.3/100ep, loss = 2.33225
I1201 00:19:07.303480   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.231771 (* 2 = 0.463542 loss)
I1201 00:19:07.303490   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 1.86867 (* 1 = 1.86867 loss)
I1201 00:19:07.303501   125 sgd_solver.cpp:180] [0.0] Iteration 35640, lr = 1.21635e-06, m = 0.9, lrm = 1.21635e-05, wd = 2.5e-07, gs = 1
I1201 00:19:12.648226   125 solver.cpp:333]     [0.0] Iteration 35684 (8.23229 iter/s, 5.34481s/44 iter), 99.4/100ep, loss = 3.64849
I1201 00:19:12.648267   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.747561 (* 2 = 1.49512 loss)
I1201 00:19:12.648278   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 2.15333 (* 1 = 2.15333 loss)
I1201 00:19:12.648290   125 sgd_solver.cpp:180] [0.0] Iteration 35684, lr = 1.21182e-06, m = 0.9, lrm = 1.21182e-05, wd = 2.5e-07, gs = 1
I1201 00:19:17.984426   125 solver.cpp:333]     [0.0] Iteration 35728 (8.24554 iter/s, 5.33622s/44 iter), 99.5/100ep, loss = 7.43237
I1201 00:19:17.984462   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.607556 (* 2 = 1.21511 loss)
I1201 00:19:17.984473   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.21723 (* 1 = 6.21723 loss)
I1201 00:19:17.984484   125 sgd_solver.cpp:180] [0.0] Iteration 35728, lr = 1.20731e-06, m = 0.9, lrm = 1.20731e-05, wd = 2.5e-07, gs = 1
I1201 00:19:23.323881   125 solver.cpp:333]     [0.0] Iteration 35772 (8.24051 iter/s, 5.33948s/44 iter), 99.6/100ep, loss = 4.06571
I1201 00:19:23.323920   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.231283 (* 2 = 0.462566 loss)
I1201 00:19:23.323930   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 3.60311 (* 1 = 3.60311 loss)
I1201 00:19:23.323941   125 sgd_solver.cpp:180] [0.0] Iteration 35772, lr = 1.20281e-06, m = 0.9, lrm = 1.20281e-05, wd = 2.5e-07, gs = 1
I1201 00:19:28.664531   125 solver.cpp:333]     [0.0] Iteration 35816 (8.23865 iter/s, 5.34068s/44 iter), 99.8/100ep, loss = 6.38546
I1201 00:19:28.664572   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.748569 (* 2 = 1.49714 loss)
I1201 00:19:28.664583   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.88829 (* 1 = 4.88829 loss)
I1201 00:19:28.664595   125 sgd_solver.cpp:180] [0.0] Iteration 35816, lr = 1.19833e-06, m = 0.9, lrm = 1.19833e-05, wd = 2.5e-07, gs = 1
I1201 00:19:34.007597   125 solver.cpp:333]     [0.0] Iteration 35860 (8.23496 iter/s, 5.34307s/44 iter), 99.9/100ep, loss = 5.48533
I1201 00:19:34.007777   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.449215 (* 2 = 0.898429 loss)
I1201 00:19:34.007791   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 4.58687 (* 1 = 4.58687 loss)
I1201 00:19:34.007802   125 sgd_solver.cpp:180] [0.0] Iteration 35860, lr = 1.19386e-06, m = 0.9, lrm = 1.19386e-05, wd = 2.5e-07, gs = 1
I1201 00:19:35.348871   167 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:19:35.464903   169 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:19:38.741865   125 solver.cpp:333]     [0.0] Iteration 35900 (8.23776 iter/s, 4.73429s/39 iter), 100/100ep, loss = 7.7717
I1201 00:19:38.741907   125 solver.cpp:361]     [0.0]     Train net output #0: loss_bbox = 0.505325 (* 2 = 1.01065 loss)
I1201 00:19:38.741919   125 solver.cpp:361]     [0.0]     Train net output #1: loss_coverage = 6.76102 (* 1 = 6.76102 loss)
I1201 00:19:38.741930   125 solver.cpp:769] Snapshotting to binary proto file snapshot_iter_35900.caffemodel
I1201 00:19:38.789085   125 sgd_solver.cpp:419] Snapshotting solver state to binary proto file snapshot_iter_35900.solverstate
I1201 00:19:38.830090   125 solver.cpp:501] Iteration 35900, Testing net (#0)
I1201 00:19:51.909828   152 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:19:52.082814   149 data_reader.cpp:321] Restarting data pre-fetching
I1201 00:19:56.991431   125 solver.cpp:588]     (0.0)    Test net output #0: loss_bbox = 0.487947 (* 2 = 0.975895 loss)
I1201 00:19:56.991468   125 solver.cpp:588]     (0.0)    Test net output #1: loss_coverage = 8.77595 (* 1 = 8.77595 loss)
I1201 00:19:56.991478   125 solver.cpp:588]     (0.0)    Test net output #2: mAP = 19.8302
I1201 00:19:56.991485   125 solver.cpp:588]     (0.0)    Test net output #3: precision = 28.6556
I1201 00:19:56.991492   125 solver.cpp:588]     (0.0)    Test net output #4: recall = 54.4944
I1201 00:19:56.991518   125 caffe.cpp:265] Solver performance on device 0: 6.162 * 10 = 61.62 img/sec (35900 itr in 5825 sec)
I1201 00:19:56.991535   125 caffe.cpp:269] Optimization Done in 1h 42m 19s
